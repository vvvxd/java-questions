
### 1. Фундаментальные концепции (Мастерство на базовом уровне)

**Apache Airflow** — это платформа для программного создания, планирования и мониторинга рабочих процессов (workflows). Она представляет рабочие процессы в виде направленных ациклических графов (DAG) задач. Основная функция Airflow — это оркестрация, то есть управление выполнением задач в правильной последовательности, обработка зависимостей между ними и обеспечение их повторного выполнения в случае сбоев.

---

### 1. DAG (Directed Acyclic Graph)

#### Декларативное определение, а не исполняемый скрипт

Python-файл с определением DAG не является скриптом, который выполняется пошагово для обработки данных. Вместо этого, планировщик Airflow (Scheduler) периодически исполняет этот файл с целью парсинга. Во время парсинга Airflow ищет в глобальной области видимости файла объекты класса `DAG` и `Operator`.

Процесс выглядит так:
1.  **Парсинг:** Scheduler выполняет код в `dag.py`.
2.  **Обнаружение объектов:** Он находит инстанс `DAG` и связанные с ним инстансы операторов (`BashOperator`, `PythonOperator` и т.д.).
3.  **Сериализация в метабазу:** Airflow сохраняет структуру DAG, его параметры и задачи в свою метаданные базу данных. Он записывает определение графа: какие задачи существуют и как они зависят друг от друга.

Сам код, который вы определяете внутри операторов (например, Python-функция для `PythonOperator`), **не выполняется на этапе парсинга**. Он будет выполнен позже, на отдельном процессе (Worker), когда Scheduler решит, что пришло время для запуска конкретного экземпляра задачи (Task Instance).

Таким образом, DAG-файл — это **декларация** структуры и свойств воркфлоу, а не **императивная** инструкция по его немедленному выполнению.

#### Ключевые параметры DAG

Рассмотрим на примере:
```python
from airflow.models.dag import DAG
import pendulum
from datetime import timedelta

with DAG(
    dag_id='technical_dag_definition',
    # Дата, с которой начинаются расчеты интервалов для запуска.
    start_date=pendulum.datetime(2023, 1, 1, tz="UTC"),
    # CRON-выражение для расписания. '0 0 * * *' означает запуск каждый день в 00:00 UTC.
    schedule_interval='@daily',
    # Если True, Airflow создаст и запустит DAG Run'ы для всех пропущенных интервалов с start_date до текущего момента.
    # В проде почти всегда False, чтобы избежать неконтролируемых запусков.
    catchup=False,
    # Ограничивает количество одновременно активных DAG Run'ов для данного DAG'а.
    # Значение 1 гарантирует, что следующий запуск не начнется, пока предыдущий не завершится.
    max_active_runs=1,
    # Метаданные для фильтрации и организации DAG'ов в UI.
    tags=['finance', 'elt'],
    # Время, которое может выполняться весь DAG Run, прежде чем он будет помечен как 'failed'.
    dagrun_timeout=timedelta(hours=2),
) as dag:
    ...
```

#### Разница между логической датой (`logical_date`) и датой запуска

Это фундаментальный концепт для понимания работы Airflow.

*   **Интервал данных (Data Interval):** Период времени, за который обрабатываются данные. Он определяется расписанием (`schedule_interval`). Для `schedule_interval='@daily'`, интервал длится 24 часа.
*   **Логическая дата (`logical_date`):** Это **начало** интервала данных. Она доступна в шаблонах Jinja как `{{ data_interval_start }}` (ранее `execution_date`). Это временная метка, с которой логически ассоциируется данный запуск (DAG Run).
*   **Дата запуска:** Фактическое время, когда Scheduler инициирует DAG Run. По умолчанию, запуск для определенного интервала происходит **сразу после его завершения**.

**Пример:**
*   DAG с `schedule_interval='@daily'` (`0 0 * * *`).
*   Рассмотрим интервал данных: с `2023-10-25 00:00:00` по `2023-10-26 00:00:00`.
*   **Логическая дата** для этого запуска — `2023-10-25 00:00:00`.
*   **Дата запуска** этого DAG Run'а — `2023-10-26 00:00:00`.

Воркфлоу, обрабатывающий данные за 25-е число, стартует 26-го.

---

### 2. Operators, Sensors и Deferrable Operators

#### Operator
*   **Функция:** Выполняет активное действие. Это может быть запуск скрипта, выполнение SQL-запроса, обращение к API.
*   **Механизм работы:** Основная логика содержится в методе `execute(self, context)`. Когда Worker (исполнитель) получает задачу, он вызывает этот метод. Пока метод `execute` не завершится (успешно или с ошибкой), задача занимает рабочий слот Worker'а.
*   **Примеры:** `PythonOperator` (выполняет Python-функцию), `BashOperator` (выполняет shell-команду), `PostgresOperator` (выполняет SQL в PostgreSQL), `GCSToBigQueryOperator` (загружает данные из GCS в BigQuery).

#### Sensor
*   **Функция:** Это подвид оператора, который ожидает выполнения некоторого условия. Он не выполняет активных действий, а периодически проверяет состояние внешней системы.
*   **Механизм работы:** Основная логика содержится в методе `poke(self, context)`. Worker вызывает этот метод с интервалом `poke_interval`. Если `poke` возвращает `True`, сенсор завершается успешно. Если `False`, он "засыпает" на `poke_interval` секунд и затем повторяет проверку.
*   **Проблема:** В "режиме ожидания" сенсор **продолжает занимать рабочий слот Worker'а**, что крайне неэффективно для долгих ожиданий (минуты, часы), так как слот блокируется без выполнения полезной работы.

#### Deferrable Operator (Откладываемый оператор)
*   **Функция:** Решает проблему неэффективности сенсоров. Он также ожидает выполнения условия, но делает это, не занимая рабочий слот.
*   **Механизм работы:**
    1.  Задача запускается на Worker'e и вызывает метод `execute`.
    2.  Внутри `execute` оператор понимает, что нужно перейти в режим ожидания. Он создает "триггер" (специальный объект, описывающий условие пробуждения) и выбрасывает исключение `TaskDeferred`.
    3.  Worker перехватывает это исключение, помечает задачу как `deferred` и **освобождает рабочий слот**.
    4.  Информация о триггере передается в отдельный, легковесный, асинхронный сервис Airflow — **Triggerer**.
    5.  Triggerer асинхронно и эффективно отслеживает сотни таких условий одновременно.
    6.  Когда условие выполняется, Triggerer сообщает Scheduler'у, что задача готова к продолжению.
    7.  Scheduler снова ставит задачу в очередь. Worker забирает её и вызывает второй метод — `execute_complete`, который завершает работу.

---

### 3. Tasks и Task Instances

#### Task
*   **Определение:** Узел в графе DAG. Это **статическое определение** единицы работы. В коде `my_task = PythonOperator(...)`, `my_task` — это Task. Он является шаблоном и существует в единственном экземпляре в рамках определения DAG'а.

#### Task Instance
*   **Определение:** Это **конкретный экземпляр** выполнения Task'а, привязанный к **конкретной логической дате**. Если DAG запускается ежедневно, то для Task'а `my_task` каждый день будет создаваться новый Task Instance: один для `logical_date=2023-10-25`, другой для `logical_date=2023-10-26` и т.д. У каждого Task Instance есть свой жизненный цикл и состояние.

#### Жизненный цикл и состояния Task Instance
1.  **`scheduled`**: Scheduler определил, что все зависимости для этого Task Instance выполнены, и он готов к постановке в очередь.
2.  **`queued`**: Scheduler поместил задачу в очередь сообщений (например, Redis или RabbitMQ), откуда её может забрать Worker.
3.  **`running`**: Worker забрал задачу из очереди и выполняет её метод `execute`.
4.  **`success`**: Метод `execute` завершился без исключений (возвратил 0 для `BashOperator`, не вызвал исключение в `PythonOperator`).
5.  **`failed`**: Метод `execute` завершился с ошибкой, и все доступные попытки (`retries`) исчерпаны.
6.  **`skipped`**: Задача была пропущена. Это происходит, когда вышестоящие (upstream) задачи не были выполнены успешно или когда логика ветвления (например, `BranchPythonOperator`) решила не выполнять эту ветку графа.
7.  **`up_for_retry`**: Задача завершилась с ошибкой, но у нее еще есть попытки для перезапуска. Она будет поставлена в очередь снова после задержки `retry_delay`.

---

### 4. Hooks (Хуки)

*   **Определение:** Низкоуровневые интерфейсы для взаимодействия с внешними системами (базы данных, облачные хранилища, API). Хук инкапсулирует логику аутентификации, установления соединения и выполнения базовых операций.
*   **Назначение:** Хуки предоставляют стандартизированный способ доступа к внешним сервисам. Операторы используют хуки для выполнения своей работы. Например, `PostgresOperator` использует `PostgresHook` для подключения к базе и выполнения SQL.
*   **Преимущество:** Использование хуков напрямую в `PythonOperator` позволяет создавать гибкий и переиспользуемый код. Вместо того чтобы хардкодить логику подключения в своей функции, вы инстанцируете хук, передав ему `conn_id`. Хук сам извлечет необходимые креды из Airflow Connections. Это разделяет вашу бизнес-логику от логики подключения.

---

### 5. Connections & Variables

Это два основных механизма для хранения конфигурации и секретов в Airflow.

#### Connections
*   **Назначение:** Хранение информации для подключения к внешним системам.
*   **Структура:** Это структурированная запись, содержащая поля: `Conn Id`, `Conn Type`, `Host`, `Login`, `Password`, `Port`, `Schema` и `Extra` (JSON-поле для дополнительных параметров).
*   **Использование:** Операторы и хуки используют `Conn Id` для получения настроек подключения.

#### Variables
*   **Назначение:** Хранение произвольной конфигурационной информации в виде пар "ключ-значение".
*   **Структура:** Простое строковое значение, ассоциированное с ключом. Может хранить JSON для более сложных структур.
*   **Использование:** Для хранения путей, имен таблиц, флагов, пороговых значений и т.п. — всего, что не является кредами.

**Разница:** **Connections** — для *доступов*, **Variables** — для *настроек*.

**Способы задания (для обоих):**
1.  **Airflow UI:** Ручное добавление/редактирование.
2.  **Airflow CLI:** `airflow connections add ...`, `airflow variables set ...`.
3.  **Переменные окружения:** Формат `AIRFLOW_CONN_{CONN_ID_UPPERCASE}` и `AIRFLOW_VAR_{VAR_NAME_UPPERCASE}`. Удобно для CI/CD и контейнеризации.
4.  **Secrets Backend (рекомендуется для продакшена):** Интеграция с внешними хранилищами секретов, такими как HashiCorp Vault, AWS Secrets Manager или GCP Secret Manager. Airflow запрашивает секреты "на лету" и не хранит их в своей метабазе.

---

### 6. XComs (Cross-Communications)

*   **Определение:** Механизм для передачи небольших объемов данных между задачами в рамках одного DAG Run'а. XCom (cross-communication) — это, по сути, хранилище "ключ-значение", где каждый объект привязан к `task_id` и `dag_run`.
*   **Механизм работы:**
    *   **Push (отправка):** Задача может явно отправить XCom с помощью метода `ti.xcom_push(key, value)`. `PythonOperator` неявно отправляет XCom со значением, которое вернула его `python_callable` функция (с ключом по умолчанию `return_value`).
    *   **Pull (получение):** Другая задача может получить это значение с помощью `ti.xcom_pull(task_ids='source_task_id', key='some_key')`.

#### Ограничения и правильное использование

*   **Хранение:** XCom'ы по умолчанию хранятся в метаданных базе Airflow (например, в PostgreSQL). Эта база данных оптимизирована для частых, небольших транзакций, а не для хранения больших объемов данных.
*   **Размер:** Существует технический лимит на размер XCom, зависящий от бэкенда (например, ~1 ГБ для Postgres), но **категорически не рекомендуется** приближаться к этому лимиту. Передача даже нескольких мегабайт через XCom может серьезно замедлить работу всей инсталляции Airflow, так как это создает нагрузку на метабазу.
*   **Когда НЕ использовать:** Никогда не передавайте через XCom большие данные: pandas DataFrame, содержимое файлов, большие JSON-ответы от API.
*   **Корректный паттерн использования:**
    1.  Первая задача генерирует большой объем данных (например, CSV-файл).
    2.  Она сохраняет этот файл во внешнее промежуточное хранилище (например, S3, GCS, HDFS или общую файловую систему).
    3.  Через XCom она передает **только указатель** на эти данные — например, путь к файлу (`'s3://my-bucket/temp/data.csv'`).
    4.  Вторая задача получает этот путь из XCom и использует его для чтения данных напрямую из внешнего хранилища.
    
---

### 2. Архитектура и внутреннее устройство (Сердце Airflow)

### 1. Scheduler (Планировщик)
 Это "мозг" и "сердце" всей системы Airflow. Scheduler является долгоживущим процессом (демоном), который отвечает за запуск и управление жизненным циклом всех воркфлоу.

*   **Как работает:** Scheduler выполняет непрерывный цикл, состоящий из нескольких ключевых шагов:
    1.  **Парсинг DAG-файлов:** С определенной периодичностью он сканирует папку с DAG'ами (`dags_folder`). Он исполняет каждый Python-файл, чтобы обнаружить объекты `DAG` и сериализовать их структуру (задачи, зависимости, параметры) в Метабазу.
    2.  **Создание DAG Run'ов:** Для каждого DAG он проверяет его расписание (`schedule_interval`) и последнюю выполненную логическую дату. Если пришло время для нового запуска, он создает запись о новом `DAG Run` в Метабазе со статусом `running`.
    3.  **Постановка Задач в очередь:** Scheduler постоянно опрашивает Метабазу на предмет `Task Instances`, которые готовы к выполнению. Задача считается готовой, если все ее upstream-зависимости (задачи, от которых она зависит) успешно завершились.
    4.  **Отправка Задач Исполнителю:** Как только задача готова, Scheduler меняет ее статус на `scheduled`, а затем на `queued` и передает ее Исполнителю (Executor'у).
    5.  **Heartbeat ("Сердцебиение"):** Scheduler отслеживает запущенные задачи. Worker, выполняющий задачу, периодически отправляет "heartbeat" (обновляет временную метку в Метабазе), сообщая, что он "жив". Если Scheduler не видит обновлений в течение определенного времени (`scheduler.task_queued_timeout` или `scheduler.zombie_detection_interval`), он считает задачу "зомби" (процесс Worker'а мог умереть), помечает ее как `failed` и может попытаться запустить ее заново.

*   **Нюансы:**
    *   `min_file_process_interval`: Этот параметр конфигурации определяет, как часто Scheduler перечитывает каждый DAG-файл. Увеличение этого значения (например, до 60 секунд) снижает нагрузку на CPU Scheduler'а, но увеличивает задержку перед тем, как изменения в коде DAG'а или новые файлы будут обнаружены. Уменьшение значения ускоряет реакцию, но повышает нагрузку.
    *   В инсталляции может быть несколько реплик Scheduler'а (режим High Availability), которые координируют свою работу через Метабазу, чтобы избежать дублирования запусков.

---

### 2. Metadatabase (Метабаза)
 Единственный и абсолютный "источник правды" для всей инсталляции Airflow. Это реляционная база данных, которая хранит все состояния.

*   **Как работает:** Это центральный узел, к которому обращаются все остальные компоненты:
    *   **Scheduler** записывает и читает состояния `DAG Runs` и `Task Instances`.
    *   **Webserver** читает из нее данные для отображения в UI и записывает изменения, инициированные пользователем (например, ручной запуск, очистка состояния задачи).
    *   **Workers** постоянно обновляют в ней статус выполняемых ими задач (`running`, `success`, `failed`) и отправляют "heartbeat".
    *   **В ней хранится:**
        *   Список и структура всех распарсенных DAG'ов.
        *   История всех запусков (`DAG Runs`).
        *   Состояния всех экземпляров задач (`Task Instances`).
        *   **Connections** (информация для подключений, пароли шифруются).
        *   **Variables** (глобальные переменные).
        *   **XComs** (данные для обмена между задачами).
        *   Аудит логов, информация о пользователях и ролях.

*   **Нюансы:**
    *   **SQLite vs Production DB:** SQLite, используемая по умолчанию, хранит базу в одном файле. Она не поддерживает одновременные операции записи от нескольких процессов, что является нормой для Airflow (Scheduler и Webserver пишут одновременно). Поэтому она подходит **только** для локальной разработки и тестирования. В продакшене **необходимо** использовать полноценную СУБД, такую как **PostgreSQL** или **MySQL**, которая способна обрабатывать множество одновременных подключений.
    *   **Производительность:** Метабаза — самое частое узкое место в больших инсталляциях Airflow. Любая задержка в работе с ней (медленные диски, недостаток ресурсов, плохая конфигурация БД) напрямую замедляет всю систему.

---

### 3. Executor (Исполнитель)
 Компонент, который отвечает за **фактический запуск** кода задачи. Scheduler решает, *что* и *когда* запускать, а Executor решает, *как* и *где* это будет запущено. Выбор Executor'а — ключевое архитектурное решение, определяющее масштабируемость и изоляцию.

*   **Типы:**
    *   `LocalExecutor`: Задачи запускаются как дочерние процессы на той же машине, где работает Scheduler.
        *   **Принцип:** Scheduler форкает новый процесс для каждой задачи.
        *   **Плюсы:** Простота настройки.
        *   **Минусы:** Все задачи конкурируют за ресурсы одного сервера. Сбой сервера останавливает всё. Нет масштабирования.
    *   `CeleryExecutor`: Распределенный исполнитель, использующий брокер сообщений.
        *   **Принцип:** Scheduler отправляет задачу в очередь сообщений (например, **RabbitMQ** или **Redis**). Независимые процессы **Celery Workers** на других машинах слушают эту очередь, забирают задачи и выполняют их.
        *   **Плюсы:** Горизонтальное масштабирование (можно добавлять больше машин с Worker'ами для увеличения пропускной способности). Высокая отказоустойчивость.
        *   **Минусы:** Более сложная настройка (требуется развернуть и обслуживать брокер сообщений).
    *   `KubernetesExecutor`: Динамический исполнитель для облачных сред.
        *   **Принцип:** Для каждого `Task Instance` Scheduler через API Kubernetes создает новый **Pod** (микро-контейнер). Код задачи выполняется внутри этого пода, и после завершения под удаляется.
        *   **Плюсы:** Идеальная изоляция зависимостей (каждая задача может иметь свой Docker-образ с нужными библиотеками). Динамическое управление ресурсами (каждой задаче можно выделить точное количество CPU/RAM).
        *   **Минусы:** Требует наличия и знаний Kubernetes. Есть задержка на запуск пода для каждой задачи.
    *   `CeleryKubernetesExecutor`: Гибрид, сочетающий лучшее из двух миров.
        *   **Принцип:** Позволяет указать для каждой задачи, где она должна быть выполнена. Например, легкие и частые задачи можно отправлять в статическую очередь Celery (быстрый запуск), а тяжелые задачи с особыми зависимостями — в динамические поды Kubernetes.
        *   **Плюсы:** Максимальная гибкость.
        *   **Минусы:** Самый сложный в настройке и управлении.

---

### 4. Webserver
 Предоставляет пользовательский интерфейс (UI) для мониторинга, управления и отладки воркфлоу.

*   **Как работает:** Это stateless веб-приложение (на базе Flask), которое:
    *   Читает данные напрямую из **Метабазы**, чтобы отобразить актуальное состояние DAG'ов, запусков и задач.
    *   Позволяет пользователям выполнять действия, которые приводят к записи в **Метабазу** (например, "Trigger DAG", "Clear Task Instance", "Mark as Success/Failed").
    *   Отображает логи задач, которые обычно хранятся в файловой системе или в облачном хранилище (например, S3/GCS).
    *   Предоставляет интерфейс для управления **Connections** и **Variables**.

---

### 5. Triggerer (Новое и важное!)
 Это отдельный, высокоэффективный асинхронный сервис, предназначенный исключительно для работы с **Deferrable Operators** (откладываемыми операторами и сенсорами).

*   **Как работает:**
    1.  Worker начинает выполнять откладываемый оператор (например, сенсор, который ждет появления файла 2 часа).
    2.  Оператор не блокирует Worker'а. Вместо этого он "откладывает" себя: он регистрирует условие для своего пробуждения в **Triggerer'е** и освобождает Worker'а.
    3.  Worker становится свободен для выполнения других задач.
    4.  **Triggerer** в одном асинхронном процессе (`asyncio`) эффективно отслеживает сотни или тысячи таких "ждущих" условий от разных задач.
    5.  Когда условие выполняется (файл появился), Triggerer уведомляет Scheduler.
    6.  Scheduler снова ставит задачу в очередь, чтобы Worker выполнил ее финальную часть.

*   **Нюансы:** Использование Triggerer'а и откладываемых операторов — это современный способ кардинально снизить потребление ресурсов. Вместо того чтобы держать 100 Worker-слотов занятыми для 100 сенсоров, которые просто ждут, вы используете 0 Worker-слотов и один легковесный процесс Triggerer'а. Это позволяет значительно экономить на инфраструктуре.

---

### 3. Продвинутые техники и Best Practices


### Идемпотентность (Idempotency)

*   **Что это?**
    Идемпотентность — это свойство операции, которое гарантирует, что многократное ее выполнение дает тот же результат, что и однократное. В контексте Airflow, это означает, что ваш таск, перезапущенный для той же логической даты, должен приводить систему в то же самое конечное состояние. `f(x) = f(f(f(x)))`.

*   **Почему это ключевой принцип?**
    Сбои в data-pipeline — это не "если", а "когда". Сеть может отказать, API может вернуть ошибку, система может упасть. Airflow позволяет легко перезапускать упавшие таски. Если ваш таск не идемпотентен, каждый перезапуск будет приводить к нежелательным побочным эффектам: дублированию данных, повторной отправке счетов, неверным расчетам.

*   **Как этого достичь (Примеры):**
    Предположим, таск должен вставить данные за `2023-10-25` (`{{ ds }}`).

    *   **Плохо (не идемпотентно):**
        ```sql
        INSERT INTO daily_summary (date, value) SELECT '{{ ds }}', SUM(amount) FROM sales WHERE sale_date = '{{ ds }}';
        ```
        При каждом перезапуске этого таска будет добавляться новая строка для `2023-10-25`, что приведет к дублированию.

    *   **Хорошо (идемпотентно):**
        **Способ 1: Удаление перед вставкой (Delete/Insert)**
        ```sql
        -- В рамках одной транзакции
        DELETE FROM daily_summary WHERE date = '{{ ds }}';
        INSERT INTO daily_summary (date, value) SELECT '{{ ds }}', SUM(amount) FROM sales WHERE sale_date = '{{ ds }}';
        ```
        **Способ 2: Вставка с обновлением при конфликте (UPSERT)**
        ```sql
        -- Для PostgreSQL
        INSERT INTO daily_summary (date, value)
        SELECT '{{ ds }}', SUM(amount) FROM sales WHERE sale_date = '{{ ds }}'
        ON CONFLICT (date) DO UPDATE SET value = EXCLUDED.value;
        ```
    Всегда проектируйте таски так, как будто они могут упасть и будут перезапущены.

---

### TaskFlow API (`@task`)

Это современный способ определения DAG'ов с использованием Python-декораторов. Он абстрагирует создание `PythonOperator`'ов и передачу данных через XComs, делая код более чистым, лаконичным и "питоническим".

Вместо явного создания экземпляров операторов, вы просто декорируете свои Python-функции. Airflow автоматически преобразует их в таски. Передача данных происходит путем вызова одной декорированной функции из другой.

Код становится значительно чище. Под капотом Airflow все еще создает `PythonOperator` и использует XComs, но вся эта "обвязка" скрыта от разработчика.

---

### Dynamic DAGs (Динамические DAG'и)

*   **Что это?**
    Это практика программной генерации нескольких объектов `DAG` в одном Python-файле на основе некоторой внешней конфигурации (например, YAML-файла, списка в коде, ответа от API).

*   **Почему это важно?**
    Чтобы не повторяться (принцип DRY). Если вам нужно создать 20 одинаковых по структуре DAG'ов, которые отличаются только именами таблиц и параметрами, вы не должны копировать 20 файлов. Вы создаете один "фабричный" файл, который генерирует их все. Это упрощает поддержку и внесение изменений.

*   **Как это работает:**
    Вы читаете конфигурацию и в цикле создаете экземпляры `DAG`. Важно, чтобы каждый созданный объект `DAG` был помещен в глобальную область видимости (globals()), чтобы Scheduler мог его обнаружить.

*   **Нюансы:** Логика генерации (чтение конфига) должна быть **очень быстрой**. Scheduler парсит этот файл часто. **Никогда** не делайте тяжелые операции (например, запросы к базе данных) в top-level коде DAG-файла, это замедлит весь ваш Airflow.

---

### Trigger Rules (Правила запуска)

*   **Что это?**
    Это правило, которое определяет, при каком состоянии родительских (upstream) тасков должен запускаться текущий таск.

*   **Зачем это нужно?**
    Для построения сложной, отказоустойчивой логики. По умолчанию используется `all_success` (все родительские таски должны завершиться успешно), но это не всегда то, что нужно.

*   **Основные правила:**
    *   `all_success` (по умолчанию): Запустится, только если все upstream таски успешны.
    *   `all_failed`: Запустится, только если все upstream таски упали.
    *   `all_done`: Запустится, когда все upstream таски завершились в любом состоянии (success, failed, skipped). **Идеально для тасков очистки** (например, удаление временных файлов), которые должны выполниться в любом случае.
    *   `one_failed`: Запустится, как только хотя бы один upstream таск упал. **Идеально для отправки уведомлений о сбое**.
    *   `one_success`: Запустится, как только хотя бы один upstream таск успешен.
    *   `none_failed`: Запустится, если ни один upstream таск не упал (они могли быть успешными или пропущенными).
    *   `none_failed_min_one_success`: Запустится, если ни один upstream таск не упал и хотя бы один был успешен. Полезно после операторов ветвления.
---

### Pools & Priority Weight (Пулы и приоритеты)

*   **Что это?**
    Механизмы для управления ресурсами и очередностью выполнения тасков.
    *   **Pools (Пулы):** Ограничивают количество тасков, которые могут выполняться одновременно из определенной группы. Пул имеет название и количество "слотов".
    *   **Priority Weight (Вес приоритета):** Число, определяющее относительный приоритет таска.

*   **Зачем это нужно?**
    *   **Pools:** Чтобы не перегружать внешние системы. Если у вас есть API с ограничением в 5 одновременных запросов, вы создаете пул `api_pool` с 5 слотами и назначаете все таски, использующие это API, в данный пул. Airflow не запустит 6-й таск из этого пула, пока один из 5 не освободит слот.
    *   **Priority Weight:** Чтобы более важные таски выполнялись раньше. Если в очереди стоит 100 готовых к запуску тасков, а у вас всего 16 свободных worker-слотов, Scheduler отдаст предпочтение таскам с наибольшим `priority_weight`.
    
---

### SLAs (Service Level Agreements)

*   **Что это?**
    Соглашение об уровне обслуживания. В Airflow это механизм для отправки оповещений, если таск не завершился в течение определенного времени *от начала своего интервала данных*.

*   **Как работает:**
    Вы задаете SLA как `timedelta`. Airflow отслеживает время. **Важный нюанс:** SLA отсчитывается не от момента старта таска, а от его логической даты (`data_interval_start`).
    *   Пример: DAG запускается ежедневно (`@daily`) в 00:00. Логическая дата для запуска — `2023-10-25 00:00:00`. Если у таска стоит `sla=timedelta(hours=2)`, то Airflow ожидает, что этот таск завершится до `2023-10-25 02:00:00`. Если он не завершился (даже если он еще не стартовал!), будет отправлено email-уведомление (SLA miss).

*   **Зачем нужно:**
    Для мониторинга производительности и своевременной поставки данных, а не только для отслеживания ошибок.

---
            