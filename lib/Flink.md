### 1. Состояние и Отказоустойчивость (Сердце Flink)

Отлично, давайте разберем эти ключевые концепции Apache Flink углубленно, понятно и без упрощающих аналогий. Мы сосредоточимся на механике и
внутреннем устройстве.

### Что такое Flink (в контексте этих тем)

**Apache Flink** — это фреймворк и распределенный движок для обработки потоков данных с сохранением состояния (stateful). Ключевое слово
здесь — **stateful**. В отличие от систем, которые обрабатывают каждое событие изолированно (stateless), Flink позволяет накапливать
информацию и использовать ее в последующих вычислениях. Например, подсчитывать сумму транзакций для каждого пользователя за последний час.
Эта накопленная информация и есть **состояние (state)**.

Три концепции, которые мы разберем — **State Backends, Checkpoints и Savepoints** — это фундаментальные столпы, на которых держится вся мощь
и отказоустойчивость Flink. Они отвечают на вопросы:

1. **Где** физически хранится состояние? (**State Backends**)
2. **Как** Flink обеспечивает целостность и сохранность этого состояния при сбоях? (**Checkpoints**)
3. **Как** мы можем управлять жизненным циклом приложения и его состоянием для обслуживания и обновлений? (**Savepoints**)

---

### 1. State Backends (Хранилища состояния)

#### Что это?

**State Backend** — это компонент Flink, отвечающий за физическое хранение и управление состоянием вашего приложения во время его
выполнения. Когда вы в своем коде используете `ValueState`, `ListState` или агрегируете данные в окнах, именно State Backend определяет, где
эти данные будут находиться: в памяти JVM или на диске. Он также отвечает за то, как эти данные будут сохранены при создании чекпоинта.

#### Разница между `HashMapStateBackend` и `EmbeddedRocksDBStateBackend`

Это два основных и принципиально разных способа хранения состояния.

**`HashMapStateBackend`**

* **Как работает:** Состояние хранится непосредственно в куче (heap) JVM вашего TaskManager в виде обычных Java-объектов внутри `HashMap`.
  Когда Flink делает чекпоинт, он сериализует эти объекты и копирует их в удаленное персистентное хранилище (например, HDFS или S3).
* **Производительность:**
    * **Чтение/Запись:** Максимально быстрая, так как доступ к состоянию — это просто доступ к объекту в оперативной памяти. Никакой
      дополнительной сериализации/десериализации при каждом доступе не требуется.
    * **Чекпоинты:** Могут быть медленными. Создание снимка требует полной сериализации всего состояния, что может быть затратно по времени
      и CPU.
* **Ограничения:**
    * **Размер состояния:** Строго ограничен размером кучи JVM. Вы не можете хранить состояние, которое превышает доступную оперативную
      память.
    * **Сборка мусора (GC):** Большой объем состояния в куче JVM приводит к длительным и непредсказуемым паузам на сборку мусора. Во время
      Full GC вся работа приложения останавливается, что критично для систем с низкой задержкой.
* **Когда использовать:**
    * Локальная разработка и тестирование.
    * Приложения с очень маленьким, предсказуемым объемом состояния (мегабайты, десятки мегабайт).
    * Задачи, где важна минимальная задержка на доступ к состоянию, а не его объем.

**`EmbeddedRocksDBStateBackend`**

* **Как работает:** Состояние хранится в key-value базе данных RocksDB, которая встроена в TaskManager. RocksDB управляет памятью
  самостоятельно (используя как оперативную память (off-heap), так и локальный диск). Данные в RocksDB хранятся в сериализованном виде (в
  виде байтовых массивов).
* **Производительность:**
    * **Чтение/Запись:** Медленнее, чем у `HashMapStateBackend`. Каждая операция чтения/записи требует:
        1. Сериализации (для записи) или десериализации (для чтения) Java-объекта в/из байтового массива.
        2. Обращения к RocksDB, которое может повлечь за собой дисковый ввод-вывод.
    * **Чекпоинты:** Очень эффективные и быстрые. RocksDB имеет встроенные механизмы для создания легковесных снимков. Flink просто
      использует эту нативную возможность, что позволяет создавать чекпоинты для огромных состояний (терабайты) с минимальным влиянием на
      основную обработку.
* **Преимущества:**
    * **Огромный размер состояния:** Позволяет хранить состояния, значительно превышающие объем оперативной памяти (терабайты), так как
      основная масса данных лежит на диске.
    * **Предсказуемая производительность:** Поскольку состояние находится вне кучи JVM, размер кучи можно держать небольшим. Это приводит к
      коротким и частым паузам GC, что делает производительность приложения более стабильной и предсказуемой.
* **Асинхронный режим:** Чтобы сгладить задержки, связанные с доступом к RocksDB, Flink предлагает асинхронный режим для чекпоинтов. В этом
  режиме запись состояния в RocksDB во время чекпоинта происходит в отдельном потоке, не блокируя основной поток обработки данных. Это
  повышает пропускную способность за счет небольшого увеличения задержки.

#### Вопрос для самопроверки: В каком случае я выберу RocksDB, даже если мое состояние помещается в память?

**Ответ:** Если я хочу избежать **длительных и непредсказуемых пауз на сборку мусора (GC)**. Даже если состояние объемом 20 ГБ помещается в
кучу JVM размером 32 ГБ, полная сборка мусора на такой куче может остановить работу приложения на несколько секунд или даже десятков секунд.
Это недопустимо для потоковых приложений, требующих стабильной обработки. Используя RocksDB, мы выносим эти 20 ГБ состояния за пределы кучи,
оставляя JVM маленький объем для работы, что гарантирует короткие и быстрые циклы GC.

---

### 2. Checkpoints (Контрольные точки)

#### Что это?

**Чекпоинт** — это внутренний, автоматический механизм отказоустойчивости Flink. Его цель — создать **глобально согласованный снимок
состояния** всего работающего приложения в определенный момент времени. Этот снимок включает:

1. **Состояние всех операторов** (например, текущие суммы, данные в окнах).
2. **Позиции (офсеты) в источниках данных** (например, офсеты в топиках Kafka).

При сбое Flink может перезапустить приложение и восстановить его из последнего успешного чекпоинта, гарантируя, что ни одно событие не будет
потеряно или обработано дважды *внутри состояния*.

#### Как работает алгоритм (Асинхронные барьеры)

В основе лежит вариация алгоритма **Chandy-Lamport** для создания распределенных снимков.

1. **Инициация:** JobManager (координирующий процесс Flink) периодически посылает специальное сообщение — **барьер (checkpoint barrier)** —
   всем источникам (sources) в графе выполнения. Каждый чекпоинт имеет свой уникальный ID.

2. **Движение барьера:** Барьер "течет" по потоку данных от оператора к оператору. Он не обгоняет обычные события и не отстает от них. Он
   является маркером, разделяющим поток данных на "до чекпоинта" и "после чекпоинта".

3. **Реакция оператора на барьер:**
    * **Оператор с одним входом:** Получив барьер, оператор понимает, что все данные для этого снимка он уже обработал. Он немедленно
      начинает делать снимок своего текущего состояния (синхронно или асинхронно, в зависимости от State Backend) и сохраняет его в
      удаленное хранилище (HDFS, S3). После этого он пересылает барьер дальше всем своим исходящим потокам.
    * **Оператор с несколькими входами (ключевой момент):** Здесь вступает в игру **выравнивание барьеров (barrier alignment)**. Оператор
      должен получить барьер с *каждого* из своих входящих потоков, прежде чем он сможет сделать свой снимок.
        * Предположим, у оператора два входа: A и B.
        * Он получает барьер с ID=N от потока A.
        * С этого момента он **перестает обрабатывать данные из потока A** и начинает их буферизировать.
        * Он продолжает обрабатывать данные из потока B, пока не получит барьер с тем же ID=N от потока B.
        * Как только барьер от потока B получен, оператор знает, что он обработал все данные, относящиеся к снимку N. Он делает снимок
          своего состояния, пересылает барьер дальше и начинает обрабатывать забуферизированные данные из потока A, а затем продолжает
          работу в обычном режиме.

4. **Завершение:** Когда все приемники (sinks) получили барьер и сообщили об этом JobManager'у, а также все операторы подтвердили успешное
   сохранение своего состояния, JobManager отмечает чекпоинт как завершенный.

#### Exactly-once vs. At-least-once

Это семантики обработки, которые Flink обеспечивает для своего *состояния*.

* **Exactly-once (строго однократно):** Это режим по умолчанию. Благодаря механизму выравнивания барьеров, Flink гарантирует, что каждый
  элемент данных из источника повлияет на состояние операторов **ровно один раз**. При восстановлении из чекпоинта состояние будет в
  точности таким, каким оно должно было быть.
* **At-least-once (как минимум однократно):** Этот режим можно включить для повышения производительности. В нем выравнивание барьеров
  отключается. Оператор делает снимок своего состояния, как только получает первый барьер от любого из входов. Это быстрее, но если
  произойдет сбой, некоторые события (те, что были между первым и последним барьером) могут быть обработаны повторно после восстановления.

**Важное уточнение:** Flink гарантирует `exactly-once` для **состояния внутри Flink**. Он не может дать такую гарантию для всей end-to-end
системы "из коробки". Почему? Потому что Flink не контролирует внешние системы (приемники/sinks). Если Flink падает после того, как записал
результат в базу данных, но до того, как завершил чекпоинт, после восстановления он заново обработает данные и попытается записать тот же
результат в базу еще раз.

Для **end-to-end exactly-once** нужны:

1. **Транзакционные источники:** Которые позволяют перечитывать данные с определенной позиции (например, Kafka).
2. **Транзакционные или идемпотентные приемники:**
    * **Транзакционные (Two-Phase Commit Sink):** Приемник участвует в процессе создания чекпоинта. На первой фазе он начинает транзакцию и
      записывает в нее данные. На второй фазе, когда Flink подтверждает успешность чекпоинта, приемник коммитит транзакцию. Если чекпоинт не
      удался, транзакция откатывается.
    * **Идемпотентные:** Приемник устроен так, что повторная запись одного и того же результата не меняет состояние системы (например,
      запись в key-value хранилище по ключу: `UPSERT` или `PUT`).

---

### 3. Savepoints (Точки сохранения)

#### Что это?

**Savepoint** — это согласованный снимок состояния приложения, который инициируется **вручную пользователем**. Технически он создается с
помощью того же механизма чекпоинтов, но его назначение и жизненный цикл совершенно другие.

#### Чем они отличаются от обычных чекпоинтов?

| Характеристика     | Checkpoint                                                   | Savepoint                                                                         |
|:-------------------|:-------------------------------------------------------------|:----------------------------------------------------------------------------------|
| **Инициатор**      | **Автоматически** (JobManager по таймеру)                    | **Вручную** (пользователь через CLI или REST API)                                 |
| **Цель**           | **Отказоустойчивость.** Восстановление после сбоев.          | **Операционное управление.** Обновления, миграции, обслуживание.                  |
| **Жизненный цикл** | **Временные.** Flink автоматически удаляет старые чекпоинты. | **Постоянные.** Хранятся, пока пользователь их не удалит вручную.                 |
| **Формат**         | Может быть более легковесным и специфичным для версии Flink. | Обычно имеет более универсальный и переносимый формат, чтобы пережить обновления. |

#### Основные сценарии использования

Savepoint — это ваш главный инструмент для управления жизненным циклом stateful-приложения без потери данных.

1. **Обновление версии Flink:**
    * `flink stop --withSavepoint <jobId> <savepointDirectory>`
    * Вы останавливаете приложение, создавая финальный savepoint.
    * Запускаете новый кластер Flink с обновленной версией.
    * Запускаете ваше приложение из этого savepoint: `flink run -s <savepointPath> ...`

2. **Изменение кода приложения:**
    * Вы нашли баг в логике или хотите добавить новую функциональность.
    * Останавливаете текущую версию с созданием savepoint.
    * Загружаете новый JAR-файл с исправленным кодом.
    * Запускаете новую версию из savepoint. Flink корректно сопоставит состояние со старыми операторами (если их ID не изменились).

3. **Изменение параллелизма:**
    * Ваше приложение не справляется с нагрузкой, и вы хотите увеличить количество параллельных экземпляров оператора с 10 до 20.
    * Создаете savepoint.
    * Останавливаете старое задание.
    * Запускаете новое задание с параметром `-p 20`, указав путь к savepoint. Flink автоматически перераспределит состояние между новыми 20
      экземплярами.

4. **A/B тестирование и отладка:**
    * Вы можете сделать savepoint с работающего production-приложения.
    * Затем запустить вторую, экспериментальную версию приложения из этого же savepoint в отдельном окружении. Это позволит вам
      протестировать новую логику на реальных данных, не затрагивая production.

---

### 2. Время и Окна (Душа потоковой обработки)

Конечно, давайте глубоко погрузимся в систему времени, вотермарков и окон во Flink. Это ядро его возможностей по обработке потоков на основе
времени события.

---

### 1. Типы времени (Time Characteristics)

В потоковой обработке "время" — это не однородное понятие. То, *когда* произошло событие, и то, *когда* мы его обрабатываем, — это две
разные вещи. Flink предоставляет три способа измерения времени.

* **Processing Time (Время обработки):**
    * **Что это:** Это системное время (wall-clock time) машины, на которой работает оператор Flink. Это `System.currentTimeMillis()` в JVM.
      Время обработки — это "сейчас" для конкретного TaskManager'a.
    * **Характеристики:**
        * **Недетерминированность:** Результат зависит от множества факторов: загрузка CPU, сетевые задержки, паузы на сборку мусора (GC).
          Если вы запустите одно и то же задание на одних и тех же входных данных дважды, вы, скорее всего, получите разные результаты.
        * **Простота:** Не требует никакой специальной настройки или извлечения временных меток из данных.
    * **Когда использовать:** Крайне редко. Подходит только для задач, где важна самая низкая возможная задержка и где корректность
      результатов в зависимости от времени не является строгим требованием (например, мониторинг пропускной способности самой системы).

* **Ingestion Time (Время поступления):**
    * **Что это:** Это время, когда событие **попадает в Flink**, то есть проходит через оператор-источник (source). Источник присваивает
      каждому событию текущее системное время и дальше эта метка времени "путешествует" вместе с событием.
    * **Характеристики:**
        * **Компромисс:** Дает более детерминированные результаты, чем Processing Time, так как временная метка присваивается один раз в
          самом начале и больше не меняется. Это решает проблему разной скорости обработки на разных операторах.
        * **Не решает проблему источника:** Если данные приходят в Flink с задержкой (например, мобильное устройство было офлайн и отправило
          пачку событий), Ingestion Time не отразит реальное время, когда эти события произошли.
    * **Когда использовать:** Когда Event Time недоступен в данных, но хочется более предсказуемых результатов, чем с Processing Time.

* **Event Time (Время события):**
    * **Что это:** Это временная метка, **встроенная в само событие**. Она указывает, когда событие произошло в реальном мире. Например,
      время совершения транзакции, время снятия показания с датчика. Flink не генерирует это время, он его **извлекает** из данных.
    * **Характеристики:**
        * **Детерминированность и Корректность:** Результаты вычислений не зависят от скорости работы Flink или задержек в сети. Запустив
          задание на тех же данных, вы всегда получите идентичный результат. Это позволяет воспроизводить и анализировать обработку.
        * **Требует управления "опозданиями":** Flink должен как-то понять, когда он может считать, что все события за определенный период (
          например, за 10:00-10:01) уже прибыли. Эту проблему решают вотермарки.

#### Почему Event Time — золотой стандарт?

Потому что он позволяет строить **корректные и воспроизводимые** системы, работающие с реальным порядком событий, а не с артефактами их
доставки и обработки. Он решает две фундаментальные проблемы потоковой обработки:

1. **Проблема задержки и скорости:** Неважно, пришло ли событие через 10 миллисекунд или через 10 минут, Flink поместит его в правильное
   временное "ведро" (окно) для анализа. Результат не будет искажен из-за того, что система была под нагрузкой.
2. **Проблема неупорядоченных данных (Out-of-Order Events):** В реальных системах события часто приходят не в том порядке, в котором они
   произошли. Event Time вместе с вотермарками позволяет Flink "подождать" опоздавшие события и обработать их правильно.

---

### 2. Watermarks (Водяные знаки)

#### Что это?

**Вотермарк (Watermark)** — это фундаментальный механизм в Flink для работы в режиме Event Time. Это специальная метка в потоке данных,
которая несет в себе временную метку `T`. Вотермарк `W(T)` — это утверждение Flink: **"Я считаю, что событий с временной меткой меньше или
равной `T` в этом потоке больше не появится"**.

Это сигнал о **прогрессе времени события**. Он позволяет Flink принимать решения о завершении вычислений. Без вотермарков Flink'у пришлось
бы ждать бесконечно, чтобы быть уверенным, что все события для определенного окна (например, за прошлый час) прибыли.

#### Как они генерируются (`WatermarkStrategy`)

Вотермарки генерируются в источнике или сразу после него с помощью `WatermarkStrategy`. Два основных типа стратегий:

1. **`forMonotonousTimestamps()` (Пунктуальные)**
    * **Предположение:** События приходят в поток строго по возрастанию их временных меток. Опозданий нет.
    * **Как работает:** Вотермарк генерируется как `timestamp_текущего_события - 1`. Это означает, что как только пришло событие с
      меткой `T`, мы уверены, что событий с меткой `< T` уже не будет.
    * **Реальность:** В распределенных системах почти никогда не используется, так как идеальный порядок — большая редкость.

2. **`forBoundedOutOfOrderness(Duration maxOutOfOrderness)` (Для ограниченных опозданий)**
    * **Предположение:** События могут приходить не по порядку, но их "опоздание" ограничено некоторой максимальной величиной.
    * **Как работает:** Это самая распространенная стратегия. Flink отслеживает максимальную временную метку (`maxTimestamp`) среди всех
      увиденных событий. Периодически он генерирует вотермарк со значением `currentWatermark = maxTimestamp - maxOutOfOrderness`.
    * **Пример:** `maxOutOfOrderness` = 5 секунд.
        * Приходит событие с `T = 10:00:12`. `maxTimestamp` становится `10:00:12`. Генерируется вотермарк `W(10:00:07)`.
        * Приходит опоздавшее событие с `T = 10:00:09`. `maxTimestamp` не меняется.
        * Приходит событие с `T = 10:00:14`. `maxTimestamp` становится `10:00:14`. Генерируется новый вотермарк `W(10:00:09)`.
    * Этот параметр `maxOutOfOrderness` — это компромисс между задержкой и полнотой данных. Большое значение позволяет дождаться больше
      опоздавших событий, но увеличивает задержку результатов.

#### Проблема "холостого хода" (Idleness)

Представьте, что у вас источник Kafka с 10 партициями. Flink запускает 10 параллельных инстансов источника, каждый генерирует свои локальные
вотермарки. **Глобальный вотермарк** для всего приложения — это **минимум** из всех локальных вотермарков.

**Проблема:** Если одна из партиций (например, партиция №3) перестает получать данные, ее локальный `maxTimestamp` не растет, и ее
вотермарк "застревает". Так как глобальный вотермарк — это минимум, он тоже застревает на значении вотермарка из партиции №3. В итоге, **ни
одно окно во всем приложении не будет закрыто**, даже если остальные 9 партиций активно поставляют данные.

**Решение:** `WatermarkStrategy.withIdleness(Duration)`. Эта настройка говорит Flink: "Если источник не поставляет события в течение
указанного `Duration`, считать его неактивным (idle) и временно исключить его из расчета глобального вотермарка". Это позволяет глобальному
времени продвигаться вперед, даже если часть источников "молчит".

---

### 3. Окна (Windows)

Окно — это механизм для группировки бесконечного потока событий в конечные "пакеты" для обработки. Механика окна состоит из нескольких
ключевых компонентов:

* **Window Assigner (Назначение окна):** Определяет, к какому окну (или окнам) принадлежит каждое входящее событие.
    * **Tumbling (Наклоняющиеся/Непересекающиеся):** Каждое событие принадлежит ровно одному окну фиксированного размера (напр., окна по 1
      часу: `[10:00, 11:00)`, `[11:00, 12:00)`).
    * **Sliding (Скользящие):** Окна фиксированного размера, которые "накладываются" друг на друга. Событие может принадлежать нескольким
      окнам. (напр., размер 1 час, сдвиг 30 минут: `[10:00, 11:00)`, `[10:30, 11:30)`).
    * **Session (Сессионные):** Окна определяются не временем, а активностью. Окно открывается с первым событием и расширяется, пока между
      событиями проходит не более заданного "промежутка неактивности" (session gap).
    * **Global (Глобальные):** По умолчанию все события попадают в одно глобальное окно. Требует кастомного триггера, чтобы когда-либо
      выдать результат.

Когда событие попадает в окно, оно сохраняется во внутреннем буфере этого окна (который хранится в выбранном **State Backend**).

#### Triggers (Триггеры)

**Триггер** отвечает на вопрос: **"КОГДА вычислять и выдавать результат для окна?"**.

* **Как работает:** У каждого окна есть привязанный триггер. Триггер может "сработать" (fire) по разным событиям: по приходу элемента, по
  таймеру времени обработки, или (что самое главное) по продвижению вотермарка.
* **Стандартный триггер (`EventTimeTrigger`):** Он срабатывает, когда **вотермарк проходит конец окна**. Например, для
  окна `[10:00, 11:00)`, триггер сработает, как только придет вотермарк `W(T)` где `T >= 11:00:00`. Это стандартное и наиболее интуитивное
  поведение.
* **Другие триггеры:** Можно написать свои. Например, `CountTrigger` сработает после N элементов в окне, или `ProcessingTimeTrigger`
  сработает по системному времени. Это позволяет получать промежуточные результаты до закрытия окна вотермарком.

#### Evictors (Вытеснители)

**Вытеснитель** отвечает на вопрос: **"КАКИЕ элементы из окна обрабатывать?"**. Он позволяет удалить часть элементов из буфера окна
*непосредственно перед* тем, как будет вызвана функция агрегации (например, `sum()` или `reduce()`).

* **Как работает:** Evictor запускается после того, как триггер сработал, но до вызова оконной функции.
* **Пример использования:** "Посчитать сумму транзакций за последний час, но учитывать только 100 последних транзакций в этом часе". Здесь
  окно — 1 час. Evictor, настроенный на 100 элементов, пройдет по всем элементам в окне и оставит только 100 последних, а затем Flink
  посчитает сумму. Это очень специфичный и редко используемый инструмент.

#### Allowed Lateness (Допустимое опоздание)

**Allowed Lateness** отвечает на вопрос: **"Что делать с событиями, которые пришли ПОСЛЕ того, как вотермарк закрыл окно?"**.

* **Проблема:** Вотермарк `W(11:00:01)` пришел, окно `[10:00, 11:00)` было посчитано и результат выдан. Через 2 минуты приходит событие с
  меткой `10:59:59`. По умолчанию, оно будет просто проигнорировано.
* **Решение:** `window(...).allowedLateness(Duration.ofMinutes(5))`.
* **Как работает:** Когда вотермарк закрывает окно, Flink вычисляет результат, но **не удаляет состояние этого окна**. Он держит его "в
  живых" на протяжении указанного периода `allowedLateness`.
    * Если в течение этих 5 минут приходит опоздавшее событие, оно добавляется в окно, и триггер **срабатывает снова**, выдавая *
      *обновленный результат**.
    * Когда проходит и само опоздание (т.е. вотермарк становится `> window.end + allowedLateness`), состояние окна окончательно
      уничтожается. Все события, пришедшие после этого, будут проигнорированы (или отправлены
      в [side output](https://nightlies.apache.org/flink/flink-docs-stable/docs/dev/datastream/side_output/) для специальной обработки).

---

### 3. Архитектура и Модель выполнения

Отлично! Мы переходим от "что Flink делает" к "как Flink это делает". Разберем архитектуру и механику выполнения.

---

### 1. Компоненты кластера

Кластер Flink работает по классической модели **master-worker**. Есть один координирующий процесс (JobManager) и один или несколько исполняющих процессов (TaskManager).

#### **JobManager (Мастер-процесс)**

**JobManager** — это мозг и дирижер всего кластера. Он не выполняет непосредственно код вашей программы (операции `map`, `filter` и т.д.), но отвечает за координацию. У одного Flink-кластера может быть несколько JobManager'ов для обеспечения высокой доступности (High Availability), но только один из них является активным лидером.

Его ключевые обязанности разделены между тремя основными компонентами:

1.  **Dispatcher (Диспетчер):**
    *   **Что делает:** Это "входная дверь" для вашего задания. Когда вы отправляете JAR-файл с вашим кодом в кластер (`flink run ...`), именно Dispatcher его принимает.
    *   **Основная функция:** Запускает новый **JobMaster** для каждого отправленного задания. Предоставляет REST API для управления заданиями (отправка, отмена, просмотр статуса).

2.  **ResourceManager (Менеджер ресурсов):**
    *   **Что делает:** Управляет ресурсами кластера — **TaskManager'ами** и их **слотами**.
    *   **Основная функция:** Отвечает за выделение слотов по запросу от JobMaster'а. Он знает, сколько TaskManager'ов зарегистрировано в кластере и сколько свободных слотов на каждом из них. Если Flink работает под управлением YARN или Kubernetes, ResourceManager взаимодействует с ними для запроса новых воркеров (TaskManager'ов).

3.  **JobMaster (Мастер задания):**
    *   **Что делает:** Это "мозг" и дирижер для **одного конкретного задания**. Для каждого запущенного приложения создается свой собственный JobMaster.
    *   **Основная функция:**
        *   Принимает **JobGraph** от Dispatcher'a.
        *   Преобразует его в **ExecutionGraph**.
        *   Запрашивает необходимые слоты у ResourceManager'a.
        *   Распределяет задачи (tasks) по выделенным слотам на TaskManager'ах.
        *   Координирует весь жизненный цикл задания: инициирует чекпоинты и savepoint'ы, отслеживает статус выполнения задач и запускает механизм восстановления в случае сбоя.

#### **TaskManager (Рабочий процесс)**

**TaskManager** — это "мускулы" кластера. Это JVM-процесс, который выполняет фактическую работу — код вашего потокового приложения.

*   **Слоты (Slots):**
    *   **Что это:** Слот — это базовая единица параллелизма в TaskManager. Каждый TaskManager имеет как минимум один слот. Слот — это не просто поток, это **фиксированная порция ресурсов TaskManager'а**.
    *   **Изоляция:** Слоты обеспечивают изоляцию. Задачи, выполняющиеся в разных слотах, имеют изолированные порции памяти из кучи JVM. Это предотвращает ситуацию, когда одна "тяжелая" задача отбирает всю память у другой.
    *   **Совместное использование (Slot Sharing):** По умолчанию слоты могут совместно использоваться. Один слот может выполнять целую цепочку задач от *разных* операторов одного и того же задания (например, `source -> map -> filter`). Это позволяет очень эффективно утилизировать ресурсы.

#### Разница между Параллелизмом и Количеством Слотов

Это критически важный для понимания аспект.

*   **Параллелизм (Parallelism):** Это свойство **вашего задания (job)**. Вы устанавливаете его с помощью `setParallelism()`. Оно определяет, на сколько параллельных подзадач будет разбит каждый оператор в вашем приложении. Например, `setParallelism(10)` означает, что ваш `map` будет выполняться в 10 параллельных инстансах.
*   **Количество слотов (Number of Slots):** Это свойство **вашего кластера (cluster)**. Оно определяет, сколько задач кластер может выполнять одновременно.

**Сценарий:**
*   У вас кластер из **2 TaskManager'ов**, на каждом по **3 слота**. Итого **6 слотов** в кластере.
*   Вы запускаете задание с **параллелизмом 5**.
*   **Что произойдет:** JobMaster запросит у ResourceManager'a **5 слотов**. ResourceManager выделит, например, 3 слота на первом TaskManager'е и 2 слота на втором. Ваше задание запустится. Один слот в кластере останется свободным.
*   Вы пытаетесь запустить то же задание с **параллелизмом 8**.
*   **Что произойдет:** JobMaster запросит **8 слотов**. ResourceManager увидит, что доступно только 6. Задание **не запустится** и будет ждать, пока не освободятся ресурсы.

**Вывод:** Общее количество слотов в кластере — это верхний предел для максимального параллелизма, который вы можете использовать для всех запущенных заданий.

---

### 2. Граф выполнения

Когда вы пишете код на DataStream API, он проходит несколько стадий трансформации, прежде чем превратиться в исполняемые задачи.

1.  **StreamGraph:**
    *   **Что это:** Прямое представление вашего кода. Каждый вызов оператора (`map`, `keyBy`, `window`) создает узел в этом графе. Это логический граф, который еще не оптимизирован.

2.  **JobGraph:**
    *   **Что это:** Оптимизированная версия StreamGraph'а. На этом этапе происходит ключевая оптимизация — **конвейеризация операторов (Operator Chaining)**.
    *   **Operator Chains:** Flink анализирует StreamGraph и объединяет последовательные операторы, которые не требуют перераспределения данных (shuffling), в одну **задачу (Task)**. Например, последовательность `source -> map -> filter` будет объединена в одну большую задачу. Это делается для максимальной производительности.
        *   **Почему это важно:** Вместо того чтобы передавать данные от `map` к `filter` через сериализацию, сетевой стек и десериализацию, данные передаются как простой вызов метода внутри одного потока. Это кардинально снижает накладные расходы.
        *   **Управление:** Chaining происходит автоматически. Но вы можете им управлять:
            *   `startNewChain()`: Начать новую цепочку с этого оператора.
            *   `disableChaining()`: Никогда не объединять этот оператор с предыдущим.
    *   JobGraph — это то, что отправляется в Dispatcher.

3.  **ExecutionGraph:**
    *   **Что это:** Это "живой" граф, который создается в JobMaster'е. Он берет JobGraph и "разворачивает" его в соответствии с заданным **параллелизмом**.
    *   **Пример:** Если в JobGraph'е была одна задача `Source-Map-Filter`, а параллелизм задания равен 10, то в ExecutionGraph'е будет 10 параллельных копий (инстансов) этой задачи. Каждый инстанс называется **ExecutionVertex**.
    *   ExecutionGraph отслеживает состояние каждой подзадачи в реальном времени (SCHEDULED, DEPLOYING, RUNNING, FINISHED, FAILED).

4.  **Physical Graph (Физический граф):**
    *   **Что это:** Это не отдельная структура данных во Flink, а скорее концептуальное представление того, как ExecutionGraph распределен по физическим ресурсам. Он показывает, какой ExecutionVertex (подзадача) на каком слоте какого TaskManager'а выполняется.

---

### 3. Передача данных и Backpressure

#### Передача данных (Data Shuffling)

Это стратегии, которые Flink использует для передачи данных между задачами, когда их нельзя объединить в цепочку (chain). Обычно это происходит после операций, меняющих партиционирование.

*   **`keyBy` (Хэш-партиционирование):**
    *   **Как работает:** Для каждой записи вычисляется хэш от указанного ключа. По этому хэшу определяется, в какой из N параллельных инстансов следующего оператора нужно отправить эту запись.
    *   **Гарантия:** Все записи с одним и тем же ключом всегда попадут в один и тот же инстанс задачи. Это фундаментальное требование для любой stateful-обработки (например, чтобы считать сумму по каждому `userId`).

*   **`broadcast` (Широковещательная передача):**
    *   **Как работает:** Каждая запись копируется и отправляется **во все** параллельные инстансы следующего оператора.
    *   **Использование:** Для передачи небольших наборов данных, которые нужны всем задачам (например, правила, конфигурация).

*   **`rebalance` (Перебалансировка):**
    *   **Как работает:** Распределяет данные между следующими задачами по принципу "карусели" (round-robin), чтобы обеспечить абсолютно равномерную нагрузку.
    *   **Использование:** Когда нужно избавиться от перекоса данных (data skew).

*   **`rescale` (Масштабирование):**
    *   **Как работает:** Более эффективная версия `rebalance`. Каждая исходящая задача отправляет данные только в некоторое подмножество входящих задач. Это локализованный round-robin.
    *   **Оптимизация:** Значительно сокращает количество сетевых соединений между TaskManager'ами по сравнению с `rebalance`. Если производительность важна и строгая "карусель" не нужна, `rescale` предпочтительнее.

#### Backpressure (Обратное давление)

*   **Что это:** Backpressure — это нативный механизм контроля потока данных во Flink. Это ситуация, когда **потребляющая (downstream) задача работает медленнее, чем производящая (upstream) задача**. В результате медленная задача "оказывает давление" вверх по потоку, заставляя быстрые задачи замедляться до ее скорости.

*   **Как это работает (механика):**
    1.  Данные между задачами передаются через сетевые буферы с фиксированным размером.
    2.  Задача-производитель (например, `Source`) запрашивает буфер из своего локального пула, заполняет его данными и отправляет задаче-потребителю (например, `Map`).
    3.  Задача-потребитель обрабатывает данные из буфера и, когда буфер пуст, **возвращает его обратно** производителю для повторного использования.
    4.  **Ключевой момент:** Если потребитель медленный (занят вычислениями, ждет ответа от внешней системы), он не будет быстро освобождать буферы.
    5.  У производителя заканчиваются доступные буферы в его пуле. Он не может отправить новые данные и **блокируется**, ожидая, пока потребитель вернет ему хотя бы один пустой буфер.
    6.  Это замедление каскадом распространяется вверх по всему графу.

*   **Что это означает:** Backpressure — это не ошибка, а **симптом**. Он сигнализирует о том, что в вашем приложении есть "бутылочное горлышко". Потребитель не справляется с потоком данных.

*   **Как обнаружить:** В веб-интерфейсе Flink есть вкладка "Backpressure". Она показывает статус для каждой задачи:
    *   **OK (зеленый):** Потребитель успевает обрабатывать данные (использование буферов < 10%).
    *   **LOW (синий):** Нагрузка растет (10% < использование < 50%).
    *   **HIGH (красный):** Потребитель не справляется, производитель часто блокируется (использование > 50%).

Если вы видите статус **HIGH**, это значит, что производительность вашего задания упирается именно в эту медленную задачу. Вам нужно либо оптимизировать ее код, либо выделить ей больше ресурсов (увеличить параллелизм).


---

### 4. Производительность и Оптимизация


### 1. Управление памятью (Memory Management)

Понимание того, как TaskManager использует память — это ключ к предотвращению `OutOfMemoryError` и длительных пауз GC, которые являются главными врагами стабильности.

Представим всю память, выделенную процессу TaskManager:

```
+-------------------------------------------------------------+
|                      TaskManager Process Memory             |
| +-------------------------+ +-----------------------------+ |
| |     JVM Process Memory    | |     Off-Heap Memory         | |
| |-------------------------| |-----------------------------| |
| |      Framework Heap     | |       Managed Memory        | |
| |-------------------------| |-----------------------------| |
| |         Task Heap       | |      Direct/Native Mem      | |
| +-------------------------+ +-----------------------------+ |
|                                                             |
|          JVM Overhead, Metaspace, Network Buffers...        |
+-------------------------------------------------------------+
```

#### Компоненты памяти TaskManager'а

*   **Framework Heap:** Память в куче JVM, используемая самим фреймворком Flink для своих внутренних структур данных (координация, метаданные). Обычно она небольшая, и вы ее напрямую не настраиваете.

*   **Task Heap:** Память в куче JVM, выделенная для выполнения **вашего кода**. Здесь создаются объекты в ваших UDF (User-Defined Functions), таких как `MapFunction`, `ProcessFunction`.
    *   **Важность:** Если вы используете `HashMapStateBackend`, все ваше состояние будет жить здесь. Большой Task Heap — прямой путь к длинным и непредсказуемым паузам на сборку мусора (Full GC), которые останавливают всю обработку.

*   **Network Buffers:** Отдельный, выделенный пул **off-heap** памяти для передачи данных между задачами. Это небольшие буферы фиксированного размера. Их количество вычисляется автоматически на основе конфигурации, и они являются основой механизма backpressure. Выделение их за пределы кучи гарантирует, что сетевое взаимодействие не будет страдать от GC.

*   **Managed Memory (Управляемая память) — Ключ к стабильности**
    *   **Что это:** Это большой пул **off-heap** памяти (памяти вне кучи JVM), которым Flink управляет напрямую, байт за байтом. Flink не полагается на сборщик мусора Java для управления этой областью.
    *   **Для чего используется:**
        1.  **Сортировки и Хэш-таблицы:** Для операций, требующих большого объема памяти (например, `join`, или агрегации на больших окнах), Flink может использовать Managed Memory для выполнения этих операций, не рискуя вызвать `OutOfMemoryError` в куче JVM.
        2.  **Кэш для RocksDB:** Это **самое важное** применение. Когда вы используете `EmbeddedRocksDBStateBackend`, состояние хранится на локальном диске. Чтобы ускорить доступ, RocksDB использует кэш в оперативной памяти (Block Cache). Flink выделяет свою Managed Memory **на нужды этого кэша**.
    *   **Почему это так важно:**
        *   **Производительность:** Чем больше Managed Memory вы выделяете, тем больше кэш у RocksDB. Чем больше кэш, тем чаще RocksDB находит нужные данные в памяти (cache hit) и тем реже ему приходится читать с медленного диска. Правильная настройка этого параметра — главный рычаг для ускорения работы с `RocksDB`.
        *   **Стабильность:** Вынося большие объемы данных (кэш состояния) за пределы кучи JVM, вы можете держать Task Heap небольшим. Это приводит к очень коротким и частым циклам GC, что делает производительность приложения предсказуемой и стабильной, без внезапных "замираний".

**Практический вывод:** Для stateful-приложений с `RocksDB` выделите как можно больше **Managed Memory** (`taskmanager.memory.managed.fraction` или `taskmanager.memory.managed.size`), оставив Task Heap достаточно большим только для логики вашего приложения.

---

### 2. Сериализация

Сериализация — это процесс преобразования Java-объектов в байты и обратно. В распределенной системе, как Flink, это происходит постоянно: при передаче данных по сети, при записи состояния в State Backend, при создании чекпоинтов. Медленная сериализация = медленное приложение.

#### Система типов и сериализаторов Flink

Flink не доверяет стандартной сериализации Java и избегает универсальных библиотек, таких как Kryo, по несколь-ким причинам:
*   **Производительность:** Универсальные сериализаторы должны хранить метаинформацию о классах. Flink, зная тип данных заранее, может сгенерировать очень компактный и быстрый код для сериализации/десериализации.
*   **Возможность модификации:** Flink может напрямую оперировать сериализованными данными (в байтах), не преобразуя их в объекты, что позволяет делать некоторые оптимизации (например, сравнивать ключи в сериализованной форме).
*   **Эволюция схемы:** Система типов Flink лучше подготовлена к изменениям в структуре данных (добавлению/удалению полей), что критично для обновления приложений с сохранением состояния из savepoint'ов.

#### Как помочь Flink (и себе)

1.  **Используйте POJO (Plain Old Java Objects):** Это лучший способ. Если ваши классы данных соответствуют правилам POJO, Flink сгенерирует для них `PojoSerializer` — самый эффективный из возможных.
    *   **Правила POJO для Flink:**
        *   Класс должен быть `public`.
        *   Должен быть `public` конструктор без аргументов.
        *   Все поля либо `public`, либо доступны через `public` геттеры и сеттеры.
        *   Типы всех полей должны поддерживаться сериализаторами Flink.

2.  **Используйте простые типы:** `String`, `Long`, `Integer`, а также флинковские `TupleN`. Для них существуют высокооптимизированные встроенные сериализаторы.

#### Когда нужен Kryo

Иногда вы не можете использовать POJO (например, работаете с классом из внешней библиотеки). В этом случае Flink откатывается к использованию **Kryo**.

*   **Проблема по умолчанию:** Если Flink использует Kryo для неизвестного ему типа, он будет записывать полное имя класса вместе с каждым объектом. Это медленно и неэффективно по объему.
*   **Решение:** Если вы вынуждены использовать не-POJO тип, **зарегистрируйте его в Kryo**.
    ```java
    env.getConfig().registerKryoType(MyComplexClass.class);
    ```
    В этом случае Kryo присвоит вашему классу целочисленный ID, что сделает сериализацию гораздо более компактной. Также можно указать сериализатор по умолчанию, если стандартный не подходит: `env.getConfig().setDefaultKryoSerializer(MyClass.class, MySerializer.class);`.

---

### 3. Мониторинг и метрики

Вы не можете оптимизировать то, что не измеряете. Flink предоставляет огромное количество метрик. Вот самые важные для оценки здоровья и производительности:

*   **`lastCheckpointDuration` и `lastCheckpointSize`**
    *   **Что это:** Длительность и размер последнего успешного чекпоинта.
    *   **Что искать:**
        *   **Резкие скачки `duration`:** Могут указывать на проблемы с сетью или диском в удаленном хранилище, или на внезапное возникновение backpressure (барьеры долго идут).
        *   **Постоянный рост `size`:** Это "красный флаг". Скорее всего, у вас **утечка состояния** — вы накапливаете данные в состоянии и никогда их не очищаете (например, забыли установить TTL для `MapState`). Это рано или поздно приведет к проблемам с производительностью и памятью.
        *   **Высокое значение `checkpointAlignmentTime` (часть `duration`):** Указывает, что барьеры долго выравниваются. Это прямой признак backpressure или неравномерной загрузки параллельных инстансов.

*   **`currentInputWatermark`**
    *   **Что это:** Показывает текущий вотермарк на входе в задачу. Это индикатор "прогресса времени события".
    *   **Что искать:** **"Застрявший" вотермарк.** Если эта метрика не растет, значит, окна не будут закрываться и приложение не будет выдавать результаты.
    *   **Причины:** Чаще всего — "холостой ход" (idleness) одной из партиций источника. Решение — использовать `WatermarkStrategy.withIdleness()`. Реже — "отравленное" событие с аномально низкой или некорректной временной меткой.

*   **Задержка (Latency)**
    *   **Что это:** Время, которое проходит с момента создания события до момента его обработки в приемнике (sink). Flink не предоставляет одну "магическую" метрику для этого.
    *   **Как измерить:**
        1.  Использовать метрику `millisBehindLatest` для коннектора Kafka, которая показывает, насколько вы отстаете от последнего сообщения в топике.
        2.  Внедрить свою метрику: в источнике добавлять в запись текущее время (`System.currentTimeMillis()`), а в приемнике вычислять разницу. Flink Latency Markers предоставляют более продвинутый встроенный механизм для этого.
    *   **Что искать:** Растущая задержка — главный признак того, что ваше приложение не справляется с входным потоком.

*   **Метрики Backpressure**
    *   **Что это:** UI Flink предоставляет самый удобный способ мониторинга.
    *   **Что искать:** Статус **HIGH** (красный) у какой-либо задачи. Это означает, что ее входные буферы почти всегда полны, и она тормозит все вышестоящие (upstream) задачи.
    *   **Действие:** Backpressure — это симптом. Нужно найти причину. Зайдите в метрики самой "красной" задачи и посмотрите, чем она занята. Возможно, она делает медленный вызов во внешнюю систему, или ее CPU загружен на 100%. Это точное указание на "бутылочное горлышко" в вашем приложении.

*   **Метрики GC (Garbage Collection)**
    *   **Что это:** Метрики сборки мусора JVM (`Status.JVM.GarbageCollector.*`).
    *   **Что искать:**
        *   **`Count` (количество сборок):** Частое срабатывание GC — это нормально.
        *   **`Time` (время, потраченное на сборку):** Это ключевой показатель. Ищите не только общее время, но и длительность отдельных пауз. Длительные паузы (сотни мс или секунды) в `OldGen` GC (Full GC) — это катастрофа для потокового приложения.
    *   **Причины и действия:** Высокое давление на GC почти всегда означает, что у вас слишком много данных в **Task Heap**. Причины: неэффективный код, создающий много временных объектов, или использование `HashMapStateBackend` с большим состоянием. Первое решение — **переключиться на `EmbeddedRocksDBStateBackend`**, чтобы вынести состояние за пределы кучи.
    

