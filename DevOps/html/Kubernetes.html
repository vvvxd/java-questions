<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Вопросы по собеседованию</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        .question-block {
            cursor: pointer;
            transition: background-color 0.3s ease;
            word-break: break-word;
        }
        .question-block:hover {
            background-color: #f3f4f6;
        }
    </style>
</head>
<body class="bg-gray-100 flex items-center justify-center min-h-screen">

<!-- Контейнер с вопросом -->
<div id="question-container" class="bg-white shadow-lg rounded-lg p-6 w-[800px] h-[750px] flex items-center justify-center text-center relative">
    <div id="question-block" class="question-block p-4 border-b w-full h-full flex items-center justify-center text-center relative" onclick="toggleAnswer()">
        <strong class="text-lg block" id="question-text"></strong>
        <div id="answer-text" class="text-gray-700 hidden" onclick="toggleAnswer()"></div>
    </div>
</div>

<!-- Навигация -->
<div class="absolute bottom-10 flex justify-center gap-4">
    <button onclick="prevQuestion()" class="bg-blue-500 text-white px-4 py-2 rounded hover:bg-blue-600">Назад</button>
    <button onclick="location.href='main.html'" class="bg-gray-500 text-white px-4 py-2 rounded hover:bg-gray-600">На главную</button>
    <button onclick="nextQuestion()" class="bg-blue-500 text-white px-4 py-2 rounded hover:bg-blue-600">Вперед</button>
</div>

<!-- Модальное окно -->
<div id="modal" class="fixed inset-0 flex items-center justify-center bg-black bg-opacity-50 hidden">
    <div class="bg-white p-6 rounded-lg shadow-lg w-[900px] h-[800px] overflow-y-auto">
        <h2 class="text-lg font-semibold mb-4">Ответ</h2>
        <p id="modal-answer" class="text-gray-700"></p>
        <button onclick="closeModal()" class="mt-4 bg-red-500 text-white px-4 py-2 rounded hover:bg-red-600 w-full">Закрыть</button>
    </div>
</div>

<script>
    let currentQuestionIndex = 0;
    const MAX_ANSWER_LENGTH = 2000; // Максимальная длина ответа для отображения без модального окна

    const questions = [
        {
  question: "Что такое Kubernetes?",
  answer: "Kubernetes — это портативная расширяемая платформа с открытым исходным кодом для управления контейнеризованными рабочими нагрузками и сервисами, которая облегчает как декларативную настройку, так и автоматизацию. У платформы есть большая, быстро растущая экосистема. Сервисы, поддержка и инструменты Kubernetes широко доступны."
}
,{
  question: "Что такое OpenShift ?",
  answer: "OpenShift — готовая платформа для разработки и эксплуатации контейнерных приложений. Ее можно установить на свои серверы или арендовать у облачного провайдера. OpenShift — это больше чем Kubernetes. Kubernetes лежит в основе платформы, но кроме него еще есть много других инструментов, которые упрощают работу с кластером и контейнерными приложениями в целом. Некоторые инструменты, которые в простом Kubernetes нужно изучать и настраивать, тут доступны «из коробки». Например, в OpenShift более строгая политика безопасности, которая не позволяет запускать контейнеры от root-пользователя, есть инструменты для упрощения интеграции с Active Directory, встроенный конвейер CI/CD и другое."
}
,{
  question: "Зачем вам Kubernetes и что он может сделать",
  answer: "Контейнеры — отличный способ связать и запустить ваши приложения. В производственной среде необходимо управлять контейнерами, которые запускают приложения, и гарантировать отсутствие простоев. Например, если контейнер выходит из строя, необходимо запустить другой контейнер. Не было бы проще, если бы такое поведение обрабатывалось системой?<br>Вот тут Kubernetes приходит на помощь! Kubernetes дает вам фреймворк для гибкой работы распределенных систем. Он занимается масштабированием и обработкой ошибок в приложении, предоставляет шаблоны развертывания и многое другое. Например, Kubernetes может легко управлять канареечным развертыванием вашей системы.Kubernetes предоставляет вам:Мониторинг сервисов и распределение нагрузки Kubernetes может обнаружить контейнер, используя имя DNS или собственный IP-адрес. Если трафик в контейнере высокий, Kubernetes может сбалансировать нагрузку и распределить сетевой трафик, чтобы развертывание было стабильным.Оркестрация хранилища Kubernetes позволяет вам автоматически смонтировать систему хранения по вашему выбору, такую как локальное хранилище, провайдеры общедоступного облака и многое другое.Автоматическое развертывание и откаты Используя Kubernetes можно описать желаемое состояние развернутых контейнеров и изменить фактическое состояние на желаемое. Например, вы можете автоматизировать Kubernetes на создание новых контейнеров для развертывания, удаления существующих контейнеров и распределения всех их ресурсов в новый контейнер.Автоматическое распределение нагрузки Вы предоставляете Kubernetes кластер узлов, который он может использовать для запуска контейнерных задач. Вы указываете Kubernetes, сколько ЦП и памяти (ОЗУ) требуется каждому контейнеру. Kubernetes может разместить контейнеры на ваших узлах так, чтобы наиболее эффективно использовать ресурсы.Самоконтроль Kubernetes перезапускает отказавшие контейнеры, заменяет и завершает работу контейнеров, которые не проходят определенную пользователем проверку работоспособности, и не показывает их клиентам, пока они не будут готовы к обслуживанию.Управление конфиденциальной информацией и конфигурацией Kubernetes может хранить и управлять конфиденциальной информацией, такой как пароли, OAuth-токены и ключи SSH. Вы можете развертывать и обновлять конфиденциальную информацию и конфигурацию приложения без изменений образов контейнеров и не раскрывая конфиденциальную информацию в конфигурации стека."
}
,{
  question: "Чем Kubernetes не является?",
  answer: "Kubernetes ― это не традиционная комплексная система PaaS (платформа как услуга). Поскольку Kubernetes работает на уровне контейнеров, а не на уровне оборудования, у него имеется определенные общеприменимые возможности, характерные для PaaS, такие как развертывание, масштабирование, балансировка нагрузки, ведение журналов и мониторинг. Тем не менее, Kubernetes это не монолитное решение, поэтому указанные возможности по умолчанию являются дополнительными и подключаемыми. У Kubernetes есть компоненты для создания платформы разработчика, но он сохраняет право выбора за пользователем и гибкость там, где это важно.Kubernetes:Не ограничивает типы поддерживаемых приложений. Kubernetes стремится поддерживать широкий спектр рабочих нагрузок, включая те, у которых есть или отсутствует состояние, а также связанные с обработкой данных. Если приложение может работать в контейнере, оно должно отлично работать и в Kubernetes.Не развертывает исходный код и не собирает приложение. Рабочие процессы непрерывной интеграции, доставки и развертывания (CI/CD) определяются культурой и предпочтениями организации, а также техническими требованиями.Не предоставляет сервисы для приложения, такие как промежуточное программное обеспечение (например, очереди сообщений), платформы обработки данных (например, Spark), базы данных (например, MySQL), кеши или кластерные системы хранения (например, Ceph), как встроенные сервисы. Такие компоненты могут работать в Kubernetes и/или могут быть доступны для приложений, работающих в Kubernetes, через переносные механизмы, такие как Open Service Broker.Не включает решения для ведения журнала, мониторинга или оповещения. Он обеспечивает некоторые интеграции в качестве доказательства концепции и механизмы для сбора и экспорта метрик.Не указывает и не требует настройки языка/системы (например, Jsonnet). Он предоставляет декларативный API, который может быть нацелен на произвольные формы декларативных спецификаций.Не предоставляет и не принимает никаких комплексных систем конфигурации, технического обслуживания, управления или самовосстановления.Кроме того, Kubernetes — это не просто система оркестрации. Фактически, Kubernetes устраняет необходимость в этом. Техническое определение оркестрации — это выполнение определенного рабочего процесса: сначала сделай A, затем B, затем C. Напротив,<br>Kubernetes содержит набор независимых, компонуемых процессов управления, которые непрерывно переводит текущее состояние к предполагаемому состоянию. Неважно, как добраться от А до С. Не требуется также централизованный контроль. Это делает систему более простой в использовании, более мощной, надежной, устойчивой и расширяемой."
}
,{
  question: "Что такое minikube?",
  answer: "Локальный кластер для знакомства с кубером, или для проверки каких-либо вещей."
}
,{
  question: "Приведи пример проблемы, которая упрощает работу именно с использованием кубернетеса?",
  answer: "Например, у нас есть три машины. На них запущены контейнеры.<br>И вдруг одна из машин встала с запущенными контейнерами. Или нужно машину перезапустить.<br>И контейнеры нужно переносить.В итоге нужно будет решать проблемы<br>Контейнеры могут быть связаны, и они должны быть на одной ноде. Значит и перенести нужно на другую ноду их, сохранив эту связанность. Связанность - это использование общих данных. Или активное взаимодействие между собой.Контейнеры не могут 'поместиться' на одном узле, и нужно думать а куда вот эти перевести и распределитьПри возвращении ноды в строй придётся возвращать все контейнеры. Снова нужно делать те же манипуляции."
}
,{
  question: "Что такое под (pod) Kubernetes?",
  answer: "Под — это сущность, которая состоит из одного или нескольких контейнеров (docker), размещённых на одном хосте и настроенных на совместное использование ресурсов сетевого стека и других ресурсов наподобие томов. Поды — это базовые строительные блоки, из которых построены приложения, работающие на платформе Kubernetes. Каждому Pod'у присваивается уникальный IP-адрес. Внутри Pod'а каждый контейнер использует общее пространство имен (namespace) сети, включая IP-адрес и сетевые порты.На практике это означает, что все контейнеры, входящие в состав пода, могут взаимодействовать друг с другом через localhost. Если в поде есть контейнер, в котором выполняется nginx, прослушивающий порт 80, и ещё один контейнер, в котором выполняется scrapyd, то этот контейнер может обратиться к первому контейнеру по адресу http://localhost:80."
}
,{
  question: "Почему в под должно быть как можно меньше контейнеров?",
  answer: "Pod'ы могут содержать несколько контейнеров, но вы должны ограничивать их количество, когда это возможно. Поскольку контейнеры масштабируются как единое целое, все контейнеры в паке должны масштабироваться вместе, независимо от их индивидуальных потребностей. Это приводит к потраченным впустую ресурсам и дорогому счету. Чтобы решить эту проблему, Pod'ы должны оставаться меньше на сколько это возможно, обычно вмещая только основной процесс и его тесно связанные вспомогательные контейнеры (эти вспомогательные контейнеры обычно называют Side-cars)."
}
,{
  question: "Как работает хранилище в под?",
  answer: "Pod может определить набор общих томов (volumes) для хранения данных. Контейнеры внутри Pod'а могут работать с этими томами и, таким образом, обмениваться данными между собой. Благодаря использованию томов, можно сохранить данные, если один из контейнеров Pod'а (которому нужны эти данные для корректной работы) должен быть перезапущен. Время жизни томов совпадает с временем жизни самого Pod'а."
}
,{
  question: "В чем разница между контейнером init и контейнером sidecar?",
  answer: "Самый простой дизайн модуля — это модуль с одним контейнером, который обслуживает основную функциональность модуля, но что, если вы хотите расширить существующую функциональность, не изменяя и не усложняя свой основной контейнер?<br>По этой причине в pods можно завернуть один контейнер или несколько. Существует шаблон проектирования контейнера, который полезен для различных сценариев, но строительные блоки для этих шаблонов проектирования реализованы с помощью контейнера инициализации и контейнера sidecar.<br>Контейнер Init — контейнеры Init всегда запускаются перед коляской и основным контейнером приложения. Контейнер Init должен быть запущен до успешного завершения, прежде чем смогут выполняться остальные контейнеры. Причиной использования контейнера Init может быть наличие универсальных опций. Например, его можно использовать для проверки наличия зависимостей приложения, настройки основной среды или среды контейнера sidecar и многого другого.<br>Контейнер sidecar — контейнер sidecar проходит параллельно основному контейнеру приложения. Причиной использования контейнера sidecar могут быть разные факторы. Например, в истории контейнер sidecar используется в качестве прокси-сервера для управления входящим трафиком для основного контейнера, его также можно использовать для ведения журнала, мониторинга и многого другого."
}
,{
  question: "В чем разница между подом и контейнером?",
  answer: "Под это минимальная единица куба. В котором есть контейнеры."
}
,{
  question: "Как создается под? Какие компоненты задействуются при его создании?",
  answer: "Предварительная информация. Воркер узлы состоят из трех компонентов. kubelet - это модуль коммуникации сервера с kubeapi.Он сообщает информацию о себе в куб апи. И принимает ее оттуда же. CRI - container runtime engine - штука, которая непосредственно создает контейнер. proxy kube server - нужен для взаимодействия узлов между собой, например, когда вычислительные мощности требуют задействовать более, чем один узел.Первое что задействуется - команда kubectl. Далее оно попадает на kubeAPI. KubeAPI - является основным компонентом управления кластером кубера.Далее kubeapi аутентифицирует и валидирует запрос. Проверит кто делает запрос, и проверит есть ли у запрашиваемого доступ к кластеру.Далее апи сервер запишет этот под в etcd. Etcd - это хранилище данных, которое распределено по кластеру, и является 'точкой правды' для кластера кубера. Далее etcd возвращает ответ в апи о том, что под создан. Но по факту пока что еще ничего не создано кроме записи в базе.<br>Далее в дело вступает планировщик, scheduler. Он следит за нагрузкой которую необходимо создать. Он определяет на какую ноду можно разместить тот или иной под. Он периодически опрашивает куб апи на предмет наличия задач. Шедулер создает поды на воркер узлах, и смотрит на доступные вычивлительные мощности, место и на ограничения. После того, как он определяет где можно создать подходящий под, он сообщает об этом в kubeAPI.kubeapi обращается в kubelet той ноды, на которую указал шедулер, как на подходящую. kubelet работает вместе с CRI, который создаст под, в котором работает контейнер."
}
,{
  question: "Может ли под запуститься на двух разных узлах?",
  answer: "Нет. Поскольку есть поле узел. И шедулер назначает какому поду куда ехать"
}
,{
  question: "Что означает версия api (apiVersion)?",
  answer: "v1<br>v2beta1<br>v3aplha1<br>extensions/v1/beta1Alpha-версии - отключены по умолчанию. Могут содержать баги. Поддержка может быть прекращена в любое время. И совместоимость с будущими не гарантируется. Не рекомендуется использовать в продакшене.Beta-версии включены по умолчанию. Хорошо протестированы. Поддержка не будет прекращена, но может быть разница в семантике. Если она меняется - будет инструкция по миграции. Не рекомендуется использовать в проде. Но можно в dev для тестирования фич.Стабильные версии API - готовы для продакшена. Совместимы с будущими версиями."
}
,{
  question: "Что такое kubectl?",
  answer: "С точки зрения пользователя, kubectl — панель управления, которая позволяет выполнять операции Kubernetes.<br>С технической точки зрения, kubectl — клиент Kubernetes API.<br>Kubernetes API — это HTTP REST API. Этот API — настоящий пользовательский интерфейс Kubernetes, через который он полностью контролируется. Это означает, что каждая операция Kubernetes представляется как конечная точка API и может быть выполнена HTTP-запросом к этой конечной точке.<br>Следовательно, основная задача kubectl — выполнять HTTP-запросы к API Kubernetes.<br>Kubernetes — полностью ресурсно-ориентированная система. Это означает, что он поддерживает внутреннее состояние ресурсов, и все операции Kubernetes являются операциями CRUD.<br>Вы полностью контролируете Kubernetes, управляя этими ресурсами, и Kubernetes выясняет, что делать, основываясь на текущем состоянии ресурсов. По этой причине ссылка на API Kubernetes организована в виде списка типов ресурсов со связанными с ними операциями."
}
,{
  question: "Что такое метки (labels) в kubernetes?",
  answer: "Метки — это пары ключ-значение, которые добавляются к объектам, как поды. Метки предназначены для идентификации атрибутов объектов, которые имеют значимость и важны для пользователей, но при этом не относятся напрямую к основной системе. Метки можно использовать для группировки и выбора подмножеств объектов. Метки могут быть добавлены к объектам во время создания и изменены в любое время после этого. Каждый объект может иметь набор меток в виде пары ключ-значение. Каждый ключ должен быть уникальным в рамках одного и того же объекта.<br>'metadata': {<br>'labels': {<br>'key1' : 'value1',<br>'key2' : 'value2'<br>}<br>}"
}
,{
  question: "Что такое Селекторы меток?",
  answer: "Метки не гарантируют уникальность. Поэтому мы предполагаем, что многие объекты будут иметь одинаковые метки.<br>С помощью селектора меток клиент/пользователь может идентифицировать набор объектов. Селектор меток — основное средство группировки в Kubernetes.<br>Селекторы меток позволяют выбрать подмножество модулей, помеченных определенными метками, и выполнять операцию на этих модулях. Селектор меток - это критерий, который фильтрует ресурсы на основе того, содержат они определенную метку с определенным значением или нет.Селектор меток может выбирать ресурсы в зависимости от того:содержит ли (или не содержит) ресурс метку с определенным ключом;содержит ли ресурс метку с определенным ключом и значением;содержит ли ресурс метку с определенным ключом, но со значением, не равным указанному вами."
}
,{
  question: "Что такое Аннотации Kubernetes?",
  answer: "Аннотации являются парами ключ-значение. Аннотации могут содержать большие фрагменты информации и в первую очередь предназначены для использования утилитами. Некоторые аннотации автоматически добавляются в объекты с помощью<br>Kubernetes, а другие добавляются пользователями вручную<br>Замечательное применение аннотаций - это добавление описаний для каждого модуля или другого объекта API, чтобы каждый, кто использует кластер, мог быстро найти информацию о каждом отдельном объекте.<br>Например:аннотация,используемая для указания имени пользователя, создавшего объект,Информация о сборке, выпуске или образе, например, метка времени, идентификаторы выпуска, ветка git, номера PRСсылки на репозитории логирования, мониторинга, аналитики или аудита."
}
,{
  question: "Что такое пространства имён Kubernetes?",
  answer: "Namespace можно рассматривать как виртуальный кластер внутри вашего кластера Kubernetes. Вы можете иметь несколько изолированных друг от друга пространств имен внутри одного кластера Kubernetes."
}
,{
  question: "Причины использования нескольких пространств имен?",
  answer: "Пространства имён применяются в окружениях с многочисленными пользователями, распределенными по нескольким командам или проектам. Пространства имён не нужно создавать, если есть кластеры с небольшим количеством пользователей (например, десяток пользователей). Пространства имён имеет смысл использовать, когда необходима такая функциональность.<br>Пространства имён определяют область имён. Имена ресурсов должны быть уникальными в пределах одного и того же пространства имён. Пространства имён не могут быть вложенными, а каждый ресурс Kubernetes может находиться только в одном пространстве имён.<br>Пространства имён — это способ разделения ресурсов кластера между несколькими пользователями<br>По умолчанию в будущих версиях Kubernetes объекты в одном и том же пространстве имён будут иметь одинаковую политику контроля доступа.<br>Не нужно использовать пространства имён только для разделения слегка отличающихся ресурсов, например, в случае разных версий одного и того же приложения. Используйте метки, чтобы различать ресурсы в рамках одного пространства имён.<br>По умолчанию в кластере Kubernetes будет создан неймспейс default, в котором и будут размещаться запускаемые объекты (поды, сервисы, развертывания и т.д.). Неймспейсы kube-public и kube-system используются для запуска служебных объектов Kubernetes, необходимых для корректной работы кластера."
}
,{
  question: "Что такое Контроллеры в Kubernetes?",
  answer: "Контроллеры — это общее название класса средств управления, которые следят за кластером и стараются поддерживать желаемое состояние. Есть несколько типов контроллеров, которые следят за ресурсами и делают это немного по-разному, например:Deployment — это описание желаемого состояния для подов; указание Kubernetes, как он должен управлять жизненным циклом подов. Поддерживает набор подов с нужной конфигурацией, управляет обновлениями и откатами. Самый распространенный способ разместить приложение в Kubernetes.ReplicaSet — создает стабильный набор подов, выполняющих одну и ту же задачу. Гарантирует, что всегда работает указанное число реплик подов. То есть если с каким-то подом что-то случится, Kubernetes запустит новый, чтобы число реплик оставалось заданным. Обычно это служебный объект, который Kubernetes создает сам.StatefulSet — используется для управления приложениями с отслеживанием состояния (Stateful-приложениями) с помощью постоянного хранилища.DaemonSet — гарантирует, что все или некоторые узлы запускают копию пода. То есть по мере добавления узлов в кластер добавляются поды.Job — недолговечные рабочие нагрузки, используемые для выполнения одной задачи. Job создает один или несколько подов и дождется, пока они выполнят свою работу.CronJob — создает задачи по расписанию."
}
,{
  question: "Как k8s поддерживает поды в здоровом состоянии?",
  answer: "Как только под назначен узлу, агент Kubelet на том самом узле запустит его контейнеры и с того момента будет поддерживать их в рабочем состоянии, пока под существует. Если происходит аварийный сбой главного процесса<br>контейнера, Kubelet перезапустит контейнер. Если ваше приложение имеет<br>ошибку, которая время от времени приводит к его падению, Kubernetes автоматически<br>его перезапустит, поэтому, даже не делая ничего особенного в самом приложении, запуск приложения в Kubernetes автоматически придает ему способность самоисцелиться.<br>Но иногда приложения перестают работать без падения их процесса. Например, приложение Java с утечкой памяти начнет выдавать ошибки из-за нехватки оперативной памяти, но процесс JVM будет продолжать работать. Kubernetes может проверить текущую работоспособность контейнера по средством проверок живучести (livenessProbe). Для каждого контейнера в спецификации модуля можно указать проверку живучести. Kubernetes будет периодически выполнять проверку и перезапускать контейнер в случае не сработки проверки.<br>Kubernetes может исследовать контейнер с помощью одного из трех механизмов:проверка HTTP GET выполняет запрос HTTP GET на IP-адрес, порт и путь контейнера, которые вы укажете. Если проверка получает отклик и код ответа не представляет ошибку (другими словами, если код отклика HTTP будет 2xx или 3xx), проверка считается сработавшей. Если сервер возвращает отклик с кодом ошибки или вообще не отвечает, то проверка считается несработавшей, и в результате контейнер будет перезапущен;проверка сокета TCP пытается открыть TCP подключение к указанному порту контейнера. Если подключение установлено успешно, то проверка сработала. В противном случае контейнер перезапускается;проверка Exec выполняет произвольную команду внутри контейнера и проверяет код состояния на выходе из команды. Если код состояния равен 0, то проверка выполнена успешно. Все остальные коды считаются<br>несработавшими.livenessProbe:<br>httpGet:<br>path: /<br>port: 8080"
}
,{
  question: "Почему при запуске под может начать автоматически перезагружаться?",
  answer: "Если вы не зададите первоначальную задержку, проверка начнет опробирование контейнера сразу же после его запуска, что обычно приводит к несработке проверки, так как приложение не готово к получению запросов. Если количество несработок превышает пороговое значение несработки, контейнер перезапускается, прежде чем он даже сможет начать откликаться на запросы должным образом.<br>Чтобы задать начальную задержку, добавьте в проверку живучести свойство initialDelaySeconds.livenessProbe:<br>httpGet:<br>path: /<br>port: 8080<br>initialDelaySeconds: 15"
}
,{
  question: "Что такое ReplicaSet?",
  answer: "ReplicaSet- это ресурс Kubernetes, который обеспечивает поддержание постоянной работы его pod. Если pod исчезает по любой причине, например в случае исчезновения узла из кластера или потому, что pod был вытеснен из узла, ReplicaSet замечает отсутствующий pod и создает сменный pod.<br>ReplicaSet постоянно отслеживает список запущенных pod и удостоверяется, что фактическое количество модулей определенному селектору меток всегда совпадает с требуемым числом. Если запущено слишком мало таких pod, то из шаблона pod создаются новые реплики. Если запущено слишком много таких pod, то он удаляет лишние реплики.<br>Как это может быть больше чем нужное количество реплик.<br>- кто-то создает pod того же типа вручную;<br>- кто-то изменяет метки существующего pod;<br>- кто-то уменьшает требуемое количество pod и т. д."
}
,{
  question: "Части ReplicaSet?",
  answer: "ReplicaSet состоит из трех основных частейселектор меток, определяющий, какие модули находятся в области действия контроллера репликации;количество реплик, указывающее на требуемое количество модулей, которые должны быть запущены;шаблон pod, используемый при создании новых реплик pod.Количество реплик ReplicaSet, селектор меток и даже шаблон pod могут быть изменены в любое время, но только изменения количества реплик влияют на то, как ведется работа с существующими модулями."
}
,{
  question: "Преимущества использования ReplicaSet?",
  answer: "- он гарантирует, что pod (или несколько реплик pod) всегда работает путем запуска нового pod, когда существующий пропадает;<br>- когда узел кластера аварийно завершает работу, он создает сменные реплики для всех pod, которые работали на отказавшем узле (которые находились под управлением ReplicaSet);<br>- обеспечивает простое горизонтальное масштабирование модулей - как<br>  ручное, так и автоматическое"
}
,{
  question: "Что будет если поменять селектор меток в ReplicaSet?",
  answer: "Изменения в селекторе меток и шаблоне podне влияют на существующие pod. Изменение селектора меток приводит к выпадению существующих pod из области действия ReplicaSet, поэтому ReplicaSet перестает о них заботиться. ReplicaSet также не заботятся о фактическом «содержимом» своих pod (образах контейнеров, переменных среды и других аспеках) после создания модуля. Таким образом, шаблон влияет только на новые pod, создаваемые этим ReplicaSet. Эту процедуру можно представить как форму для печенья для вырезания новых pod."
}
,{
  question: "Что отличаеться ReplicaSet от ReplicationController?",
  answer: "ReplicaSet - это следующее поколение Replication Controller. Единственная разница между ReplicaSet и Replication Controller - это поддержка селектора. ReplicaSet поддерживает множественный выбор в селекторе, тогда как Replication Controller поддерживает в селекторе только выбор на основе равенстваIn - значение метки должно совпадать с одним из указанных значений<br>values;NotIn - значение метки не должно совпадать с любым из указанных зна-<br>чений values;Exists - модуль должен содержать метку с указанным ключом (значение не важно). При использовании этого оператора не следует указывать поле values;DoesNotExist - модуль не должен содержать метку с указанным ключом.<br>Свойство values не должно быть указано."
}
,{
  question: "Что такое DaemonSet ?",
  answer: "DaemonSet гарантирует, что все (или некоторые) узлы запускают копию Pod. Когда узлы добавляются в кластер, к ним добавляются Pod'ы. Когда узлы удаляются из кластера, эти Pod'ы удаляются. Удаление DaemonSet приведет к очистке созданных им Pod'овНекоторые типичные применения DaemonSet:запуск демона кластерного хранилища, такого как glusterd, ceph, на каждом узле.запуск демона сбора журналов на каждом узле, таком как fluentd или logstash.запуск демона мониторинга узла на каждом узле, таком как экспортер узлов Prometheus, агент Sysdig, collectd, Dynatrace OneAgent, агент AppDynamics, агент Datadog, агент New Relic, агент Ganglia gmond или агент Instana.В простом случае один DaemonSet, охватывающий все узлы, будет использоваться для каждого типа демона. Более сложная установка может использовать несколько DaemonSets для одного типа демона, но с разными флагами и/или разными запросами памяти и процессора для разных типов оборудования."
}
,{
  question: "DaemonSet зачем нужен для чего его обычно используют?",
  answer: "У него широкое распространение. Нужен для сбора логов по разным нодам. Логи как-то надо собирать. Сертификаты нод. Смотреть через демонсет можно такие штуки"
}
,{
  question: "Что такое Job?",
  answer: "Одноразовая задача. Создает один или несколько подов, и ожидает их успешного завершения. Если что-то завершается с ошибкой, то джоб бдует запускать новые копии, пока количество успешных выполнений не будет равно заданному (или нет, смотря как настроено).<br>Job полезны для нерегулярных задач, где крайне важно, чтобы задача закончилась правильноТиповые примеры:<br>Запуск тестов<br>Применение миграций базы данных<br>Выполнение одноразовых скриптовНастройки<br>completions - Успешное выполнение сколько раз нужно чтоб выполнились задачи<br>parallelism - Параллельные запуски - контейнеры будут подниматься, одновременно выполняться. Если 1, то друг за дружкой выполняться<br>Backofflimit - максимальное количество попыток. Джоб после этого не будет пытаться что-то делать. И новых контейнеров не создаёт.<br>activeDeadlineSecond - таймлайны для джобы. Больше ничего создаваться не будет.<br>ttlSecondsAfterFinished - максимальное время жизни завершенного джоба. Нужна для того, чтобы человек мог успеть посмотреть результат. В контейнере логи глянуть например.<br>restartPolicy - регулируем перезапускать или нет. Но самому контейнеру за этим следить не надо. Поэтому Never"
}
,{
  question: "Что такое CronJob?",
  answer: "Абстракция, которая автоматически создаёт поды по расписанию. Расписание задаётся в крон-формате. В настроенное время Kubernetes создаст ресурс Job в соответствии с шаблоном задания, настроенным в объекте CronJob. При создании ресурса Job будут созданы одна или несколько реплик модуля и запущены в соответствии с шаблоном модуля ресурса Job.Применение:<br>Рассылки писем, уведомлений<br>Бэкапы<br>Выполнение задач в менее нагруженное время"
}
,{
  question: "Что такое service в Kubernetes?",
  answer: "Служба Kubernetes - это ресурс, который вы создаете, чтобы сформировать единую постоянную точку входа в группу pod, предоставляющих одну и ту же службу. Каждая служба имеет IP-адрес и порт, которые никогда не меняются до тех пор, пока существует служба. Клиенты могут открывать подключения к этому IP-адресу и порту, а затем маршрутизировать эти подключения в один из pod, поддерживающих эту службу. Благодаря этому клиентам службы не требуется знать расположение отдельных pod, предоставляющих службу, что позволяет перемещать данные модули по кластеру в любое время."
}
,{
  question: "Как service находит pod?",
  answer: "Service не связываются с pod напрямую. Вместо этого посередине находится ресурс конечных точек (Endpoints). Ресурс Endpoints (да, конечные точки во множественном числе) - это список IP-адресов и портов, предоставляющих доступ к службе<br>Несмотря на то что селектор pod определен в поле спецификации service, он не используется непосредственно при перенаправлении входящих подключений. Вместо этого селектор используется для построения списка IP-адресов и портов, который затем хранится в ресурсе конечных точек. Когда клиент подключается к service, служебный прокси выбирает одну из этих пар IP-адресов и портов и перенаправляет входящее подключение на<br>сервер, прослушивающий в этом месте."
}
,{
  question: "Перечислите различные типы serviсe и для чего они используются?",
  answer: "Служба Kubernetes — это логическая абстракция группы модулей, выбранных селектором. Служба используется для настройки политики, с помощью которой можно получить доступ к базовым площадкам.ClusterIP — является типом сервиса по умолчанию и наиболее распространенным сервисом в экосистеме Kubernetes. Служба кластерного IP-адреса имеет внутренний кластерный IP-адрес и доступна только изнутри кластера.LoadBalancer — тип службы LoadBalancer используется для доступа к внешнему трафику путем выделения loadbalancer. Чтобы использовать этот тип сервиса, необходима поддерживающая платформа, которая сможет распределять балансировщик нагрузки. Балансировщик нагрузки будет создан асинхронно, и информация о балансировщике нагрузки будет доступна в службе, когда она будет доступна и назначена службе. Тип службы балансировки нагрузки также имеет ClusterIP и выделяет порт узла для доступа.NodePort — тип службы NodePort обычно используется, когда вы хотите предоставить службе доступ к внешнему трафику из кластера, а тип службы LoadBalancer недоступен. С типом службы NodePort вы выбираете порт (в пределах допустимого диапазона от 3000 до 32767), который каждый узел в кластере будет предоставлять для приема трафика и пересылки службе. Тип службы порта узла также имеет ClusterIP, который позволяет службе быть доступной из кластера.Headless — тип обслуживания Headless используется, когда требуется прямая связь с модулем. Например, в приложениях с отслеживанием состояния в качестве баз данных вторичные модули должны напрямую взаимодействовать с первичными блоками для репликации данных между репликами. Headless позволяет DNS разрешать базовые pod'ы и получать к ним доступ по имени pod. Headless — это сервис, у которого нет настройки ClusterIP. Пример доступа к pod через Headless службу будет следующим: <pod-name>.<service-name>.<namespace>.svc.cluster.local"
}
,{
  question: "Что такое Ingress?",
  answer: "Kubernetes Ingress - это ресурс для добавления правил маршрутизации трафика из внешних источников в службы в кластере kubernetes.Вы должны создать правила Ingress в том же пространстве имен, в котором развернуты службы. Вы не можете направлять трафик на службу в другом пространстве имен, где у вас нет Ingress объекта.Ingress объект требует ingress controller для маршрутизации трафика.Внешний трафик не будет попадать на Ingress API, вместо этого он будет попадать на службу ingress controllerIngress Controller состоит из 2х компонентов — реверсивного прокси и контроллера который общается с API сервером кубернетеса. Реверсивный прокси слушает входящий трафик на портах которые указаны в настройках (обычно в настройках по умолчанию указан только порт 80). Контроллер может быть как отдельным демоном (как в nginx), так и встроенным в прокси (как в traefik).<br>Не все клауд провайдеры кубернетеса предустанавливают Ingress Controller по умолчанию.<br>Контроллеры могут запускаться либо как DaemonSet либо как Deployment. DaemonSet идеально использовать как единственный Ingress Controller, что бы реверсивное прокси слушало на всех IP адресах воркеров. Deployment отлично подходит если перед Ingress контроллером стоит балансировщик — от провайдера кубернетиса (GKE, AKS), MetalLB если онпремис или обычный haproxy/nginx установленный на сервере (требутеся ручная настройка). При этой установке возможно установить несколько Ingress Controller."
}
,{
  question: "Через что реализованы сети в kubernetes?",
  answer: "Кубер для реализации сетей использует различные плагины CNI (Container Networking Interface). Наиболее известные flannel и calico.<br>Пример получения IP используя flannel: Kube-controller-manager каждому узлу присваивает podCIDR. Pod'ы каждого узла получают IP-адреса из пространства адресов в выделенном диапазоне podCIDR. Поскольку podCIDR'ы узлов не пересекаются, все pod'ы получают уникальные IP-адреса. Во время старта агент сетевого провайдера генерирует конфиг CNI. Когда pod планируется на узел, kubelet вызывает CRI-плагин для его создания. Далее, если используется containerd, плагин Containerd CRI вызывает CNI-плагин, указанный в конфиге CNI, для настройки сети pod'а. В результате pod получает IP-адрес.Плюсы использования calico<br>поддерживает network policies"
}
,{
  question: "Проверка готовности pod в kubernetes?",
  answer: "При запуске контейнера система Kubernetes может быть настроена на ожидание заданного периода времени перед выполнением первой проверки готовности. После этого она периодически вызывает проверку и действует на основании результата проверки готовности. Если pod сообщает, что он не готов, он удаляется из службы. Если модуль потом становится готовым, он снова добавляется.<br>В отличие от проверок живучести, если контейнер не проходит проверку<br>готовности, он не убивается и не перезапускается. В этом состоит важное различие между проверками живучести и готовности. Проверки живучести поддерживают модули здоровым, убивая нездоровые контейнеры и заменяя их новыми, здоровыми, тогда как проверки готовности гарантируют, что запросы получают только те модули, которые готовы их обслуживать. Это главным образом необходимо во время исходного запуска контейнера, но также полезно после того, как контейнер проработал некоторое время."
}
,{
  question: "В чем важность проверок готовности?",
  answer: "Представьте, что группа pod (например, pod, на которых работают<br>серверы приложений) зависит от службы, предоставляемой другим модулем<br>(например, бэкенд-базой данных). Если в какой-то момент один из фронтенд-pod испытывает проблемы с подключением и больше не может достичь базы данных, может оказаться разумным, чтобы его проверка готовности отправила сигнал в Kubernetes, что модуль пока не готов обслуживать любые запросы. Если другие экземпляры модуля не испытывают такого же типа проблем с подключением, они могут обслуживать запросы обычным образом. Проверка готовности удостоверяет, что клиенты коммуницируют только со здоровыми модулями и никогда не заметят, что с системой что-то не так."
}
,{
  question: "Что такое Readiness, Liveness, Startup пробы, какое отличие?",
  answer: "Kubelet использует Liveness пробу для проверки, когда перезапустить контейнер. Например, Liveness проба должна поймать блокировку, когда приложение запущено, но не может ничего сделать. В этом случае перезапуск приложения может помочь сделать приложение доступным, несмотря на баги.<br>Kubelet использует Readiness пробы, чтобы узнать, готов ли контейнер принимать траффик. Pod считается готовым, когда все его контейнеры готовы.<br>Одно из применений такого сигнала - контроль, какие Pod будут использованы в качестве бекенда для сервиса. Пока Pod не в статусе ready, он будет исключен из балансировщиков нагрузки сервиса.<br>Kubelet использует Startup пробы, чтобы понять, когда приложение в контейнере было запущено. Если проба настроена, он блокирует Liveness и Readiness проверки, до того как проба становится успешной, и проверяет, что эта проба не мешает запуску приложения. Это может быть использовано для проверки работоспособности медленно стартующих контейнеров, чтобы избежать убийства kubelet'ом прежде, чем они будут запущены."
}
,{
  question: "Что такое DNS?",
  answer: "Система доменных имен DNS — это система связи различных типов информации, например связи IP адресов с легко запоминающимися именами. По умолчанию большинство кластеров Kubernetes автоматически настраивают внутреннюю службу DNS в качестве компактного механизма поиска служб. Встроенная система обнаружения служб позволяет приложениям легко находить друг друга и взаимодействовать друг с другом на кластерах Kubernetes, даже в случае создания подов и служб, их удаления и перемещения между узлами."
}
,{
  question: "Что предоставляет служба Kubernetes DNS?",
  answer: "Создается служба с именем kube-dns и один или несколько подов.Служба kube-dns прослушивает события службы и события конечных точек через Kubernetes API и обновляет записи DNS по мере необходимости. Эти события активируются при создании, обновлении или удалении служб Kubernetes и связанных с ними подов.kubelet задает опцию /etc/resolv.conf nameserver для каждого нового пода как IP-адрес кластера службы kube-dns с соответствующими опциями поиска, позволяющими использовать более короткие имена хостов:nameserver 10.32.0.10<br>search namespace.svc.cluster.local svc.cluster.local cluster.local<br>options ndots:5Работающие в контейнерах приложения могут разрешать такие имена хостов как example-service.namespace в корректные IP-адреса кластера."
}
,{
  question: "Какие объекты получают DNS-имена?",
  answer: "Каждому сервису, определенному в кластере (включая сам DNS-сервер), присваивается имя DNS. По умолчанию в список поиска DNS клиентского Pod'а будет входить собственное пространство имен Pod'а и домен кластера по умолчанию. Это лучше всего иллюстрируется примером:<br>Предположим, что сервис называется foo в пространстве имен Kubernetes bar. Pod, работающий в пространстве имен bar, может найти этот сервис, просто выполнив DNS-запрос для foo. Pod, работающий в пространстве имен quux, может найти этот сервис, выполнив DNS-запрос для foo.bar."
}
,{
  question: "Что такое Volume?",
  answer: "Volume - это абстракция файлового хранилища.<br>Решает следующие основные проблемы:Файловая ситема контейнера существует только до его удаления или перезапускаНекоторым контейнерам нужно общее пространство для хранения файлов, или для обращения к конфигурационным файлам.Изолирует приложение от технологий хранения данныхЖивет только с подом"
}
,{
  question: "Какие бывают типы файловых хранилищ?",
  answer: "1) emptyDir<br>   Каталог, который создается до пода, и и живет пока под не будет удален. Все контейнеры в нем могут читать данные из этого volume.<br>   В качестве системы хранения - используется файловая система узла.<br>   При сбое в работе пода и его дальнейшего самовосстановления (перезапуска), данные из этого volume не удаляются. Если под был удален администратором и затем был автоматически перезапущен, данные из volume будут удалены.Обычно используется для:<br>Размещения кеш файлов.Данных, которые необходимо сохранить при сбое в работе контейнера.Обмена файлами между несколькими контейнерами в под.2) hostPath<br>   В hostpath папка на узле уже существует, и подключается к подам. Данные не пропадают после удаления пода.<br>   В случае с emptyDir создается папка, подмонтируется. Если под падает - данные пропадают.<br>   Используется для случаев, когда под отслеживает состояние узла. Предоставляется доступ к системным каталогам<br>   Также там есть ключи DirectoryOrCreate и FileOrCreate - они нужны для задачи кубернетесу проверить наличие папки, и потом обращение к файлу.<br>   Используется, когда необходимо предоставить доступ к локальной файловой системе. Например, к логам приложений в /var/log. Не поддерживают управление правами доступа или перемаркировку SELinux.<br>   Файлы на хостах доступны для записи только подам, запущенным с правами пользователя root. Если контейнер будет запускаться с правами другого пользователя, вы должны заранее позаботиться об установке необходимых прав на файл или директории."
}
,{
  question: "Что такое configMap?",
  answer: "ConfigMaps это API объект, который используется для хранение неконфиценциальных параметров типа ключ значение.<br>Использование конфигмапов (ConfigMaps) позволяет разделять конфигурационные файлы и контейнеры с приложениями, избавляя от необходимости упаковывать конфиги в docker-образ.<br>configMap применяется для:<br>Создание конфигурационных файлов или любых других не пустых файлов.Определения большого количества переменных среды окружения контейнера.Содержимое configMap хранится в базе etcd. Поэтому не имеет смысл использовать его для больших бинарных файлов.Поды могут использовать значения оттуда несколькими способами:<br>Конф файлы, подключаемые как volumes<br>Через Переменные окружения<br>Через Параметры запуска контейнеров"
}
,{
  question: "Что такое Secret?",
  answer: "Объект, который содержит конфиденциально важное значение. (пароль, токен, ключ).<br>Хранение важных параметров в виде секретов более безопасно и гибко, чем включение их в конфигурацию пода или в образы контейнеров. Для использования секрета поду необходимо указать его.Секрет может использоваться следующими способами:Файл подключенный через volume контейнера.Значение переменной окруженияkubelet использует секреты для подключения к апи серверу, для загрзки образов из докер регистри"
}
,{
  question: "Что такое PersistentVolume, PersistentVolumeClaim?",
  answer: "Это способ хранить данные между перезапусками контейнеров.<br>Контейнеры по своей природе непостоянные сущности. Они могут быть в любой момент уничтожены или перезапущены. Идея контейнеров в том, что они легко «умирают» и появляются заново при необходимости. Поэтому любые постоянные данные нужно хранить где-то вне контейнера. Но контейнеры изолированы от основной системы — это сделано для безопасности. Приложения не могут напрямую получить доступ к файловой системе. Также часто для отказоустойчивости создается несколько экземпляров контейнеров, и это порождает новую проблему: нужно как-то синхронизировать данные между репликами.<br>Kubernetes решает эти проблемы с помощью Persistent Volume. Это абстракция над хранилищами данных, которая позволяет хранить данные в зависимости от жизни контейнеров. Это постоянные тома, жизненный цикл которых никак не связан с подами и контейнерами. PV — это самостоятельные ресурсы, которые создаются и управляются отдельно.<br>Для работы с PV используются два ресурса: PersistentVolume и PersistentVolumeClaim1) PersistentVolume — это место, где хранятся постоянные данные: раздел на жестком диске, облачное хранилище или распределенная файловая система (CephFS, NFS и др.). Жизненный цикл PV не зависит какого-то отдельного контейнера или пода. Если контейнер или под уничтожается, PV остается.2) PersistentVolumeClaim — это запрос на использование хранилища. Под отправляет этот запрос в PV с просьбой выделить ему место в постоянном хранилище. Storage Provisioner (специальная программа, которую запускает Kubernetes) оценивает запрос и принимает решение, где лучше выделить место, ведь PV может быть несколько и они могут быть разных типов. Когда решение найдено, PVC выделяет место и возвращает результат поду.Такой подход позволяет приложениям абстрагироваться от конкретной реализации хранилища. Вместо того чтобы запрашивать конкретное хранилище по конкретному адресу, приложения просто запрашивают PVC, как бы говоря: «Мне нужно 1GB для моих данных». А PersistentVolume уже сам определяет, где находится это хранилище, и резервирует место для пода.<br>При этом сами хранилища не создаются автоматически. Для начала нужно определить, какое это хранилище и где оно будет находиться, создать его. Потом создать соответствующий ресурс в Kubernetes и подключить его к хранилищу. Если запускать Kubernetes On-premise, то внедрение и обслуживание постоянного хранилища — дополнительная головная боль.Типы доступа у PVC:<br>ReadWriteOnce - том может быть смонтирован на чтение и запись к одному поду<br>ReadOnlyMany - том может быть смонтирован на много подов в режиме реального времени<br>ReadWriteMany - том может быть смонтирован к множеству подов в режиме чтения и записи"
}
,{
  question: "Что такое Deployment ?",
  answer: "Развертывание Deployment - это ресурс более высокого уровня, предназначенный для развертывания приложений и их обновления декларативным образом, вместо того чтобы делать это через ReplicaSet, которые рассматриваются как более низкоуровневые понятия.<br>Когда вы создаете развертывание, под поверхностью создается ресурс<br>ReplicaSet (а в итоге несколько таких ресурсов). Наборы репликаций точно так же реплицируют и управляют pod. При использовании развертывания фактические модули создаются и управляются наборами реплик объекта Deployment, а не непосредственно объектом Deployment.<br>При обновлении приложения необходимо вводить дополнительный контроллер репликации и координировать два контроллера, чтобы они могли танцевать вокруг друг друга, не наступая друг другу на ноги. И поэтому требуется что-то, что координирует этот танец. Ресурс Deployment заботится именно об этом (не сам ресурс развертывания, а процесс контроллера, запущенный в плоскости управления Kubernetes, который это делает)."
}
,{
  question: "Стратегии Deployment?",
  answer: "Стратегия воссоздания Recreate приводит к удалению всех старых моду-<br>лей перед созданием новых. Используйте эту стратегию, если приложение не<br>поддерживает параллельного выполнения нескольких версий и требует пол-<br>ной остановки старой версии перед запуском новой. Эта стратегия включает<br>в себя короткий период времени, когда ваше приложение станет полностью<br>недоступным.Стратегия RollingUpdate, с другой стороны, удаляет старые модули один за<br>другим, одновременно добавляя новые, сохраняя приложение доступным на<br>протяжении всего процесса и гарантируя отсутствие падения его способно-<br>сти обрабатывать запросы. Эта стратегия принята по умолчанию. Верхний и<br>нижний пределы количества модулей выше или ниже требуемого количества<br>реплик поддаются конфигурированию. Эту стратегию следует использовать<br>только в том случае, если приложение может одновременно работать как со<br>старой, так и с новой версией.Стратегия Blue/Green<br>Стратегия сине-зеленого развертывания (иногда ее ещё называют red/black, т.е. красно-чёрной) предусматривает одновременное развертывание старой (зеленой) и новой (синей) версий приложения. После размещения обеих версий обычные пользователи получают доступ к зеленой, в то время как синяя доступна для QA-команды для автоматизации тестов через отдельный сервис или прямой проброс портов. После того, как синяя (новая) версия была протестирована и был одобрен ее релиз, сервис переключается на неё, а зеленая (старая) сворачивается"
}
,{
  question: "Что произойдет после обновления шаблона pod в deployment (kubectl set image deployment)?",
  answer: "Изменив шаблон модуля в ресурсе развертывания, вы обновили приложение до более новой версии - изменив одно единственное поле!<br>Контроллеры, работающие в составе плоскости управления Kubernetes, затем<br>выполнили обновление."
}
,{
  question: "Как сделать откат deployment?",
  answer: "Вы можете откатиться к определенной ревизии, указав ревизию в команде undo<br>kubectl rollout undo deployment"
}
,{
  question: "В чем отличие Deployment от Replicaset?",
  answer: "Deployment упрощает обновление модулей до какой-то определенной или новой версии. Допустим, у нас есть набор подов из ReplicaSet-A, чтобы выкатить новую версию нужно создать Replicaset-B. При этом нужно уменьшить Replicaset-A и увеличить Replicaset-B на один шаг несколько раз. То есть выполнить последовательное обновление.<br>А deployment может это делать автоматически. И просто добавляет еще одну абстракцию.<br>Иными словами - deployment просто выполняет непрерывное обновление с использованием наборов реплик."
}
,{
  question: "В чем разница между развертыванием и набором с сохранением состояния?",
  answer: "Развертывание (Deployment) — является самым простым и наиболее часто используемым ресурсом для развертывания приложений в кластере Kubernetes. Развертывания обычно используются для приложений без состояния, что означает, что данные, находящиеся в модуле, будут удалены вместе с модулем. Если мы используем постоянное хранилище при развертывании, у нас будет одна заявка на постоянный объем для всех модулей, которые принимают участие в развертывании. Развертывания оборачивают ресурс набора реплик, позволяя ему легко переключаться между версиями. Соглашение об именовании модуля настроено следующим образом <deployment-name>-<replicaset-id>-<pod-id>.<br>Statefulset — ресурс, который стал стабильным в версии Kubernetes 1.9, поскольку сообщество запросило возможность размещения приложений с отслеживанием состояния в кластере Kubernetes. Statefulset не использует Replicaset в качестве вторичного контроллера, но он управляет блоками самостоятельно. Соглашение об именовании модулей выглядит следующим образом <Statefulset-name>-0, <Statefulset-name>-1.<br>Соглашение об именовании используется для сетевых идентификаторов и управления обновлением. Statefulset требует безголовой службы, позволяющей идентифицировать сеть и разрешать DNS для модулей, участвующих в Statefulset. Каждая реплика в развертывании Statefulset получает свое собственное утверждение о постоянном томе, так что каждый модуль будет иметь свое собственное состояние.<br>Наконец, эмпирическое правило заключается в том, что приложения без состояния должны развертываться вместе с развертываниями. Развертывания включают в себя другой контроллер, называемый Replicaset, для упрощения обновления и отката. Statefulset был создан исходя из потребностей сообщества и обычно используется для приложений с отслеживанием состояния в качестве баз данных, где идентификация других реплик в кластере имеет решающее значение, и обновления должны выполняться корректно."
}
,{
  question: "Что такое приложения с сохранением состояния?",
  answer: "Это приложения, которые сохраняют данные и помогают их отслеживать. Все базы данных, в частности, MySQL, Oracle и PostgreSQL - это примеры приложений, сохраняющих состояние. С другой стороны, в приложениях без сохранения состояния данные долго не держатся. Примеры приложений без сохранения состояния — Node.js и Nginx. Если состояние в приложении не сохраняется, то на каждый запрос приложение будет получать новые данные и обрабатывать их.<br>В современных веб-приложениях такие приложения без сохранения состояния соединяются с приложениями, сохраняющими состояние, чтобы обслужить пользовательский запрос. Приложение Node.js не сохраняет состояние, оно получает новые данные при каждом запросе, поступающем от пользователя. Далее это приложение соединяется для обработки данных с другим, сохраняющим состояние, например, с базой данных MySQL. База данных MySQL сохраняет данные и продолжает их обновлять, исходя из пользовательского запроса."
}
,{
  question: "Что такое StatefulSet?",
  answer: "StatefulSet - это контроллер Kubernetes, применяемый для эксплуатации сохраняющих состояние приложений в виде контейнеров (подов) в кластере Kubernetes. StatefulSet присваивают каждому поду идентификатор-липучку (sticky identity) - порядковый номер начиная с нуля — а не случайные ID каждой реплике пода. Новый под создается клонированием данных уже существовавшего пода. Если ранее существовавший под находился в ожидающем состоянии, то новый под создан не будет. Удаление подов происходит в обратном порядке, а не в случайном. Например, если у вас было четыре реплики, и в результате масштабирования их количество было сокращено до трех, то под номер 3 будет удален."
}
,{
  question: "Когда использовать StatefulSets?",
  answer: "Есть несколько причин, по которым может быть целесообразно использовать StatefulSets. Рассмотрим два примера:Допустим, вы развернули базу данных MySQL в кластере Kubernetes и масштабировали ее до трех реплик, а клиентское приложение пытается получить доступ к кластеру MySQL, чтобы считывать и записывать данные. Запрос на считывание будет переадресовываться на три пода. Однако запрос на запись будет переадресовываться только на первый (ведущий) под, а записанные сюда данные будут синхронизироваться с другими подами. Это достижимо при помощи StatefulSets.Если удалить StatefulSet или отмасштабировать вниз, то не будут удалены тома, связанные с приложением, сохраняющим состояние. Так вашим данным обеспечивается безопасность. Если удалить или перезапустить под с MySQL, то вы сможете обращаться к данным из все того же тома, что и раньше."
}
,{
  question: "Что такое Nodes (Ноды, узлы)?",
  answer: "Это виртуальные или физические серверы, на которых работает Kubernetes. Они бывают двух типов:Master (мастер-нода) — узел, который управляет всем кластером. Он следит за остальными нодами и распределяет между ними нагрузку. Как правило, мастер-нода занимается только управлением и не берет на себя никакие рабочие нагрузки. Для повышения отказоустойчивости мастер-нод должно быть несколько.Worker (рабочие ноды) — узлы, на которых и работают контейнеры. На одном узле может работать много контейнеров в зависимости от параметров ноды (объем памяти и CPU) и требований контейнера.Рабочих узлов обычно больше, чем мастер-нод. Потенциально чем их больше, тем большее количество приложений можно запустить и тем отказоустойчивее будет кластер, потому что в случае выхода из строя одной ноды нагрузка переносится на другие."
}
,{
  question: "Каковы компоненты плоскости управления Kubernetes и их назначение?",
  answer: "Узлы плоскости управления Kubernetes являются 'мозгом' кластерных операций Kubernetes. Они управляют блоками в кластере и рабочими узлами, которые принимают участие в кластере.<br>Плоскость управления Kubernetes состоит из четырех компонентов в кластере Kubernetes on-prem и пяти в облачных/гибридных кластерах Kubernetes. Как администраторы кластера, мы хотели бы иметь по крайней мере три узла плоскости управления в производственной среде по соображениям безопасности.<br>Kube-api-server — сервер API Kubernetes проверяет и настраивает данные для объектов API, включая модули, службы, контроллеры репликации и другие. Сервер API обслуживает операции REST и предоставляет интерфейс для общего состояния кластера, через который взаимодействуют все остальные компоненты.<br>Kube-controller-manager — диспетчер контроллеров Kubernetes. Он встраивает основные контуры управления, поставляемые с Kubernetes. В приложениях робототехники и автоматизации контур управления — это непрерывный контур, который регулирует состояние системы. Примерами контроллеров, которые сегодня поставляются с Kubernetes, являются контроллер репликации, контроллер конечных точек, контроллер пространства имен и контроллер service accounts.<br>Kube-scheduler — Планировщик Kubernetes - это процесс плоскости управления, который назначает модули узлам. Планировщик определяет, какие узлы являются допустимыми местами размещения для каждого модуля в очереди планирования в соответствии с ограничениями и доступными ресурсами. Затем планировщик ранжирует каждый допустимый узел и привязывает модуль к подходящему узлу. Планировщика может быть несколько.<br>Etcd — распределенное, согласованное хранилище ключей и значений с открытым исходным кодом для совместной настройки, обнаружения служб и координации планировщика распределенных систем или кластеров машин. В плоскости управления Kubernetes Etcd используется для хранения и репликации всех состояний кластера Kubernetes.<br>Cloud-controller-manager (используется у облачных провайдеров) — Cloud-controller-manager обеспечивает интерфейс между кластером Kubernetes и API облачных сервисов. Диспетчер облачных контроллеров позволяет кластеру Kubernetes предоставлять, отслеживать и удалять облачные ресурсы, необходимые для работы кластера.<br>В сценарии, когда большинство узлов плоскости управления не работают, кластер не сможет обслуживать запросы API, и кластер будет недоступен. Хотя, если рабочие узлы исправны, модули будут продолжать работать, но не смогут перепланировать."
}
,{
  question: "Каковы компоненты рабочего узла и их назначение?",
  answer: "Рабочие узлы отвечают за размещение модулей приложений в кластере. Хотя прикладные модули можно размещать в узлах плоскости управления, наилучшей практикой является планирование модулей на рабочих узлах по соображениям безопасности. Рабочие узлы содержат компоненты, которые позволяют им выполнять запросы плоскости управления.Kube-proxy — kube-proxy отвечает за поддержание сетевых правил на ваших узлах. Сетевые правила позволяют осуществлять сетевую связь с вашими модулями как внутри, так и за пределами вашего кластера.Kubelet — это агент, который запускается на каждом узле. Он отвечает за создание модулей в соответствии с предоставленной спецификацией YAML, отправку на сервер API состояния работоспособности модулей и предоставление информации о состоянии узла, такой как сеть, дисковое пространство и многое другое."
}
,{
  question: "Компоненты Kubernetes?",
  answer: "1) Компоненты плоскости управления(Control Plane)<br>   Плоскость управления - это то, что управляет и заставляет весь кластер<br>   функционировать.Плоскость управления состоит из следующих компонентов:<br>- распределенное постоянное хранилище etcd;<br>- API server (API-сервер);<br>- планировщик (Scheduler);<br>- менеджер контроллеров (Controller Manager).<br>  Эти компоненты сохраняют и управляют состоянием кластера, но они не<br>  запускают контейнеры приложений.2) Компоненты, работающие на рабочих узлах<br>   Задача запуска контейнеров зависит от компонентов, работающих на каждом<br>   рабочем узле:<br>- агент Kubelet;<br>- служебный прокси Kubernetes (kube-proxy);<br>- среда выполнения контейнеров (Docker, rkt или др.).3) Дополнительные компоненты<br>   Помимо компонентов плоскости управления и компонентов, работающих<br>   на узлах, для обеспечения всего, что обсуждалось до сих пор, кластеру необходимо иметь несколько дополнительных компонентов. Они включают:<br>- DNS-сервер Kubernetes;<br>- панель управления (Dashboard);<br>- Контроллер Ingress;<br>- компонент Heapster;<br>- сетевой плагин контейнерного сетевого интерфейса."
}
,{
  question: "Как Kubernetes использует хранилище etcd?",
  answer: "Все объекты, которые вы создавали - Pod, ReplicaSet, Service, и т. д. - должны храниться где-то постоянно, чтобы их манифесты выдерживали перезапуски и аварийные сбои сервера API. Для этого Kubernetes использует хранилище etcd, которое представляет собой быстрое, распределенное и согласованное хранилище в формате ключ-значение. Поскольку хранилище etcd является распределенным, для обеспечения высокой доступности и повышения производительности вы можете запускать несколько его экземпляров.<br>Единственным компонентом, который напрямую взаимодействует с хранилищем etcd, является сервер API Kubernetes. Все остальные компоненты читают и записывают данные в хранилище etcd косвенно через сервер API. Это приносит немного преимуществ, среди которых более устойчивая система оптимистической блокировки, а также валидация; и, абстрагируя фактический механизм хранения от всех других компонентов, его гораздо проще заменить в будущем. Стоит подчеркнуть, что хранилище etcd является единственным местом, где Kubernetes хранит состояние кластера и метаданные"
}
,{
  question: "Что делает сервер API (API server)?",
  answer: "Сервер API Kubernetes является центральным компонентом, используемым всеми другими компонентами и клиентами, такими как kubectl. Он предоставляет интерфейс CRUD (Create, Read, Update, Delete) для запросов и изменения состояния кластера через API RESTful. Он хранит это состояние в хранилище etcd.<br>В дополнение к обеспечению согласованного способа хранения объектов в хранилище etcd он также выполняет валидацию этих объектов, так что клиенты не могут хранить в нем неправильно сконфигурированные объекты (что они могли бы, если бы они писали в хранилище напрямую). Наряду с валидацией он также занимается оптимистической блокировкой, поэтому в случае одновременных обновлений изменения объекта никогда не переопределяются другими клиентами."
}
,{
  question: "Как сервер API уведомляет клиентов об изменениях ресурсов?",
  answer: "Сервер API ничего не делает, кроме того что мы обсуждали. Например, он<br>не создает модули при создании ресурса ReplicaSet и не управляет конечными<br>точками службы. Этим занимаются контроллеры в менеджере контроллеров.<br>Но сервер API даже не говорит этим контроллерам, что делать. Он лишь позволяет этим контроллерам и другим компонентам наблюдать за изменениями в развернутых ресурсах. Компонент плоскости управления может запросить уведомление при создании, изменении или удалении ресурса. Это позволяет компоненту выполнять любую задачу, необходимую в ответ на изменение метаданных кластера. Клиенты следят за изменениями, открывая соединение HTTP с сервером API. Через это соединение клиент будет получать поток изменений в наблюдаемых объектах. При каждом обновлении объекта сервер отправляет новую версию объекта всем подключенным клиентам, наблюдающим за объектом."
}
,{
  question: "Что делает Scheduler(планировщик)?",
  answer: "Вы обычно не указываете, на каком узле кластера должен работать pod. Эта работа оставлена на усмотрение планировщика. Издалека работа планировщика выглядит простой. Вся его работа заключается в том, чтобы на основе реализованного в сервере API механизма наблюдения ждать вновь созданных pod и назначать узел для каждого нового pod, для которого узел еще не был задан.<br>Планировщик не предписывает выбранному узлу (или агенту Kubelet, работающему на этом узле) запускать модуль. Планировщик лишь обновляет определение pod через сервер API. Затем сервер API уведомляет Kubelet (опять же, через механизм наблюдения, описанный ранее) о том, что pod назначен. Как только агент Kubelet на целевом узле увидит, что модуль назначен на его узел, он создает и запускает контейнеры модуля.<br>Каждому Pod'у требуются определенные ресурсы: память, CPU, железо... в общем, стандартный набор. Планировщик должен решить, какой узел соответствует требованиям Pod'а. Поэтому планировщик выполняет два действия:<br>1 Подбирает узлы-кандидаты для Pod'а;<br>2 Останавливает свой выбор на одном из них."
}
,{
  question: "Что делает Controller manager?",
  answer: "Как отмечалось ранее, сервер API ничего не делает, кроме того что хранит ресурсы в хранилище etcd и уведомляет клиентов об изменении. Планировщик только назначает узел модулю, поэтому, для того чтобы убедиться, что фактическое состояние системы сходится к желаемому состоянию, как указано в ресурсах, развернутых через сервер API, вам нужны другие активные компоненты. Эта работа выполняется контроллерами, работающими в менеджере контроллеров.<br>Единый процесс менеджера контроллеров в настоящее время объединяет множество контроллеров, выполняющих различные задачи согласования. В конечном итоге эти контроллеры будут разделены на отдельные процессы, что позволит при необходимости заменять каждый из них собственной реализацией. Список этих контроллеров включает:<br>- контроллер репликации (контроллер для ресурсов ReplicationController);<br>- контроллер набора реплик ReplicaSet, набора демонов DaemonSet и за-<br>  дания Job;<br>- контроллер ресурса развертывания Deployment;<br>- контроллер набора модулей с внутренним состоянием StatefulSet;<br>- контроллер узла;<br>- контроллер службы Service;<br>- контроллер конечных точек Endpoints;<br>- контроллер пространства имен Namespace;<br>- контроллер постоянного тома PersistentVolume;<br>- другие.<br>  То, что делает каждый из этих контроллеров, должно быть видно из его имени. По этому списку вы можете сказать, что почти для каждого ресурса есть свой контроллер, который вы можете создать. Ресурсы - это описания того, что должно выполняться в кластере, тогда как контроллеры - это активные компоненты Kubernetes, которые выполняют фактическую работу в результате развертывания ресурсов."
}
,{
  question: "Что делают контроллеры, и как они это делают?",
  answer: "Контроллеры делают много разных вещей, но все они наблюдают за изменениями ресурсов (развертываниями, службами и т. д.) на сервере API и выполняют операции для каждого изменения, будь то создание нового объекта или обновление или удаление существующего объекта. В большинстве случаев эти операции включают создание других ресурсов или обновление самих отслеживаемых ресурсов (например, для обновления состояния объекта).<br>Как правило, контроллеры выполняют цикл согласования, который согласовывает фактическое состояние с требуемым состоянием (указанным в секции spec ресурса) и записывают новое фактическое состояние в секцию status ресурса. Для того чтобы получать уведомления об изменениях, контроллеры используют механизм наблюдения, но поскольку использование наблюдений не гарантирует, что контроллер не пропустит событие, они также периодически выполняют операцию запроса списка, чтобы убедиться, что они ничего не пропустили.<br>Контроллеры никогда не обмениваются друг с другом напрямую. Они даже не знают, что существуют другие контроллеры. Каждый контроллер подключается к серверу API через механизм наблюдения, запрашивает об уведомлении, когда в списке ресурсов любого типа, за который отвечает контроллер, происходит изменение."
}
,{
  question: "Что делает контроллер ReplicaSet?",
  answer: "Cервер API уведомлять клиентов через механизм наблюдения, ясно, что контроллер не опрашивает pod в каждой итерации, а вместо этого уведомляется механизмом наблюдения о каждом изменении, которое может повлиять на требуемое количество реплик или количество совпавших pod. Любые такие изменения инициируют<br>контроллер перепроверять требуемое количество с фактическим количеством реплик и действовать соответственно.<br>Когда выполняется слишком мало экземпляров pod, ReplicaSet запускает дополнительные экземпляры. Но на самом деле он не управляет ими сам. Он создает новые манифесты модулей, отправляет их на сервер API и поручает планировщику и агенту Kubelet выполнить свою работу по назначению модуля узлу и запуску модуля.<br>Менеджер репликации выполняет свою работу, управляя объектами API<br>pod через сервер API. Так работают все контроллеры."
}
,{
  question: "Что делает контроллер Deployment?",
  answer: "Контроллер развертывания Deployment обеспечивает синхронизацию фактического состояния развертывания с требуемым состоянием, указанным в соответствующем объекте API Deployment.<br>Контроллер развертывания Deployment выполняет развертывание новой версии каждый раз при изменении объекта развертывания (если изменение должно повлиять на развернутые pod). Это делается путем создания реплик, а затем соответствующего масштабирования как старой, так и новой реплик на основе стратегии, указанной в развертывании. Масштабирование выполняется до тех пор, пока все старые pod не будут заменены новыми. Оно не создает никаких pod напрямую."
}
,{
  question: "Что делает контроллер StatefulSet?",
  answer: "Контроллер набора StatefulSet, создает, управляет и удаляет pod в соответствии со спецификацией ресурса StatefulSet. Но, в отличие от других контроллеров, которые лишь управляют модулями, контроллер набора StatefulSet также создает экземпляры и управляет заявками PersistentVolumeClaim для каждого экземпляра pod."
}
,{
  question: "Что делает контроллер Node?",
  answer: "Контроллер узла управляет ресурсами узла, которые описывают рабочие узлы кластера. Помимо прочего, контроллер узла синхронизирует список объектов Node с фактическим списком машин, работающих в кластере. Он также отслеживает работоспособность каждого узла и удаляет pod из недоступных узлов. Контроллер узла не является единственным компонентом, вносящим изменения в объекты Node. Они также изменяются посредством агента Kubelet и, безусловно, могут также изменяться пользователями через вызовы API REST."
}
,{
  question: "Что делает контроллер Service?",
  answer: "Cуществует несколько различных типов служб. Одной из них была служба LoadBalancer, которая запрашивает из инфраструктуры подсистему балансировки нагрузки, чтобы сделать службу доступной извне. Контроллер службы запрашивает и освобождает подсистему балансировки нагрузки из инфраструктуры при создании<br>или удалении службы типа LoadBalancer."
}
,{
  question: "Что делает контроллер Endpoints?",
  answer: "Cлужбы не связаны непосредственно с pod, а содержат список конечных точек (IP-адресов и портов), который создается и обновляется вручную или автоматически в соответствии с селектором модулей, определенным в службе. Контроллер конечных точек Endpoints является активным компонентом, который постоянно обновляет список конечных точек IP-адресами и портами модулей, соответствующих селектору меток.<br>Этот контроллер наблюдает и за службами, и за pod. Когда службы добавляются или обновляются, или pod добавляются, обновляются или удаляются, он выбирает модули, соответствующие селектору модуля службы, и добавляет их IP-адреса и порты в ресурс конечных точек. Напомним, что объект Endpoints является автономным объектом, поэтому контроллер создает его по мере необходимости. Кроме того, он также удаляет объект конечных точек при удалении службы."
}
,{
  question: "Что делает контроллер PersistentVolume?",
  answer: "Как только пользователь создает заявку PersistentVolumeClaim, система Kubernetes должна найти соответствующий постоянный том PersistentVolume и привязать его к заявке. Это выполняется контроллером постоянного тома.<br>Когда возникает заявка PersistentVolumeClaim, контроллер находит наилучшее соответствие для заявки, выбирая наименьший постоянный том с режимом доступа, соответствующим тому, который запрошен в заявке и объявленной емкости выше емкости, запрошенной в заявке. Он делает это, сохраняя упорядоченный список постоянных томов для каждого режима доступа по возрастанию емкости и возвращая первый том из списка.<br>Затем, когда пользователь удаляет заявку PersistentVolumeClaim, том отсоединяется и освобождается в соответствии с политикой освобождения тома (остается как есть, удаляется или очищается)."
}
,{
  question: "Что делает агент Kubelet?",
  answer: "Если говорить коротко, агент Kubelet - это компонент, отвечающий за все, что выполняется на рабочем узле. Его первоначальная задача - зарегистрировать узел, на котором он работает, путем создания ресурса узла на сервере API. Затем он должен непрерывно отслеживать сервер API для pod, которые были назначены на этот узел, и запускать контейнеры pod. Он это делает, поручая сконфигурированной среде выполнения контейнеров (то есть платформе Docker, CoreOS платформы rkt или чему-то еще) запустить контейнер из конкретного образа контейнера. Затем агент Kubelet постоянно отслеживает запущенные контейнеры и сообщает об их статусе, событиях и потреблении ресурсов серверу API.<br>Агент Kubelet также является тем компонентом, который выполняет проверки живучести контейнеров, перезапуская контейнеры, когда проверки не срабатывают. Наконец, он завершает работу контейнеров, когда их модуль удаляется из сервера API, и уведомляет сервер о том, что модуль прекратил работу."
}
,{
  question: "Что делает kube-proxy?",
  answer: "Кроме агента Kubelet, каждый рабочий узел также выполняет сетевой прокси kube-proxy, цель которого - убедиться, что клиенты могут подключаться к службам, которые вы определяете посредством API Kubernetes. Сетевой прокси kube-proxy гарантирует, что подключения к IP-адресу и порту службы в итоге окажутся в одном из модулей, привязанных к службе (или других, не модульных, конечных точках службы). Когда служба поддерживается несколькими модулями, прокси выполняет балансировку нагрузки между этими pod"
}
,{
  question: "Аутентификация в k8s",
  answer: "В Kubernetes есть два типа пользователей:Service Accounts — аккаунты, управляемые Kubernetes API;Users — «нормальные» пользователи, управляемые внешними, независимыми сервисами.Основное отличие этих типов в том, что для Service Accounts существуют специальные объекты в Kubernetes API (они так и называются — ServiceAccounts), которые привязаны к пространству имён и набору авторизационных данных, хранящихся в кластере в объектах типа Secrets. Такие пользователи (Service Accounts) предназначены в основном для управления правами доступа к Kubernetes API процессов, работающих в кластере Kubernetes.<br>Обычные же Users не имеют записей в Kubernetes API: управление ими должно осуществляться внешними механизмами. Они предназначены для людей или процессов, живущих вне кластера.<br>Каждый запрос к API привязан либо к Service Account, либо к User, либо считается анонимным."
}
,
    ];

    const questionText = document.getElementById('question-text');
    const answerText = document.getElementById('answer-text');
    const modal = document.getElementById('modal');
    const modalAnswer = document.getElementById('modal-answer');

    function toggleAnswer() {
        const answer = questions[currentQuestionIndex].answer;
        if (answer.length > MAX_ANSWER_LENGTH) {
            showModal(answer);
        } else {
            if (answerText.classList.contains('hidden')) {
                answerText.innerHTML = answer;
                answerText.classList.remove('hidden');
                questionText.classList.add('hidden');
            } else {
                answerText.classList.add('hidden');
                questionText.classList.remove('hidden');
            }
        }
    }

    function showModal(answer) {
        modalAnswer.innerHTML = answer;
        modal.classList.remove('hidden');
    }

    function showQuestion(index) {
        questionText.textContent = questions[index].question;
        answerText.innerHTML = ""; // Скрываем ответ при смене вопроса
        questionText.classList.remove('hidden');
        answerText.classList.add('hidden');
    }

    function nextQuestion() {
        if (currentQuestionIndex < questions.length - 1) {
            currentQuestionIndex++;
            showQuestion(currentQuestionIndex);
        }
    }

    function prevQuestion() {
        if (currentQuestionIndex > 0) {
            currentQuestionIndex--;
            showQuestion(currentQuestionIndex);
        }
    }

    function closeModal() {
        modal.classList.add('hidden');
    }

    showQuestion(currentQuestionIndex);
</script>

</body>
</html>
