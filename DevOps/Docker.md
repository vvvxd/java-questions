#### Контейнеризация vs. Виртуализация

Обе технологии предназначены для изоляции приложений и их зависимостей, но они работают на разных уровнях системной архитектуры.

**Виртуальная машина (VM): Абстракция на уровне аппаратного обеспечения.**

* **Как это работает:** На физическом сервере устанавливается специальное программное обеспечение — **гипервизор** (например, VMware ESXi,
  KVM, Hyper-V). Задача гипервизора — эмулировать полноценный набор виртуального оборудования (виртуальный CPU, RAM, сетевую карту, диски)
  для каждой VM.
* **Структура:** Поверх этого виртуального оборудования устанавливается полноценная, немодифицированная **гостевая операционная система (
  Guest OS)** со своим собственным, независимым **ядром (kernel)**. Уже внутри этой гостевой ОС устанавливаются библиотеки, бинарные файлы и
  само приложение.
* **Последствия:**
    * **Высокие накладные расходы:** Каждая VM несет в себе полную копию ОС и ядра. Если у вас 10 VM, у вас работает 10 лишних ядер ОС,
      которые потребляют значительные ресурсы (CPU, RAM, дисковое пространство) еще до запуска самого приложения.
    * **Медленный запуск:** Запуск VM — это полноценный процесс загрузки операционной системы, который может занимать минуты.
    * **Большой размер:** Образы VM измеряются в гигабайтах, так как содержат всю ОС.
    * **Сильная изоляция:** Изоляция происходит на уровне эмуляции железа. Критическая ошибка или kernel panic в одной гостевой ОС никак не
      затронет гипервизор или другие VM.

**Контейнер: Абстракция на уровне операционной системы.**

* **Как это работает:** На сервере установлена одна **хостовая операционная система (Host OS)**. Поверх нее работает **движок
  контейнеризации** (например, Docker Engine). Движок использует существующие возможности **ядра хостовой ОС** (в основном, Namespaces и
  Cgroups в Linux) для создания изолированных сред для процессов.
* **Структура:** Контейнер содержит **только приложение и его зависимости** (библиотеки, конфигурационные файлы). Он **не включает в себя
  ядро ОС**. Все процессы внутри контейнера напрямую обращаются к ядру хостовой системы через системные вызовы, как и любой другой процесс
  на хосте, но ядро "обманывает" их, предоставляя изолированное представление системных ресурсов.
* **Последствия:**
    * **Минимальные накладные расходы:** Нет дублирования ОС. Все контейнеры делят одно ядро хоста. Потребление ресурсов близко к нативному
      запуску процесса.
    * **Быстрый запуск:** Запуск контейнера — это, по сути, запуск нового процесса в хостовой ОС, но в изолированном пространстве. Это
      занимает секунды или доли секунды.
    * **Малый размер:** Образы контейнеров измеряются в мегабайтах, так как содержат только необходимое приложению.
    * **Сильная, но иная изоляция:** Изоляция обеспечивается программно на уровне ядра. Она достаточна для большинства приложений, но
      критическая уязвимость в ядре хоста потенциально может затронуть все контейнеры.

**Ключевое различие:** VM виртуализирует железо, чтобы запустить несколько ОС. Контейнер виртуализирует ОС, чтобы запустить несколько
приложений на одной ОС.

---

###  Неизменяемость (Immutability)

Это основной принцип, обеспечивающий предсказуемость и воспроизводимость в Docker.

**Техническая основа: Слоистая файловая система (Layered Filesystem)**

* **Образ (Image):** Образ Docker — это не монолитный блок, а набор слоев, доступных **только для чтения (read-only)**. Каждый слой
  представляет собой результат выполнения одной из инструкций в `Dockerfile` (например, `COPY`, `RUN`, `ADD`).
    * Пример: `RUN apt-get install -y curl` создает новый слой, содержащий все файлы, которые были добавлены или изменены в файловой системе
      в результате выполнения этой команды.
    * Эта слоистая структура позволяет эффективно хранить и передавать образы. Если несколько образов основаны на одном и том же базовом
      образе (например, `ubuntu:22.04`), эти базовые слои хранятся на диске только один раз и переиспользуются.

**Механизм Copy-on-Write (CoW)**

* **Контейнер (Container):** Когда вы запускаете контейнер из образа (`docker run`), Docker Engine выполняет следующие действия:
    1. Берет все read-only слои образа.
    2. Добавляет поверх них один новый, тонкий **записываемый слой (writable layer)**. Этот слой уникален для каждого контейнера.

* **Как происходят изменения:**
    * **Чтение файла:** Процесс в контейнере запрашивает файл. Поиск идет сверху вниз по слоям. Файл считывается из первого слоя, где он был
      найден.
    * **Создание нового файла:** Файл создается непосредственно в верхнем записываемом слое.
    * **Изменение существующего файла:** Если процесс пытается изменить файл, который находится в одном из нижних read-only слоев,
      срабатывает механизм **Copy-on-Write**. Движок контейнеризации перехватывает операцию, копирует исходный файл из read-only слоя в
      верхний writable-слой, и все дальнейшие изменения применяются уже к этой копии. Оригинальный файл в образе остается **неизменным**.
    * **Удаление файла:** Вместо реального удаления файла из read-only слоя, в writable-слое создается специальный маркер ("whiteout" файл),
      который скрывает нижележащий файл, делая его недоступным для контейнера.

**Гарантии, которые дает неизменяемость:**

1. **Консистентность:** Любой запуск контейнера из одного и того же образа гарантирует абсолютно идентичное начальное состояние среды.
2. **Воспроизводимость:** Вместо отладки и исправления работающего контейнера ("stateful mutation"), принят подход удаления сбойного
   контейнера и запуска нового из того же чистого образа. Это делает развертывание и откат атомарными и предсказуемыми операциями.

---

### Изоляция

Изоляция в Docker — это не эмуляция, а использование встроенных в ядро Linux механизмов для разделения системных ресурсов. Два основных
инструмента для этого — **пространства имен (Namespaces)** и **контрольные группы (cgroups)**.

**1. Пространства имен (Namespaces): Обеспечивают "ВИДИМОСТЬ"**

Namespaces позволяют создать для процесса иллюзию того, что он имеет свою собственную, эксклюзивную копию глобальных системных ресурсов.

* **PID (Process ID) Namespace:** Изолирует дерево процессов. Процесс внутри контейнера видит только другие процессы в том же контейнере.
  Его главный процесс обычно имеет PID 1. Он не может видеть или посылать сигналы процессам хоста или других контейнеров.
* **NET (Network) Namespace:** Изолирует сетевой стек. Каждый контейнер получает свой собственный набор сетевых интерфейсов, свой IP-адрес,
  свою таблицу маршрутизации и собственное пространство портов. Именно поэтому несколько контейнеров могут слушать один и тот же порт (
  например, 80) без конфликтов.
* **MNT (Mount) Namespace:** Изолирует точки монтирования файловой системы. Корень файловой системы (`/`) внутри контейнера — это файловая
  система, собранная из слоев его образа, а не корень хостовой системы. Это предотвращает несанкционированный доступ к файлам хоста.
* **UTS (UNIX Timesharing System) Namespace:** Изолирует `hostname` и `domainname`. Это позволяет каждому контейнеру иметь свое уникальное
  имя хоста.
* **IPC (Inter-Process Communication) Namespace:** Изолирует системные объекты для межпроцессного взаимодействия (семафоры, очереди
  сообщений, разделяемая память).
* **User Namespace:** Изолирует идентификаторы пользователей и групп (UID/GID). Это позволяет запускать процесс в контейнере с
  правами `root` (UID 0), в то время как на хост-системе этот процесс будет выполняться от имени непривилегированного пользователя с высоким
  UID. Это критически важный механизм безопасности для предотвращения "побега из контейнера".

**2. Контрольные группы (cgroups): Обеспечивают "РЕСУРСЫ"**

Если namespaces определяют, *что* процесс может видеть, то cgroups определяют, *сколько* ресурсов он может использовать.

* **Функция:** cgroups позволяют ограничивать и измерять потребление системных ресурсов (CPU, память, дисковый ввод-вывод, сетевой трафик)
  для группы процессов.
* **Применение в Docker:** Когда вы запускаете контейнер с флагами `--memory=1g` или `--cpus=2`, Docker Engine использует cgroups, чтобы
  ядро Linux принудительно ограничило потребление памяти и процессорного времени для всех процессов этого контейнера. Это гарантирует, что
  один "прожорливый" контейнер не сможет монополизировать все ресурсы и нарушить работу хоста или других контейнеров.

Отлично, давайте разберем ключевые компоненты Docker углубленно, технически и без аналогий. Мы сосредоточимся на том, *что* это и *как* оно
работает на самом деле.

---

#### Dockerfile: Рецепт для создания образа

Dockerfile — это текстовый файл, содержащий последовательность команд (инструкций), которые Docker-демон выполняет для автоматической сборки
образа. Каждая инструкция в Dockerfile создает новый слой в образе.

**Основные инструкции:**

* **`FROM <image>:<tag>`**
    * **Что это:** Самая первая инструкция в любом Dockerfile (за исключением `ARG`). Она определяет базовый образ, на основе которого будут
      строиться последующие слои. Это может быть минималистичный образ ОС (например, `ubuntu:22.04`, `alpine:3.18`) или образ с уже
      предустановленным ПО (например, `python:3.11-slim`, `node:18`).
    * **Как работает:** Docker загружает указанный образ (если его нет локально) и использует его файловую систему как основу для всех
      дальнейших изменений.

* **`RUN <command>`**
    * **Что это:** Выполняет любую команду в командной оболочке внутри образа *во время сборки*. Используется для установки пакетов,
      компиляции кода, создания директорий и т.д.
    * **Как работает:** `RUN` создает новый слой поверх предыдущего. Docker запускает временный контейнер из предыдущего слоя, выполняет в
      нем указанную команду, а затем фиксирует изменения файловой системы (новые, измененные, удаленные файлы) в виде нового слоя. Временный
      контейнер после этого удаляется.

* **`COPY <src>... <dest>` и `ADD <src>... <dest>`**
    * **Что это:** Инструкции для копирования файлов и директорий с хост-машины (из "контекста сборки") в файловую систему образа.
    * **Разница (критически важно):**
        * **`COPY`:** Прямолинейное копирование. Копирует локальные файлы и директории из `<src>` в `<dest>` внутри образа. Это
          предпочтительный и более предсказуемый вариант в 99% случаев.
        * **`ADD`:** Обладает двумя дополнительными возможностями:
            1. Если `<src>` является URL-адресом, `ADD` скачает файл по этому адресу и поместит его в `<dest>`.
            2. Если `<src>` является локальным `.tar` архивом (в различных форматах сжатия: gzip, bzip2, xz), `ADD` автоматически распакует
               его содержимое в `<dest>`.
    * **Рекомендация:** Всегда используйте `COPY`, если вам не нужна специфическая функциональность `ADD` (скачивание по URL или
      авто-распаковка). Это делает ваш Dockerfile более явным и безопасным.

* **`CMD` vs `ENTRYPOINT`**
    * Обе инструкции определяют команду, которая будет выполнена при запуске контейнера. Их различие и совместное использование — ключевой
      аспект.
    * **`CMD` ["executable","param1","param2"]` (exec форма, предпочтительная)** или `CMD command param1 param2` (shell форма)
        * **Назначение:** Задает *команду по умолчанию* и/или её параметры.
        * **Поведение:** Если пользователь при запуске контейнера (`docker run <image> some-other-command`) указывает другую команду, `CMD`
          полностью игнорируется.
    * **`ENTRYPOINT` ["executable","param1","param2"]` (exec форма, предпочтительная)**
        * **Назначение:** Конфигурирует контейнер так, чтобы он всегда запускался как *конкретное исполняемое приложение*.
        * **Поведение:** Команда `ENTRYPOINT` не переопределяется так же легко. Все, что передается в `docker run <image> ...` после имени
          образа, будет добавлено в конец `ENTRYPOINT` в качестве аргументов.
    * **Совместное использование (лучшая практика):**
        * `ENTRYPOINT` используется для указания основной команды.
        * `CMD` используется для указания *параметров по умолчанию* для этой команды.
        * **Пример:**
          ```dockerfile
          ENTRYPOINT ["ping"]
          CMD ["localhost"]
          ```
            * `docker run my-image` выполнит `ping localhost`.
            * `docker run my-image google.com` выполнит `ping google.com`. `CMD` был переопределен, а `ENTRYPOINT` остался.

* **`WORKDIR /path/to/workdir`**
    * **Что это:** Устанавливает рабочую директорию для всех последующих инструкций (`RUN`, `CMD`, `ENTRYPOINT`, `COPY`, `ADD`). Если
      директория не существует, она будет создана.
    * **Зачем:** Избавляет от необходимости писать `RUN cd /app && ...`. Это более чистое и надежное решение.

* **`EXPOSE <port>`**
    * **Что это:** Инструкция-метаданные. Она информирует Docker о том, что контейнер *прослушивает* указанный сетевой порт во время
      выполнения.
    * **Важно:** `EXPOSE` **не публикует** порт на хост-машине. Это просто документация для пользователя и для других инструментов. Чтобы
      сделать порт доступным извне, нужно использовать флаг `-p` или `-P` при запуске `docker run`.

* **`ENV <key>=<value>`**
    * **Что это:** Устанавливает переменную окружения. Эта переменная доступна как во время сборки (для последующих `RUN`), так и во время
      выполнения контейнера.

* **`ARG <name>[=<default value>]`**
    * **Что это:** Определяет переменную, которую пользователь может передать во время сборки с помощью флага `--build-arg <name>=<value>`.
    * **Отличие от `ENV`:** `ARG` существует **только во время сборки**. После того как образ собран, этой переменной в нем нет. Исключение:
      если `ENV` инициализируется значением `ARG`, то эта переменная сохранится.

* **`VOLUME ["/path/in/container"]`**
    * **Что это:** Создает точку монтирования с указанным именем. Docker будет управлять данными в этой директории отдельно от жизненного
      цикла контейнера. Если при запуске контейнера для этого пути не будет подключен volume, Docker автоматически создаст анонимный volume
      и примонтирует его.

---

**Многостадийные сборки (Multi-stage builds)**

* **Проблема:** В образе для production-окружения часто оказываются ненужные инструменты сборки (компиляторы, SDK, dev-зависимости), что
  делает образ большим и менее безопасным.
* **Решение:** Использование нескольких инструкций `FROM` в одном Dockerfile. Каждая `FROM` начинает новую "стадию" сборки.
* **Как работает:**
    1. **Первая стадия (сборщик):** Используется полный образ (например, `golang:1.20` или `node:18`) для компиляции приложения, сборки
       статики, установки зависимостей. Этой стадии можно дать имя с помощью `as builder`.
    2. **Вторая стадия (финальная):** Начинается с чистого, минимального базового образа (например, `alpine` или `distroless`).
    3. **Копирование артефактов:** С помощью `COPY --from=builder /path/to/artifact /destination/path` мы копируем *только* результат
       сборки (скомпилированный бинарный файл, папку `dist` и т.д.) из первой стадии в финальную.
* **Результат:** Итоговый образ содержит только необходимое для запуска приложения, его размер может уменьшиться в 10-100 раз.

---

**Кэширование слоев**

* **Как работает:** При выполнении `docker build` Docker проходит по инструкциям Dockerfile. Для каждой инструкции он проверяет, есть ли уже
  в его локальном кэше слой, сгенерированный этой же инструкцией на основе того же родительского слоя.
    * Для `RUN` "той же инструкцией" означает, что текст команды не изменился.
    * Для `COPY` и `ADD` Docker вычисляет контрольную сумму файлов, которые копируются. Если контрольная сумма не изменилась, кэш
      используется.
* **Пробитие кэша:** Как только Docker доходит до инструкции, для которой кэш не может быть использован (например, изменился копируемый
  файл), он выполняет эту инструкцию и **все последующие инструкции заново**, не используя кэш.
* **Оптимизация:** Располагайте инструкции в порядке от наименее изменяемых к наиболее изменяемым.
    * **Плохо:** `COPY . .` в начале, а потом `RUN apt-get install ...`
    * **Хорошо:** `RUN apt-get install ...` (устанавливается один раз), потом `COPY package.json .` и `RUN npm install` (выполняется только
      при изменении зависимостей), и только в конце `COPY . .` (выполняется при каждом изменении кода).

---

**.dockerignore**

* **Что это:** Файл в корне контекста сборки, синтаксис которого аналогичен `.gitignore`.
* **Назначение:** Указывает Docker-демону, какие файлы и директории из контекста сборки **не нужно** отправлять демону перед началом сборки.
* **Польза:**
    1. **Ускорение сборки:** Уменьшает размер контекста, который передается по сети (или через сокет) демону. Особенно актуально для папок
       вроде `node_modules` или `.git`.
    2. **Размер образа:** Предотвращает случайное попадание ненужных файлов в образ через `COPY . .`.
    3. **Безопасность:** Предотвращает попадание в образ секретов, ключей, конфигурационных файлов для локальной
       разработки (`.env`, `id_rsa` и т.д.).

---

#### Образы (Images) и Слои (Layers)

* **Образ (Image):** Это неизменяемый (read-only) шаблон, состоящий из упорядоченного набора слоев файловой системы. Он содержит все
  необходимое для запуска приложения: код, рантайм, библиотеки, переменные окружения и конфигурационные файлы.
* **Слои (Layers):** Каждый слой — это результат выполнения одной инструкции в Dockerfile. Технически, слой представляет собой набор
  изменений относительно предыдущего слоя (добавленные, измененные, удаленные файлы). Слои неизменяемы. Если вы в одном слое добавили файл,
  а в следующем его удалили, файл все еще будет существовать в предыдущем слое, но будет невидим в итоговой файловой системе. Это объясняет,
  почему образы могут быть большими, даже если вы удаляете файлы.

**Union File System (e.g., OverlayFS)**

* **Что это:** Технология, которая позволяет Docker "складывать" несколько файловых систем (слоев) одна на другую и представлять их как
  единую, целостную файловую систему. OverlayFS является самой распространенной реализацией в современных версиях Docker.
* **Как работает:**
    1. **`lowerdir`:** Все слои образа, доступные только для чтения, объединяются в один `lowerdir`.
    2. **`upperdir`:** Когда создается контейнер, поверх `lowerdir` добавляется пустой слой для записи, называемый `upperdir`.
    3. **`merged`:** OverlayFS представляет пользователю и процессам внутри контейнера объединенное представление (`merged`), которое
       является результатом наложения `upperdir` на `lowerdir`.

    * **Чтение:** Если процесс читает файл, OverlayFS ищет его сначала в `upperdir`. Если не находит, ищет в `lowerdir`.
    * **Запись/Изменение:** Это и есть **Copy-on-Write (CoW)**. Когда процесс пытается изменить файл, который существует только
      в `lowerdir` (в слое образа), происходит следующее:
        1. Файл копируется из `lowerdir` в `upperdir`.
        2. Все последующие изменения этого файла происходят уже с копией в `upperdir`.
           Оригинальный файл в слое образа (`lowerdir`) остается нетронутым.
* **Эффект:** Создание контейнера происходит почти мгновенно, так как не нужно копировать всю файловую систему образа. Создается лишь тонкий
  пустой слой для записи.

---

#### Контейнеры (Containers)

* **Что это:** Запущенный экземпляр образа. Технически, это процесс (или группа процессов), изолированный от хост-системы и других
  контейнеров с помощью механизмов ядра Linux (namespaces и cgroups). Ключевое отличие от образа — наличие **writable layer** (того
  самого `upperdir` из OverlayFS) поверх неизменяемых слоев образа.
* **Жизненный цикл:**
    * `docker create`: Создает контейнер (включая его writable layer), но не запускает его.
    * `docker start`: Запускает выполнение основной команды (`ENTRYPOINT`/`CMD`) в уже созданном контейнере.
    * `docker stop`: Отправляет процессу в контейнере сигнал `SIGTERM` (просьба завершиться корректно), а после таймаута — `SIGKILL` (
      принудительное завершение).
    * `docker rm`: Удаляет остановленный контейнер, включая его writable layer. **Все данные, записанные в этот слой, безвозвратно теряются.
      **
* **Эфемерность:** Это фундаментальное свойство контейнеров. Они рассматриваются как временные, одноразовые сущности. Если вам нужно
  сохранить данные после остановки и удаления контейнера, вы не должны хранить их в его writable layer. Для этого существуют механизмы
  хранения.

---

#### Хранение данных (Volumes & Bind Mounts)

* **Volumes:**
    * **Что это:** Специальная директория, управляемая Docker, которая хранится на хост-машине (обычно в `/var/lib/docker/volumes/` для
      Linux), но ее жизненный цикл не связан с жизненным циклом какого-либо конкретного контейнера.
    * **Преимущества:** Это **предпочтительный способ** хранения постоянных данных. Volumes можно создавать, удалять, бэкапить и переносить
      независимо от контейнеров. Они более производительны для операций ввода-вывода, чем запись в writable layer.
* **Bind Mounts:**
    * **Что это:** Прямое "пробрасывание" файла или директории с хост-машины в файловую систему контейнера. Путь на хосте может быть любым.
    * **Сценарии использования:** В основном для разработки, когда нужно, чтобы изменения в коде на хост-машине немедленно отражались в
      работающем контейнере без пересборки образа.
    * **Недостатки:** Делает контейнер зависимым от конкретной структуры файловой системы хоста, что снижает его портируемость. Также могут
      возникнуть проблемы с правами доступа (UID/GID пользователя на хосте и внутри контейнера).
* **`tmpfs`:**
    * **Что это:** Временное хранилище, которое монтируется непосредственно в оперативную память хост-машины.
    * **Свойства:** Очень быстрое, так как нет дискового I/O. Данные в `tmpfs` полностью теряются при остановке контейнера. Не записываются
      ни на диск хоста, ни в writable layer контейнера. Идеально для временных, чувствительных данных, которые не должны оставаться на
      диске.

---

#### Сеть (Networking)

Docker предоставляет сетевую изоляцию и управление через сетевые драйверы.

* **`bridge` (по умолчанию):**
    * **Как работает:** При установке Docker создает виртуальный сетевой мост на хосте (обычно `docker0`). Когда вы запускаете контейнер,
      Docker создает для него собственный сетевой namespace, виртуальный Ethernet-интерфейс (`veth`) и подключает его к этому мосту. Каждому
      контейнеру в этой сети присваивается внутренний IP-адрес.
    * **Свойства:**
        * Контейнеры в одной bridge-сети могут общаться друг с другом по IP-адресам или, что более удобно, по именам (Docker предоставляет
          встроенный DNS-сервер).
        * Сеть изолирована от хоста. Чтобы сделать сервис в контейнере доступным извне, необходимо выполнить **проброс портов
          ** (`-p 8080:80`), который создает правило в `iptables` на хосте, перенаправляющее трафик с порта 8080 хоста на порт 80
          контейнера.
* **`host`:**
    * **Как работает:** Контейнер не получает свой собственный сетевой стек. Вместо этого он использует сетевой стек хост-машины напрямую.
    * **Свойства:**
        * Нет сетевой изоляции. Если приложение в контейнере слушает порт 80, оно будет слушать порт 80 на всех сетевых интерфейсах хоста.
        * **Максимальная производительность**, так как отсутствует слой трансляции сетевых адресов (NAT), который есть в `bridge`.
        * Риск конфликта портов, если несколько контейнеров или приложений на хосте захотят использовать один и тот же порт.
* **`overlay`:**
    * **Как работает:** Это драйвер для многохостовых сетей. Он создает распределенную сеть, которая может охватывать несколько
      Docker-хостов. Контейнеры, подключенные к одной overlay-сети, могут общаться друг с другом напрямую, даже если они запущены на разных
      физических или виртуальных машинах. Это достигается путем инкапсуляции трафика (например, с помощью VXLAN).
    * **Назначение:** Основа для оркестрации контейнеров в кластере (используется в Docker Swarm и является одним из сетевых плагинов для
      Kubernetes).
* **`none`:**
    * **Как работает:** Контейнер получает свой сетевой стек, но без какого-либо внешнего сетевого интерфейса, кроме `loopback` (`lo`).
    * **Назначение:** Полная сетевая изоляция. Контейнер не может общаться ни с внешним миром, ни с другими контейнерами. Полезно для
      выполнения пакетных заданий, которые только обрабатывают данные (читают с volume и пишут на volume) и не требуют доступа к сети.

---

#### Архитектура Docker: Клиент-Серверное приложение

Фундаментально, Docker — это не монолитное приложение, а система, построенная по клиент-серверной архитектуре. Это означает, что есть два
основных, независимых компонента, которые общаются друг с другом.

* **Docker Daemon (`dockerd`)**
    * **Что это:** Серверная часть. Это постоянно работающий фоновый процесс (в системах с systemd он запускается как
      сервис `docker.service`). `dockerd` — это мозг и руки всей системы.
    * **Функции:**
        * Прослушивает запросы от Docker-клиента через API.
        * Управляет объектами Docker: образами, контейнерами, сетями, томами (volumes).
        * Выполняет всю "тяжелую" работу: скачивает образы из реестров (e.g., Docker Hub), собирает образы из Dockerfile, создает и
          запускает контейнеры, настраивает сети и тома.
    * **Как он слушает:** По умолчанию `dockerd` слушает на Unix-сокете `/var/run/docker.sock`. Этот файл-сокет используется для локального
      взаимодействия между клиентом и сервером. Доступ к этому файлу обычно требует прав суперпользователя (root) или членства в
      группе `docker`, что является механизмом контроля доступа. `dockerd` также можно настроить на прослушивание TCP-порта, что позволяет
      управлять им по сети.

* **Docker CLI (`docker`)**
    * **Что это:** Клиентская часть. Это утилита командной строки, с которой вы взаимодействуете в терминале.
    * **Функции:**
        * Основная задача — предоставлять пользователю интерфейс для управления Docker.
        * Она не выполняет никакой работы по управлению контейнерами сама.
        * Она преобразует ваши команды (например, `docker run -it ubuntu bash`) в структурированные вызовы REST API.
        * Отправляет эти API-запросы демону `dockerd` через сокет или TCP-соединение.
        * Получает ответ от демона и форматирует его для вывода в консоль.

* **REST API**
    * **Что это:** Это протокол, который определяет, как клиент (`docker`) должен общаться с сервером (`dockerd`). Он описывает набор
      конечных точек (endpoints), HTTP-методов (GET, POST, DELETE и т.д.) и форматы данных (JSON), которые используются для взаимодействия.
    * **Пример взаимодействия:**
        1. Вы вводите команду: `docker ps`
        2. Клиент `docker` формирует HTTP-запрос `GET /containers/json`
        3. Этот запрос отправляется демону `dockerd` через `/var/run/docker.sock`.
        4. `dockerd` обрабатывает запрос, собирает информацию о запущенных контейнерах.
        5. `dockerd` отправляет обратно HTTP-ответ с телом в формате JSON, содержащим список контейнеров и их атрибуты.
        6. Клиент `docker` получает этот JSON, парсит его и выводит в виде красивой таблицы в вашей консоли.

    * **Ключевой вывод:** Поскольку взаимодействие происходит через стандартный API, вы можете использовать любой другой клиент для
      управления Docker-демоном, будь то графический интерфейс (как Docker Desktop), веб-интерфейс (как Portainer) или ваш собственный
      скрипт на Python с использованием соответствующей библиотеки. Возможность удаленного управления через TCP-сокет является прямым
      следствием этой архитектуры.

---

#### Среды выполнения контейнеров (Container Runtimes)

Это более глубокий уровень, который объясняет, что `dockerd` на самом деле не является самым низкоуровневым компонентом, непосредственно
запускающим контейнеры. Произошло разделение обязанностей для соответствия отраслевым стандартам.

Современная архитектура Docker выглядит как цепочка делегирования:

**`docker` (CLI) → `dockerd` (Daemon) → `containerd` → `runc`**

Давайте разберем каждый элемент этой цепочки:

* **`containerd`**
    * **Что это:** Это отдельный, самостоятельный проект (переданный Docker в CNCF - Cloud Native Computing Foundation), который является
      отраслевым стандартом для управления жизненным циклом контейнеров.
    * **Функции:** `containerd` — это высокоуровневая среда выполнения. Его зона ответственности:
        * Управление всем жизненным циклом контейнеров: создание, запуск, пауза, возобновление, остановка, удаление.
        * Управление передачей образов: скачивание образов из реестров и их загрузка (push).
        * Управление хранилищем (snapshotter'ы для слоев образов) и сетевыми интерфейсами контейнеров.
    * **Взаимодействие:** `dockerd` больше не занимается этими задачами напрямую. Когда вы просите `dockerd` запустить контейнер, он
      обращается к `containerd` через его API (gRPC) и говорит: "Пожалуйста, запусти контейнер на основе этого образа с такими-то
      параметрами". Это разделение позволяет другим проектам (например, Kubernetes через плагин CRI) использовать `containerd` напрямую,
      минуя `dockerd`.

* **`runc`**
    * **Что это:** Это низкоуровневая среда выполнения контейнеров. `runc` — это утилита командной строки, которая делает только одно:
      создает и запускает контейнеры в соответствии со спецификацией OCI.
    * **Функции:**
        1. Получает на вход бандл (bundle) — директорию, содержащую файл конфигурации `config.json` (описывающий, что нужно запустить, какие
           namespaces использовать, какие cgroups применить и т.д.) и корневую файловую систему контейнера.
        2. Использует системные вызовы ядра Linux (такие как `clone`, `unshare` для создания namespaces и `setrlimit` для cgroups) для
           создания изолированной среды.
        3. Запускает указанный в конфигурации процесс внутри этой среды.
    * **Взаимодействие:** `containerd` использует `runc` для фактического запуска контейнера. После того как `runc` запустил процесс
      контейнера, он завершает свою работу. Сам процесс контейнера продолжает работать под управлением небольшого
      процесса-прослойки (`containerd-shim`), который позволяет `containerd` (и `dockerd`) перезапускаться, не затрагивая уже запущенные
      контейнеры.

* **OCI (Open Container Initiative)**
    * **Что это:** Это консорциум, созданный под эгидой The Linux Foundation для разработки открытых отраслевых стандартов в области
      контейнеризации.
    * **Основные стандарты:**
        1. **Runtime Specification (runtime-spec):** Определяет, как должна работать среда выполнения контейнеров. Она описывает
           конфигурацию контейнера (`config.json`) и его жизненный цикл. `runc` является эталонной реализацией этой спецификации.
        2. **Image Specification (image-spec):** Определяет формат контейнерного образа. Описывает, как должны быть устроены слои,
           манифест (описание образа) и конфигурация.
    * **Зачем это нужно:** Стандартизация OCI — это ключ к взаимозаменяемости. Любой инструмент, который может создать OCI-совместимый
      образ (например, Docker, Buildah, Podman), создает образ, который может быть запущен любой OCI-совместимой средой выполнения (
      например, `runc` через `containerd`, или `crun`). Это предотвращает привязку к одному поставщику (vendor lock-in) и способствует
      развитию всей экосистемы контейнеров.

---

### Docker Compose

* **Что это:** Это инструмент для определения и запуска многоконтейнерных приложений. Его основная задача — упростить управление сложными
  приложениями, состоящими из нескольких взаимосвязанных сервисов (например, веб-сервер, база данных, кэш), на одной хост-машине. Он
  использует декларативный подход: вы описываете желаемое состояние вашей системы в одном файле, а Docker Compose берет на себя его
  реализацию.

* **`docker-compose.yml`:** Это YAML-файл, который является центральным элементом Docker Compose. В нем вы описываете сервисы, сети и тома,
  из которых состоит ваше приложение.

  **Ключевые секции и директивы `docker-compose.yml`:**

  **Как это работает:** Когда вы запускаете `docker-compose up`, Compose:
    1. Читает `docker-compose.yml`.
    2. Создает сети (`frontend`, `backend`), если они не существуют.
    3. Создает тома (`db_data`, `app_data`), если они не существуют.
    4. Для каждого сервиса:
        * Если указан `build`, запускает `docker build` для создания образа.
        * Создает и запускает контейнер с указанными параметрами (порты, переменные, тома).
        * Подключает контейнер к указанным сетям.
    5. По умолчанию Compose создает одну общую сеть типа `bridge` для всех сервисов в файле, что позволяет им обращаться друг к другу по
       именам сервисов (`webapp` может обратиться к `database` по hostname `database`).

---

### Реестры (Registries)

* **Что это:** Это система хранения и распространения образов Docker. Реестр является централизованным репозиторием, из которого вы можете
  загружать (`pull`) образы и в который можете публиковать (`push`) свои собственные. Docker Hub — это публичный реестр по умолчанию.

* **Приватные реестры:**
    * **Зачем нужны:** Для хранения проприетарных, чувствительных или специфичных для компании образов, которые не должны быть общедоступны.
      Также они обеспечивают контроль доступа, более высокую скорость загрузки (если реестр находится в той же сети, что и хосты Docker) и
      интеграцию с CI/CD-пайплайнами.
    * **Примеры:**
        * **GitLab Container Registry / GitHub Packages:** Интегрированы напрямую в платформы GitLab и GitHub. Идеальны для хранения
          образов, собранных в CI/CD пайплайнах этих же систем.
        * **Amazon ECR (Elastic Container Registry) / Google Artifact Registry:** Реестры, предоставляемые облачными провайдерами. Глубоко
          интегрированы с их экосистемами (IAM для аутентификации, близость к вычислительным ресурсам типа EKS/GKE).
        * **Harbor:** Популярный open-source проект, который можно развернуть на собственных серверах (on-premise). Предоставляет
          расширенные функции: сканирование уязвимостей, репликацию образов, сборку мусора и т.д.

---

### Безопасность

* **Сканирование образов:**
    * **Что это:** Процесс автоматического анализа слоев образа на наличие известных уязвимостей (CVE - Common Vulnerabilities and
      Exposures) в пакетах операционной системы (например, в `apt` или `apk` пакетах) и в зависимостях приложения (например,
      в `npm`, `pip`, `maven` пакетах).
    * **Как работает:** Инструмент (сканер) разбирает образ, составляет список всего установленного ПО и его версий, а затем сверяет этот
      список со своей базой данных уязвимостей.
    * **Инструменты:**
        * **Trivy:** Очень популярный, быстрый и простой в использовании open-source сканер.
        * **Snyk:** Коммерческий продукт (с бесплатным тарифом), который часто интегрируется в CI/CD и может быть вызван
          через `docker scan`.
    * **Зачем:** Это позволяет обнаружить и исправить проблемы безопасности до того, как образ попадет в production-среду (принцип "Shift
      Left Security").

* **Принцип наименьших привилегий:**
    * **Проблема:** По умолчанию, процессы внутри контейнера запускаются от имени пользователя `root` (UID 0). Если злоумышленник сможет
      эксплуатировать уязвимость в приложении и "выйти" из контейнера (container escape), он получит права `root` на хост-машине. Это
      критическая уязвимость.
    * **Решение:** Никогда не запускать контейнеры от `root`, если для этого нет абсолютной необходимости.


* **Управление секретами:**
    * **Почему нельзя хранить секреты в `ENV`:** Переменные окружения, заданные через `ENV` в Dockerfile, "запекаются" в метаданные образа.
      Любой, кто имеет доступ к образу (`docker pull`), может легко просмотреть их с помощью команды `docker inspect`. Это небезопасно для
      хранения паролей, токенов, ключей API.
    * **Docker Secrets (для Docker Swarm и Compose):**
        * **Что это:** Механизм для безопасной передачи секретов в контейнеры.
        * **Как работает:** Секрет не является частью образа или его конфигурации. Он управляется Docker отдельно. Когда сервис (контейнер)
          получает доступ к секрету, Docker монтирует его как файл в специальную директорию внутри контейнера (`/run/secrets/`), которая
          находится в памяти (`tmpfs`) и никогда не записывается на диск. Приложение читает секрет из этого файла.
        * `docker-compose.yml` имеет похожий механизм для локальной разработки.
    * **Внешние системы управления секретами (лучшая практика для production):**
        * **Что это:** Специализированные инструменты, такие как **HashiCorp Vault**, **AWS Secrets Manager**, **Google Secret Manager**, *
          *Azure Key Vault**.
        * **Как работает:** Приложение в контейнере при старте проходит аутентификацию во внешней системе (например, с помощью токена или
          роли, предоставленной средой выполнения) и запрашивает необходимые ему секреты по безопасному API.
        * **Преимущества:** Централизованное управление, строгий контроль доступа и аудит, возможность ротации (автоматической смены)
          секретов без перезапуска приложений. Это самый надежный и масштабируемый подход.
        
