## 1. Основы ClickHouse

### 1.1 Назначение
ClickHouse — это столбцовая СУБД, разработанная для аналитических запросов (OLAP), где требуется высокая производительность при обработке больших объемов данных. Она оптимизирована для чтения и агрегации данных (суммы, средние, группировки), а не для частых обновлений или транзакций, характерных для OLTP-систем.

- **Ключевые особенности**:
    - Быстрая обработка запросов на миллионах или миллиардах строк.
    - Эффективное сжатие данных и использование индексов.
    - Подходит для анализа логов, метрик IoT, временных рядов, бизнес-аналитики и мониторинга.
- **Примеры задач**:
    - Анализ логов веб-серверов (например, подсчет запросов по URL).
    - Мониторинг производительности систем (загрузка CPU, время ответа API).
    - Обработка временных рядов (цены акций, данные датчиков).
    - Построение отчетов для маркетинга или продаж.

### 1.2 Архитектура

#### 1.2.1 Столбцовое хранение
ClickHouse хранит данные по столбцам, а не по строкам, как традиционные СУБД (например, PostgreSQL). Это позволяет читать только необходимые столбцы, снижая объем операций ввода-вывода. Значения в столбцах хранятся в порядке вставки, а метаданные связывают их в логические строки. Например:
- Столбец "Имя": `[Иван, Маша, Петя]`
- Столбец "Возраст": `[25, 30, 28]`
- Метаданные обеспечивают, что `Иван, 25` — одна строка.

#### 1.2.2 Сервер
Сервер ClickHouse — это единый процесс, который обрабатывает запросы через HTTP, TCP или другие интерфейсы. Он поддерживает многопоточность, эффективно используя многоядерные процессоры для параллельной обработки.

#### 1.2.3 Движки таблиц
Движки определяют, как данные хранятся, индексируются и обрабатываются:
- **MergeTree**: Основной движок для аналитики. Поддерживает индексы, сжатие, партиционирование. Используется для временных рядов и больших таблиц.
- **ReplacingMergeTree**: Удаляет дубликаты строк с одинаковым ключом сортировки при фоновом слиянии.
- **SummingMergeTree**: Суммирует числовые значения для строк с одинаковым ключом.
- **AggregatingMergeTree**: Хранит агрегированные данные (например, `SUM`, `COUNT`) для материализованных представлений.
- **Log**: Простой движок без индексов и сжатия, для небольших данных.
- **Memory**: Хранит данные в RAM, теряет их при перезапуске. Подходит для временных вычислений.
- **Dictionary**: Для справочных данных (ключ-значение), загружаемых из внешних источников (например, CSV).

#### 1.2.4 Шардирование
Шардирование распределяет данные по серверам (шардам) для горизонтального масштабирования. Движок `Distributed` перенаправляет запросы к нужным шардам по ключу шардирования (например, хэш от `user_id`).

#### 1.2.5 Репликация
Репликация копирует данные на несколько серверов для отказоустойчивости. Используется движок `ReplicatedMergeTree`, синхронизирующий данные через Apache ZooKeeper или ClickHouse Keeper. При сбое одной реплики запросы перенаправляются на другие.

#### 1.2.6 Как работает
1. Клиент отправляет SQL-запрос.
2. Сервер анализирует запрос, использует индексы для выборки данных.
3. Движок `Distributed` распределяет запрос по шардам, если нужно.
4. Данные агрегируются и возвращаются клиенту.
5. Репликация и сжатие работают в фоновом режиме.

---

## 2. Сценарии использования

### 2.1 Основные сценарии
- **Анализ логов**: Обработка логов веб-серверов, приложений или сетевых устройств (например, подсчет запросов по IP).
- **Метрики и мониторинг**: Сбор данных о производительности серверов или приложений.
- **Временные ряды**: Анализ данных, упорядоченных по времени (IoT, финансы).
- **Бизнес-аналитика**: Построение отчетов по продажам, конверсиям, маркетингу.
- **Ad-hoc аналитика**: Сложные запросы на больших данных без предварительной подготовки.

### 2.2 Когда не подходит
- **OLTP**: Неэффективен для частых вставок, обновлений или транзакций.
- **Маленькие данные**: Преимущества не заметны при объемах <1 ГБ.
- **Сложные транзакции**: Ограниченная поддержка ACID.

---

## 3. Преимущества ClickHouse

### 3.1 Производительность
- Столбцовое хранение минимизирует чтение данных.
- Первичные и вторичные индексы ускоряют поиск.
- Многопоточность и векторизация запросов эффективно используют CPU.

### 3.2 Сжатие данных
- Алгоритмы LZ4 и ZSTD сокращают объем данных в 5–10 раз.
- Сжатие ускоряет чтение, особенно для столбцов с повторяющимися значениями.

### 3.3 SQL с расширениями
- Поддерживает стандартный SQL и уникальные функции (`arrayJoin`, `JSONExtract`).
- Специфичные типы данных: `DateTime64`, `Array`, `Nullable`.

### 3.4 Масштабируемость
- Шардирование и репликация позволяют масштабировать кластеры до сотен серверов.
- Производительность растет почти линейно с добавлением серверов.

### 3.5 Простота эксплуатации
- Легкая настройка и интеграция с Grafana, Superset, Kafka.
- Минимальные требования к администрированию для небольших установок.

---

## 4. Технические аспекты

### 4.1 Индексы

#### 4.1.1 Первичные индексы
- Создаются через `ORDER BY` в таблицах `MergeTree`.
- Ускоряют запросы по ключу сортировки (например, `WHERE event_time > '2025-07-01'`).

#### 4.1.2 Вторичные индексы (Skip Indexes)
- Ускоряют фильтрацию по столбцам вне ключа сортировки. Типы: `minmax`, `set`, `bloom_filter`. Пример:
  ```sql
  CREATE TABLE logs (
      event_time DateTime,
      user_id UInt32,
      action String,
      INDEX action_idx action TYPE bloom_filter GRANULARITY 1
  ) ENGINE = MergeTree()
  ORDER BY (event_time, user_id);
  ```
- **Проектирование**:
    - Первичный ключ: для частых фильтров (например, даты).
    - Вторичные индексы: для столбцов в `WHERE`, не входящих в `ORDER BY`.
    - Используйте `EXPLAIN` для проверки эффективности.

### 4.2 Сжатие данных
- **LZ4**: Быстрое сжатие, используется по умолчанию.
- **ZSTD**: Высокое сжатие, больше CPU. Пример:
  ```sql
  CREATE TABLE example (
      id UInt32,
      data String
  ) ENGINE = MergeTree()
  ORDER BY id
  SETTINGS compression = 'ZSTD';
  ```
- Сжатие снижает объем данных, ускоряет чтение, но требует CPU для декомпрессии.

### 4.3 Шардирование и репликация
- **Шардирование**: Движок `Distributed` распределяет данные по шардам. Пример:
  ```sql
  CREATE TABLE logs_distributed (
      event_time DateTime,
      user_id UInt32
  ) ENGINE = Distributed(cluster_name, database, logs_local, user_id % 4);
  ```
- **Репликация**: Движок `ReplicatedMergeTree` синхронизирует данные через ZooKeeper. Пример:
  ```sql
  CREATE TABLE logs_replicated (
      event_time DateTime,
      user_id UInt32
  ) ENGINE = ReplicatedMergeTree('/clickhouse/tables/logs', 'replica1')
  ORDER BY (event_time, user_id);
  ```
 
### 4.4 Форматы данных
- **Parquet**, **ORC**: Столбцовые, для больших данных.
- **CSV**, **TSV**, **JSONEachRow**: Для простых данных.
- **Native**: Быстрый для ClickHouse.
- **Оптимизация**:
    - Используйте Parquet для больших объемов.
    - Загружайте данные пакетами (тысячи/миллионы строк).
    - Применяйте сжатие (`gzip`) при передаче.
    - Используйте материализованные представления для автоматической агрегации.

---

## 5. SQL в ClickHouse

### 5.1 Особенности SQL
- Поддерживает стандартный SQL (`SELECT`, `WHERE`, `GROUP BY`, `JOIN`), но с ограничениями:
    - Нет полноценных транзакций.
    - `UPDATE`/`DELETE` асинхронные, через `ALTER TABLE`.
    - `JOIN` менее оптимизирован.
- **Уникальные функции**:
    - `uniq`: Примерный подсчет уникальных значений.
    - `groupArray`: Создает массив значений.
    - `arrayJoin`: Разворачивает массивы в строки.
    - `JSONExtract`: Извлекает данные из JSON.
- **Пример**:
  ```sql
  SELECT user_id, groupArray(event_type) AS events
  FROM events
  ARRAY JOIN events AS event
  WHERE event IN ('click', 'view')
  GROUP BY user_id;
  ```

### 5.2 Оптимизация запросов
- **Query Execution Plan**: Использует столбцовое хранение и индексы для минимизации чтения данных.
- **EXPLAIN**: Анализирует план запроса. Пример:
  ```sql
  EXPLAIN PIPELINE
  SELECT user_id, COUNT(*) FROM events
  WHERE event_time >= '2025-07-01'
  GROUP BY user_id;
  ```
- **Оптимизация**:
    - **WHERE**: Фильтруйте по ключу сортировки.
    - **GROUP BY**: Используйте низкую кардинальность.
    - **JOIN**: Заменяйте словарями или денормализацией.
    - Указывайте только нужные столбцы в `SELECT`.

### 5.3 Агрегатные функции и материализованные представления
- **Агрегатные функции**:
    - `uniqExact`: Точный подсчет уникальных значений.
    - `quantile`: Квантили (например, медиана).
    - `argMin`/`argMax`: Значение столбца для минимального/максимального другого столбца.
- **Материализованные представления**:
    - Автоматически агрегируют данные. Пример:
      ```sql
      CREATE MATERIALIZED VIEW daily_stats
      ENGINE = AggregatingMergeTree()
      ORDER BY (day, region)
      AS
      SELECT toDate(event_time) AS day, region, countState() AS event_count
      FROM sales
      GROUP BY day, region;
      ```
    - Чтение:
      ```sql
      SELECT day, region, countMerge(event_count) AS count
      FROM daily_stats
      GROUP BY day, region;
      ```

---

## 6. Производительность и оптимизация

### 6.1 Проектирование схемы
- **Первичный ключ**:
    - Используйте столбцы для частых фильтров (например, `event_time`).
    - Избегайте высокой кардинальности в начале ключа.
- **Денормализация**:
    - Объединяйте данные в одну таблицу, чтобы избежать `JOIN`.
    - Используйте словари для справочных данных.

### 6.2 Оптимизация производительности
- **Партиционирование**:
    - Используйте `toYYYYMM(event_time)` для выборочного чтения.
    - Оптимизируйте размер партиций (1–10 млн строк).
- **Параметры сервера**:
    - `max_threads`: Число потоков (например, 16).
    - `max_memory_usage`: Ограничение памяти (например, 20 ГБ).
    - `index_granularity`: Размер гранулы индекса (например, 4096).
- **PREWHERE**:
    - Фильтрует данные до чтения столбцов. Пример:
      ```sql
      SELECT user_id, event_type
      FROM events
      PREWHERE event_time >= '2025-07-01'
      WHERE event_type = 'click';
      ```

### 6.3 Мониторинг и профилирование
- **Системные таблицы**:
    - `system.query_log`: Анализ времени запросов и объема данных.
    - `system.parts`: Размер и состояние партиций.
    - `system.processes`: Текущие запросы.
- **Инструменты**:
    - Grafana: Визуализация метрик (например, время запросов).
    - Zabbix/Prometheus: Мониторинг сервера.
- **Профилирование**:
    - Используйте `EXPLAIN PIPELINE` для анализа этапов запроса.
    - Проверяйте `system.query_log` для выявления медленных запросов.