
### Что такое оптимизация запросов?

Когда вы отправляете SQL-запрос в PostgreSQL (например, `SELECT * FROM users WHERE registration_date > '2023-01-01'`), база данных не выполняет его "в лоб". Вместо этого в дело вступает специальный компонент — **планировщик запросов (Query Planner)**, он же **оптимизатор**.

Его задача — найти самый эффективный способ (план выполнения) для получения данных, которые вы запросили. "Эффективный" здесь означает "самый дешевый" с точки зрения внутренних ресурсов: дискового ввода-вывода (I/O), процессорного времени и т.д.

Процесс выглядит так:
1.  **Парсинг (Parsing):** SQL-запрос проверяется на синтаксические ошибки и превращается во внутреннее представление — дерево запроса.
2.  **Переписывание (Rewriting):** Правила и представления (views) "разворачиваются". Например, если вы делаете запрос к `view`, система подставит в дерево запроса тот `SELECT`, который определяет это `view`.
3.  **Планирование (Planning):** Это самый главный этап. Планировщик генерирует множество возможных планов выполнения запроса и, основываясь на статистике данных и своей модели стоимости, выбирает самый "дешевый".

---

### Сердце оптимизатора: статистика и стоимость

Планировщик — не волшебник. Он принимает решения на основе данных. Главный источник этих данных — **статистика таблиц**.

*   **Что такое статистика?** Это информация о распределении данных в ваших таблицах:
    *   Количество строк в таблице.
    *   Количество уникальных значений в столбце (кардинальность).
    *   Наиболее частые значения.
    *   Гистограмма распределения значений.
*   **Как она собирается?** Командой `ANALYZE`. К счастью, в современных версиях PostgreSQL работает **`autovacuum`**, который автоматически запускает `VACUUM` и `ANALYZE` для таблиц, которые часто изменяются.
*   **Почему это важно?** Без актуальной статистики планировщик слеп. Он может решить, что `WHERE user_id = 123` вернет половину таблицы, хотя на самом деле вернет одну строку. В результате он выберет полный перебор таблицы (`Seq Scan`) вместо быстрого поиска по индексу (`Index Scan`).

**Стоимость (Cost)** — это абстрактная единица, которой планировщик измеряет "дороговизну" операции. Она не равна миллисекундам. Главный фактор, влияющий на стоимость, — это **дисковый ввод-вывод**, так как чтение с диска на порядки медленнее чтения из памяти.

---

### Главный инструмент разработчика: `EXPLAIN`

Чтобы понять, *что именно* делает планировщик и почему запрос работает медленно, используется команда `EXPLAIN`.

#### 1. `EXPLAIN`
Показывает *план* выполнения, который выбрал планировщик, но не выполняет сам запрос.

```sql
EXPLAIN SELECT * FROM users WHERE id = 10;
```

**Пример вывода:**
```
                          QUERY PLAN
--------------------------------------------------------------
 Index Scan using users_pkey on users  (cost=0.29..8.31 rows=1 width=118)
   Index Cond: (id = 10)
(2 rows)
```
Что мы здесь видим:
*   **`Index Scan`**: Тип операции (узел плана). В данном случае — сканирование по индексу.
*   **`users_pkey`**: Имя использованного индекса.
*   **`cost=0.29..8.31`**:
    *   `0.29` — стоимость *начала* выполнения (например, найти первую запись).
    *   `8.31` — *общая* стоимость получения всех записей.
*   **`rows=1`**: *Ожидаемое* количество строк, которое вернет этот узел.
*   **`width=118`**: *Ожидаемый* средний размер одной строки в байтах.
*   **`Index Cond: (id = 10)`**: Условие, примененное к индексу.

#### 2. `EXPLAIN ANALYZE`
Это мощнейший инструмент. Он **выполняет** запрос и показывает не только *план*, но и *реальные* метрики выполнения.

```sql
EXPLAIN ANALYZE SELECT * FROM users WHERE last_name LIKE 'Иванов%';
```
**Пример вывода:**
```
                                               QUERY PLAN
-----------------------------------------------------------------------------------------------------------------------
 Seq Scan on users  (cost=0.00..1842.00 rows=102 width=118) (actual time=0.033..22.581 rows=110 loops=1)
   Filter: ((last_name)::text ~~ 'Иванов%'::text)
   Rows Removed by Filter: 99890
 Planning Time: 0.150 ms
 Execution Time: 22.623 ms
(5 rows)
```
Что нового появилось:
*   **`actual time=0.033..22.581`**:
    *   `0.033` — реальное время в миллисекундах до получения первой строки.
    *   `22.581` — реальное общее время выполнения этого узла.
*   **`rows=110`**: Реальное количество строк, которое вернул узел.
*   **`loops=1`**: Сколько раз этот узел был выполнен.
*   **`Planning Time`**: Сколько времени заняло планирование запроса.
*   **`Execution Time`**: Сколько времени заняло выполнение запроса.

**Сравнивая `rows=102` (ожидание) и `rows=110` (реальность), мы видим, что статистика работает довольно точно.** Если бы разница была в разы или порядки, это был бы первый признак устаревшей статистики.

#### 3. `EXPLAIN (ANALYZE, BUFFERS)`
Добавляет информацию о работе с буферным кешем. Очень полезно для понимания, сколько данных было прочитано с диска, а сколько из кеша.

*   `shared hit` — блок найден в кеше PostgreSQL.
*   `shared read` — блок прочитан с диска.

**Цель — максимизировать `hit` и минимизировать `read`.**

---

### Основные узлы плана выполнения (что читать в `EXPLAIN`)

1.  **Сканирование таблиц (Scans):**
    *   `Seq Scan` (Sequential Scan): Полный перебор таблицы. Эффективен для маленьких таблиц или когда нужно получить большую часть таблицы.
    *   `Index Scan`: Поиск по индексу для нахождения указателей на строки в таблице, а затем обращение к таблице за самими данными. Идеально для выборки небольшого процента строк.
    *   `Index Only Scan`: То же, что и `Index Scan`, но все необходимые данные берутся *прямо из индекса*, без обращения к основной таблице. Это возможно, если все столбцы в `SELECT` и `WHERE` есть в индексе. Очень быстро.
    *   `Bitmap Heap Scan`: Двухэтапная операция. Сначала по одному или нескольким индексам создается "битовая карта" строк, удовлетворяющих условию, а затем по этой карте последовательно считываются нужные страницы из таблицы. Эффективно, когда по нескольким индексам нужно выбрать не очень маленькую, но и не очень большую часть таблицы.

2.  **Соединения таблиц (Joins):**
    *   `Nested Loop Join`: Для каждой строки из первой (внешней) таблицы ищет совпадения во второй (внутренней) таблице. Очень эффективен, если одна из таблиц маленькая. Часто используется вместе с `Index Scan` по внутренней таблице.
    *   `Hash Join`: Строит хеш-таблицу по одной (меньшей) из таблиц в памяти, а затем проходит по второй таблице, проверяя для каждой строки наличие совпадения в хеш-таблице. Идеален для соединения больших таблиц, когда нет подходящих индексов для `Nested Loop` и данные не отсортированы. Требует памяти (`work_mem`).
    *   `Merge Join`: Обе таблицы должны быть отсортированы по ключу соединения. Затем планировщик просто "сливает" их, двигаясь по обеим таблицам одновременно. Очень эффективен для соединения больших, уже отсортированных таблиц (например, по выходу из `Index Scan`).

3.  **Прочие узлы:**
    *   `Sort`: Сортировка данных. Дорогая операция, особенно если данные не помещаются в память (`work_mem`) и сбрасываются на диск.
    *   `Aggregate` / `HashAggregate`: Группировка данных для агрегатных функций (`COUNT`, `SUM`, `AVG`). `HashAggregate` строит хеш-таблицу для групп и обычно быстрее.
    *   `Limit`: Ограничение количества возвращаемых строк.

---

### Практические методы оптимизации

1.  **Индексы — ваше всё.**
    *   **B-Tree:** Индекс по умолчанию. Идеален для операторов `=`, `>`, `<`, `>=`, `<=`, `BETWEEN`, `IN`, а также для `LIKE 'префикс%'`.
    *   **Частичные индексы (Partial Indexes):** Индексируют не всю таблицу, а только ее часть. Очень мощно.
        ```sql
        -- Индексируем только активных, но не оплаченных пользователей
        CREATE INDEX idx_users_unpaid_active ON users (id) WHERE status = 'active' AND is_paid = false;
        ```
    *   **Индексы по выражениям:** Индексируют результат функции.
        ```sql
        -- Если часто ищем по lower(email)
        CREATE INDEX idx_users_lower_email ON users (lower(email));
        -- Теперь запрос WHERE lower(email) = '...' будет использовать индекс.
        ```
    *   **Покрывающие индексы (Covering Indexes):** Позволяют выполнять `Index Only Scan`.
        ```sql
        -- Запрос: SELECT email, created_at FROM users WHERE id = 123;
        -- Чтобы он был быстрее, создаем индекс, включающий доп. поля:
        CREATE INDEX idx_users_id_covering ON users (id) INCLUDE (email, created_at);
        ```
    *   **Другие типы индексов:**
        *   `GIN`: Для полнотекстового поиска, поиска по массивам, JSONB.
        *   `GiST`: Для геометрических данных, диапазонов.
        *   `BRIN`: Для очень больших таблиц с данными, которые физически упорядочены (например, по дате логов).

2.  **Пишите "хорошие" запросы.**
    *   **Избегайте `SELECT *`**: Выбирайте только те столбцы, которые вам нужны. Это уменьшает I/O и позволяет использовать `Index Only Scan`.
    *   **Избегайте функций над индексированными столбцами:** Запрос `WHERE lower(email) = 'test@test.com'` не будет использовать обычный индекс по `email`. Вместо этого используйте индекс по выражению (см. выше) или тип данных `CITEXT` (case-insensitive text).
    *   **`JOIN` > подзапросы:** Чаще всего `JOIN` оптимизируется лучше, чем коррелирующий подзапрос в `WHERE`. Но всегда проверяйте через `EXPLAIN`.
    *   **`UNION ALL` вместо `UNION`:** Если вам не нужно удалять дубликаты, `UNION ALL` намного быстрее, так как не требует дорогостоящей операции сортировки/хеширования для поиска дублей.

3.  **Обслуживание базы данных.**
    *   **Следите за статистикой:** Убедитесь, что `autovacuum` работает. Для критичных таблиц можно запускать `ANALYZE` вручную после массовых изменений.
    *   **`VACUUM`:** Не только собирает статистику, но и очищает "мертвые" строки, оставшиеся после `UPDATE` и `DELETE`, предотвращая раздувание (bloat) таблиц и индексов.
    *   **`REINDEX`:** Если индекс стал сильно "раздутым" и неэффективным, его можно перестроить.

4.  **Настройка PostgreSQL (`postgresql.conf`).**
    *   `shared_buffers`: Размер кеша PostgreSQL. Обычно 25% от RAM — хорошая отправная точка.
    *   `work_mem`: Память, выделяемая на операции сортировки, хеширования. Если ваши запросы сбрасывают данные на диск при сортировке (`Sort Method: external merge Disk`), увеличение этого параметра может помочь.
    *   `effective_cache_size`: Подсказка планировщику о том, сколько всего памяти (RAM) доступно для кеширования (включая кеш ОС). Обычно `50-75%` от RAM.

### Заключение: Итеративный процесс

Оптимизация — это не разовая акция, а цикл:
1.  **Измерить:** Найти медленный запрос (например, через `pg_stat_statements`).
2.  **Проанализировать:** Изучить его план с помощью `EXPLAIN ANALYZE`. Найти "бутылочное горлышко" — самый дорогой узел.
3.  **Сформулировать гипотезу:** "Кажется, здесь поможет индекс по полю X" или "Если переписать этот `JOIN`, он станет быстрее".
4.  **Проверить:** Создать индекс или переписать запрос в транзакции (чтобы можно было откатить) и снова запустить `EXPLAIN ANALYZE`.
5.  **Повторить:** Если стало лучше — закрепить результат. Если нет — откатить изменения и вернуться к шагу 3.

Понимание того, как работает планировщик и как читать его планы — ключевой навык для любого разработчика, работающего с PostgreSQL.

----------------------------------------------------------------

23)Использование индексов для оптимизации.

Добавить индексы - это первый вариант ускорение запроса, но так ли он хорош?

В 90% случаях, да, в 10% он не будет применён.

Индекс позволит нам быстро найти наши данные по условию с операторами > < = >= <=, LIKE, BETWEEN (b-map)

Но мы можем ускорить даже обычные индексы.

1)Индексы бывают 2 типов - составные и одинарные.

Для ускорения индексов мы можем проверить для нашего условия, какой из этих типов(если у нас больше 1 условия) для нас быстрее.

2)Использование индексов для получения данных, если нам нужны данные только из индекса, то лучше взять только их, ведь будет использоваться  сканированием только индекса.

3)Частичные индексы - это индексы, которые строятся только на определённых данных описанных в WHERE

Так же при соединении таблиц стоит использовать индексы, для более быстрого соединения.

--------------------------------------------------------------------------------------------------------------------

24)Не Использование индексов для оптимизации.


Избегание использования индексов может быть целесообразным в определенных сценариях. Разработчики баз данных часто считают, что индексы улучшают производительность запросов, но это не всегда так. Существуют две основные причины, по которым может быть желательно избегать индексов:

Полностью считываемая в память таблица:

Если таблица относительно небольшая и может полностью поместиться в оперативной памяти, использование индексов может быть излишним и даже снижать производительность.
Запрос требует большую часть строк таблицы:

В случаях, когда выполнение запроса требует обработки большого количества строк таблицы, индексы могут только замедлить выполнение запроса.
В некоторых случаях оптимизатор базы данных автоматически определит, когда использовать индексы, но иногда его решения могут быть неоптимальными. В таких случаях можно изменить критерии фильтрации или воспользоваться преобразованиями столбцов, чтобы предотвратить использование индексов.

Примеры преобразований столбцов включают добавление нуля к числовому столбцу или использование функции coalesce для блокировки использования индексов. Например, условие attr1 + 0 = p_value предотвращает использование индекса для столбца attr1. Также, при использовании функции coalesce, например, coalesce(t1.attr2, '0') = coalesce(t2.attr2, '0'), можно блокировать индексы для столбца attr2, предполагая, что он не содержит неопределенных значений.

--------------------------------------------------------------------------------------------------------------------

25)Что такое длинные запросы?

Длинный запрос - это запрос в котором от действия к действию передаётся большое количество записей

--------------------------------------------------------------------------------------------------------------------

26)Длинные запросы и полное сканирование

Почему предпочтительно использовать полное сканирование таблицы для длинных запросов? Это связано с тем, что при индексном доступе, особенно когда количество необходимых строк велико (как показано на рис. 3.1), требуется больше операций ввода-вывода. Термин "достаточно большим" зависит от различных факторов и может изменяться с развитием аппаратного обеспечения. Важно отметить, что PostgreSQL обычно правильно вычисляет этот процент.

В предыдущей главе было сказано схожее о коротких запросах, однако оценить "достаточно велико" сложнее, чем "достаточно мало". Эта верхняя граница изменяется в зависимости от развития аппаратного обеспечения, дисков и процессоров. Поэтому в книге избегается указания конкретных числовых значений порогов, которые могут с течением времени измениться. Для иллюстрации в этой главе использованы таблицы с сотнями миллионов строк данных, но даже они могут стать недостаточными для некоторых примеров через несколько лет.

--------------------------------------------------------------------------------------------------------------------

27)Длинные запросы и соединения хешированием


Большинство примеров в данной главе используют алгоритм соединения хешированием, предпочитая его для выполнения длинных запросов. Этот выбор обоснован тем, что стоимость соединения хешированием, как было показано в главе 3, обычно меньше стоимости вложенного цикла для длинных запросов. Размер таблиц R и S, а также количество уникальных значений атрибута соединения JA, влияют на разницу в стоимости: чем больше таблицы и JA, тем более выгодно использовать соединение хешированием.

Соединения хешированием работают наилучшим образом, когда первая таблица помещается в оперативную память, и размер доступной памяти может быть настроен с помощью параметров сервера.

--------------------------------------------------------------------------------------------------------------------

28)Длинные запросы и порядок соединений

Для коротких запросов предпочтительным является порядок соединений, в котором в первую очередь используются индексы с более низкой селективностью. Несмотря на то, что не предполагается использование индексов в длинных запросах, порядок соединений имеет значение. Размеры больших таблиц могут значительно различаться, и даже при отсутствии использования индексов порядок соединений важен для минимизации размера промежуточных наборов данных.

Существенное значение имеет порядок соединений даже тогда, когда индексы не используются, так как важно, чтобы промежуточные наборы данных были минимальными при выборе "почти всех записей", где "почти" может означать как 30%, так и 100%. Оптимальный порядок соединений включает выполнение наиболее ограничительных соединений (т.е., тех, которые сильнее всего уменьшают количество результирующих строк) в первую очередь. Хотя в большинстве случаев оптимизатор автоматически выбирает правильный порядок, разработчик должен убедиться, что оптимизатор сделал правильный выбор.

--------------------------------------------------------------------------------------------------------------------

29)Длинные запросы: Что такое полусоединение и антисоединение?

Полусоединение:

Полусоединение – особый вид соединения, удовлетворяющий двум условиям. 
Во-первых, в результирующем множестве появляются только столбцы из первой таблицы. 
Во-вторых, строки из первой таблицы не дублируются, если во второй таблице для них есть несколько соответствий. Чаще всего полусоединение вообще не предполагает ключевое слово JOIN. Первый и наиболее распространенный способ получить полусоединение представлен в листинге 6.3. Этот запрос находит всю информацию о рейсах с по крайней мере одним бронированием.

        SELECT * FROM flight f WHERE EXISTS
        (SELECT flight_id FROM booking_leg WHERE flight_id = f.flight_id)

Антисоединение:

Антисоединение двух таблиц R и S возвращает строки из таблицы R, для которых в таблице S нет строк с совпадающим значением в столбце соединения.

        SELECT * FROM flight f WHERE NOT EXISTS
        (SELECT flight_id FROM booking_leg WHERE flight_id = f.flight_id)

--------------------------------------------------------------------------------------------------------------------

30)Длинные запросы: Использование операций над множествами

Иногда операции над множествами позволяют выбрать эффективный альтернативный план выполнения и повысить удобочитаемость.

Часто можно:
    использовать EXCEPT вместо NOT EXISTS и NOT IN;
    использовать INTERSECT вместо EXISTS и IN;
    использовать UNION вместо сложных критериев выбора с OR.

--------------------------------------------------------------------------------------------------------------------

31)Длинные запросы: Избегаем многократного сканирования


Еще одна причина медленных запросов - многократные сканирования таблиц, часто обусловленные неудачным дизайном схемы данных. Эту проблему можно теоретически исправить, но в случаях, когда это невозможно, мы предлагаем эффективные методы написания запросов при несовершенной схеме.

Моделируемая в нашей схеме postgres_air ситуация, где требуется хранить дополнительную информацию для уже существующих объектов в базе данных, не уникальна. Часто при использовании таблицы сущность-атрибут-значение (EAV) решаются подобные задачи. В схеме postgres_air этот шаблон реализован в таблице custom_field, где хранятся атрибуты, такие как номер паспорта, срок действия и название страны выдачи.

Представим, что необходим отчет, отображающий имена пассажиров и их паспортные данные. Однако, типичное предложенное решение в листинге 6.26 включает три сканирования таблицы custom_field, что сказывается на производительности запроса. Эффективный способ выполнения этой задачи можно представить, избегая многократного сканирования таблицы и оптимизируя процесс.

--------------------------------------------------------------------------------------------------------------------

32)Временные таблицы

Длинная цепочка временных таблиц может вызвать ряд проблем, включая следующие:

Индексы: После сохранения данных во временной таблице нельзя использовать индексы из исходной таблицы. Это может привести к необходимости обхода индексов или созданию новых во временных таблицах, требующих дополнительных ресурсов.

Статистика: Поскольку создана новая таблица, оптимизатор не может использовать статистические данные из исходной таблицы. Это может потребовать отказа от статистики или выполнения команды ANALYZE для временной таблицы.

Место на диске: Временные таблицы сохраняются на диске, если промежуточные результаты не помещаются в оперативной памяти. Большие запросы с соединениями, сортировками и группировками могут конкурировать за пространство с временными таблицами, что может привести к отмене запросов.

Чрезмерный ввод-вывод: Временные таблицы требуют дополнительного времени для записи и чтения с диска, что может привести к чрезмерному вводу-выводу.

Однако основной негативный эффект чрезмерного использования временных таблиц заключается в том, что такая практика ограничивает способность оптимизатора переписывать запросы. Сохранение результатов каждого соединения во временную таблицу фиксирует порядок создания временных таблиц и мешает оптимизатору выбирать оптимальный порядок соединений.

--------------------------------------------------------------------------------------------------------------------

33)Общие табличные выражения (CTE)

В плане выполнения зависит от версии PostgreSQL. Для версий ниже 12 общее табличное выражение (CTE) обрабатывалось так же, как временная таблица, результаты материализовались в памяти с возможным сбросом на диск. Это означало, что использование CTE не приносило преимуществ перед временной таблицей.

CTE было предназначено для более эффективного использования в случаях, когда вложенный подзапрос используется несколько раз в запросе. В таких случаях PostgreSQL мог вычислить результаты один раз и использовать их повторно.

Оптимизатор планировал выполнение CTE отдельно, не перемещая условия соединения внутрь CTE. Это было важно, особенно при использовании CTE в командах INSERT, DELETE или UPDATE, а также в рекурсивных вызовах CTE. В PostgreSQL 12 изменена оптимизация CTE: если нерекурсивное CTE используется один раз, то оно встраивается во внешний запрос. Если CTE используется несколько раз, сохраняется старое поведение.

Это поведение можно изменить с использованием ключевых слов MATERIALIZED и NOT MATERIALIZED. Ключевое слово MATERIALIZED вызывает старое поведение, а NOT MATERIALIZED – встраивание, независимо от других соображений.

--------------------------------------------------------------------------------------------------------------------

34)Представления

Представление – это объект базы данных, в котором хранится запрос, определяющий виртуальную таблицу.

С одной стороны, представление обычно создают именно для инкапсуляции, чтобы другие могли использовать его, не разбираясь в логике запроса.
С другой стороны, эта непрозрачность приводит к низкой производительности. Это особенно ярко проявляется, когда некоторые столбцы в представлении являются результатами преобразования.
Ещё одна проблема представлений - невозможность создания индексов, при больших количествах записей, выборка может быть не оптимальна.

Однако они не дают никакого преимущества в плане производительности.
Лучшее и,  возможно, единственно оправданное использование представлений – это построение уровня безопасности или определение элементов
отчетов, гарантирующих, что все соединения и бизнес-логика определены
правильно.

--------------------------------------------------------------------------------------------------------------------

35)Материализованные представления

Материализованное представление – это объект базы данных, который объединяет
в себе и определение запроса, и таблицу для хранения результатов этого запроса, когда
он выполнен.

Когда можно использовать?

Можно использовать, когда есть запрос, которому не нужно 100% актуальная информация.

Какое преимущество в отличие от обычного представления?

Главное преимущество в том, что запрос сохраняет данные, которые мы можем проиндексировать и ускорить выполнение.

--------------------------------------------------------------------------------------------------------------------

36)Секционирование


Секционирование таблиц - форма организации данных, где таблица разбивается на несколько секций, каждая из которых представляет собой отдельную таблицу. Каждая строка хранится в соответствующей секции в соответствии с определенными правилами. Поддержка секций в PostgreSQL появилась с версии 10, и с каждым выпуском вносятся улучшения для упрощения их использования.

Наиболее распространенный случай - секционирование по диапазонам, где каждая секция содержит строки с значениями атрибута в определенном диапазоне. Секции не пересекаются, и строки, не попадающие в ни одну секцию, не могут быть вставлены.

Секции могут быть добавлены и удалены, причем операция DROP выполняется быстрее, чем DELETE. Это часто используется, например, при добавлении новой секции в конце каждого месяца к таблице, разделенной по диапазонам дат.

Секционирование также может быть использовано для распределения данных по нескольким серверам баз данных. С точки зрения производительности, секционирование может уменьшить время полного сканирования таблицы, ограничив сканирование только подходящими секциями. Это особенно полезно для длинных запросов, часто требующих полного сканирования.

--------------------------------------------------------------------------------------------------------------------

37)Два способа оптимизации модификации данных

Команды DML (Data Manipulation Language) включают выбор записей и их изменение. В случае INSERT первая часть может быть опущена при вставке констант, но при использовании INSERT-SELECT необходимо сначала найти записи для вставки.

Оптимизация DML состоит из оптимизации выборки и оптимизации изменения данных. Если проблема связана с выборкой, следует оптимизировать часть SELECT. Эта глава фокусируется на второй части - оптимизации записи данных.

В большинстве случаев системы OLTP выполняют гораздо меньше команд DML по сравнению с командами SELECT. Это основная причина того, что редко обсуждается оптимизация DML. Однако длительные операции DML могут вызвать проблемы, так как обновленные данные могут задерживаться и из-за возможного появления блокирующих замков, замедляющих выполнение других команд.

--------------------------------------------------------------------------------------------------------------------

38)Функции

При создании функции PostgreSQL выполняет только начальный разбор текста, обнаруживая только тривиальные синтаксические ошибки. В отличие от Oracle, PostgreSQL не компилирует функции, а хранит их в виде исходного кода, интерпретируя их во время выполнения.

Интерпретатор PL/pgSQL создает внутреннее дерево инструкций при первом вызове функции в каждом сеансе. Выражения SQL и команды не транслируются сразу, а анализируются и создается подготовленный оператор только при выполнении определенной команды. Это может привести к тому, что синтаксические ошибки в коде не будут обнаружены до момента выполнения.

При создании функции в PL/pgSQL:

План выполнения не сохраняется.
Не выполняются проверки на наличие таблиц, столбцов или других функций.
Работу функции можно определить только при ее выполнении, и часто это требуется несколько раз для различных путей выполнения.

Функции PostgreSQL также являются "атомарными" в нескольких смыслах. Нельзя начинать транзакции внутри функций, поэтому инструкции DML выполняются как "все или ничего". Планировщик PostgreSQL не учитывает пользовательские функции при оптимизации плана выполнения запроса.

Время выполнения функции составляет 3,5 секунды, в то время как аналогичная инструкция SQL выполняется примерно за 900 мс. Это значительное различие объясняется тем, что функции в PostgreSQL не оптимизируются так же эффективно, как представления или общие табличные выражения.

Функции действуют как черные ящики для внешней инструкции SQL, и PostgreSQL выполняет каждый вызов функции столько раз, сколько выбрано строк. Экономия времени за счет использования подготовленного оператора при последующих вызовах может как ускорить, так и замедлить выполнение, так как план выполнения может игнорировать различия в статистике между вызовами функций.

Разница между временем выполнения 0,9 секунды и 3,5 секунды может показаться незначительной, но это критичное значение времени ожидания пользователя. Важно отметить, что в данном примере запрос внутри функции легкий и быстро выполняется.

Таким образом, выполнение запросов, встроенных в инструкцию SELECT, не является оптимальным. Даже для функций, выполняющих простые преобразования данных, разница в производительности может быть заметной, особенно при возвращении большого количества строк.

--------------------------------------------------------------------------------------------------------------------

39)Пошаговое руководство

Шаг 1: Определите, является ли запрос коротким или длинным, учитывая бизнес-требования и приоритеты. Рассмотрите необходимость работы с владельцами бизнеса и бизнес-аналитиками.

Шаг 2 (для коротких запросов):
Шаг 2.1: Найдите самые ограничительные критерии запроса, уточняя их с владельцами бизнеса.
Шаг 2.2: Проверьте наличие поддерживающих индексов и создайте их при необходимости.
Шаг 2.3: Рассмотрите добавление избыточного критерия отбора, если запрос включает соединение таблиц с различными критериями.
Шаг 2.4: Постройте запрос, начиная с самых ограничительных критериев, проверяя производительность на каждом этапе. Обратите внимание на использование общих табличных выражений при необходимости.

Шаг 3 (для длинных запросов):
Шаг 3.1: Рассмотрите возможность инкрементального обновления, работая с владельцами бизнеса для определения обновляемых данных.

Шаг 4 (при использовании инкрементального обновления):
Применяйте шаги оптимизации коротких запросов к новым или обновленным записям. Разработайте стратегию хранения и обновления данных для оптимизации времени выполнения.

Шаг 5 (если инкрементальное обновление невозможно):
Шаг 5.1: Найдите наиболее ограничительное соединение и убедитесь, что оно выполняется первым, оптимизируя порядок выполнения.
Шаг 5.2: Постепенно соединяйте таблицы, проверяя производительность и план выполнения. Оптимизируйте порядок соединения.
Шаг 5.3: Убедитесь, что большие таблицы читаются только один раз, рассматривая возможность кэширования или временного хранения промежуточных результатов.
Шаг 5.4: Отложите группировку до последнего шага, если возможно. Рассмотрите использование оконных функций для эффективной группировки данных.

