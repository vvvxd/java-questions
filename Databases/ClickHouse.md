# ClickHouse

## 1. Основы ClickHouse

### 1.1 Назначение
ClickHouse создан для выполнения аналитических запросов (OLAP — Online Analytical Processing), которые обычно включают обработку больших объемов данных для получения агрегированных результатов, таких как суммы, средние значения, группировки и т.д. Он предназначен для сценариев, где требуется высокая производительность на чтение данных, а не на частые обновления или транзакции.

- **Ключевая особенность**: ClickHouse оптимизирован для работы с большими наборами данных, где запросы выполняются редко, но требуют обработки миллионов или миллиардов строк.
- **Примеры задач**: анализ логов веб-приложений, обработка метрик IoT-устройств, анализ временных рядов, бизнес-аналитика, мониторинг.

### 1.2 Архитектура ClickHouse

#### 1.2.1 Столбцовое хранение данных
- В колоночной базе, такой как ClickHouse, значения в каждом столбце хранятся в том же порядке, в котором они были вставлены. Например:
  - Столбец "Имя": `[Иван, Маша, Петя]`
  - Столбец "Возраст": `[25, 30, 28]`
  - Столбец "Город": `[Москва, Питер, Казань]`
- Поскольку порядок одинаков, база знает, что `Иван` (1-е значение в столбце "Имя"), `25` (1-е значение в столбце "Возраст") и `Москва` (1-е значение в столбце "Город") — это одна строка.
- Это как если в Excel вы разрезали таблицу на отдельные столбцы, но запомнили, что строка №1 — это всегда первые значения в каждом столбце, строка №2 — вторые и так далее.

#### 1.2.2 Сервер
- Сервер ClickHouse — это основная компонента, которая обрабатывает запросы, управляет хранилищем и координирует распределенные вычисления.
- Он работает как единый процесс, который обрабатывает запросы клиентов через протоколы HTTP, TCP или другие интерфейсы.
- Сервер поддерживает многопоточность, что позволяет эффективно использовать ресурсы многоядерных процессоров.

#### 1.2.3 Движки таблиц
- ClickHouse поддерживает разные **движки таблиц**, которые определяют, как данные хранятся, индексируются и обрабатываются. Движок выбирается при создании таблицы и влияет на её поведение.
- **Примеры движков**:
  - **MergeTree**: самый популярный движок для аналитических таблиц. Поддерживает первичные и вторичные индексы, сжатие данных, партиционирование.
  - **ReplacingMergeTree**: автоматически удаляет дубликаты строк с одинаковым ключом сортировки.
  - **SummingMergeTree**: автоматически агрегирует данные (например, суммирует значения) при слиянии строк с одинаковым ключом.
  - **Log**: простой движок для небольших таблиц, не поддерживает индексы или сжатие.
  - **Memory**: хранит данные в оперативной памяти для временных вычислений.
- Выбор движка зависит от сценария использования. Например, для временных рядов часто используют `MergeTree` с партиционированием по времени.

#### 1.2.4 Шардирование
- Шардирование позволяет распределять данные по нескольким серверам (шардам) для горизонтального масштабирования.
- Каждый шард хранит часть данных, а запросы распределяются между ними. Это полезно для обработки больших объемов данных, когда один сервер не справляется.
- ClickHouse использует **распределенные таблицы** (движок `Distributed`), которые автоматически перенаправляют запросы к нужным шардам.

#### 1.2.5 Репликация
- Репликация обеспечивает отказоустойчивость и высокую доступность. Данные копируются на несколько серверов, и в случае сбоя одного из них запросы перенаправляются на другие реплики.
- Репликация в ClickHouse реализуется через движок `ReplicatedMergeTree`, который синхронизирует данные между серверами с помощью Apache ZooKeeper (или его встроенной альтернативы ClickHouse Keeper).
- **Пример**: Если у вас есть таблица с репликацией, запись данных на один сервер автоматически синхронизируется с другими репликами.

#### 1.2.6 Как это работает вместе?
- Клиент отправляет SQL-запрос серверу ClickHouse.
- Сервер анализирует запрос, определяет, какие столбцы и таблицы нужны, и использует индексы для минимизации чтения данных.
- Если данные распределены по шардам, запрос распределяется через движок `Distributed`.
- Результаты агрегируются и возвращаются клиенту.
- Репликация и сжатие работают в фоновом режиме, обеспечивая надежность и экономию ресурсов.

#### 1.2.6 СAP
**ClickHouse — это AP система** по CAP-теореме.

Это означает, что он делает выбор в пользу **Доступности** (Availability) и **Устойчивости к разделению** (Partition Tolerance), жертвуя при этом строгой **Согласованностью** (Consistency).

*   **A (Доступность):** Кластер всегда доступен для чтения и записи, даже если часть узлов-реплик недоступна.
*   **P (Устойчивость к разделению):** Система продолжает работать, если между узлами пропадает сетевая связь.
*   **C (Согласованность):** Жертвуется. Из-за асинхронной репликации данные на разных репликах могут на короткое время расходиться. ClickHouse гарантирует **согласованность в конечном счете** (eventual consistency).

Этот компромисс идеален для аналитических систем (OLAP), где скорость и доступность важнее, чем мгновенная синхронизация данных между всеми узлами.

---

## 2. Сценарии использования

### 2.1 Основные сценарии
ClickHouse идеально подходит для задач, где требуется быстрая аналитика на больших объемах данных. Основные сценарии:

1. **Анализ логов**:
- Хранение и анализ логов веб-серверов, приложений или сетевых устройств.
- Пример: анализ логов Nginx для подсчета количества запросов по URL или IP-адресам.

2. **Метрики и мониторинг**:
- Сбор и анализ метрик производительности систем, серверов или приложений.
- Пример: мониторинг загрузки процессора или времени ответа API.

3. **Временные ряды**:
- Обработка данных, упорядоченных по времени, таких как показания датчиков IoT, финансовые данные или телеметрия.
- Пример: анализ цен акций с группировкой по дням или часам.

4. **Бизнес-аналитика**:
- Построение отчетов и дашбордов для анализа продаж, поведения пользователей или маркетинговых кампаний.
- Пример: подсчет конверсий на сайте по регионам и каналам трафика.

5. **Ad-hoc аналитика**:
- Выполнение сложных аналитических запросов на больших данных без предварительной подготовки.
- Пример: фильтрация и агрегация данных для исследования пользовательских паттернов.

### 2.2 Когда ClickHouse **не подходит**?
- **OLTP (транзакционные системы)**: ClickHouse не предназначен для частых операций вставки, обновления или удаления отдельных строк. Для таких задач лучше использовать PostgreSQL или MySQL.
- **Маленькие объемы данных**: Если объем данных небольшой (например, менее 1 ГБ), преимущества ClickHouse не так заметны, и проще использовать традиционные СУБД.
- **Сложные транзакции**: ClickHouse не поддерживает сложные транзакции с ACID-свойствами в полной мере.

---

## 3. Основные преимущества ClickHouse

### 3.1 Высокая производительность
- Столбцовое хранение позволяет минимизировать объем данных, считываемых с диска.
- Первичные и вторичные индексы ускоряют поиск данных.
- Многопоточность и векторизация запросов позволяют эффективно использовать CPU.
- **Пример**: Запрос на агрегацию миллиардов строк может выполняться за секунды на современном оборудовании.

### 3.2 Сжатие данных
- ClickHouse автоматически сжимает данные, используя алгоритмы вроде LZ4 или ZSTD.
- Сжатие особенно эффективно для столбцов с повторяющимися или однотипными значениями.
- **Пример**: Таблица с миллиардами строк может занимать в разы меньше места на диске, чем в несжатом виде.

### 3.3 Поддержка SQL с расширениями
- ClickHouse поддерживает большинство стандартных SQL-конструкций (SELECT, JOIN, GROUP BY и т.д.).
- Есть расширения, специфичные для ClickHouse, такие как функции для работы с массивами, словарями или специальными типами данных (например, `DateTime64`).
- **Пример**: Функция `arrayJoin` позволяет "разворачивать" массивы в строках, что удобно для анализа JSON-подобных данных.

### 3.4 Масштабируемость
- Шардирование и репликация позволяют масштабировать ClickHouse до кластеров с сотнями серверов.
- Линейное масштабирование: добавление новых серверов увеличивает производительность почти пропорционально.

### 3.5 Простота эксплуатации
- ClickHouse легко настраивается и поддерживает интеграцию с популярными инструментами (Grafana, Superset, Kafka).
- Минимальные требования к администрированию в небольших установках.

---

## 4. Технические аспекты

### 4.1 Движки таблиц
Движки таблиц в ClickHouse определяют, как данные хранятся, индексируются и обрабатываются. Выбор движка критически важен, так как он влияет на производительность, возможности обработки данных и сценарии использования. Рассмотрим основные движки:

#### 4.1.1 MergeTree и его варианты
- **MergeTree**:
  - Основной движок для аналитических таблиц. Поддерживает первичные и вторичные индексы, партиционирование, сжатие данных.
  - Данные сортируются по указанному ключу сортировки (`ORDER BY`), что ускоряет запросы с фильтрацией и сортировкой.
  - Поддерживает партиционирование (например, по дате) для эффективного управления большими таблицами.
  - **Пример**:
    ```sql
    CREATE TABLE events (
        id UInt32,
        event_time DateTime,
        event_type String
    ) ENGINE = MergeTree()
    PARTITION BY toYYYYMM(event_time)
    ORDER BY (event_time, id);
    ```
  - Используется для временных рядов, логов, аналитики.
- **ReplacingMergeTree**:
  - Расширение MergeTree. Автоматически удаляет дубликаты строк с одинаковым ключом сортировки при слиянии данных (процесс merge).
  - Полезно для данных, где возможны дубли, например, обновления записей.
  - **Пример**: Логи, где нужно оставить только последнюю версию события для каждого `id`.
  - **Особенность**: Дубли удаляются не сразу, а во время фонового слияния.
- **SummingMergeTree**:
  - Автоматически суммирует значения числовых столбцов для строк с одинаковым ключом сортировки.
  - Полезно для агрегации данных, например, подсчета метрик.
  - **Пример**: Подсчет суммарных продаж по дням и регионам.
  - **Пример**:
    ```sql
    CREATE TABLE sales (
        date Date,
        region String,
        amount UInt32
    ) ENGINE = SummingMergeTree()
    ORDER BY (date, region);
    ```
- **AggregatingMergeTree**:
  - Хранит агрегированные данные, используя функции агрегации (например, `SUM`, `COUNT`, `AVG`).
  - Полезно для материализованных представлений (materialized views), где данные агрегируются автоматически.
  - **Пример**: Хранение предвычисленных метрик для дашбордов.
  - Требует специального типа данных `AggregateFunction`.
- **CollapsingMergeTree** и **VersionedCollapsingMergeTree**:
  - Позволяют "сворачивать" строки (удалять или обновлять) на основе специального столбца `sign` или версии.
  - Используются для сценариев, где данные часто обновляются, но без транзакций.

#### 4.1.2 Log
- Простой движок для небольших таблиц. Не поддерживает индексы, партиционирование или сжатие.
- Данные хранятся в виде логов (каждая вставка добавляет новый файл).
- Подходит для временных или тестовых данных, но не для больших объемов из-за низкой производительности.
- **Пример**: Логирование небольших событий для отладки.

#### 4.1.3 Memory
- Хранит данные в оперативной памяти (RAM), что обеспечивает максимальную скорость чтения и записи.
- Не сохраняет данные на диск, поэтому теряет их при перезапуске сервера.
- Используется для временных вычислений или кэширования.
- **Пример**: Временная таблица для промежуточных расчетов.

#### 4.1.4 Dictionary
- Специальный движок для хранения словарей (ключ-значение).
- Используется для быстрого доступа к справочным данным, например, сопоставления кодов стран и их названий.
- Может загружать данные из внешних источников (например, CSV или базы данных).
- **Пример**:
  ```sql
  CREATE DICTIONARY country_dict (
      code String,
      name String
  ) PRIMARY KEY code
  SOURCE(FILE(path '/path/to/countries.csv' format 'CSV'))
  LAYOUT(FLAT());
  ```

**Как движки влияют на хранение и обработку?**
- **MergeTree** и его варианты оптимизированы для больших данных, поддерживают индексы и сжатие, что делает их подходящими для аналитики.
- **Log** и **Memory** просты, но не масштабируются для больших объемов.
- **Dictionary** ускоряет доступ к справочным данным, минимизируя JOIN’ы.
- Выбор движка зависит от задачи: для временных рядов — `MergeTree`, для агрегации — `SummingMergeTree` или `AggregatingMergeTree`, для временных данных — `Memory`.

### 4.2 Индексы

ClickHouse использует два основных типа индексов для ускорения запросов:

#### 4.2.1 Первичные индексы
- Создаются автоматически на основе ключа сортировки (`ORDER BY`) в таблицах семейства `MergeTree`.
- Индекс хранит указатели на блоки данных (гранулы), отсортированные по ключу.
- **Как работает**: При запросе с фильтрацией по ключу сортировки (например, `WHERE event_time > '2025-07-01'`) ClickHouse использует индекс, чтобы читать только нужные гранулы, а не всю таблицу.
- **Пример**:
  ```sql
  CREATE TABLE logs (
      event_time DateTime,
      user_id UInt32
  ) ENGINE = MergeTree()
  ORDER BY (event_time, user_id);
  ```
  Запрос `SELECT * FROM logs WHERE event_time > '2025-07-01'` использует первичный индекс для быстрого поиска.

#### 4.2.2 Вторичные индексы (Skip Indexes)
- Дополнительные индексы, которые создаются с помощью конструкции `INDEX`.
- Используются для ускорения запросов по столбцам, не входящим в ключ сортировки.
- Типы skip-индексов:
  - **minmax**: Хранит минимальные и максимальные значения для гранулы.
  - **set**: Хранит уникальные значения столбца.
  - **bloom_filter**: Вероятностный индекс для быстрого поиска значений.
- **Пример**:
  ```sql
  CREATE TABLE logs (
      event_time DateTime,
      user_id UInt32,
      action String,
      INDEX action_idx action TYPE bloom_filter GRANULARITY 1
  ) ENGINE = MergeTree()
  ORDER BY (event_time, user_id);
  ```
  Запрос `SELECT * FROM logs WHERE action = 'click'` будет использовать `action_idx` для фильтрации.

**Как проектировать индексы?**
- **Первичный индекс**:
  - Выбирайте столбцы, по которым чаще всего фильтруете или сортируете (например, `event_time` для временных рядов).
  - Используйте составные ключи (например, `(event_time, user_id)`), если запросы комбинируют несколько условий.
  - Избегайте слишком длинных ключей, так как это увеличивает размер индекса.
- **Вторичные индексы**:
  - Добавляйте их для столбцов, часто используемых в `WHERE`, но не входящих в ключ сортировки.
  - Используйте `bloom_filter` для столбцов с высокой кардинальностью (много уникальных значений).
  - Настройте параметр `GRANULARITY` (обычно 1–4) в зависимости от размера данных: меньшая гранулярность ускоряет запросы, но увеличивает размер индекса.
- **Совет**: Тестируйте запросы с помощью `EXPLAIN` для проверки, какие индексы используются.

### 4.3 Сжатие данных

ClickHouse активно использует сжатие данных, чтобы уменьшить объем хранимых данных и ускорить чтение с диска.

#### 4.3.1 Алгоритмы сжатия
- **LZ4**: Быстрое сжатие и декомпрессия, используется по умолчанию. Подходит для большинства сценариев, где важна скорость.
- **ZSTD**: Более высокая степень сжатия, но требует больше CPU для компрессии/декомпрессии. Используется, когда нужно минимизировать объем данных.
- **Настройка**:
  ```sql
  CREATE TABLE example (
      id UInt32,
      data String
  ) ENGINE = MergeTree()
  ORDER BY id
  SETTINGS index_granularity = 8192, compression = 'ZSTD';
  ```

#### 4.3.2 Как сжатие влияет на производительность и хранение?
- **Хранение**: Сжатие может уменьшить объем данных в 5–10 раз, особенно для столбцов с повторяющимися значениями (например, категории, даты).
- **Производительность**: Сжатые данные быстрее читаются с диска, так как объем данных меньше, но декомпрессия требует дополнительных ресурсов CPU.
- **Пример**: Таблица с миллиардами строк логов может занимать 100 ГБ вместо 1 ТБ благодаря сжатию.
- **Оптимизация**:
  - Используйте `LZ4` для высоконагруженных систем, где важна скорость.
  - Используйте `ZSTD` для архивных данных или если дисковое пространство ограничено.
  - Выбирайте типы данных с меньшим размером (например, `UInt32` вместо `Int64`, если значения не превышают 4 млрд).

### 4.4 Шардирование и репликация

#### 4.4.1 Шардирование
- Шардирование распределяет данные по нескольким серверам (шардам), чтобы увеличить пропускную способность и объем хранимых данных.
- Используется движок `Distributed`, который действует как прокси: он перенаправляет запросы к нужным шардам и агрегирует результаты.
- **Пример настройки**:
  ```sql
  CREATE TABLE logs_local (
      event_time DateTime,
      user_id UInt32
  ) ENGINE = MergeTree()
  ORDER BY (event_time, user_id);

  CREATE TABLE logs_distributed (
      event_time DateTime,
      user_id UInt32
  ) ENGINE = Distributed(cluster_name, database, logs_local, user_id % 4);
  ```
  Здесь `user_id % 4` определяет, на какой из 4 шардов отправить данные.
- **Как работает**:
  - Данные делятся по ключу шардирования (например, хэш от `user_id`).
  - Запросы к таблице `logs_distributed` автоматически распределяются по шардам.
- **Совет**: Выбирайте ключ шардирования, который равномерно распределяет данные (например, хэш от идентификатора).

#### 4.4.2 Репликация
- Репликация копирует данные на несколько серверов для отказоустойчивости и балансировки нагрузки.
- Используется движок `ReplicatedMergeTree`, который синхронизирует данные через Apache ZooKeeper или ClickHouse Keeper.
- **Пример настройки**:
  ```sql
  CREATE TABLE logs_replicated (
      event_time DateTime,
      user_id UInt32
  ) ENGINE = ReplicatedMergeTree('/clickhouse/tables/logs', 'replica1')
  ORDER BY (event_time, user_id);
  ```
  Здесь `/clickhouse/tables/logs` — путь в ZooKeeper, `replica1` — имя реплики.
- **Как работает**:
  - ZooKeeper координирует вставки и слияния данных между репликами.
  - При сбое одной реплики запросы перенаправляются к другой.
- **Настройка ZooKeeper**:
  - Установите ZooKeeper (или используйте встроенный ClickHouse Keeper).
  - Настройте конфигурацию сервера ClickHouse для подключения к ZooKeeper:
    ```xml
    <zookeeper>
        <node>
            <host>zookeeper1</host>
            <port>2181</port>
        </node>
    </zookeeper>
    ```

**Совет**:
- Комбинируйте шардирование и репликацию для крупных систем: каждый шард может иметь несколько реплик.
- Используйте `Distributed` для чтения данных, но вставляйте данные напрямую в локальные таблицы (`logs_local`), чтобы избежать дублирования.

### 4.5 Форматы данных

#### 4.5.1 Поддерживаемые форматы
- **CSV**: Простой текстовый формат, подходит для небольших данных.
- **JSONEachRow**: Каждая строка — отдельный JSON-объект. Удобно для парсинга сложных данных.
- **Parquet**: Столбцовый формат, оптимизированный для больших данных. Высокая степень сжатия и поддержка сложных структур.
- **ORC**: Альтернатива Parquet, также столбцовый, используется в экосистемах Hadoop.
- **TSV**: Табличный формат, разделенный табуляцией.
- **Native**: Внутренний бинарный формат ClickHouse, самый быстрый для обмена данными между серверами ClickHouse.

#### 4.5.2 Оптимизация загрузки данных
- **Используйте Parquet или ORC** для больших объемов данных, так как они сжимают данные и поддерживают столбцовую структуру, что ускоряет импорт.
- **Пример импорта**:
  ```sql
  INSERT INTO logs FROM INFILE 'data.parquet' FORMAT Parquet;
  ```
- **Пакетная загрузка**: Загружайте данные большими партиями (тысячи или миллионы строк), чтобы минимизировать накладные расходы.
- **Сжатие при передаче**: Используйте сжатие (например, `gzip`) при загрузке через HTTP:
  ```bash
  cat data.csv.gz | clickhouse-client --query="INSERT INTO logs FORMAT CSV"
  ```
- **Параллельная загрузка**: Для больших данных используйте несколько потоков или шардов для параллельного импорта.
- **Материализованные представления**: Используйте их для автоматической обработки и агрегации входящих данных:
  ```sql
  CREATE MATERIALIZED VIEW logs_mv
  ENGINE = AggregatingMergeTree()
  ORDER BY (event_time)
  AS SELECT
      toStartOfHour(event_time) AS hour,
      countState() AS count
  FROM logs
  GROUP BY hour;
  ```

---

## 5. SQL в ClickHouse

### 5.1 Особенности SQL
ClickHouse поддерживает стандартный SQL (синтаксис, близкий к ANSI SQL), но имеет свои особенности и расширения, которые делают его особенно мощным для аналитических запросов. Вот ключевые аспекты:

#### 5.1.1 Поддержка стандартного SQL с отличиями
- ClickHouse поддерживает основные конструкции SQL: `SELECT`, `WHERE`, `GROUP BY`, `JOIN`, `ORDER BY`, `LIMIT`, и т.д.
- **Отличия от классического SQL**:
  - Нет полноценной поддержки транзакций (ClickHouse не является OLTP-системой).
  - Операции `UPDATE` и `DELETE` ограничены и выполняются асинхронно (через `ALTER TABLE ... UPDATE/DELETE`).
  - `JOIN` менее оптимизирован, чем в транзакционных СУБД, и требует осторожного использования.
  - Некоторые функции и синтаксис уникальны для ClickHouse (например, работа с массивами).
- **Пример простого запроса**:
  ```sql
  SELECT user_id, COUNT(*) as event_count
  FROM events
  WHERE event_time >= '2025-07-01'
  GROUP BY user_id
  ORDER BY event_count DESC
  LIMIT 10;
  ```

#### 5.1.2 Уникальные функции
- **Агрегатные функции**:
  - `uniq`: Подсчитывает количество уникальных значений (примерно, использует HyperLogLog).
  - `groupArray`: Создает массив из значений столбца для каждой группы.
  - `topK`: Возвращает топ-K значений по частоте.
  - `sumIf`, `countIf`: Условные агрегации.

- **Функции для работы с массивами**:
  - ClickHouse поддерживает тип данных `Array`, что упрощает работу с массивами.
  - `arrayJoin`: "Разворачивает" массив в отдельные строки.
  - Другие функции: `length`, `arrayElement`, `arrayConcat`.
  
- **Функции для работы с JSON**:
  - `JSONExtract`: Извлекает данные из JSON-строк.
  - Полезно для обработки логов или данных с динамической структурой.

#### 5.1.3 Расширения SQL
- Поддержка типов данных, специфичных для аналитики: `DateTime64`, `UInt64`, `Nullable`.
- Специальные конструкции, такие как `WITH` для CTE (Common Table Expressions):
  ```sql
  WITH daily_counts AS (
      SELECT toDate(event_time) AS day, COUNT(*) AS cnt
      FROM events
      GROUP BY day
  )
  SELECT day, cnt
  FROM daily_counts
  WHERE cnt > 1000;
  ```

### 5.2 Оптимизация запросов

#### 5.2.1 Как ClickHouse выполняет запросы (Query Execution Plan)
- ClickHouse использует **столбцовое хранение**, что позволяет читать только нужные столбцы.
- **Первичные индексы** (на основе ключа сортировки) и **skip-индексы** минимизируют объем данных, считываемых с диска.
- Запросы выполняются в несколько этапов:
  1. Парсинг запроса и проверка синтаксиса.
  2. Определение, какие столбцы и гранулы данных нужны (с использованием индексов).
  3. Чтение данных с диска (сжатые данные декомпрессируются).
  4. Выполнение фильтрации (`WHERE`), агрегации (`GROUP BY`), сортировки (`ORDER BY`).
  5. Возврат результата.
- ClickHouse активно использует многопоточность и векторизацию для ускорения вычислений.

#### 5.2.2 Использование `EXPLAIN` для анализа запросов
- Команда `EXPLAIN` показывает, как ClickHouse планирует выполнить запрос.
- **Пример**:
  ```sql
  EXPLAIN
  SELECT user_id, COUNT(*) AS event_count
  FROM events
  WHERE event_time >= '2025-07-01'
  GROUP BY user_id;
  ```
  Вывод покажет:
  - Какие индексы используются.
  - Какие столбцы читаются.
  - Объем данных, который будет обработан.
- **Типы EXPLAIN**:
  - `EXPLAIN PLAN`: Показывает план выполнения.
  - `EXPLAIN PIPELINE`: Показывает этапы обработки (например, фильтрация, агрегация).
  - **Пример**:
    ```sql
    EXPLAIN PIPELINE
    SELECT user_id, COUNT(*) AS event_count
    FROM events
    WHERE event_time >= '2025-07-01'
    GROUP BY user_id;
    ```
- Используйте `EXPLAIN` для проверки, какие индексы задействованы, и нет ли полного сканирования таблицы.

#### 5.2.3 Оптимизация `WHERE`, `GROUP BY`, `JOIN`
- **WHERE**:
  - Фильтруйте по столбцам, входящим в ключ сортировки (`ORDER BY`) или первичный индекс.
  - Используйте условия, которые минимизируют объем данных (например, фильтрация по дате).
  - **Пример**:
    ```sql
    SELECT user_id
    FROM events
    WHERE event_time >= '2025-07-01' AND event_type = 'click';
    ```
    Если `event_time` в ключе сортировки, а `event_type` имеет skip-индекс, запрос будет быстрым.
- **GROUP BY**:
  - Минимизируйте количество группировок, используя столбцы с низкой кардинальностью (например, регион вместо user_id).
  - Используйте предварительную агрегацию через материализованные представления (см. ниже).
  - **Пример**:
    ```sql
    SELECT toDate(event_time) AS day, COUNT(*)
    FROM events
    GROUP BY day;
    ```
- **JOIN**:
  - `JOIN` в ClickHouse менее оптимизирован, чем в транзакционных СУБД, и может быть медленным для больших таблиц.
  - Используйте `INNER JOIN` или `LEFT JOIN` вместо `FULL JOIN`.
  - Старайтесь заменять `JOIN` на словари (`Dictionary`) или денормализацию данных.
  - **Пример оптимизации**:
    Вместо:
    ```sql
    SELECT e.user_id, u.name
    FROM events e
    JOIN users u ON e.user_id = u.user_id;
    ```
    Используйте словарь:
    ```sql
    CREATE DICTIONARY users_dict (
        user_id UInt32,
        name String
    ) PRIMARY KEY user_id
    SOURCE(...);
    SELECT user_id, dictGet('users_dict', 'name', user_id) AS name
    FROM events;
    ```
- **Общие советы**:
  - Указывайте только нужные столбцы в `SELECT` (ClickHouse читает только их).
  - Избегайте `SELECT *`.
  - Используйте партиционирование для ограничения объема данных (например, `PARTITION BY toYYYYMM(event_time)`).

### 5.3 Агрегатные функции и материализованные представления

#### 5.3.1 Агрегатные функции
- ClickHouse поддерживает мощные агрегатные функции, которые можно использовать для сложных аналитических задач.
- **Примеры**:
  - `uniqExact`: Точный подсчет уникальных значений (медленнее, но точнее, чем `uniq`).
  - `quantile`: Вычисление квантилей (например, медианы).
    ```sql
    SELECT quantile(0.5)(duration) AS median_duration
    FROM events;
    ```
  - `argMin`, `argMax`: Находят значение столбца, соответствующее минимальному/максимальному значению другого столбца.
    ```sql
    SELECT argMax(user_id, event_time) AS last_user
    FROM events;
    ```
- Агрегатные функции можно комбинировать с `GROUP BY` для сложных вычислений.

#### 5.3.2 Материализованные представления (`MATERIALIZED VIEW`)
- Материализованные представления автоматически обрабатывают входящие данные и сохраняют результат в отдельной таблице.
- Они идеальны для предварительной агрегации данных, что ускоряет запросы и снижает нагрузку на сервер.
- **Пример**:
  ```sql
  CREATE MATERIALIZED VIEW daily_stats
  ENGINE = AggregatingMergeTree()
  ORDER BY (day, region)
  AS
  SELECT
      toDate(event_time) AS day,
      region,
      countState() AS event_count,
      sumState(amount) AS total_amount
  FROM sales
  GROUP BY day, region;
  ```
  - Данные, вставленные в таблицу `sales`, автоматически агрегируются в `daily_stats`.
  - Для чтения агрегированных данных:
    ```sql
    SELECT
        day,
        region,
        countMerge(event_count) AS count,
        sumMerge(total_amount) AS total
    FROM daily_stats
    GROUP BY day, region;
    ```
- **Особенности**:
  - Используйте движок `AggregatingMergeTree` для хранения агрегированных данных с функциями вроде `countState`, `sumState`.
  - Материализованные представления обновляются в реальном времени при вставке данных.
  - Они позволяют избежать выполнения тяжелых запросов на лету.

#### 5.3.3 Оптимизация с помощью материализованных представлений
- Создавайте представления для часто используемых агрегаций (например, по дням, часам, регионам).
- Используйте их для замены сложных `GROUP BY` в запросах.
- Пример: Вместо выполнения `SELECT toDate(event_time), COUNT(*) FROM events GROUP BY toDate(event_time)` каждый раз, создайте материализованное представление и читайте из него.

---

## 6. Производительность и оптимизация

### 6.1 Проектирование схемы данных

#### 6.1.1 Выбор правильного первичного ключа и сортировки (`ORDER BY`)
- **Первичный ключ**:
  - В таблицах семейства `MergeTree` первичный ключ определяется в конструкции `ORDER BY` при создании таблицы.
  - Он задает порядок сортировки данных на диске и создает первичный индекс, который используется для ускорения запросов.
  - Выбирайте столбцы, по которым чаще всего фильтруете или сортируете (например, `event_time` для временных рядов).
  - **Рекомендации**:
    - Используйте столбцы с умеренной кардинальностью (например, даты, категории) в начале ключа.
    - Избегайте столбцов с очень высокой кардинальностью (например, уникальные ID) в начале ключа, так как это увеличивает размер индекса и снижает эффективность.
    - Составные ключи (например, `(event_time, user_id)`) полезны для запросов с комбинированными фильтрами.
  - **Пример**:
    ```sql
    CREATE TABLE events (
        event_time DateTime,
        user_id UInt32,
        event_type String
    ) ENGINE = MergeTree()
    PARTITION BY toYYYYMM(event_time)
    ORDER BY (event_time, user_id);
    ```
    Запрос `SELECT * FROM events WHERE event_time >= '2025-07-01' AND user_id = 123` будет использовать первичный индекс для быстрого поиска.
- **Сортировка (`ORDER BY`)**:
  - Данные физически сортируются на диске по указанным столбцам, что ускоряет запросы с фильтрацией и группировкой.
  - Порядок столбцов в `ORDER BY` важен: сначала указывайте столбцы, используемые в `WHERE`, затем — в `GROUP BY` или `ORDER BY` запросов.

#### 6.1.2 Денормализация данных для минимизации `JOIN`-ов
- В ClickHouse операции `JOIN` менее оптимизированы, чем в транзакционных СУБД, и могут быть медленными на больших таблицах.
- **Денормализация**:
  - Храните данные в одной таблице, объединяя информацию, которая часто запрашивается вместе.
  - Вместо `JOIN` с таблицей справочника используйте словари (`Dictionary`) или встраивайте данные напрямую.
  - **Пример**:
    Вместо двух таблиц:
    ```sql
    CREATE TABLE users (
        user_id UInt32,
        name String
    ) ENGINE = MergeTree() ORDER BY user_id;

    CREATE TABLE events (
        event_time DateTime,
        user_id UInt32,
        event_type String
    ) ENGINE = MergeTree() ORDER BY event_time;
    ```
    Создайте одну денормализованную таблицу:
    ```sql
    CREATE TABLE events (
        event_time DateTime,
        user_id UInt32,
        user_name String,
        event_type String
    ) ENGINE = MergeTree()
    ORDER BY (event_time, user_id);
    ```
  - Если справочные данные нужны редко, используйте словарь:
    ```sql
    CREATE DICTIONARY users_dict (
        user_id UInt32,
        name String
    ) PRIMARY KEY user_id
    SOURCE(FILE(path '/path/to/users.csv' format 'CSV'))
    LAYOUT(FLAT());

    SELECT event_time, user_id, dictGet('users_dict', 'name', user_id) AS user_name
    FROM events;
    ```
- **Преимущества денормализации**:
  - Ускоряет запросы за счет устранения `JOIN`.
  - Упрощает схему данных.
- **Недостатки**:
  - Увеличивает объем хранимых данных.
  - Требует дополнительных усилий при обновлении справочных данных.

### 6.2 Оптимизация производительности

#### 6.2.1 Управление партициями и их влияние на производительность
- **Партиционирование**:
  - Партиции разбивают таблицу на логические части, что позволяет читать только нужные данные.
  - Используйте столбец с низкой кардинальностью для партиционирования, например, `toYYYYMM(event_time)` для данных по месяцам.
  - **Пример**:
    ```sql
    CREATE TABLE events (
        event_time DateTime,
        user_id UInt32,
        event_type String
    ) ENGINE = MergeTree()
    PARTITION BY toYYYYMM(event_time)
    ORDER BY (event_time, user_id);
    ```
    Запрос `SELECT * FROM events WHERE event_time >= '2025-07-01'` будет читать только партиции за июль 2025 года.
- **Преимущества**:
  - Ускоряет запросы, так как читаются только нужные партиции.
  - Упрощает удаление старых данных с помощью `ALTER TABLE DROP PARTITION`.
- **Рекомендации**:
  - Не создавайте слишком много партиций (например, по дням для многолетних данных), чтобы избежать накладных расходов.
  - Оптимизируйте размер партиций: идеально, если каждая партиция содержит от 1 до 10 млн строк.
  - Используйте команду `OPTIMIZE TABLE` для слияния данных внутри партиций, но делайте это с осторожностью, так как это ресурсоемкая операция.

#### 6.2.2 Настройка параметров сервера
- ClickHouse позволяет настраивать параметры сервера для оптимизации производительности. Эти параметры задаются в конфигурационном файле (`config.xml`) или в запросах.
- **Ключевые параметры**:
  - **`max_threads`**:
    - Определяет максимальное количество потоков для выполнения запроса.
    - Значение по умолчанию: равно количеству CPU-ядер.
    - Увеличьте для больших запросов, но избегайте чрезмерного увеличения, чтобы не перегружать сервер.
    - **Пример**:
      ```xml
      <max_threads>16</max_threads>
      ```
      Или в запросе:
      ```sql
      SET max_threads = 16;
      ```
  - **`max_memory_usage`**:
    - Ограничивает объем оперативной памяти, используемой одним запросом.
    - Значение по умолчанию: 10 ГБ.
    - Увеличьте для сложных запросов с большими `GROUP BY` или `JOIN`, но следите за общим потреблением памяти.
    - **Пример**:
      ```xml
      <max_memory_usage>20000000000</max_memory_usage> <!-- 20 GB -->
      ```
  - **`index_granularity`**:
    - Определяет размер гранулы данных для первичного индекса (по умолчанию 8192 строки).
    - Меньшее значение ускоряет точечные запросы, но увеличивает размер индекса.
    - **Пример**:
      ```sql
      CREATE TABLE events (
          event_time DateTime,
          user_id UInt32
      ) ENGINE = MergeTree()
      ORDER BY (event_time, user_id)
      SETTINGS index_granularity = 4096;
      ```
- **Совет**:
  - Настраивайте параметры в зависимости от оборудования и нагрузки. Например, для сервера с 32 ядрами установите `max_threads = 24` для баланса между запросами.
  - Используйте профили настроек для разных типов пользователей:
    ```xml
    <profiles>
        <default>
            <max_threads>8</max_threads>
            <max_memory_usage>10000000000</max_memory_usage>
        </default>
        <heavy_user>
            <max_threads>16</max_threads>
            <max_memory_usage>20000000000</max_memory_usage>
        </heavy_user>
    </profiles>
    ```

#### 6.2.3 Использование `PREWHERE` для фильтрации данных
- `PREWHERE` — это специальная конструкция в ClickHouse, которая выполняет предварительную фильтрацию данных до чтения всех столбцов.
- Используется для условий, которые могут быстро отфильтровать большие объемы данных, особенно если они связаны с первичным индексом.
- **Пример**:
  ```sql
  SELECT user_id, event_type
  FROM events
  PREWHERE event_time >= '2025-07-01'
  WHERE event_type = 'click';
  ```
  - `PREWHERE event_time >= '2025-07-01'` использует первичный индекс для выбора нужных гранул данных.
  - Затем `WHERE event_type = 'click'` фильтрует оставшиеся строки.
- **Когда использовать**:
  - Для условий на столбцы из первичного ключа или с низкой селективностью.
  - Если есть skip-индексы, ClickHouse может автоматически перевести `WHERE` в `PREWHERE`.
- **Преимущества**:
  - Снижает объем данных, считываемых с диска.
  - Ускоряет запросы, особенно на больших таблицах.
- **Совет**: Используйте `EXPLAIN` для проверки, применяется ли `PREWHERE`:
  ```sql
  EXPLAIN
  SELECT user_id, event_type
  FROM events
  PREWHERE event_time >= '2025-07-01'
  WHERE event_type = 'click';
  ```

### 6.3 Мониторинг и профилирование

#### 6.3.1 Использование системных таблиц
- ClickHouse предоставляет системные таблицы для мониторинга и анализа производительности.
- **Ключевые системные таблицы**:
  - **`system.query_log`**:
    - Хранит информацию о выполненных запросах: текст запроса, время выполнения, объем прочитанных данных, ошибки.
    - **Пример**:
      ```sql
      SELECT
          query,
          query_duration_ms,
          read_rows,
          read_bytes
      FROM system.query_log
      WHERE type = 'QueryFinish'
      ORDER BY query_duration_ms DESC
      LIMIT 10;
      ```
    - Используйте для поиска медленных запросов или запросов с большим потреблением ресурсов.
  - **`system.parts`**:
    - Содержит информацию о партициях и частях данных (data parts) в таблицах `MergeTree`.
    - Позволяет отслеживать размер партиций, количество строк, сжатие и активность.
    - **Пример**:
      ```sql
      SELECT
          table,
          partition,
          rows,
          bytes_on_disk / 1024 / 1024 AS size_mb
      FROM system.parts
      WHERE active
      ORDER BY size_mb DESC;
      ```
    - Используйте для анализа объема данных и выявления партиций, которые нужно оптимизировать.
  - **`system.processes`**:
    - Показывает текущие выполняющиеся запросы.
    - **Пример**:
      ```sql
      SELECT query, elapsed, read_rows
      FROM system.processes;
      ```
    - Полезно для мониторинга текущей нагрузки.
- **Настройка `system.query_log`**:
  - Включите логирование запросов в конфигурации:
    ```xml
    <query_log>
        <database>system</database>
        <table>query_log</table>
        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
    </query_log>
    ```

#### 6.3.2 Инструменты мониторинга
- **Grafana + ClickHouse**:
  - ClickHouse может быть источником данных для Grafana, что позволяет визуализировать метрики производительности.
  - Настройте подключение Grafana к ClickHouse через плагин ClickHouse.
  - Создайте дашборды для мониторинга:
    - Время выполнения запросов (на основе `system.query_log`).
    - Объем прочитанных данных.
    - Использование CPU и памяти.
  - **Пример запроса для Grafana**:
    ```sql
    SELECT
        toStartOfMinute(event_time) AS minute,
        AVG(query_duration_ms) AS avg_duration
    FROM system.query_log
    WHERE type = 'QueryFinish'
    GROUP BY minute
    ORDER BY minute;
    ```
    Это покажет среднее время выполнения запросов по минутам.
- **Другие инструменты**:
  - **clickhouse-client**: Для интерактивного анализа и выполнения команд.
  - **Zabbix** или **Prometheus**: Для мониторинга серверных метрик (CPU, память, диск).
- **Рекомендации**:
  - Настройте алерты в Grafana для медленных запросов (например, `query_duration_ms > 10000`).
  - Регулярно проверяйте `system.parts` для выявления партиций, которые требуют слияния или удаления.

#### 6.3.3 Профилирование запросов
- Используйте `EXPLAIN PIPELINE` для анализа этапов выполнения запроса:
  ```sql
  EXPLAIN PIPELINE
  SELECT user_id, COUNT(*) AS event_count
  FROM events
  WHERE event_time >= '2025-07-01'
  GROUP BY user_id;
  ```
  Это покажет, какие операции (чтение, фильтрация, агрегация) занимают больше времени.
- Проверяйте использование индексов и объем прочитанных данных в `system.query_log`.
- Оптимизируйте запросы, если видите:
  - Полное сканирование таблицы (отсутствие использования индексов).
  - Большой объем прочитанных данных (`read_rows` или `read_bytes`).
