# ClickHouse

## 1. Основы ClickHouse

### 1.1 Назначение
ClickHouse создан для выполнения аналитических запросов (OLAP — Online Analytical Processing), которые обычно включают обработку больших объемов данных для получения агрегированных результатов, таких как суммы, средние значения, группировки и т.д. Он предназначен для сценариев, где требуется высокая производительность на чтение данных, а не на частые обновления или транзакции.

- **Ключевая особенность**: ClickHouse оптимизирован для работы с большими наборами данных, где запросы выполняются редко, но требуют обработки миллионов или миллиардов строк.
- **Примеры задач**: анализ логов веб-приложений, обработка метрик IoT-устройств, анализ временных рядов, бизнес-аналитика, мониторинг.

Когда ClickHouse **не подходит**?

- **OLTP (транзакционные системы)**: ClickHouse не предназначен для частых операций вставки, обновления или удаления отдельных строк. Для таких задач лучше использовать PostgreSQL или MySQL.
- **Маленькие объемы данных**: Если объем данных небольшой (например, менее 1 ГБ), преимущества ClickHouse не так заметны, и проще использовать традиционные СУБД.
- **Сложные транзакции**: ClickHouse не поддерживает сложные транзакции с ACID-свойствами в полной мере.


### 1.2 Архитектура ClickHouse

#### 1.2.1 Столбцовое хранение данных
- В колоночной базе, такой как ClickHouse, значения в каждом столбце хранятся в том же порядке, в котором они были вставлены. Например:
  - Столбец "Имя": `[Иван, Маша, Петя]`
  - Столбец "Возраст": `[25, 30, 28]`
  - Столбец "Город": `[Москва, Питер, Казань]`
- Поскольку порядок одинаков, база знает, что `Иван` (1-е значение в столбце "Имя"), `25` (1-е значение в столбце "Возраст") и `Москва` (1-е значение в столбце "Город") — это одна строка.
- Это как если в Excel вы разрезали таблицу на отдельные столбцы, но запомнили, что строка №1 — это всегда первые значения в каждом столбце, строка №2 — вторые и так далее.

#### 1.2.2 Сервер
- Сервер ClickHouse — это основная компонента, которая обрабатывает запросы, управляет хранилищем и координирует распределенные вычисления.
- Он работает как единый процесс, который обрабатывает запросы клиентов через протоколы HTTP, TCP или другие интерфейсы.
- Сервер поддерживает многопоточность, что позволяет эффективно использовать ресурсы многоядерных процессоров.

#### 1.2.3 СAP
**ClickHouse — это AP система** по CAP-теореме.

Это означает, что он делает выбор в пользу **Доступности** (Availability) и **Устойчивости к разделению** (Partition Tolerance), жертвуя при этом строгой **Согласованностью** (Consistency).

*   **A (Доступность):** Кластер всегда доступен для чтения и записи, даже если часть узлов-реплик недоступна.
*   **P (Устойчивость к разделению):** Система продолжает работать, если между узлами пропадает сетевая связь.
*   **C (Согласованность):** Жертвуется. Из-за асинхронной репликации данные на разных репликах могут на короткое время расходиться. ClickHouse гарантирует **согласованность в конечном счете** (eventual consistency).

Этот компромисс идеален для аналитических систем (OLAP), где скорость и доступность важнее, чем мгновенная синхронизация данных между всеми узлами.

---

## 2. Основные преимущества ClickHouse

### 2.1 Высокая производительность
- Столбцовое хранение позволяет минимизировать объем данных, считываемых с диска.
- Первичные и вторичные индексы ускоряют поиск данных.
- Многопоточность и векторизация запросов позволяют эффективно использовать CPU.
- **Пример**: Запрос на агрегацию миллиардов строк может выполняться за секунды на современном оборудовании.

### 2.2 Сжатие данных
- ClickHouse автоматически сжимает данные, используя алгоритмы вроде LZ4 или ZSTD.
- Сжатие особенно эффективно для столбцов с повторяющимися или однотипными значениями.
- **Пример**: Таблица с миллиардами строк может занимать в разы меньше места на диске, чем в несжатом виде.

### 2.3 Поддержка SQL с расширениями
- ClickHouse поддерживает большинство стандартных SQL-конструкций (SELECT, JOIN, GROUP BY и т.д.).
- Есть расширения, специфичные для ClickHouse, такие как функции для работы с массивами, словарями или специальными типами данных (например, `DateTime64`).
- **Пример**: Функция `arrayJoin` позволяет "разворачивать" массивы в строках, что удобно для анализа JSON-подобных данных.

### 2.4 Масштабируемость
- Шардирование и репликация позволяют масштабировать ClickHouse до кластеров с сотнями серверов.
- Линейное масштабирование: добавление новых серверов увеличивает производительность почти пропорционально.

### 2.5 Простота эксплуатации
- ClickHouse легко настраивается и поддерживает интеграцию с популярными инструментами (Grafana, Superset, Kafka).
- Минимальные требования к администрированию в небольших установках.

---

## 3. Технические аспекты

### 3.1 Движки таблиц
Движки таблиц в ClickHouse определяют, как данные хранятся, индексируются и обрабатываются. Выбор движка критически важен, так как он влияет на производительность, возможности обработки данных и сценарии использования. Рассмотрим основные движки:

#### 3.1.1 MergeTree и его варианты
- **MergeTree**:
  - Основной движок для аналитических таблиц. Поддерживает первичные и вторичные индексы, партиционирование, сжатие данных.
  - Данные сортируются по указанному ключу сортировки (`ORDER BY`), что ускоряет запросы с фильтрацией и сортировкой.
  - Поддерживает партиционирование (например, по дате) для эффективного управления большими таблицами.
  - **Пример**:
    ```sql
    CREATE TABLE events (
        id UInt32,
        event_time DateTime,
        event_type String
    ) ENGINE = MergeTree()
    PARTITION BY toYYYYMM(event_time)
    ORDER BY (event_time, id);
    ```
  - Используется для временных рядов, логов, аналитики.
- **ReplacingMergeTree**:
  - Расширение MergeTree. Автоматически удаляет дубликаты строк с одинаковым ключом сортировки при слиянии данных (процесс merge).
  - Полезно для данных, где возможны дубли, например, обновления записей.
  - **Пример**: Логи, где нужно оставить только последнюю версию события для каждого `id`.
  - **Особенность**: Дубли удаляются не сразу, а во время фонового слияния.
- **SummingMergeTree**:
  - Автоматически суммирует значения числовых столбцов для строк с одинаковым ключом сортировки.
  - Полезно для агрегации данных, например, подсчета метрик.
  - **Пример**: Подсчет суммарных продаж по дням и регионам.
  - **Пример**:
    ```sql
    CREATE TABLE sales (
        date Date,
        region String,
        amount UInt32
    ) ENGINE = SummingMergeTree()
    ORDER BY (date, region);
    ```
- **AggregatingMergeTree**:
  - Хранит агрегированные данные, используя функции агрегации (например, `SUM`, `COUNT`, `AVG`).
  - Полезно для материализованных представлений (materialized views), где данные агрегируются автоматически.
  - **Пример**: Хранение предвычисленных метрик для дашбордов.
  - Требует специального типа данных `AggregateFunction`.
- **CollapsingMergeTree** и **VersionedCollapsingMergeTree**:
  - Позволяют "сворачивать" строки (удалять или обновлять) на основе специального столбца `sign` или версии.
  - Используются для сценариев, где данные часто обновляются, но без транзакций.

#### 3.1.2 Log
- Простой движок для небольших таблиц. Не поддерживает индексы, партиционирование или сжатие.
- Данные хранятся в виде логов (каждая вставка добавляет новый файл).
- Подходит для временных или тестовых данных, но не для больших объемов из-за низкой производительности.
- **Пример**: Логирование небольших событий для отладки.

#### 3.1.3 Memory
- Хранит данные в оперативной памяти (RAM), что обеспечивает максимальную скорость чтения и записи.
- Не сохраняет данные на диск, поэтому теряет их при перезапуске сервера.
- Используется для временных вычислений или кэширования.
- **Пример**: Временная таблица для промежуточных расчетов.

#### 3.1.4 Dictionary
- Специальный движок для хранения словарей (ключ-значение).
- Используется для быстрого доступа к справочным данным, например, сопоставления кодов стран и их названий.
- Может загружать данные из внешних источников (например, CSV или базы данных).
- **Пример**:
  ```sql
  CREATE DICTIONARY country_dict (
      code String,
      name String
  ) PRIMARY KEY code
  SOURCE(FILE(path '/path/to/countries.csv' format 'CSV'))
  LAYOUT(FLAT());
  ```

**Как движки влияют на хранение и обработку?**
- **MergeTree** и его варианты оптимизированы для больших данных, поддерживают индексы и сжатие, что делает их подходящими для аналитики.
- **Log** и **Memory** просты, но не масштабируются для больших объемов.
- **Dictionary** ускоряет доступ к справочным данным, минимизируя JOIN’ы.
- Выбор движка зависит от задачи: для временных рядов — `MergeTree`, для агрегации — `SummingMergeTree` или `AggregatingMergeTree`, для временных данных — `Memory`.

### 3.2 Индексы

ClickHouse использует два основных типа индексов для ускорения запросов:

#### 3.2.1 Первичные индексы
- Создаются автоматически на основе ключа сортировки (`ORDER BY`) в таблицах семейства `MergeTree`.
- Индекс хранит указатели на блоки данных (гранулы), отсортированные по ключу.
- **Как работает**: При запросе с фильтрацией по ключу сортировки (например, `WHERE event_time > '2025-07-01'`) ClickHouse использует индекс, чтобы читать только нужные гранулы, а не всю таблицу.
- **Пример**:
  ```sql
  CREATE TABLE logs (
      event_time DateTime,
      user_id UInt32
  ) ENGINE = MergeTree()
  ORDER BY (event_time, user_id);
  ```
  Запрос `SELECT * FROM logs WHERE event_time > '2025-07-01'` использует первичный индекс для быстрого поиска.

#### 3.2.2 Вторичные индексы (Skip Indexes)
- Дополнительные индексы, которые создаются с помощью конструкции `INDEX`.
- Используются для ускорения запросов по столбцам, не входящим в ключ сортировки.
- Типы skip-индексов:
  - **minmax**: Хранит минимальные и максимальные значения для гранулы.
  - **set**: Хранит уникальные значения столбца.
  - **bloom_filter**: Вероятностный индекс для быстрого поиска значений.
- **Пример**:
  ```sql
  CREATE TABLE logs (
      event_time DateTime,
      user_id UInt32,
      action String,
      INDEX action_idx action TYPE bloom_filter GRANULARITY 1
  ) ENGINE = MergeTree()
  ORDER BY (event_time, user_id);
  ```
  Запрос `SELECT * FROM logs WHERE action = 'click'` будет использовать `action_idx` для фильтрации.

**Как проектировать индексы?**
- **Первичный индекс**:
  - Выбирайте столбцы, по которым чаще всего фильтруете или сортируете (например, `event_time` для временных рядов).
  - Используйте составные ключи (например, `(event_time, user_id)`), если запросы комбинируют несколько условий.
  - Избегайте слишком длинных ключей, так как это увеличивает размер индекса.
- **Вторичные индексы**:
  - Добавляйте их для столбцов, часто используемых в `WHERE`, но не входящих в ключ сортировки.
  - Используйте `bloom_filter` для столбцов с высокой кардинальностью (много уникальных значений).
  - Настройте параметр `GRANULARITY` (обычно 1–4) в зависимости от размера данных: меньшая гранулярность ускоряет запросы, но увеличивает размер индекса.
- **Совет**: Тестируйте запросы с помощью `EXPLAIN` для проверки, какие индексы используются.

### 3.3 Сжатие данных

ClickHouse активно использует сжатие данных, чтобы уменьшить объем хранимых данных и ускорить чтение с диска.

#### 3.3.1 Алгоритмы сжатия
- **LZ4**: Быстрое сжатие и декомпрессия, используется по умолчанию. Подходит для большинства сценариев, где важна скорость.
- **ZSTD**: Более высокая степень сжатия, но требует больше CPU для компрессии/декомпрессии. Используется, когда нужно минимизировать объем данных.
- **Настройка**:
  ```sql
  CREATE TABLE example (
      id UInt32,
      data String
  ) ENGINE = MergeTree()
  ORDER BY id
  SETTINGS index_granularity = 8192, compression = 'ZSTD';
  ```

#### 3.3.2 Как сжатие влияет на производительность и хранение?
- **Хранение**: Сжатие может уменьшить объем данных в 5–10 раз, особенно для столбцов с повторяющимися значениями (например, категории, даты).
- **Производительность**: Сжатые данные быстрее читаются с диска, так как объем данных меньше, но декомпрессия требует дополнительных ресурсов CPU.
- **Пример**: Таблица с миллиардами строк логов может занимать 100 ГБ вместо 1 ТБ благодаря сжатию.
- **Оптимизация**:
  - Используйте `LZ4` для высоконагруженных систем, где важна скорость.
  - Используйте `ZSTD` для архивных данных или если дисковое пространство ограничено.
  - Выбирайте типы данных с меньшим размером (например, `UInt32` вместо `Int64`, если значения не превышают 4 млрд).

### 3.4 Шардирование и репликация

#### 3.4.1 Шардирование
- Шардирование распределяет данные по нескольким серверам (шардам), чтобы увеличить пропускную способность и объем хранимых данных.
- Используется движок `Distributed`, который действует как прокси: он перенаправляет запросы к нужным шардам и агрегирует результаты.
- **Пример настройки**:
  ```sql
  CREATE TABLE logs_local (
      event_time DateTime,
      user_id UInt32
  ) ENGINE = MergeTree()
  ORDER BY (event_time, user_id);

  CREATE TABLE logs_distributed (
      event_time DateTime,
      user_id UInt32
  ) ENGINE = Distributed(cluster_name, database, logs_local, user_id % 4);
  ```
  Здесь `user_id % 4` определяет, на какой из 4 шардов отправить данные.
- **Как работает**:
  - Данные делятся по ключу шардирования (например, хэш от `user_id`).
  - Запросы к таблице `logs_distributed` автоматически распределяются по шардам.
- **Совет**: Выбирайте ключ шардирования, который равномерно распределяет данные (например, хэш от идентификатора).

#### 3.4.2 Репликация
- Репликация копирует данные на несколько серверов для отказоустойчивости и балансировки нагрузки.
- Используется движок `ReplicatedMergeTree`, который синхронизирует данные через Apache ZooKeeper или ClickHouse Keeper.
- **Пример настройки**:
  ```sql
  CREATE TABLE logs_replicated (
      event_time DateTime,
      user_id UInt32
  ) ENGINE = ReplicatedMergeTree('/clickhouse/tables/logs', 'replica1')
  ORDER BY (event_time, user_id);
  ```
  Здесь `/clickhouse/tables/logs` — путь в ZooKeeper, `replica1` — имя реплики.
- **Как работает**:
  - ZooKeeper координирует вставки и слияния данных между репликами.
  - При сбое одной реплики запросы перенаправляются к другой.
- **Настройка ZooKeeper**:
  - Установите ZooKeeper (или используйте встроенный ClickHouse Keeper).
  - Настройте конфигурацию сервера ClickHouse для подключения к ZooKeeper:
    ```xml
    <zookeeper>
        <node>
            <host>zookeeper1</host>
            <port>2181</port>
        </node>
    </zookeeper>
    ```

**Совет**:
- Комбинируйте шардирование и репликацию для крупных систем: каждый шард может иметь несколько реплик.
- Используйте `Distributed` для чтения данных, но вставляйте данные напрямую в локальные таблицы (`logs_local`), чтобы избежать дублирования.

### 3.5 Форматы данных

#### 3.5.1 Поддерживаемые форматы
- **CSV**: Простой текстовый формат, подходит для небольших данных.
- **JSONEachRow**: Каждая строка — отдельный JSON-объект. Удобно для парсинга сложных данных.
- **Parquet**: Столбцовый формат, оптимизированный для больших данных. Высокая степень сжатия и поддержка сложных структур.
- **ORC**: Альтернатива Parquet, также столбцовый, используется в экосистемах Hadoop.
- **TSV**: Табличный формат, разделенный табуляцией.
- **Native**: Внутренний бинарный формат ClickHouse, самый быстрый для обмена данными между серверами ClickHouse.

#### 3.5.2 Оптимизация загрузки данных
- **Используйте Parquet или ORC** для больших объемов данных, так как они сжимают данные и поддерживают столбцовую структуру, что ускоряет импорт.
- **Пример импорта**:
  ```sql
  INSERT INTO logs FROM INFILE 'data.parquet' FORMAT Parquet;
  ```
- **Пакетная загрузка**: Загружайте данные большими партиями (тысячи или миллионы строк), чтобы минимизировать накладные расходы.
- **Сжатие при передаче**: Используйте сжатие (например, `gzip`) при загрузке через HTTP:
  ```bash
  cat data.csv.gz | clickhouse-client --query="INSERT INTO logs FORMAT CSV"
  ```
- **Параллельная загрузка**: Для больших данных используйте несколько потоков или шардов для параллельного импорта.
- **Материализованные представления**: Используйте их для автоматической обработки и агрегации входящих данных:
  ```

---

## 5. SQL в ClickHouse

### 5.1 Особенности SQL
ClickHouse поддерживает стандартный SQL (синтаксис, близкий к ANSI SQL), но имеет свои особенности и расширения, которые делают его особенно мощным для аналитических запросов. Вот ключевые аспекты:

#### 5.1.1 Поддержка стандартного SQL с отличиями
- ClickHouse поддерживает основные конструкции SQL: `SELECT`, `WHERE`, `GROUP BY`, `JOIN`, `ORDER BY`, `LIMIT`, и т.д.
- **Отличия от классического SQL**:
  - Нет полноценной поддержки транзакций (ClickHouse не является OLTP-системой).
  - Операции `UPDATE` и `DELETE` ограничены и выполняются асинхронно (через `ALTER TABLE ... UPDATE/DELETE`).
  - `JOIN` менее оптимизирован, чем в транзакционных СУБД, и требует осторожного использования.
  - Некоторые функции и синтаксис уникальны для ClickHouse (например, работа с массивами).
- **Пример простого запроса**:
  ```sql
  SELECT user_id, COUNT(*) as event_count
  FROM events
  WHERE event_time >= '2025-07-01'
  GROUP BY user_id
  ORDER BY event_count DESC
  LIMIT 10;
  ```

#### 5.1.2 Уникальные функции
- **Агрегатные функции**:
  - `uniq`: Подсчитывает количество уникальных значений (примерно, использует HyperLogLog).
  - `groupArray`: Создает массив из значений столбца для каждой группы.
  - `topK`: Возвращает топ-K значений по частоте.
  - `sumIf`, `countIf`: Условные агрегации.

- **Функции для работы с массивами**:
  - ClickHouse поддерживает тип данных `Array`, что упрощает работу с массивами.
  - `arrayJoin`: "Разворачивает" массив в отдельные строки.
  - Другие функции: `length`, `arrayElement`, `arrayConcat`.
  
- **Функции для работы с JSON**:
  - `JSONExtract`: Извлекает данные из JSON-строк.
  - Полезно для обработки логов или данных с динамической структурой.

#### 5.1.3 Расширения SQL
- Поддержка типов данных, специфичных для аналитики: `DateTime64`, `UInt64`, `Nullable`.
- Специальные конструкции, такие как `WITH` для CTE (Common Table Expressions):
  ```sql
  WITH daily_counts AS (
      SELECT toDate(event_time) AS day, COUNT(*) AS cnt
      FROM events
      GROUP BY day
  )
  SELECT day, cnt
  FROM daily_counts
  WHERE cnt > 1000;
  ```

### 5.2 Оптимизация запросов

#### 5.2.1 Как ClickHouse выполняет запросы (Query Execution Plan)
- ClickHouse использует **столбцовое хранение**, что позволяет читать только нужные столбцы.
- **Первичные индексы** (на основе ключа сортировки) и **skip-индексы** минимизируют объем данных, считываемых с диска.
- Запросы выполняются в несколько этапов:
  1. Парсинг запроса и проверка синтаксиса.
  2. Определение, какие столбцы и гранулы данных нужны (с использованием индексов).
  3. Чтение данных с диска (сжатые данные декомпрессируются).
  4. Выполнение фильтрации (`WHERE`), агрегации (`GROUP BY`), сортировки (`ORDER BY`).
  5. Возврат результата.
- ClickHouse активно использует многопоточность и векторизацию для ускорения вычислений.

#### 5.2.2 Использование `EXPLAIN` для анализа запросов
- Команда `EXPLAIN` показывает, как ClickHouse планирует выполнить запрос.
- **Пример**:
  ```sql
  EXPLAIN
  SELECT user_id, COUNT(*) AS event_count
  FROM events
  WHERE event_time >= '2025-07-01'
  GROUP BY user_id;
  ```
  Вывод покажет:
  - Какие индексы используются.
  - Какие столбцы читаются.
  - Объем данных, который будет обработан.
- **Типы EXPLAIN**:
  - `EXPLAIN PLAN`: Показывает план выполнения.
  - `EXPLAIN PIPELINE`: Показывает этапы обработки (например, фильтрация, агрегация).
  - **Пример**:
    ```sql
    EXPLAIN PIPELINE
    SELECT user_id, COUNT(*) AS event_count
    FROM events
    WHERE event_time >= '2025-07-01'
    GROUP BY user_id;
    ```
- Используйте `EXPLAIN` для проверки, какие индексы задействованы, и нет ли полного сканирования таблицы.

#### 5.2.3 Оптимизация `WHERE`, `GROUP BY`, `JOIN`
- **WHERE**:
  - Фильтруйте по столбцам, входящим в ключ сортировки (`ORDER BY`) или первичный индекс.
  - Используйте условия, которые минимизируют объем данных (например, фильтрация по дате).
  - **Пример**:
    ```sql
    SELECT user_id
    FROM events
    WHERE event_time >= '2025-07-01' AND event_type = 'click';
    ```
    Если `event_time` в ключе сортировки, а `event_type` имеет skip-индекс, запрос будет быстрым.
- **GROUP BY**:
  - Минимизируйте количество группировок, используя столбцы с низкой кардинальностью (например, регион вместо user_id).
  - Используйте предварительную агрегацию через материализованные представления (см. ниже).
  - **Пример**:
    ```sql
    SELECT toDate(event_time) AS day, COUNT(*)
    FROM events
    GROUP BY day;
    ```
- **JOIN**:
  - `JOIN` в ClickHouse менее оптимизирован, чем в транзакционных СУБД, и может быть медленным для больших таблиц.
  - Используйте `INNER JOIN` или `LEFT JOIN` вместо `FULL JOIN`.
  - Старайтесь заменять `JOIN` на словари (`Dictionary`) или денормализацию данных.
  - **Пример оптимизации**:
    Вместо:
    ```sql
    SELECT e.user_id, u.name
    FROM events e
    JOIN users u ON e.user_id = u.user_id;
    ```
    Используйте словарь:
    ```sql
    CREATE DICTIONARY users_dict (
        user_id UInt32,
        name String
    ) PRIMARY KEY user_id
    SOURCE(...);
    SELECT user_id, dictGet('users_dict', 'name', user_id) AS name
    FROM events;
    ```
- **Общие советы**:
  - Указывайте только нужные столбцы в `SELECT` (ClickHouse читает только их).
  - Избегайте `SELECT *`.
  - Используйте партиционирование для ограничения объема данных (например, `PARTITION BY toYYYYMM(event_time)`).

### 5.3 Агрегатные функции и материализованные представления

#### 5.3.1 Агрегатные функции
- ClickHouse поддерживает мощные агрегатные функции, которые можно использовать для сложных аналитических задач.
- **Примеры**:
  - `uniqExact`: Точный подсчет уникальных значений (медленнее, но точнее, чем `uniq`).
  - `quantile`: Вычисление квантилей (например, медианы).
    ```sql
    SELECT quantile(0.5)(duration) AS median_duration
    FROM events;
    ```
  - `argMin`, `argMax`: Находят значение столбца, соответствующее минимальному/максимальному значению другого столбца.
    ```sql
    SELECT argMax(user_id, event_time) AS last_user
    FROM events;
    ```
- Агрегатные функции можно комбинировать с `GROUP BY` для сложных вычислений.

#### 5.3.2 Материализованные представления (`MATERIALIZED VIEW`)
- Материализованные представления автоматически обрабатывают входящие данные и сохраняют результат в отдельной таблице.
- Они идеальны для предварительной агрегации данных, что ускоряет запросы и снижает нагрузку на сервер.
- **Пример**:
  ```sql
  CREATE MATERIALIZED VIEW daily_stats
  ENGINE = AggregatingMergeTree()
  ORDER BY (day, region)
  AS
  SELECT
      toDate(event_time) AS day,
      region,
      countState() AS event_count,
      sumState(amount) AS total_amount
  FROM sales
  GROUP BY day, region;
  ```
  - Данные, вставленные в таблицу `sales`, автоматически агрегируются в `daily_stats`.
  - Для чтения агрегированных данных:
    ```sql
    SELECT
        day,
        region,
        countMerge(event_count) AS count,
        sumMerge(total_amount) AS total
    FROM daily_stats
    GROUP BY day, region;
    ```
- **Особенности**:
  - Используйте движок `AggregatingMergeTree` для хранения агрегированных данных с функциями вроде `countState`, `sumState`.
  - Материализованные представления обновляются в реальном времени при вставке данных.
  - Они позволяют избежать выполнения тяжелых запросов на лету.

#### 5.3.3 Оптимизация с помощью материализованных представлений
- Создавайте представления для часто используемых агрегаций (например, по дням, часам, регионам).
- Используйте их для замены сложных `GROUP BY` в запросах.
- Пример: Вместо выполнения `SELECT toDate(event_time), COUNT(*) FROM events GROUP BY toDate(event_time)` каждый раз, создайте материализованное представление и читайте из него.

---