

## 1. Основы Elasticsearch

Elasticsearch — это как Google для твоих данных. Он помогает искать, анализировать и хранить информацию в формате JSON. Вот что нужно знать на старте:

- **Индекс (Index)**: Это как база данных, где лежат твои документы.
- **Документ (Document)**: Основная единица данных, вроде строки в таблице, только в JSON.
- **Шард (Shard)**: Кусочек индекса, чтобы данные можно было распределить по серверам.
- **Реплика (Replica)**: Копия шарда для надёжности и скорости.
- **Кластер (Cluster)**: Несколько серверов (узлов), которые работают вместе.
- **Узел (Node)**: Один сервер с установленным Elasticsearch.

Elasticsearch общается с миром через **REST API**. Это значит, что ты можешь отправлять HTTP-запросы (GET, POST, PUT, DELETE) с помощью `curl`, Postman или Kibana Dev Tools. Например, чтобы добавить документ, достаточно одного запроса. Простота — наше всё!

---

## 2. Как работает распределённость в Elasticsearch

Elasticsearch крут тем, что может обрабатывать огромные данные, не теряя скорости и не падая, если что-то пошло не так. Это всё благодаря **шардам** и **репликам**. Давай разберёмся, как это работает, на пальцах.

### Что такое шарды?
Шарды — это как разрезанная на куски книга. Вместо того чтобы листать тысячу страниц, ты читаешь только нужный кусок. Elasticsearch делит индекс на шарды и разбрасывает их по серверам (узлам). Это делает систему:

- **Масштабируемой**: Больше данных? Добавь сервер, и шарды перераспределятся.
- **Быстрой**: Поиск идёт параллельно на всех шардах.

**Пример**: У тебя миллион документов. Elasticsearch делит их на 5 шардов (по 200 тысяч в каждом). Каждый шард лежит на своём сервере, и поиск работает в 5 раз быстрее.

### А что с репликами?
Реплики — это копии шардов. Если один сервер отвалится, данные не пропадут, потому что их копия есть на другом сервере. Плюс реплики ускоряют поиск, так как запросы можно отправлять и на них.

**Пример**: У тебя 5 шардов, и для каждого — по 1 реплике. Если один сервер ломается, Elasticsearch использует реплики, и всё продолжает работать.

### Как всё это вместе?
Ты загружаешь данные, и Elasticsearch сам решает, как их поделить на шарды и где хранить реплики. Если добавляется новый сервер, шарды автоматически переезжают, чтобы нагрузка распределилась равномерно. Это как магия, но с хэш-функциями.

**Простой пример**: У тебя интернет-магазин на 3 серверах. Данные о товарах делятся на 3 шарда:
- Сервер 1: Шард 1 (футболки) + Реплика Шарда 2.
- Сервер 2: Шард 2 (штаны) + Реплика Шарда 3.
- Сервер 3: Шард 3 (обувь) + Реплика Шарда 1.

Если Сервер 1 падает, Elasticsearch берёт Реплику Шарда 1 с Сервера 3. Никто даже не заметит сбоя!

### Почему это круто?
- **Масштабируемость**: Добавляй сервера, и всё работает.
- **Надёжность**: Данные не теряются благодаря репликам.
- **Скорость**: Поиск летает, потому что всё распараллелено.

---

## 3. Инвертированный индекс: Секрет скорости поиска

**Инвертированный индекс** — это сердце Elasticsearch (а точнее, Apache Lucene, на котором он построен). Именно он делает поиск таким быстрым. Давай разберёмся, как это работает.

### Что такое инвертированный индекс?
Обычно в книге индекс — это "страница → содержание". Инвертированный индекс — наоборот: "слово → где оно встречается". Это как таблица, где для каждого слова указано, в каких документах оно есть.

**Пример**:
У тебя три документа:
1. "Кот ест рыбу"
2. "Кот спит"
3. "Рыба плавает"

Lucene создаёт индекс:
```
кот      → [Док 1, Док 2]
ест      → [Док 1]
рыба     → [Док 1, Док 3]
спит     → [Док 2]
плавает  → [Док 3]
```
Если ищешь "кот", Lucene сразу выдаёт Док 1 и Док 2. Если ищешь "кот ест", проверяет позиции слов и возвращает только Док 1.

### Как это делается?
1. **Токенизация**:
    - Текст разбивается на слова (токены). Например, "Кот ест рыбу" → `кот`, `ест`, `рыба`.
    - Убираются знаки препинания, текст приводится к нижнему регистру.
    - Можно добавить фильтры: убрать стоп-слова ("и", "в") или привести к начальной форме ("рыбу" → "рыба").

2. **Создание индекса**:
    - Для каждого слова Lucene записывает, в каких документах оно есть, сколько раз встречается и где стоит (для поиска фраз).
    - Это всё сжимается и хранится на диске, чтобы не жрать место и быстро читаться.

3. **Оптимизация**:
    - Индекс делится на **сегменты** — маленькие кусочки, которые Lucene обрабатывает независимо. Новые документы добавляются в новые сегменты, а потом они объединяются для экономии ресурсов.

### Почему это быстро?
- Вместо того чтобы рыться во всех документах, Lucene смотрит только в индекс.
- Алгоритмы сжатия и кэширования минимизируют обращения к диску.
- Дополнительные данные (позиции слов, частота) помогают ранжировать результаты: например, документ, где "кот" встречается чаще, будет выше в выдаче.

### Как это связано с шардами?
Каждый шард в Elasticsearch — это отдельный Lucene-индекс со своим инвертированным индексом. Документы распределяются по шардам, и каждый шард ищет только в своей части данных. Это делает поиск ещё быстрее, так как всё идёт параллельно.

---

## 4. Как добавить документ в индекс?

Добавление документа — это как закинуть новую запись в Elasticsearch. Документ — это JSON, например, `{"name": "Кот Мурзик", "age": 3}`. Давай разберём, что происходит, когда ты его добавляешь.

### Шаги добавления
1. **Отправка документа**:
    - Ты делаешь HTTP-запрос, например:
      ```bash
      POST /pets/_doc
      {
        "name": "Кот Мурзик",
        "age": 3,
        "type": "cat"
      }
      ```
    - Если хочешь задать ID явно, используй `PUT /pets/_doc/1`.

2. **Маршрутизация**:
    - Elasticsearch решает, в какой шард пойдёт документ, с помощью хэш-функции: `shard = hash(document_id) % number_of_shards`.
    - Если ID не указан, оно генерируется автоматически.

3. **Проверка маппинга**:
    - Если у индекса есть схема (маппинг), Elasticsearch проверяет, подходит ли документ. Например, `age` должен быть числом.
    - Если маппинга нет, включаются **динамические маппинги**, и типы полей определяются на лету (например, `"age": 3` → `integer`).
    - Если маппинг строгий (`strict`), а поле неизвестно, будет ошибка.

4. **Индексация в Lucene**:
    - Текст (например, `name`) разбивается на токены с помощью **анализатора**. Например, "Коты едят рыбу" → `кот`, `есть`, `рыба`.
    - Токены добавляются в инвертированный индекс.
    - Полный JSON сохраняется для последующего извлечения.

5. **Запись в сегмент**:
    - Документ сначала попадает в буфер в памяти, потом записывается в сегмент на диске.
    - По умолчанию индекс обновляется для поиска каждую секунду (`refresh_interval`).

6. **Репликация**:
    - Документ отправляется на все реплики шарда, чтобы данные были одинаковыми везде.

7. **Ответ**:
    - Elasticsearch возвращает результат, например:
      ```json
      {
        "_index": "pets",
        "_id": "1",
        "_version": 1,
        "result": "created"
      }
      ```

---

## 5. Роли узлов в кластере

В кластере Elasticsearch узлы делят между собой обязанности. Каждый узел может выполнять одну или несколько ролей: **Master**, **Data**, **Ingest**, **Coordinating**. Давай разберём, кто за что отвечает.

### Master Node (Узел управления)
- **Что делает?** Это "мозг" кластера. Управляет индексами, шардами, репликами и следит за состоянием узлов.
- **Пример**: Когда ты создаёшь индекс, Master решает, куда разместить шарды.
- **Важно**: Master не хранит данные и не ищет. Если он падает, другой узел (Master-eligible) становится новым Master'ом. Обычно 3–5 узлов в кластере могут быть Master'ами, чтобы избежать проблем.

### Data Node (Узел данных)
- **Что делает?** Хранит шарды и выполняет поиск, индексацию, агрегации. Это "рабочая лошадка".
- **Пример**: Когда ты ищешь "кот", Data-узлы роются в своих шардах и возвращают результаты.
- **Важно**: Жрут много ресурсов (диск, CPU, память). Для больших данных добавляй больше Data-узлов.

### Ingest Node (Узел приёма данных)
- **Что делает?** Обрабатывает документы перед индексацией: добавляет поля, меняет форматы, фильтрует.
- **Пример**: Лог "2025-07-10 error" превращается в JSON с полями `timestamp` и `status`.
- **Важно**: Можно обойтись без Ingest, если обработка не нужна.

### Coordinating Node (Координирующий узел)
- **Что делает?** Принимает запросы от клиентов, рассылает их по Data-узлам, собирает результаты и возвращает тебе.
- **Пример**: Ты ищешь "кот", Coordinating Node отправляет запрос всем шардам, сортирует результаты и выдаёт топ-10.
- **Важно**: Любой узел может быть координатором, но в больших кластерах делают отдельные Coordinating-узлы.

### Как это работает вместе?
- **Master**: Решает, где хранить данные.
- **Data**: Хранит и ищет.
- **Ingest**: Готовит данные.
- **Coordinating**: Связывает всё воедино.

**Пример**: Ты добавляешь документ `{ "name": "Кот Мурзик" }`. Ingest добавляет поле `type: "pet"`, Master выбирает шард, Data сохраняет документ, а Coordinating подтверждает успех.

---

## 6. Как работает поиск?

Поиск в Elasticsearch — это двухэтапный процесс: **Query Phase** (поиск) и **Fetch Phase** (получение). Плюс есть **маршрутизация запросов**, которая распределяет работу по узлам. Вот как это выглядит.

### Query Phase (Фаза поиска)
1. Ты отправляешь запрос, например, "кот", на Coordinating Node.
2. Координатор рассылает запрос всем шардам (или их репликам).
3. Каждый шард ищет в своём Lucene-индексе, находит документы и считает их **релевантность** (score) с помощью алгоритмов вроде BM25.
4. Шарды возвращают топ-документы (например, по 10 с каждого).
5. Coordinating Node собирает результаты, сортирует и выбирает финальный топ.

**Пример**: Индекс с 3 шардами. Шард 1 нашёл 5 документов, Шард 2 — 3, Шард 3 — 2. Координатор берёт все 10, сортирует и выдаёт тебе топ-5.

### Fetch Phase (Фаза получения)
1. Координатор запрашивает полные документы (не только ID и score) у шардов, где они лежат.
2. Шарды отправляют JSON-документы, например, `{ "name": "Кот Мурзик", "age": 3 }`.
3. Координатор возвращает результат тебе.

**Пример**: В Query Phase выбраны документы 1, 3, 5. В Fetch Phase координатор забирает их содержимое у шардов и отдаёт тебе.

### Маршрутизация запросов
- Elasticsearch знает, какие шарды содержат данные. Для общего поиска запрос идёт всем шардам, для точного (по ID) — только нужному (по хэшу ID).
- Координатор выбирает первичные шарды или реплики, чтобы нагрузка распределялась равномерно.
- Если узел падает, запросы идут на реплики, и ничего не ломается.

**Пример**: Индекс с 3 шардами и 1 репликой. Запрос "кот" может пойти на Шард 1 (Узел 1) или его реплику (Узел 3), в зависимости от нагрузки.

### Почему это быстро?
- **Query Phase**: Lucene ищет только по индексу, а шарды работают параллельно.
- **Fetch Phase**: Обрабатывает мало документов (только отобранные).
- **Маршрутизация**: Балансирует нагрузку и обеспечивает отказоустойчивость.

---

## 7. Безопасность в Elasticsearch

Безопасность — must-have для продакшен-кластеров. Elasticsearch использует модуль **X-Pack Security** для аутентификации, авторизации и шифрования. Вот как это настроить.

### Аутентификация и авторизация
- **Аутентификация**: Проверяет, кто ты (пароль, сертификат, API-ключ).
- **Авторизация**: Решает, что тебе можно делать (чтение, запись, админка).

1. **Включение X-Pack**:
    - В `elasticsearch.yml` добавь:
      ```yaml
      xpack.security.enabled: true
      ```
    - Перезапусти кластер. В версиях 8.0+ это включено по умолчанию.

2. **Настройка паролей**:
    - Используй `elasticsearch-reset-password`:
      ```bash
      ./bin/elasticsearch-reset-password -u elastic
      ```
    - Это создаёт пароль для встроенного пользователя `elastic`.

3. **Создание ролей**:
    - Роли определяют права. Например, роль `logs_reader` для чтения логов:
      ```bash
      POST /_security/role/logs_reader
      {
        "indices": {
          "logs-*": { "privileges": ["read", "view_index_metadata"] }
        }
      }
      ```

4. **Создание пользователей**:
    - Пример:
      ```bash
      POST /_security/user/analyst
      {
        "password": "secure_password",
        "roles": ["logs_reader"],
        "full_name": "Data Analyst"
      }
      ```

### SSL/TLS для шифрования
Шифрование защищает данные при передаче между узлами и клиентами. Без него данные могут перехватить.

1. **Создание сертификатов**:
    - Используй `elasticsearch-certutil`:
      ```bash
      ./bin/elasticsearch-certutil ca
      ./bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12
      ```
    - Скопируй сертификаты в `/etc/elasticsearch/certs/`.

2. **Настройка TLS**:
    - Для узлов (порт 9300) в `elasticsearch.yml`:
      ```yaml
      xpack.security.transport.ssl.enabled: true
      xpack.security.transport.ssl.keystore.path: certs/elastic-certificates.p12
      xpack.security.transport.ssl.truststore.path: certs/elastic-certificates.p12
      ```
    - Для клиентов (порт 9200):
      ```yaml
      xpack.security.http.ssl.enabled: true
      xpack.security.http.ssl.keystore.path: certs/elastic-certificates.p12
      ```

3. **Перезапуск**:
    - После настройки TLS кластер нужно перезапустить.

### Управление ролями и пользователями
- Используй **RBAC** (Role-Based Access Control): создавай роли с минимальными правами и привязывай их к пользователям.
- Встроенные пользователи: `elastic` (админ), `kibana_system` (для Kibana).
- Для сертификатов используй **role mapping**:
  ```bash
  PUT /_security/role_mapping/kibana_certificate
  {
    "roles": ["kibana_system"],
    "rules": { "field": { "dn": "CN=kibana" } }
  }
  ```

**Совет**: Включи аудит (`xpack.security.audit.enabled: true`), чтобы следить за действиями пользователей.

---

## 8. Создание и управление индексами

Индексы — это основа хранения данных в Elasticsearch. Ты можешь настроить их структуру (**маппинги**) и параметры (**настройки**). Давай разберёмся.

### Настройка маппингов
Маппинги — это схема, которая говорит, как обрабатывать поля в документах (типы данных, индексация).

- **Пример создания индекса**:
  ```bash
  PUT /pets
  {
    "mappings": {
      "properties": {
        "name": { "type": "text" },
        "age": { "type": "integer" },
        "birth_date": { "type": "date" }
      }
    }
  }
  ```

- **Типы данных**:
    - `text`: Для поиска (разбивается на токены).
    - `keyword`: Для точного соответствия.
    - `integer`, `date`, `boolean`, `nested` и др.

- **Изменение маппинга**:
    - Добавить поле можно:
      ```bash
      PUT /pets/_mapping
      { "properties": { "color": { "type": "keyword" } } }
      ```
    - Изменить тип существующего поля нельзя — нужен новый индекс и переиндексация.

### Динамические vs статические маппинги
- **Динамические**: Elasticsearch сам угадывает типы полей. Удобно для прототипов, но может быть ошибкой в продакшене.
  ```bash
  PUT /pets
  { "mappings": { "dynamic": true } }
  ```
- **Статические**: Ты явно задаёшь схему. Лучше для контроля.
  ```bash
  PUT /pets
  { "mappings": { "dynamic": "strict", "properties": { ... } } }
  ```

### Настройки индекса
- **Шарды и реплики**:
  ```bash
  PUT /pets
  {
    "settings": {
      "number_of_shards": 3,
      "number_of_replicas": 1
    }
  }
  ```
    - Шарды нельзя изменить после создания, реплики — можно.

- **Анализаторы**:
    - Настрой анализатор для текста, например, для русского языка:
      ```bash
      PUT /pets
      {
        "settings": {
          "analysis": {
            "analyzer": {
              "russian_analyzer": {
                "tokenizer": "standard",
                "filter": ["lowercase", "russian_morphology"]
              }
            }
          }
        },
        "mappings": {
          "properties": {
            "name": { "type": "text", "analyzer": "russian_analyzer" }
          }
        }
      }
      ```

- **Другие настройки**:
    - `refresh_interval`: Как часто индекс доступен для поиска (`1s` по умолчанию).
    - `max_result_window`: Максимум результатов в запросе (10000 по умолчанию).

**Совет**: Для больших данных держи 1–5 шардов и минимум 1 реплику. Проверяй состояние: `GET /_cat/shards`.

---

## 9. Индексирование данных

Чтобы Elasticsearch заработал, нужно закинуть в него данные. Есть несколько способов: **API**, **Bulk API**, **Logstash** и **Beats**.

### Импорт через API
Самый простой способ — отправить JSON через HTTP.

- **Пример**:
  ```bash
  POST /pets/_doc
  {
    "name": "Кот Мурзик",
    "age": 3
  }
  ```

- **Когда использовать?** Для тестов, интеграции с кодом или небольших данных.

### Импорт через Logstash
Logstash — это "комбайн" для обработки данных: собирает, парсит, отправляет.

- **Пример конфига** (`logstash.conf`):
  ```conf
  input { file { path => "/var/log/app.log" } }
  filter { grok { match => { "message": "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{GREEDYDATA:msg}" } } }
  output { elasticsearch { hosts => ["http://localhost:9200"] index => "applogs-%{+YYYY.MM.dd}" } }
  ```

- **Когда использовать?** Для логов, баз данных, сложной обработки.

### Импорт через Beats
Beats — лёгкие агенты для сбора данных (логи, метрики).

- **Пример Filebeat** (`filebeat.yml`):
  ```yaml
  filebeat.inputs:
  - type: log
    paths: ["/var/log/nginx/*.log"]
  output.elasticsearch:
    hosts: ["http://localhost:9200"]
    index: "nginx-logs-%{+YYYY.MM.dd}"
  ```

- **Когда использовать?** Для логов или метрик с минимальной нагрузкой.

### Bulk API для массовой загрузки
Bulk API — это способ закинуть кучу документов за раз, чтобы не тратить время на отдельные запросы.

- **Пример**:
  ```bash
  POST /_bulk
  { "index": { "_index": "pets", "_id": "1" } }
  { "name": "Кот Мурзик", "age": 3 }
  { "index": { "_index": "pets", "_id": "2" } }
  { "name": "Собака Рекс", "age": 5 }
  ```

- **Советы**:
    - Отправляй 1–10 МБ за раз (100–1000 документов).
    - Увеличь `refresh_interval` (например, `30s`) на время загрузки.
    - Проверяй ошибки в ответе.

- **Когда использовать?** Для больших данных (миллионы документов).

---

## 9  **Анализаторы текста**

Анализаторы текста в **Elasticsearch** — это инструменты, которые обрабатывают текст для полнотекстового поиска. Они разбивают текст на части (токены), чтобы Elasticsearch мог эффективно искать и находить совпадения, даже если слова написаны в разных формах (например, "кот" и "кота"). Это особенно важно для поддержки языков, таких как русский, где слова изменяются по падежам, числам и т.д.

### Понимание токенизаторов, фильтров и анализаторов

Анализатор текста в Elasticsearch состоит из трёх компонентов, которые работают последовательно:
- **Character Filters** (символьные фильтры): Предобрабатывают текст, удаляя или заменяя символы.
- **Tokenizer** (токенизатор): Разбивает текст на токены (слова или части слов).
- **Token Filters** (токен-фильтры): Изменяют или фильтруют токены (например, приводят к нижнему регистру, удаляют стоп-слова или применяют морфологию).

#### Как это работает?
1. **Character Filters**:
    - Удаляют или заменяют ненужные символы до токенизации.
    - Примеры:
        - `html_strip`: Удаляет HTML-теги (например, `<p>Кот</p>` → `Кот`).
        - `mapping`: Заменяет символы (например, `ё` → `е`).
    - Используется редко, но полезно для очистки "грязных" данных.

2. **Tokenizer**:
    - Разбивает текст на токены (обычно слова).
    - Примеры токенизаторов:
        - `standard`: Делит текст по пробелам и знакам препинания. Например, `"Кот ест рыбу."` → `["Кот", "ест", "рыбу"]`.
        - `whitespace`: Делит только по пробелам. Например, `"Кот-ест рыбу"` → `["Кот-ест", "рыбу"]`.
        - `keyword`: Не разбивает текст, хранит как один токен. Например, `"Кот ест рыбу"` → `["Кот ест рыбу"]`.

3. **Token Filters**:
    - Преобразуют токены после токенизатора. Примеры:
        - `lowercase`: Приводит к нижнему регистру (`Кот` → `кот`).
        - `stop`: Удаляет стоп-слова (например, "и", "в" для русского).
        - `snowball` или `hunspell`: Приводит слова к начальной форме (например, `кота` → `кот`).
        - `synonym`: Добавляет синонимы (например, `кот` → `кот`, `кошка`).

#### Анализатор
- Анализатор объединяет символьные фильтры, токенизатор и токен-фильтры в один процесс.
- Встроенные анализаторы:
    - `standard`: `standard tokenizer` + `lowercase` + минимальная обработка.
    - `russian`: `standard tokenizer` + `lowercase` + `russian_stop` + `russian_morphology` (для русского языка).
- Пример работы анализатора `russian`:
    - Вход: `"Коты едят рыбу"`
    - Выход: `["кот", "есть", "рыба"]` (приведено к нижнему регистру и начальной форме).

#### Поддержка русского языка
- Русский язык сложен из-за морфологии (падежи, числа, склонения). Для корректной обработки нужен анализатор, который:
    - Приводит слова к начальной форме (например, `котов` → `кот`).
    - Удаляет стоп-слова ("и", "на", "в").
    - Игнорирует регистр.
- Встроенный анализатор `russian` уже включает `russian_morphology` и `russian_stop`, что делает его подходящим для большинства задач.

#### Пример анализа текста
- Используем API для проверки, как работает анализатор:
  ```bash
  POST /_analyze
  {
    "analyzer": "russian",
    "text": "Коты едят рыбу"
  }
  ```
- Ответ:
  ```json
  {
    "tokens": [
      { "token": "кот", "start_offset": 0, "end_offset": 4, "type": "<ALPHANUM>", "position": 0 },
      { "token": "есть", "start_offset": 5, "end_offset": 9, "type": "<ALPHANUM>", "position": 1 },
      { "token": "рыба", "start_offset": 10, "end_offset": 14, "type": "<ALPHANUM>", "position": 2 }
    ]
  }
  ```
- **Объяснение**: Текст разбит на токены, приведён к нижнему регистру, а слово "коты" преобразовано в "кот" благодаря морфологии.

### Настройка кастомных анализаторов для специфических задач

Кастомные анализаторы позволяют настроить обработку текста под конкретные требования, например:
- Поиск с учётом синонимов.
- Игнорирование определённых символов.
- Специфическая обработка текста (например, для доменных имён или хэштегов).

#### Как создать кастомный анализатор?
1. **Определение анализатора**:
    - Анализатор задаётся в настройках индекса (`settings`) при его создании.
    - Укажи символьные фильтры, токенизатор и токен-фильтры.

2. **Пример кастомного анализатора для русского языка**:
    - Задача: Создать анализатор, который:
        - Удаляет HTML-теги.
        - Разбивает текст на слова.
        - Приводит к нижнему регистру.
        - Применяет морфологию для русского языка.
        - Добавляет синонимы (например, `кот` = `кошка`).

    - Код для создания индекса с кастомным анализатором:
      ```bash
      PUT /pets
      {
        "settings": {
          "analysis": {
            "char_filter": {
              "html_clean": {
                "type": "html_strip" //Удаляет HTML-теги
              }
            },
            "analyzer": {
              "custom_russian": {
                "type": "custom",
                "char_filter": ["html_clean"],
                "tokenizer": "standard",
                "filter": [
                  "lowercase",
                  "russian_morphology",
                  "russian_stop",
                  "synonym_filter"
                ]
              }
            },
            "filter": {
              "synonym_filter": {
                "type": "synonym",
                "synonyms": [
                  "кот, кошка",
                  "собака, пёс"
                ]
              },
              "russian_stop": {
                "type": "stop",
                "stopwords": "_russian_"
              },
              "russian_morphology": {
                "type": "hunspell",
                "locale": "ru_RU",
                "dedup": true
              }
            }
          }
        },
        "mappings": {
          "properties": {
            "name": {
              "type": "text",
              "analyzer": "custom_russian"
            },
            "type": { "type": "keyword" }
          }
        }
      }
      ```

3. **Объяснение**:
    - **char_filter**:
        - `html_strip`: Удаляет HTML-теги (например, `<p>Кот</p>` → `Кот`).
    - **tokenizer**:
        - `standard`: Разбивает текст на слова по пробелам и знакам препинания.
    - **filter**:
        - `lowercase`: Приводит к нижнему регистру (`Кот` → `кот`).
        - `russian_stop`: Удаляет стоп-слова ("и", "в").
        - `russian_morphology`: Приводит слова к начальной форме (`коты` → `кот`).
        - `synonym_filter`: Добавляет синонимы (`кот` → `кот`, `кошка`).
    - **mappings**: Поле `name` использует кастомный анализатор `custom_russian`.

4. **Тестирование анализатора**:
    - Проверь, как работает анализатор:
      ```bash
      POST /pets/_analyze
      {
        "analyzer": "custom_russian",
        "text": "<p>Коты едят рыбу</p>"
      }
      ```
    - Ответ:
      ```json
      {
        "tokens": [
          { "token": "кот", "start_offset": 3, "end_offset": 7, "type": "<ALPHANUM>", "position": 0 },
          { "token": "кошка", "start_offset": 3, "end_offset": 7, "type": "SYNONYM", "position": 0 },
          { "token": "есть", "start_offset": 8, "end_offset": 12, "type": "<ALPHANUM>", "position": 1 },
          { "token": "рыба", "start_offset": 13, "end_offset": 17, "type": "<ALPHANUM>", "position": 2 }
        ]
      }
      ```
    - **Результат**: HTML-теги удалены, "коты" преобразовано в "кот" и добавлен синоним "кошка", стоп-слова убраны.

5. **Добавление документа**:
   ```bash
   POST /pets/_doc
   {
     "name": "Коты едят рыбу",
     "type": "cat"
   }
   ```
    - Теперь поиск по "кошка" или "кот" найдёт этот документ.

#### Лучшие практики
- **Тестируй анализаторы**: Используй `_analyze` API для проверки, как текст преобразуется в токены.
- **Учитывай язык**: Для русского используй `russian_morphology` или `hunspell` с локальным словарем.
- **Разделяй анализаторы для индексации и поиска**:
    - Поле `search_analyzer` можно задать отдельно, чтобы поиск был менее строгим.
    - Пример: `autocomplete_analyzer` для индексации, `standard` для поиска.
- **Оптимизация**: Не добавляй слишком много фильтров, чтобы не замедлить индексацию.
- **Закрывай индекс перед изменением анализаторов**:
  ```bash
  POST /pets/_close
  PUT /pets/_settings
  {
    "analysis": { ... }
  }
  POST /pets/_open
  ```

### Итог
- **Токенизаторы, фильтры и анализаторы**:
    - **Character Filters**: Очищают текст (например, убирают HTML).
    - **Tokenizer**: Разбивает текст на токены (например, `standard`, `keyword`).
    - **Token Filters**: Преобразуют токены (`lowercase`, `russian_morphology`, `synonym`).
    - Для русского языка используй `russian` анализатор или кастомный с `russian_morphology`.
- **Кастомные анализаторы**:
    - Настраивай для специфических задач: синонимы, хэштеги, автодополнение.
    - Задавай в `settings` индекса, тестируй через `_analyze`.
- **Пример**: Анализатор `custom_russian` с морфологией и синонимами делает поиск по русскому тексту гибким и точным.
  Эти инструменты позволяют Elasticsearch эффективно обрабатывать текст, особенно для сложных языков, таких как русский!
  
## 10 **Типы запросов**:
В **Elasticsearch** запросы и аналитика данных строятся с использованием **Query DSL** (Domain Specific Language), который позволяет выполнять поиск, фильтрацию и агрегацию данных. 

### Query DSL: Синтаксис запросов

**Query DSL** — это JSON-основанный язык запросов в Elasticsearch, который позволяет гибко искать и фильтровать данные. Запросы делятся на два контекста:
- **Query context**: Используется для полнотекстового поиска, где учитывается релевантность (score). Примеры: `match`, `multi_match`.
- **Filter context**: Используется для точной фильтрации без подсчёта релевантности. Примеры: `term`, `range`.

Запросы отправляются через API, обычно в `_search` эндпоинт:
```bash
POST /pets/_search
{
  "query": { ... }
}
```

#### Основные типы запросов
1. **match**:
    - Используется для полнотекстового поиска с анализом текста (разбивает запрос на токены, учитывает морфологию).
    - Пример: Поиск документов, где в поле `name` есть слово "кот":
      ```bash
      POST /pets/_search
      {
        "query": {
          "match": {
            "name": "кот"
          }
        }
      }
      ```
    - Находит документы с "кот", "коты", "кошка" (если используется анализатор `russian`).

2. **term**:
    - Точный поиск по значению поля (без анализа, подходит для `keyword`).
    - Пример: Поиск документов, где `type` точно равно "cat":
      ```bash
      POST /pets/_search
      {
        "query": {
          "term": {
            "type": "cat"
          }
        }
      }
      ```

3. **bool**:
    - Комбинирует несколько условий (`must`, `should`, `must_not`, `filter`).
    - Пример: Найти документы, где `name` содержит "кот" и `age` больше 2, но не "dog":
      ```bash
      POST /pets/_search
      {
        "query": {
          "bool": {
            "must": [
              { "match": { "name": "кот" } },
              { "range": { "age": { "gt": 2 } } }
            ],
            "must_not": [
              { "term": { "type": "dog" } }
            ]
          }
        }
      }
      ```
    - **must**: Все условия должны быть истинными (AND).
    - **should**: Хотя бы одно условие должно быть истинным (OR, если нет `must`).
    - **must_not**: Условия не должны выполняться (NOT).
    - **filter**: Условия без подсчёта релевантности (см. ниже).

4. **range**:
    - Поиск по диапазону значений (для чисел, дат).
    - Пример: Найти животных старше 2 лет:
      ```bash
      POST /pets/_search
      {
        "query": {
          "range": {
            "age": {
              "gte": 2,
              "lte": 5
            }
          }
        }
      }
      ```
    - `gte` (≥), `lte` (≤), `gt` (>), `lt` (<).

5. **exists**:
    - Проверяет наличие поля в документе.
    - Пример: Найти документы, где есть поле `color`:
      ```bash
      POST /pets/_search
      {
        "query": {
          "exists": {
            "field": "color"
          }
        }
      }
      ```

6. **prefix**, **wildcard**, **regexp**:
    - Для частичного соответствия.
    - Пример: Найти документы, где `name` начинается с "ко":
      ```bash
      POST /pets/_search
      {
        "query": {
          "prefix": {
            "name.keyword": "ко"
          }
        }
      }
      ```
    - `wildcard`: Например, `"ко*"` (любой текст после "ко").
    - **Осторожно**: Эти запросы могут быть медленными на больших данных.
    
### Полнотекстовый поиск: match, multi_match, query_string

Полнотекстовый поиск анализирует текст запроса и документов, чтобы найти релевантные совпадения, учитывая морфологию, синонимы и т.д.

#### a) match
- Используется для поиска по одному полю с анализом текста.
- Пример: Найти документы, где в `name` есть "кот":
  ```bash
  POST /pets/_search
  {
    "query": {
      "match": {
        "name": {
          "query": "кот кошка",
          "operator": "or" // Найти "кот" ИЛИ "кошка"
        }
      }
    }
  }
  ```
- **Параметры**:
    - `operator`: `"or"` (по умолчанию, любое слово) или `"and"` (все слова).
    - `minimum_should_match`: Минимальное количество совпадающих слов (например, `"70%"`).

#### b) multi_match
- Поиск по нескольким полям одновременно.
- Пример: Найти "кот" в полях `name` и `description`:
  ```bash
  POST /pets/_search
  {
    "query": {
      "multi_match": {
        "query": "кот",
        "fields": ["name", "description^2"], // description имеет больший вес
        "type": "best_fields"
      }
    }
  }
  ```
- **Параметры**:
    - `fields`: Список полей для поиска. Можно задавать вес (`^2` увеличивает важность).
    - `type`: `best_fields` (лучшее совпадение), `most_fields` (больше совпадений), `cross_fields` (единый анализ).

#### c) query_string
- Гибкий поиск с использованием синтаксиса запросов (поддерживает операторы `AND`, `OR`, `NOT`, wildcards и т.д.).
- Пример: Найти документы, где в `name` есть "кот" или "кошка", но не "собака":
  ```bash
  POST /pets/_search
  {
    "query": {
      "query_string": {
        "query": "(кот OR кошка) -собака",
        "fields": ["name"]
      }
    }
  }
  ```
- **Когда использовать?**
    - Для сложных запросов, которые пользователи вводят вручную (например, в поисковой строке).
    - **Осторожно**: Может быть опасно, если входные данные не проверяются, из-за сложного синтаксиса.

#### Пример полнотекстового поиска:
- Документы:
  ```json
  {"name": "Кот Мурзик", " поля: ["кот", "мурзик"]}
  {"name": "Собака Рекс", поля: ["собака", "рекс"]}
  ```
- Запрос:
  ```bash
  POST /pets/_search
  {
    "query": {
      "match": { "name": "кот" }
    }
  }
  ```
- Результат: Найдёт только документ с "Кот Мурзик", так как текст анализируется `russian` анализатором.

### Фильтры: Использование для повышения производительности

Фильтры используются в **filter context** и не рассчитывают релевантность (score), что делает их быстрее, чем запросы в query context. Они идеальны для точных условий (например, "возраст = 3" или "тип = cat").

#### Как работают фильтры?
- Фильтры применяются внутри `bool` запроса в секции `filter`:
  ```bash
  POST /pets/_search
  {
    "query": {
      "bool": {
        "filter": [
          { "term": { "type": "cat" } },
          { "range": { "age": { "gte": 2 } } }
        ]
      }
    }
  }
  ```
- **Почему быстрее?**
    - Фильтры не вычисляют score, а возвращают только документы, соответствующие условиям.
    - Elasticsearch использует кэширование для фильтров, что ускоряет повторные запросы.

#### Лучшие практики:
- Используй `filter` для условий, где релевантность не нужна (например, точные значения или диапазоны).
- Комбинируй `filter` и `must` для точной фильтрации с релевантным поиском.
- Для больших данных фильтры значительно ускоряют запросы.

### Агрегации: Metrics, Bucket, Pipeline

**Агрегации** позволяют анализировать данные, подсчитывая метрики, группируя документы или выполняя вычисления над результатами. Они делятся на три типа:
- **Metrics**: Вычисляют значения (сумма, среднее, минимум).
- **Bucket**: Группируют документы по критериям (аналог GROUP BY в SQL).
- **Pipeline**: Выполняют вычисления над результатами других агрегаций.

#### a) Metrics Aggregations
- Вычисляют числовые показатели.
- Примеры:
    - `sum`, `avg`, `min`, `max`, `stats`.
- Пример: Подсчитать средний возраст животных:
  ```bash
  POST /pets/_search
  {
    "query": { "match_all": {} },
    "aggs": {
      "avg_age": {
        "avg": { "field": "age" }
      }
    }
  }
  ```
- Ответ:
  ```json
  {
    "aggregations": {
      "avg_age": { "value": 4.5 }
    }
  }
  ```

#### b) Bucket Aggregations
- Группируют документы по категориям.
- Примеры:
    - `terms`: Группировка по значениям поля.
    - `histogram`: Группировка по числовым диапазонам.
    - `date_histogram`: Группировка по датам.
- Пример: Подсчитать количество животных по типу:
  ```bash
  POST /pets/_search
  {
    "query": { "match_all": {} },
    "aggs": {
      "by_type": {
        "terms": { "field": "type" }
      }
    }
  }
  ```
- Ответ:
  ```json
  {
    "aggregations": {
      "by_type": {
        "buckets": [
          { "key": "cat", "doc_count": 10 },
          { "key": "dog", "doc_count": 5 }
        ]
      }
    }
  }
  ```

#### c) Pipeline Aggregations
- Выполняют вычисления над результатами других агрегаций.
- Примеры:
    - `avg_bucket`, `sum_bucket`, `bucket_script`.
- Пример: Средний возраст по типам животных:
  ```bash
  POST /pets/_search
  {
    "query": { "match_all": {} },
    "aggs": {
      "by_type": {
        "terms": { "field": "type" },
        "aggs": {
          "avg_age": { "avg": { "field": "age" } }
        }
      },
      "overall_avg_age": {
        "avg_bucket": {
          "buckets_path": "by_type>avg_age"
        }
      }
    }
  }
  ```
- **Объяснение**:
    - `by_type`: Группирует по `type` и вычисляет средний возраст (`avg_age`) для каждой группы.
    - `overall_avg_age`: Вычисляет среднее значение всех `avg_age`.

#### Лучшие практики для агрегаций:
- Используй фильтры в `query`, чтобы ограничить данные перед агрегацией.
- Ограничивай количество бакетов в `terms` (например, `"size": 10`), чтобы избежать перегрузки.
- Для сложных аналитик комбинируй `bucket` и `metrics` агрегации.
- Используй `pipeline` для вычислений над агрегациями (например, среднее по группам).

### Итог
- **Query DSL**:
  - `match`, `term`, `bool`, `range` — основные типы запросов.
  - `bool` комбинирует условия (`must`, `should`, `must_not`, `filter`).
- **Полнотекстовый поиск**:
  - `match`: Для анализа текста (например, "кот" найдёт "коты").
  - `multi_match`: Поиск по нескольким полям.
  - `query_string`: Гибкий поиск с синтаксисом `AND`, `OR`, `-`.
- **Фильтры**:
  - Используй в `filter` для точных условий без подсчёта score.
  - Ускоряют запросы за счёт кэширования.
- **Агрегации**:
  - **Metrics**: Подсчёт значений (`avg`, `sum`).
  - **Bucket**: Группировка данных (`terms`, `histogram`).
  - **Pipeline**: Вычисления над агрегациями (`avg_bucket`).
Эти инструменты позволяют гибко искать, фильтровать и анализировать данные в Elasticsearch, делая его мощным для аналитики и поиска!

## 11  **Релевантность поиска**:
Релевантность поиска в **Elasticsearch** — это механизм, который определяет, насколько хорошо документ соответствует поисковому запросу, и выражается через числовое значение **score**. Elasticsearch использует алгоритмы **TF-IDF** и **BM25** для вычисления релевантности, а также предоставляет инструменты для её настройки через **boosting** и **custom scoring**. 

---

### Как Elasticsearch вычисляет score (релевантность)?

Релевантность в Elasticsearch определяется в **query context** (например, при использовании `match` или `multi_match`), где каждому документу присваивается **score** — число, показывающее, насколько он соответствует запросу. Основные алгоритмы для этого — **TF-IDF** (старый подход) и **BM25** (по умолчанию в современных версиях).

#### a) TF-IDF (Term Frequency-Inverse Document Frequency)
TF-IDF — это классический алгоритм для оценки релевантности, который учитывает частоту термина в документе и его редкость в коллекции.

- **Компоненты**:
    - **TF (Term Frequency)**: Как часто термин встречается в документе. Чем чаще (например, "кот" в документе), тем выше релевантность.
    - **IDF (Inverse Document Frequency)**: Как редко термин встречается в индексе. Редкие термины (например, "Мурзик" вместо "кот") считаются более значимыми.
    - **Длина документа**: Более короткие документы получают больший вес, так как термин в них более значим.

- **Формула (упрощённо)**:
  ```
  score = TF * IDF * normalization
  ```
    - `TF`: Количество вхождений термина в документе.
    - `IDF`: `log(общее_количество_документов / количество_документов_с_термином)`.
    - `normalization`: Учёт длины документа и других факторов.

- **Пример**:
    - Запрос: `"кот"`.
    - Документ 1: `"Кот Мурзик ест рыбу"` (3 слова, "кот" встречается 1 раз).
    - Документ 2: `"Кот кот кот спит на диване"` (6 слов, "кот" встречается 3 раза).
    - Если "кот" есть в 10 из 100 документов, то:
        - `TF` для Документа 1: 1/3 ≈ 0.33.
        - `TF` для Документа 2: 3/6 = 0.5.
        - `IDF`: `log(100/10) = 1`.
        - `score` Документа 1: `0.33 * 1 * нормализация`.
        - `score` Документа 2: `0.5 * 1 * нормализация`.
    - Документ 2 получит более высокий score из-за большей частоты термина.

- **Проблемы TF-IDF**:
    - Слишком высокая чувствительность к частоте термина (много повторов → неоправданно высокий score).
    - Меньшая точность для больших коллекций.

#### b) BM25 (Best Matching 25)
BM25 — современный алгоритм, используемый в Elasticsearch по умолчанию (начиная с версии 5.0). Он улучшает TF-IDF, делая релевантность более сбалансированной.

- **Компоненты**:
    - **TF с насыщением**: Частота термина влияет на score, но эффект уменьшается с каждым дополнительным вхождением (например, 10 "кот" не в 10 раз лучше, чем 1 "кот").
    - **IDF**: Как в TF-IDF, редкие термины важнее.
    - **Длина документа**: Короткие документы получают больший вес, но влияние длины ограничено.
    - **Параметры настройки**:
        - `k1`: Контролирует насыщение TF (обычно 1.2–2.0).
        - `b`: Контролирует влияние длины документа (обычно 0.75).

- **Формула (упрощённо)**:
  ```
  score = Σ (IDF * (TF * (k1 + 1)) / (TF + k1 * (1 - b + b * (длина_документа / средняя_длина)))
  ```
    - Это делает BM25 более устойчивым к чрезмерному влиянию длинных документов или частых терминов.

- **Пример**:
    - Запрос: `"кот"`.
    - Документ 1: `"Кот Мурзик"` (2 слова).
    - Документ 2: `"Кот кот кот спит долго на диване"` (7 слов).
    - BM25 даст Документу 1 более высокий score, так как он короче, а "кот" имеет большее относительное значение, несмотря на меньшую частоту.

- **Преимущества BM25**:
    - Более точные результаты за счёт ограничения влияния TF.
    - Лучше работает с большими и разнообразными наборами данных.
    - Настраиваемые параметры (`k1`, `b`) позволяют адаптировать релевантность.

#### Как проверить score?
- Используй параметр `explain` в запросе:
  ```bash
  POST /pets/_search
  {
    "explain": true,
    "query": {
      "match": { "name": "кот" }
    }
  }
  ```
- Ответ покажет, как score рассчитан для каждого документа (включая вклад TF, IDF и длины).


### Настройка релевантности через boosting и custom scoring

Elasticsearch позволяет настраивать релевантность, чтобы приоритетно показывать определённые документы или изменять score на основе пользовательских правил. Основные инструменты — **boosting** и **custom scoring**.

#### a) Boosting
Boosting увеличивает или уменьшает вес определённых полей или условий в запросе, чтобы повлиять на релевантность.

- **Boosting на уровне полей**:
    - Укажи вес (`boost`) для полей в `multi_match`:
      ```bash
      POST /pets/_search
      {
        "query": {
          "multi_match": {
            "query": "кот",
            "fields": ["name^2", "description"], // name важнее в 2 раза
            "type": "best_fields"
          }
        }
      }
      ```
    - Документы, где "кот" найден в `name`, получат score в 2 раза выше, чем для `description`.

- **Boosting на уровне запросов**:
    - Используй `bool` с `boost` для отдельных условий:
      ```bash
      POST /pets/_search
      {
        "query": {
          "bool": {
            "should": [
              { "match": { "name": { "query": "кот", "boost": 2 } } },
              { "match": { "description": { "query": "кот", "boost": 1 } } }
            ]
          }
        }
      }
      ```
    - Совпадения в `name` имеют больший вес.

- **Negative boosting**:
    - Уменьшай score для нежелательных документов:
      ```bash
      POST /pets/_search
      {
        "query": {
          "bool": {
            "must": [
              { "match": { "name": "кот" } }
            ],
            "should": [
              { "match": { "type": "cat" } }
            ],
            "must_not": [
              { "match": { "description": { "query": "больной", "boost": 0.1 } } }
            ]
          }
        }
      }
      ```
    - Документы с "больной" в `description` получат меньший score.

#### b) Custom Scoring
Custom scoring позволяет задавать собственные формулы для вычисления score с помощью **function_score** запроса. Это полезно, когда нужно учитывать дополнительные факторы, такие как числовые поля, даты или веса.

- **Основные функции в function_score**:
    - `weight`: Фиксированный множитель score.
    - `field_value_factor`: Использует значение поля для изменения score.
    - `script_score`: Пользовательский скрипт для вычисления score.
    - `decay_function`: Уменьшает score в зависимости от расстояния от значения (например, даты или геолокации).

- **Пример: Увеличение score для молодых животных**:
    - Допустим, более молодые животные (меньший `age`) должны быть выше в результатах:
      ```bash
      POST /pets/_search
      {
        "query": {
          "function_score": {
            "query": { "match": { "name": "кот" } },
            "functions": [
              {
                "field_value_factor": {
                  "field": "age",
                  "factor": 1,
                  "modifier": "reciprocal" // score = 1/age, меньший возраст → выше score
                }
              }
            ],
            "boost_mode": "multiply" // Умножаем score на функцию
          }
        }
      }
      ```
    - Документ с `age: 2` получит score выше, чем с `age: 5`.

- **Пример: Скрипт для custom scoring**:
    - Допустим, score зависит от `age` и `weight`:
      ```bash
      POST /pets/_search
      {
        "query": {
          "function_score": {
            "query": { "match": { "name": "кот" } },
            "functions": [
              {
                "script_score": {
                  "script": {
                    "source": "doc['age'].value * 0.5 + doc['weight'].value * 0.3"
                  }
                }
              }
            ],
            "boost_mode": "replace" // Заменяем score на результат скрипта
          }
        }
      }
      ```
    - Score вычисляется как `age * 0.5 + weight * 0.3`.

- **Пример: Decay function для актуальности по дате**:
    - Допустим, более новые записи (поле `created_date`) должны иметь больший score:
      ```bash
      POST /pets/_search
      {
        "query": {
          "function_score": {
            "query": { "match": { "name": "кот" } },
            "functions": [
              {
                "gauss": {
                  "created_date": {
                    "origin": "now",
                    "scale": "30d",
                    "decay": 0.5
                  }
                }
              }
            ],
            "boost_mode": "multiply"
          }
        }
      }
      ```
    - Документы, созданные ближе к текущей дате (`now`), получают более высокий score.

#### Лучшие практики для настройки релевантности
- **Boosting**:
    - Используй умеренные значения `boost` (например, 1–5), чтобы избежать искажения результатов.
    - Тестируй разные веса с помощью `_explain` для понимания влияния.
- **Custom Scoring**:
    - Используй `function_score` для сложных сценариев (например, учёт геолокации или популярности).
    - Избегай сложных скриптов в `script_score`, так как они замедляют поиск.
- **BM25 параметры**:
    - Настрой `k1` и `b` в маппингах индекса, если нужно изменить поведение BM25:
      ```bash
      PUT /pets
      {
        "settings": {
          "index": {
            "similarity": {
              "my_bm25": {
                "type": "BM25",
                "k1": 1.2,
                "b": 0.75
              }
            }
          }
        },
        "mappings": {
          "properties": {
            "name": { "type": "text", "similarity": "my_bm25" }
          }
        }
      }
      ```
- **Тестирование**:
    - Используй `_explain` для анализа, почему документ получил определённый score:
      ```bash
      GET /pets/_explain/1
      {
        "query": { "match": { "name": "кот" } }
      }
      ```
    
### Итог
- **Релевантность**:
    - **TF-IDF**: Учитывает частоту термина и его редкость, но чувствителен к повторам.
    - **BM25**: Более сбалансированный, ограничивает влияние частоты и длины документа, используется по умолчанию.
- **Настройка релевантности**:
    - **Boosting**: Увеличивай вес полей или условий (`multi_match`, `bool`).
    - **Custom Scoring**: Используй `function_score` для сложных правил (например, `field_value_factor`, `script_score`, `decay_function`).
- **Практика**:
    - Тестируй с `_explain` для понимания score.
    - Используй умеренные значения boost и оптимизируй скрипты для производительности.
      Эти инструменты позволяют гибко настраивать поиск, чтобы результаты соответствовали бизнес-целям или пользовательским ожиданиям!
      
## 12 **Геопространственные запросы**
Геопространственные запросы в **Elasticsearch** позволяют работать с географическими данными, такими как координаты точек (`geo_point`) или сложные геометрические фигуры (`geo_shape`). Это полезно для задач, связанных с поиском объектов по местоположению, фильтрацией по области или вычислением расстояний. 

### Основы геоданных в Elasticsearch

Elasticsearch поддерживает два основных типа геоданных:
- **`geo_point`**: Для хранения координат (широта и долгота) в формате `{ "lat": 55.75, "lon": 37.61 }`. Используется для точек на карте (например, местоположение магазина).
- **`geo_shape`**: Для хранения сложных геометрических фигур (полигоны, линии, круги). Используется для работы с областями (например, границы города).

Эти типы данных позволяют выполнять геопространственные запросы, такие как поиск точек в радиусе, проверка пересечения с фигурами или сортировка по расстоянию.


### 2. Настройка маппингов для геоданных

Чтобы использовать геопространственные запросы, нужно настроить маппинг индекса для полей с типами `geo_point` или `geo_shape`.

#### a) Маппинг для `geo_point`
- Пример создания индекса с полем `location` типа `geo_point`:
  ```bash
  PUT /places
  {
    "mappings": {
      "properties": {
        "name": { "type": "text" },
        "location": { "type": "geo_point" }
      }
    }
  }
  ```
- Форматы для `geo_point`:
    - Объект: `{ "lat": 55.75, "lon": 37.61 }` (Москва).
    - Строка: `"55.75,37.61"` (широта, долгота).
    - GeoJSON: `[37.61, 55.75]` (долгота, широта).
    - WKT: `"POINT (37.61 55.75)"`.

#### b) Маппинг для `geo_shape`
- Пример создания индекса с полем `area` типа `geo_shape`:
  ```bash
  PUT /cities
  {
    "mappings": {
      "properties": {
        "name": { "type": "text" },
        "area": { "type": "geo_shape" }
      }
    }
  }
  ```
- Форматы для `geo_shape`:
    - GeoJSON: Например, полигон для описания области.
    - Well-Known Text (WKT): Например, `"POLYGON ((30 10, 40 40, 20 40, 10 20, 30 10))"`.

#### Пример добавления данных
- Для `geo_point`:
  ```bash
  POST /places/_doc/1
  {
    "name": "Кремль",
    "location": { "lat": 55.751244, "lon": 37.618423 }
  }
  ```
- Для `geo_shape`:
  ```bash
  POST /cities/_doc/1
  {
    "name": "Москва",
    "area": {
      "type": "polygon",
      "coordinates": [[
        [37.3, 55.9], [37.9, 55.9], [37.9, 55.5], [37.3, 55.5], [37.3, 55.9]
      ]]
    }
  }
  ```

### 3. Геопространственные запросы

Elasticsearch поддерживает несколько типов геопространственных запросов для `geo_point` и `geo_shape`. Они могут использоваться в **query context** (с подсчётом score) или **filter context** (без score, быстрее).

#### a) Запросы для `geo_point`
1. **geo_distance**:
    - Находит точки в заданном радиусе от центра.
    - Пример: Найти места в радиусе 10 км от центра Москвы:
      ```bash
      POST /places/_search
      {
        "query": {
          "bool": {
            "filter": {
              "geo_distance": {
                "distance": "10km",
                "location": {
                  "lat": 55.75,
                  "lon": 37.61
                }
              }
            }
          }
        }
      }
      ```
    - Возвращает документы, где `location` находится в пределах 10 км от точки.

2. **geo_bounding_box**:
    - Находит точки в прямоугольной области, заданной верхним левым и нижним правым углами.
    - Пример: Найти места в прямоугольнике вокруг Москвы:
      ```bash
      POST /places/_search
      {
        "query": {
          "bool": {
            "filter": {
              "geo_bounding_box": {
                "location": {
                  "top_left": { "lat": 55.9, "lon": 37.3 },
                  "bottom_right": { "lat": 55.5, "lon": 37.9 }
                }
              }
            }
          }
        }
      }
      ```

3. **geo_polygon**:
    - Находит точки внутри полигона, заданного координатами.
    - Пример:
      ```bash
      POST /places/_search
      {
        "query": {
          "bool": {
            "filter": {
              "geo_polygon": {
                "location": {
                  "points": [
                    { "lat": 55.9, "lon": 37.3 },
                    { "lat": 55.9, "lon": 37.9 },
                    { "lat": 55.5, "lon": 37.9 },
                    { "lat": 55.5, "lon": 37.3 }
                  ]
                }
              }
            }
          }
        }
      }
      ```

4. **Сортировка по расстоянию**:
    - Используй `sort` для упорядочивания по расстоянию от точки:
      ```bash
      POST /places/_search
      {
        "query": { "match_all": {} },
        "sort": [
          {
            "_geo_distance": {
              "location": { "lat": 55.75, "lon": 37.61 },
              "order": "asc",
              "unit": "km"
            }
          }
        ]
      }
      ```
    - Документы сортируются по возрастанию расстояния от центра Москвы.

#### b) Запросы для `geo_shape`
1. **geo_shape**:
    - Проверяет пересечение, включение или другие отношения между фигурами.
    - Пример: Найти города, чьи области пересекаются с заданным полигоном:
      ```bash
      POST /cities/_search
      {
        "query": {
          "bool": {
            "filter": {
              "geo_shape": {
                "area": {
                  "shape": {
                    "type": "polygon",
                    "coordinates": [[
                      [37.3, 55.9], [37.9, 55.9], [37.9, 55.5], [37.3, 55.5], [37.3, 55.9]
                    ]]
                  },
                  "relation": "intersects" // Пересекается
                }
              }
            }
          }
        }
      }
      ```
    - **relation**:
        - `intersects`: Пересекается с фигурой.
        - `within`: Полностью внутри фигуры.
        - `contains`: Содержит фигуру.
        - `disjoint`: Не пересекается.

2. **geo_bounding_box** (для `geo_shape`):
    - Проверяет, попадает ли фигу.~ра в прямоугольник:
      ```bash
      POST /cities/_search
      {
        "query": {
          "bool": {
            "filter": {
              "geo_shape": {
                "area": {
                  "shape": {
                    "type": "envelope",
                    "coordinates": [[37.3, 55.9], [37.9, 55.5]]
                  },
                  "relation": "within"
                }
              }
            }
          }
        }
      }
      ```
    
### 4. Агрегации с геоданными

Elasticsearch поддерживает геопространственные агрегации для анализа данных.

1. **geo_distance** (агрегация):
    - Группирует документы по расстоянию от точки.
    - Пример: Подсчитать, сколько мест в радиусах 5, 10 и 20 км от центра Москвы:
      ```bash
      POST /places/_search
      {
        "query": { "match_all": {} },
        "aggs": {
          "by_distance": {
            "geo_distance": {
              "field": "location",
              "origin": { "lat": 55.75, "lon": 37.61 },
              "unit": "km",
              "ranges": [
                { "to": 5 },
                { "from": 5, "to": 10 },
                { "from": 10, "to": 20 }
              ]
            }
          }
        }
      }
      ```
    - Ответ:
      ```json
      {
        "aggregations": {
          "by_distance": {
            "buckets": [
              { "key": "*-5.0", "doc_count": 2 },
              { "key": "5.0-10.0", "doc_count": 5 },
              { "key": "10.0-20.0", "doc_count": 10 }
            ]
          }
        }
      }
      ```

2. **geo_centroid**:
    - Вычисляет центр масс (среднюю точку) для набора `geo_point`:
      ```bash
      POST /places/_search
      {
        "aggs": {
          "centroid": {
            "geo_centroid": { "field": "location" }
          }
        }
      }
      ```
    - Ответ:
      ```json
      {
        "aggregations": {
          "centroid": {
            "location": { "lat": 55.73, "lon": 37.62 }
          }
        }
      }
      ```

3. **geo_bounds**:
    - Вычисляет прямоугольник, охватывающий все точки:
      ```bash
      POST /places/_search
      {
        "aggs": {
          "bounds": {
            "geo_bounds": { "field": "location" }
          }
        }
      }
      ```
    - Ответ:
      ```json
      {
        "aggregations": {
          "bounds": {
            "top_left": { "lat": 55.9, "lon": 37.3 },
            "bottom_right": { "lat": 55.5, "lon": 37.9 }
          }
        }
      }
      ```

### Итог
- **Типы данных**:
    - `geo_point`: Для координат (широта, долгота).
    - `geo_shape`: Для сложных фигур (полигоны, линии).
- **Запросы**:
    - `geo_distance`: Поиск в радиусе.
    - `geo_bounding_box`: Поиск в прямоугольнике.
    - `geo_polygon`/`geo_shape`: Поиск внутри фигур.
    - Сортировка по расстоянию с `_geo_distance`.
- **Агрегации**:
    - `geo_distance`: Группировка по расстоянию.
    - `geo_centroid`: Центр масс.
    - `geo_bounds`: Охватывающий прямоугольник.
- **Практика**:
    - Используй `filter` для скорости.
    - Настраивай маппинги для точности.
    - Тестируй с Kibana Maps для визуализации.
      Эти инструменты делают Elasticsearch мощным для работы с геоданными, от поиска ближайших точек до анализа географических зон!
      

## 13 **Оптимизация запросов**:

Оптимизация запросов в **Elasticsearch** критически важна для обеспечения высокой производительности, особенно при работе с большими индексами или высоконагруженными системами. Основные подходы включают использование **фильтров вместо запросов** там, где это возможно, и избегание сложных запросов, таких как `wildcard` на больших индексах. 

###  Использование фильтров вместо запросов

В Elasticsearch запросы делятся на два контекста:
- **Query context**: Используется для полнотекстового поиска с вычислением релевантности (score). Примеры: `match`, `multi_match`.
- **Filter context**: Используется для точной фильтрации без вычисления score, что делает его быстрее. Примеры: `term`, `range` в секции `filter`.

#### Почему фильтры быстрее?
- **Без score**: Фильтры не рассчитывают релевантность, а просто возвращают документы, соответствующие условиям.
- **Кэширование**: Elasticsearch автоматически кэширует результаты фильтров (например, `term`, `range`), если они часто используются. Кэш хранится в памяти и ускоряет повторные запросы.
- **Оптимизация**: Фильтры работают с бинарной логикой (да/нет), что снижает вычислительные затраты.

#### Когда использовать фильтры?
- Когда не нужна релевантность (например, точное совпадение или диапазон).
- Для предварительного сужения выборки перед полнотекстовым поиском.
- Для часто повторяющихся условий (например, фильтрация по категории или дате).

#### Пример: Фильтры против запросов
Допустим, у нас индекс `pets` с документами вида:
```json
{"name": "Кот Мурзик", "age": 3, "type": "cat"}
{"name": "Собака Рекс", "age": 5, "type": "dog"}
```

1. **Запрос с вычислением score** (медленнее):
   ```bash
   POST /pets/_search
   {
     "query": {
       "bool": {
         "must": [
           { "match": { "type": "cat" } },
           { "range": { "age": { "gte": 2 } } }
         ]
       }
     }
   }
   ```
    - Проблема: `match` и `range` в `must` вычисляют score, что замедляет запрос.

2. **Фильтр без score** (быстрее):
   ```bash
   POST /pets/_search
   {
     "query": {
       "bool": {
         "filter": [
           { "term": { "type": "cat" } },
           { "range": { "age": { "gte": 2 } } }
         ]
       }
     }
   }
   ```
    - Преимущества:
        - `term` вместо `match` для точного совпадения (без анализа текста).
        - `filter` не вычисляет score и кэширует результаты.
        - Запрос выполняется быстрее, особенно на больших индексах.

3. **Комбинированный подход**:
    - Используй фильтры для сужения выборки, а `match` для полнотекстового поиска:
      ```bash
      POST /pets/_search
      {
        "query": {
          "bool": {
            "filter": [
              { "term": { "type": "cat" } }, // Сначала фильтруем котов
              { "range": { "age": { "gte": 2 } } }
            ],
            "must": [
              { "match": { "name": "мурзик" } } // Затем ищем по имени
            ]
          }
        }
      }
      ```
    - **Эффект**: Фильтры уменьшают количество документов, которые нужно анализировать в `match`, что ускоряет запрос.

#### Лучшие практики для фильтров
- Используй `term` для точных значений (например, `type: "cat"`) вместо `match`.
- Применяй `range` в `filter` для чисел, дат или других диапазонов.
- Для текстовых полей используй `term` с полем `.keyword` (например, `name.keyword`), если не нужен анализ текста.
- Комбинируй `filter` с `must` для баланса скорости и релевантности.
- Проверяй кэширование фильтров через API:
  ```bash
  GET /_stats/request_cache?human
  ```

### 2. Избежание сложных запросов (например, wildcard на больших индексах)

Сложные запросы, такие как `wildcard`, `regexp`, или `prefix`, могут быть ресурсоёмкими, особенно на больших индексах, так как они требуют проверки большого числа документов или токенов в инвертированном индексе. Давайте разберём, как их избегать и какие альтернативы использовать.

#### Проблемы сложных запросов
1. **wildcard**:
    - Пример: `name: ко*` ищет все документы, где `name` начинается на "ко".
    - Проблема: Elasticsearch проверяет все токены в инвертированном индексе, что медленно на больших индексах.
    - Пример проблемного запроса:
      ```bash
      POST /pets/_search
      {
        "query": {
          "wildcard": { "name.keyword": "ко*" }
        }
      }
      ```

2. **regexp**:
    - Пример: `name: k.t` (где `.` — любой символ).
    - Проблема: Требует проверки сложных шаблонов, что замедляет поиск.

3. **prefix**:
    - Похож на `wildcard`, но проверяет только начало строки.
    - Проблема: Тоже может быть медленным, особенно если префикс короткий (например, `"к*"`).

4. **Другие ресурсоёмкие запросы**:
    - Глубокие агрегации (например, `terms` на поле с миллионами уникальных значений).
    - Сложные скрипты в `script_score` или `script_fields`.
    - Запросы с большим `size` (например, возврат 10000 документов).

#### Альтернативы для оптимизации
1. **Для автодополнения (вместо wildcard/prefix)**:
    - Используй анализатор с `edge_ngram` для поддержки автодополнения:
      ```bash
      PUT /pets
      {
        "settings": {
          "analysis": {
            "analyzer": {
              "autocomplete": {
                "type": "custom",
                "tokenizer": "standard",
                "filter": ["lowercase", "autocomplete_filter"]
              }
            },
            "filter": {
              "autocomplete_filter": {
                "type": "edge_ngram",
                "min_gram": 2,
                "max_gram": 20
              }
            }
          }
        },
        "mappings": {
          "properties": {
            "name": {
              "type": "text",
              "analyzer": "autocomplete",
              "search_analyzer": "standard"
            }
          }
        }
      }
      ```
    - Пример запроса:
      ```bash
      POST /pets/_search
      {
        "query": {
          "match": { "name": "ко" }
        }
      }
      ```
    - **Эффект**: `edge_ngram` разбивает "кот" на `["ко", "кот"]` при индексации, что делает поиск по префиксу быстрым.

2. **Для точного совпадения (вместо wildcard/regexp)**:
    - Используй поле `keyword` с `term`:
      ```bash
      POST /pets/_search
      {
        "query": {
          "term": { "name.keyword": "Кот Мурзик" }
        }
      }
      ```
    - Это быстрее, так как не требует анализа текста.

3. **Для сложных шаблонов**:
    - Если нужен частичный поиск, используй `match` с анализатором, который поддерживает морфологию (например, `russian`):
      ```bash
      POST /pets/_search
      {
        "query": {
          "match": { "name": "коты" }
        }
      }
      ```
    - Это найдёт "кот", "коты", "кошка" без использования `wildcard`.

4. **Для агрегаций**:
    - Ограничивай количество бакетов в `terms`:
      ```bash
      POST /pets/_search
      {
        "aggs": {
          "by_type": {
            "terms": {
              "field": "type",
              "size": 10 // Ограничить 10 бакетами
            }
          }
        }
      }
      ```
    - Используй предварительные фильтры, чтобы уменьшить выборку:
      ```bash
      POST /pets/_search
      {
        "query": {
          "bool": {
            "filter": [
              { "range": { "age": { "gte": 2 } } }
            ]
          }
        },
        "aggs": {
          "by_type": {
            "terms": { "field": "type" }
          }
        }
      }
      ```

5. **Для больших результатов**:
    - Используй `search_after` или `scroll` вместо большого `size`:
      ```bash
      POST /pets/_search
      {
        "size": 100,
        "sort": [
          { "age": "asc" },
          { "_id": "asc" }
        ],
        "query": { "match_all": {} },
        "search_after": [5, "last_id"]
      }
      ```
    - `scroll` подходит для экспорта данных:
      ```bash
      POST /pets/_search?scroll=1m
      {
        "size": 1000,
        "query": { "match_all": {} }
      }
      ```

#### Лучшие практики для избегания сложных запросов
- **Избегай wildcard/regexp** на больших индексах. Вместо этого используй анализаторы с `edge_ngram` или `n-gram` для частичного поиска.
- **Ограничивай выборку** фильтрами перед сложными операциями (поиск, агрегации).
- **Используй keyword для точных совпадений** вместо текстовых полей с анализом.
- **Тестируй запросы** на малых данных и проверяй производительность с помощью `_profile`:
  ```bash
  POST /pets/_search
  {
    "profile": true,
    "query": { "match": { "name": "кот" } }
  }
  ```
- **Оптимизируй индекс**:
    - Уменьшай количество первичных шардов для небольших индексов.
    - Используй `force_merge` для оптимизации сегментов (осторожно, ресурсоёмко):
      ```bash
      POST /pets/_forcemerge
      ```

### Итог
- **Фильтры вместо запросов**:
    - Используй `filter` для точных условий (`term`, `range`), чтобы избежать вычисления score.
    - Комбинируй `filter` и `must` для скорости и релевантности.
    - Фильтры кэшируются, что ускоряет повторные запросы.
- **Избежание сложных запросов**:
    - Заменяй `wildcard`/`regexp` анализаторами (`edge_ngram` для автодополнения).
    - Ограничивай выборку фильтрами перед агрегациями.
    - Используй `search_after` или `scroll` для больших результатов.
    - Тестируй с `_profile` и оптимизируй индексы (`force_merge`).
      Эти подходы помогут сделать запросы быстрыми и эффективными даже на больших данных!

## 14 **Управление шардами**:
Управление шардами в **Elasticsearch** — это важный аспект для обеспечения производительности, масштабируемости и отказоустойчивости кластера. Шарды и их реплики определяют, как данные распределяются и хранятся, а такие операции, как `_forcemerge`, помогают оптимизировать индексы. 

### Оптимизация количества шардов и реплик

Шарды — это части индекса, которые распределяют данные по узлам кластера. Реплики — это копии шардов для отказоустойчивости и распределения нагрузки. Неправильная настройка их количества может привести к перегрузке узлов, низкой производительности или избыточному потреблению ресурсов.

#### a) Шарды
- **Первичные шарды** (`number_of_shards`): Делят индекс на части для параллельной обработки и распределения данных.
- **Особенности**:
    - Количество первичных шардов задаётся при создании индекса и **не может быть изменено** без переиндексации.
    - Каждый шард — это отдельный Lucene-индекс, который потребляет ресурсы (память, диск, CPU).
    - Слишком много шардов увеличивает накладные расходы, слишком мало — ограничивает масштабируемость.

- **Рекомендации по количеству шардов**:
    - **Размер данных**: Целевой размер шарда — 20–50 ГБ. Например, для 100 ГБ данных используй 2–5 шардов.
    - **Количество узлов**: Учитывай число Data Nodes. Например, для 3 узлов 3–6 шардов обеспечивают равномерное распределение.
    - **Тип нагрузки**:
        - Для поисковых запросов: 1–5 шардов на индекс для небольших данных.
        - Для аналитики (агрегации): Больше шардов для параллелизма, но не более 1–2 на узел.
    - **Пример создания индекса**:
      ```bash
      PUT /pets
      {
        "settings": {
          "number_of_shards": 3, // 3 первичных шарда
          "number_of_replicas": 1 // 1 реплика на шард
        }
      }
      ```

- **Проверка распределения шардов**:
  ```bash
  GET /_cat/shards/pets?v
  ```
    - Показывает, где находятся шарды и реплики, их размер и состояние.

#### b) Реплики
- **Реплики** (`number_of_replicas`): Копии первичных шардов для отказоустойчивости и распределения нагрузки при чтении.
- **Особенности**:
    - Реплики можно изменять **на лету** без переиндексации.
    - Увеличивают отказоустойчивость: если узел с первичным шардом выходит из строя, реплика становится первичной.
    - Ускоряют поиск, так как запросы могут распределяться между первичными шардами и репликами.
    - Увеличивают потребление диска и ресурсов (каждая реплика — копия шарда).

- **Рекомендации по количеству реплик**:
    - **Минимум 1 реплика** для отказоустойчивости (в продакшене).
    - Для высоконагруженных систем (много поисков): 2–3 реплики для распределения нагрузки.
    - Для аналитики с редкими запросами: 0–1 реплика, чтобы сэкономить ресурсы.
    - Если кластер небольшой (1–2 узла), 1 реплика достаточно.
    - **Пример изменения реплик**:
      ```bash
      PUT /pets/_settings
      {
        "number_of_replicas": 2 // Установить 2 реплики
      }
      ```

- **Проверка состояния реплик**:
  ```bash
  GET /_cat/health?v
  GET /_cat/recovery?v
  ```
    - Убедись, что все реплики синхронизированы (`status: green`).

#### c) Оптимизация шардов и реплик
1. **Слишком много шардов**:
    - Проблема: Увеличиваются накладные расходы на управление (метаданные, память).
    - Решение:
        - Уменьшай количество шардов при создании новых индексов.
        - Для существующих индексов используй `_shrink` API, чтобы уменьшить число шардов:
          ```bash
          POST /pets/_shrink/pets_shrunk
          {
            "settings": {
              "number_of_shards": 1, // Сжать до 1 шарда
              "number_of_replicas": 1
            }
          }
          ```
        - Убедись, что индекс закрыт или только для чтения перед сжатием:
          ```bash
          POST /pets/_close
          ```

2. **Слишком мало шардов**:
    - Проблема: Ограничивает масштабируемость и параллелизм.
    - Решение:
        - Создай новый индекс с большим количеством шардов и переиндексируй данные:
          ```bash
          PUT /pets_v2
          {
            "settings": {
              "number_of_shards": 6,
              "number_of_replicas": 1
            }
          }
          POST /_reindex
          {
            "source": { "index": "pets" },
            "dest": { "index": "pets_v2" }
          }
          ```

3. **Дисбаланс шардов**:
    - Проблема: Некоторые узлы перегружены, если шарды распределены неравномерно.
    - Решение:
        - Включи автоматическую балансировку:
          ```bash
          PUT /_cluster/settings
          {
            "transient": {
              "cluster.routing.allocation.enable": "all"
            }
          }
          ```
        - Проверь распределение:
          ```bash
          GET /_cat/allocation?v
          ```
        - Принудительно переместить шард:
          ```bash
          POST /_cluster/reroute
          {
            "commands": [
              {
                "move": {
                  "index": "pets",
                  "shard": 0,
                  "from_node": "node1",
                  "to_node": "node2"
                }
              }
            ]
          }
          ```

4. **Реплики для нагрузки**:
    - Увеличь реплики для высоконагруженных поисков:
      ```bash
      PUT /pets/_settings
      {
        "number_of_replicas": 3
      }
      ```
    - Мониторь нагрузку с помощью:
      ```bash
      GET /_cat/nodes?v&h=name,load_1m,load_5m,load_15m
      ```
    
### Использование `_forcemerge` для оптимизации индексов

**`_forcemerge`** — это API, который принудительно объединяет сегменты Lucene в индексе, чтобы уменьшить их количество, освободить место и улучшить производительность.

#### Как работает `_forcemerge`?
- Каждый шард — это Lucene-индекс, состоящий из **сегментов** (файлов на диске, где хранятся данные).
- Сегменты создаются при добавлении/обновлении документов. Удалённые документы помечаются, но физически остаются в сегментах.
- `_forcemerge` объединяет сегменты, удаляет помеченные документы и оптимизирует инвертированный индекс.
- Результат:
    - Меньше сегментов → меньше файлов → быстрее поиск.
    - Освобождается дисковое пространство.
    - Уменьшается потребление памяти.

#### Пример использования
- Выполнить принудительное слияние для индекса `pets`, оставляя 1 сегмент на шард:
  ```bash
  POST /pets/_forcemerge?max_num_segments=1
  ```
- **Параметры**:
    - `max_num_segments`: Целевое количество сегментов на шард (обычно 1 для максимальной оптимизации).
    - `only_expunge_deletes`: Удалить только помеченные документы, не объединяя сегменты:
      ```bash
      POST /pets/_forcemerge?only_expunge_deletes=true
      ```

#### Когда использовать `_forcemerge`?
- **После массового удаления**: Если много документов помечено как удалённые, `_forcemerge` освободит место.
- **Для индексов только для чтения**: Например, исторические логи, которые больше не обновляются.
- **Перед долгосрочным хранением**: Чтобы уменьшить размер индекса и улучшить производительность.
- **При низкой производительности**: Если слишком много сегментов замедляет поиск.

#### Ограничения и риски
- **Ресурсоёмкость**: `_forcemerge` потребляет много CPU, I/O и памяти. Выполняй в периоды низкой нагрузки.
- **Не для активных индексов**: Слияние сегментов может замедлить текущие операции записи.
- **Необратимость**: Сегменты объединяются навсегда, что может быть проблемой, если нужно отменить изменения.
- **Ограничение по размеру сегмента**: Lucene не создаёт сегменты больше ~5 ГБ, даже если `max_num_segments=1`.

#### Лучшие практики
1. **Закрой индекс перед слиянием** (если возможно):
   ```bash
   POST /pets/_close
   POST /pets/_forcemerge?max_num_segments=1
   POST /pets/_open
   ```
2. **Мониторь процесс**:
    - Проверяй состояние слияния:
      ```bash
      GET /_cat/segments/pets?v
      ```
    - Проверяй нагрузку на узлы:
      ```bash
      GET /_cat/nodes?v&h=name,disk.used,disk.avail
      ```
3. **Ограничивай слияние**:
    - Для больших индексов выполняй `_forcemerge` по одному индексу за раз.
    - Укажи `max_num_segments=5` вместо `1`, чтобы снизить нагрузку.
4. **Автоматическое управление сегментами**:
    - Elasticsearch сам выполняет слияние сегментов в фоновом режиме. Настрой параметры в `elasticsearch.yml`:
      ```yaml
      indices.forcemerge.max_num_segments: 5
      ```
    - Увеличь лимиты, если нужно:
      ```bash
      PUT /_cluster/settings
      {
        "transient": {
          "indices.forcemerge.max_bytes_per_sec": "50mb"
        }
      }
      ```

#### Пример оптимизации
- Индекс `pets` после массового удаления занимает 10 ГБ, но имеет 100 сегментов на шард.
- Оптимизируем:
  ```bash
  POST /pets/_close
  POST /pets/_forcemerge?max_num_segments=1
  POST /pets/_open
  ```
- Результат: Размер индекса уменьшился до 7 ГБ, сегментов стало 1 на шард, поиск ускорился.

### Итог
- **Оптимизация шардов и реплик**:
    - Задавай **2–5 шардов** для индексов до 100 ГБ, ориентируйся на 20–50 ГБ на шард.
    - Используй **1–2 реплики** для отказоустойчивости и распределения нагрузки.
    - Изменяй реплики на лету, для шардов используй `_shrink` или `_reindex`.
    - Балансируй шарды с помощью `_cluster/reroute` и проверяй распределение.
- **Использование `_forcemerge`**:
    - Выполняй для индексов только для чтения или после массового удаления.
    - Указывай `max_num_segments=1` для максимальной оптимизации.
    - Закрывай индекс перед слиянием и выполняй в периоды низкой нагрузки.
      Эти подходы помогут оптимизировать производительность и снизить потребление ресурсов в Elasticsearch!
      
## 15 **Кэширование**
Кэширование в **Elasticsearch** — это мощный механизм, который значительно ускоряет выполнение запросов и агрегаций за счёт хранения часто используемых данных в памяти. Elasticsearch использует несколько типов кэшей: **кэш запросов**, **кэш полей** и **кэш шардов**. Понимание их работы и правильное управление помогают оптимизировать производительность.

### Кэш запросов (Query Cache)

**Кэш запросов** хранит результаты фильтров (filter context) для повторного использования, что ускоряет запросы, не требующие вычисления релевантности (score).

#### Как работает?
- Кэш запросов применяется к запросам в **filter context** (например, `term`, `range`, `bool.filter`).
- Хранит **битовые множества** (bitsets) — компактное представление документов, соответствующих фильтру.
- Работает на уровне **шарда**: каждый шард кэширует свои результаты.
- Кэш автоматически используется для часто выполняемых фильтров (например, `type: "cat"`).
- **Когда кэш обновляется?**
    - Кэш очищается при обновлении сегментов Lucene (например, после `refresh` или `_forcemerge`).
    - Если данные в индексе изменились (добавлены/удалены документы), кэш становится недействительным для затронутых шардов.

#### Пример
- Запрос с фильтром:
  ```bash
  POST /pets/_search
  {
    "query": {
      "bool": {
        "filter": [
          { "term": { "type": "cat" } },
          { "range": { "age": { "gte": 2 } } }
        ]
      }
    }
  }
  ```
- **Что происходит?**
    - Elasticsearch создаёт битовое множество для документов, где `type: "cat"` и `age >= 2`.
    - Это множество кэшируется в памяти для каждого шарда.
    - При повторном запросе с таким же фильтром Elasticsearch использует кэш вместо сканирования индекса.

#### Управление кэшем запросов
- **Проверка использования кэша**:
  ```bash
  GET /_stats/request_cache?human
  ```
    - Показывает статистику: `hit_count` (попадания в кэш), `miss_count` (промахи), `memory_size` (объём кэша).

- **Настройка размера кэша**:
    - По умолчанию кэш запросов занимает до 1% от кучи (heap) каждого узла.
    - Изменить размер:
      ```bash
      PUT /_cluster/settings
      {
        "transient": {
          "indices.queries.cache.size": "2%" // Увеличить до 2%
        }
      }
      ```

- **Отключение кэша для запроса**:
    - Если кэш не нужен (например, для разовых запросов):
      ```bash
      POST /pets/_search?request_cache=false
      {
        "query": {
          "bool": {
            "filter": [
              { "term": { "type": "cat" } }
            ]
          }
        }
      }
      ```

#### Лучшие практики
- Используй **filter context** для условий, которые часто повторяются (например, фильтрация по категории или дате).
- Избегай кэширования для редко используемых фильтров, чтобы не занимать память.
- Мониторь использование кэша через `_stats/request_cache` и увеличивай размер, если много промахов (`miss_count`).
- Убедись, что `refresh_interval` не слишком мал (например, `1s`), чтобы кэш не очищался слишком часто.

### Кэш полей (Field Data Cache)

**Кэш полей** используется для хранения данных полей в памяти, чтобы ускорить операции сортировки, агрегаций и доступа к `script_fields`. Он применяется к полям типа `text` (для агрегаций) и другим типам данных, требующим быстрого доступа.

#### Как работает?
- Поля типа `text` анализируются (разбиваются на токены) и не подходят для агрегаций или сортировки без преобразования.
- Кэш полей создаёт **in-memory** структуру (fielddata) для таких полей, преобразуя их в формат, пригодный для операций.
- **Проблема**: Кэш полей может потреблять много памяти, особенно для полей с большим количеством уникальных значений.

#### Пример
- Агрегация по полю `name` (тип `text`):
  ```bash
  POST /pets/_search
  {
    "aggs": {
      "by_name": {
        "terms": { "field": "name" }
      }
    }
  }
  ```
- **Что происходит?**
    - Elasticsearch загружает значения поля `name` в fielddata cache.
    - Это позволяет быстро выполнить агрегацию, но требует памяти.

#### Оптимизация с `keyword`
- Поля `text` неэффективны для агрегаций/сортировки. Вместо этого используй поле `.keyword`:
  ```bash
  POST /pets/_search
  {
    "aggs": {
      "by_name": {
        "terms": { "field": "name.keyword" }
      }
    }
  }
  ```
- **Почему лучше?**
    - Поля `keyword` не требуют fielddata, так как хранятся в компактном виде.
    - Это снижает потребление памяти и ускоряет запросы.

#### Управление кэшем полей
- **Включение fielddata** (если нужно для `text`):
    - По умолчанию `fielddata` отключён для полей `text` из-за высокого потребления памяти.
    - Включить:
      ```bash
      PUT /pets/_mapping
      {
        "properties": {
          "name": {
            "type": "text",
            "fielddata": true
          }
        }
      }
      ```
    - **Осторожно**: Включай только при необходимости и для полей с низкой кардинальностью (немного уникальных значений).

- **Проверка использования кэша**:
  ```bash
  GET /_stats/fielddata?human&fields=name
  ```
    - Показывает объём памяти, занятый fielddata.

- **Ограничение размера кэша**:
    - По умолчанию fielddata ограничен 20% от кучи узла.
    - Изменить:
      ```bash
      PUT /_cluster/settings
      {
        "transient": {
          "indices.fielddata.cache.size": "15%"
        }
      }
      ```

#### Лучшие практики
- **Используй `keyword` вместо `text`** для агрегаций, сортировки и скриптов.
- Включай `fielddata` только для полей с низкой кардинальностью (например, категории, а не полные тексты).
- Мониторь использование памяти через `_stats/fielddata` и увеличивай кэш, если нужно.
- Добавляй поле `.keyword` в маппинг при создании индекса:
  ```bash
  PUT /pets
  {
    "mappings": {
      "properties": {
        "name": {
          "type": "text",
          "fields": {
            "keyword": { "type": "keyword" }
          }
        }
      }
    }
  }
  ```

### Кэш шардов (Shard Request Cache)

**Кэш шардов** (иногда называется request cache) хранит результаты целых поисковых запросов (включая агрегации) на уровне шарда. Он используется для запросов, которые возвращают одинаковые результаты при повторном выполнении.

#### Как работает?
- Кэширует **полный результат запроса** (хиты и агрегации) для каждого шарда.
- Работает только для **GET** запросов или `POST` с неизменяемыми данными (например, без `script_score` с динамическими параметрами).
- Кэш становится недействительным при обновлении сегментов (например, после `refresh`).
- По умолчанию включён для всех индексов.

#### Пример
- Запрос с агрегацией:
  ```bash
  POST /pets/_search
  {
    "query": {
      "bool": {
        "filter": [
          { "term": { "type": "cat" } }
        ]
      }
    },
    "aggs": {
      "by_age": {
        "terms": { "field": "age" }
      }
    }
  }
  ```
- **Что происходит?**
    - Результаты запроса и агрегации кэшируются для каждого шарда.
    - Повторный запрос с теми же параметрами использует кэш, что ускоряет выполнение.

#### Управление кэшем шардов
- **Проверка использования**:
  ```bash
  GET /_stats/request_cache?human
  ```
    - Показывает статистику кэша шардов (попадания, промахи, объём).

- **Отключение кэша для индекса**:
  ```bash
  PUT /pets/_settings
  {
    "index.requests.cache.enable": false
  }
  ```

- **Отключение кэша для запроса**:
  ```bash
  POST /pets/_search?request_cache=false
  {
    "query": { "match_all": {} }
  }
  ```

#### Лучшие практики
- Включай кэш шардов для запросов, которые часто повторяются и работают с неизменяемыми данными (например, аналитика по историческим данным).
- Отключай кэш для индексов с частыми обновлениями (`refresh_interval: 1s`), чтобы избежать устаревания данных.
- Мониторь использование через `_stats/request_cache` и увеличивай размер кэша при необходимости.

### Общие рекомендации по кэшированию

1. **Мониторинг кэшей**:
    - Регулярно проверяй статистику кэшей:
      ```bash
      GET /_stats/request_cache,fielddata?human
      ```
    - Следи за `evictions` (вытеснения из кэша). Если их много, увеличь размер кэша или оптимизируй запросы.

2. **Оптимизация памяти**:
    - Кэши используют кучу (heap) узла. Убедись, что heap настроен правильно (обычно 50% от RAM узла, но не более 31 ГБ).
    - Пример настройки heap в `jvm.options`:
      ```bash
      -Xms16g
      -Xmx16g
      ```

3. **Фильтры для кэширования**:
    - Используй `filter context` для условий, которые можно кэшировать (например, `term`, `range`).
    - Пример:
      ```bash
      POST /pets/_search
      {
        "query": {
          "bool": {
            "filter": [
              { "term": { "type": "cat" } },
              { "range": { "age": { "gte": 2 } } }
            ],
            "must": [
              { "match": { "name": "мурзик" } }
            ]
          }
        }
      }
      ```

4. **Избегай ненужного кэширования**:
    - Отключай кэш для разовых запросов или индексов с частыми изменениями:
      ```bash
      POST /pets/_search?request_cache=false
      ```

5. **Оптимизация индекса**:
    - Используй `_forcemerge` для уменьшения числа сегментов, что снижает нагрузку на кэши:
      ```bash
      POST /pets/_forcemerge?max_num_segments=1
      ```
    - Увеличь `refresh_interval` для массовой индексации:
      ```bash
      PUT /pets/_settings
      {
        "refresh_interval": "30s"
      }
      ```

### Итог
- **Кэш запросов**:
    - Хранит битовые множества для фильтров (`term`, `range`).
    - Ускоряет повторяющиеся запросы в filter context.
    - Управляй размером через `indices.queries.cache.size`.
- **Кэш полей**:
    - Используется для агрегаций/сортировки по полям `text`.
    - Предпочитай поля `keyword`, чтобы избежать fielddata.
    - Ограничивай размер через `indices.fielddata.cache.size`.
- **Кэш шардов**:
    - Кэширует результаты запросов и агрегаций на уровне шарда.
    - Включай для неизменяемых индексов, отключай для часто обновляемых.
- **Практика**:
    - Используй фильтры для кэшируемых условий.
    - Применяй `keyword` для агрегаций/сортировки.
    - Мониторь кэши через `_stats` и оптимизируй `refresh_interval` и `_forcemerge`.
      Эти подходы помогут максимально эффективно использовать кэширование в Elasticsearch, ускоряя запросы и снижая нагрузку на кластер!
      

## 16 **Мониторинг**
Мониторинг в **Elasticsearch** — это ключевой процесс для оценки производительности кластера, выявления узких мест и предотвращения сбоев. **Kibana** является основным инструментом для визуализации и анализа метрик, но также можно использовать другие инструменты, такие как Prometheus и Grafana. Анализ метрик, таких как использование CPU, памяти, операций ввода-вывода (I/O) и поисковых задержек, помогает оптимизировать работу кластера.

### Использование Kibana или других инструментов для мониторинга производительности

**Kibana** — это официальный инструмент для визуализации и мониторинга Elasticsearch, который предоставляет удобные дашборды для анализа состояния кластера, узлов, индексов и запросов. Другие инструменты, такие как Prometheus, Grafana или Elastic Stack Monitoring, также могут быть использованы для более гибкого или внешнего мониторинга.

#### a) Мониторинг с помощью Kibana
Kibana интегрируется с Elasticsearch и использует данные из индексов мониторинга (`.monitoring-*`) для построения графиков и дашбордов.

- **Настройка мониторинга в Kibana**:
    1. Убедись, что модуль мониторинга включён в `elasticsearch.yml`:
       ```yaml
       xpack.monitoring.enabled: true
       xpack.monitoring.collection.enabled: true
       ```
    2. В `kibana.yml` включи доступ к мониторингу:
       ```yaml
       xpack.monitoring.ui.enabled: true
       ```
    3. Перезапусти Elasticsearch и Kibana.

- **Основные дашборды в Kibana**:
    - **Overview**: Общее состояние кластера (статус, количество узлов, индексов, шардов).
    - **Nodes**: Метрики по узлам (CPU, память, I/O, JVM heap).
    - **Indices**: Информация об индексах (размер, количество документов, производительность запросов).
    - **Search and Indexing Performance**: Задержки поиска и индексации.

- **Пример использования**:
    1. Открой Kibana → **Stack Monitoring** (в меню слева).
    2. Выбери дашборд **Elasticsearch Overview**:
        - Проверяй **Cluster Status** (green/yellow/red).
        - Анализируй **Search Rate** (количество поисковых запросов в секунду).
        - Следи за **Indexing Rate** (скорость добавления документов).
    3. Перейди в **Nodes** для анализа нагрузки на конкретные узлы (CPU, память, диск).

- **Создание кастомных дашбордов**:
    - Используй **Lens** или **TSVB** (Time Series Visual Builder) для построения графиков на основе метрик.
    - Пример: Создай график для мониторинга задержек поиска:
        1. В Kibana выбери **Visualize** → **Create Visualization** → **Lens**.
        2. Выбери индекс `.monitoring-es-*`.
        3. Добавь метрику `search.query_total` (общее количество поисков) или `search.query_time` (время выполнения).

#### b) Другие инструменты
- **Prometheus + Grafana**:
    - Prometheus собирает метрики через экспортёр (например, `elasticsearch_exporter`).
    - Grafana визуализирует данные в кастомных дашбордах.
    - Установка:
        1. Установи `elasticsearch_exporter`:
           ```bash
           docker run --rm -p 9114:9114 quay.io/prometheuscommunity/elasticsearch-exporter
           ```
        2. Настрой Prometheus для сбора метрик:
           ```yaml
           scrape_configs:
             - job_name: 'elasticsearch'
               static_configs:
                 - targets: ['localhost:9114']
           ```
        3. В Grafana импортируй дашборд для Elasticsearch (например, ID 2322).
    - Преимущества: Гибкость, интеграция с другими системами, долгосрочное хранение метрик.

- **Elastic Stack Monitoring API**:
    - Получай метрики напрямую через API:
      ```bash
      GET /_cluster/health
      GET /_cat/nodes?v&h=name,load_1m,heap.percent,disk.used_percent
      GET /_stats?human
      ```
    - Используй для скриптов автоматизации или интеграции с внешними системами.

- **Другие инструменты**:
    - **Cerebro**: Лёгкий интерфейс для мониторинга узлов и шардов.
    - **ElasticHQ**: Веб-интерфейс для управления и мониторинга кластера.

#### Лучшие практики
- Настрой **Stack Monitoring** в Kibana для быстрого старта.
- Используй Prometheus + Grafana для сложных сценариев или интеграции с другими системами.
- Настрой алерты в Kibana (через **Alerting**) или Grafana для уведомлений о проблемах (например, красный статус кластера).
- Храни метрики мониторинга в отдельном кластере, чтобы не нагружать основной:
  ```yaml
  xpack.monitoring.elasticsearch.url: "http://monitoring-cluster:9200"
  ```


### Анализ метрик (CPU, память, I/O, поисковые задержки)

Для эффективного мониторинга нужно следить за ключевыми метриками, которые влияют на производительность кластера. Вот основные метрики и их интерпретация.

#### a) CPU
- **Что измеряет?** Загрузка процессора на узлах кластера.
- **Как мониторить?**
    - В Kibana: Дашборд **Nodes** → **CPU Usage**.
    - Через API:
      ```bash
      GET /_cat/nodes?v&h=name,load_1m,load_5m,load_15m
      ```
        - `load_1m`, `load_5m`, `load_15m`: Средняя загрузка за 1, 5 и 15 минут.
    - В Prometheus: Метрика `node_cpu_seconds_total`.
- **Норма**:
    - Загрузка CPU < 70–80% в среднем.
    - Пиковые нагрузки до 90% допустимы, но не постоянно.
- **Проблемы и решения**:
    - Высокая загрузка CPU:
        - Проверь запросы с помощью `_profile`:
          ```bash
          POST /pets/_search
          {
            "profile": true,
            "query": { "match": { "name": "кот" } }
          }
          ```
        - Оптимизируй запросы: используй фильтры вместо `match`, избегай `wildcard`/`regexp`.
        - Уменьши количество сегментов с помощью `_forcemerge`:
          ```bash
          POST /pets/_forcemerge?max_num_segments=1
          ```
        - Добавь узлы в кластер для распределения нагрузки.

#### b) Память (JVM Heap)
- **Что измеряет?** Использование кучи JVM (heap) на узлах, где хранятся кэши, метаданные и временные структуры.
- **Как мониторить?**
    - В Kibana: Дашборд **Nodes** → **JVM Heap Usage**.
    - Через API:
      ```bash
      GET /_cat/nodes?v&h=name,heap.percent,heap.max
      ```
        - `heap.percent`: Процент занятой кучи.
        - `heap.max`: Максимальный размер кучи.
    - В Prometheus: Метрика `jvm_memory_bytes_used`.
- **Норма**:
    - Использование кучи < 75%.
    - Частые сборки мусора (GC) указывают на нехватку памяти.
- **Проблемы и решения**:
    - Высокое использование кучи:
        - Увеличь размер кучи в `jvm.options` (до 50% RAM узла, но не более 31 ГБ):
          ```bash
          -Xms16g
          -Xmx16g
          ```
        - Уменьши кэши (query cache, fielddata):
          ```bash
          PUT /_cluster/settings
          {
            "transient": {
              "indices.queries.cache.size": "1%",
              "indices.fielddata.cache.size": "10%"
            }
          }
          ```
        - Используй поля `keyword` вместо `text` для агрегаций, чтобы снизить использование fielddata.
        - Проверь частоту GC:
          ```bash
          GET /_nodes/stats/jvm?human
          ```

#### c) I/O (дисковые операции)
- **Что измеряет?** Скорость чтения/записи на диск (важно для индексации и поиска).
- **Как мониторить?**
    - В Kibana: Дашборд **Nodes** → **Disk I/O**.
    - Через API:
      ```bash
      GET /_cat/nodes?v&h=name,disk.used_percent,disk.io.read_bytes,disk.io.write_bytes
      ```
        - `disk.used_percent`: Процент занятого диска.
        - `disk.io.read_bytes`, `disk.io.write_bytes`: Объём операций чтения/записи.
    - В Prometheus: Метрики `node_disk_read_bytes_total`, `node_disk_write_bytes_total`.
- **Норма**:
    - Диск заполнен < 85% (чтобы избежать отказов).
    - I/O не должен быть узким местом (зависит от типа диска: SSD быстрее HDD).
- **Проблемы и решения**:
    - Высокая нагрузка на I/O:
        - Увеличь `refresh_interval` для снижения частоты записи:
          ```bash
          PUT /pets/_settings
          {
            "refresh_interval": "30s"
          }
          ```
        - Выполни `_forcemerge` для уменьшения числа сегментов:
          ```bash
          POST /pets/_forcemerge?max_num_segments=1
          ```
        - Используй SSD вместо HDD для лучшей производительности.
    - Нехватка места:
        - Удали старые индексы:
          ```bash
          DELETE /old_index
          ```
        - Перемести индексы на узлы с большим объёмом диска:
          ```bash
          POST /_cluster/reroute
          {
            "commands": [
              {
                "move": {
                  "index": "pets",
                  "shard": 0,
                  "from_node": "node1",
                  "to_node": "node2"
                }
              }
            ]
          }
          ```

#### d) Поисковые задержки
- **Что измеряет?** Время выполнения поисковых запросов и агрегаций.
- **Как мониторить?**
    - В Kibana: Дашборд **Search and Indexing Performance** → **Search Latency**.
    - Через API:
      ```bash
      GET /_stats/search?human
      ```
        - `query_total`: Общее количество запросов.
        - `query_time_in_millis`: Общее время выполнения.
        - Средняя задержка = `query_time_in_millis / query_total`.
    - В Prometheus: Метрика `elasticsearch_indices_search_query_time_seconds`.
- **Норма**:
    - Задержки поиска < 100–500 мс для большинства запросов.
    - Зависит от размера индекса и сложности запросов.
- **Проблемы и решения**:
    - Высокие задержки:
        - Оптимизируй запросы: используй `filter` вместо `match`, избегай `wildcard`/`regexp`:
          ```bash
          POST /pets/_search
          {
            "query": {
              "bool": {
                "filter": [
                  { "term": { "type": "cat" } }
                ]
              }
            }
          }
          ```
        - Увеличь количество реплик для распределения нагрузки:
          ```bash
          PUT /pets/_settings
          {
            "number_of_replicas": 2
          }
          ```
        - Профилируй запросы с `_profile`:
          ```bash
          POST /pets/_search
          {
            "profile": true,
            "query": { "match": { "name": "кот" } }
          }
          ```
        - Уменьши количество сегментов с помощью `_forcemerge`.
    
### Итог
- **Мониторинг с Kibana**:
    - Используй **Stack Monitoring** для дашбордов (Overview, Nodes, Indices).
    - Создавай кастомные визуализации с **Lens** или **TSVB**.
    - Настрой алерты для критических метрик.
- **Другие инструменты**:
    - Prometheus + Grafana для гибкости и интеграции.
    - Cerebro или ElasticHQ для простого мониторинга.
- **Анализ метрик**:
    - **CPU**: < 70–80%, оптимизируй запросы или добавь узлы.
    - **Память**: Heap < 75%, используй `keyword` вместо `text`.
    - **I/O**: Диск < 85%, увеличивай `refresh_interval` или используй SSD.
    - **Поисковые задержки**: < 500 мс, профилируй с `_profile` и оптимизируй фильтры.
      Эти подходы помогут поддерживать кластер в здоровом состоянии и быстро реагировать на проблемы!
      

## 17 Экосистема Elastic Stack
**Elastic Stack** — это мощная экосистема инструментов, центром которой является **Elasticsearch**, дополненная **Kibana**, **Logstash**, **Beats**, **Elastic APM** и возможностями **Machine Learning**. Эти компоненты позволяют собирать, хранить, анализировать и визуализировать данные, а также мониторить производительность приложений и выявлять аномалии. 

### Kibana: Инструмент для визуализации данных и управления Elasticsearch

**Kibana** — это веб-интерфейс для работы с Elasticsearch, который предоставляет инструменты для визуализации данных, создания дашбордов, выполнения поисковых запросов и мониторинга кластера.

#### a) Создание дашбордов, визуализаций и поисковых запросов
- **Визуализации**:
    - Kibana поддерживает графики, таблицы, карты и другие типы визуализаций через инструменты **Lens**, **TSVB** (Time Series Visual Builder) и **Vega**.
    - Пример: Создание графика количества поисковых запросов по времени:
        1. В Kibana → **Visualize** → **Create Visualization** → **Lens**.
        2. Выбери индекс `.monitoring-es-*`.
        3. Настрой метрику `Count` по полю `search.query_total` и разбивку по времени (`@timestamp`).
        4. Сохрани визуализацию как "Search Rate".

- **Дашборды**:
    - Дашборды объединяют несколько визуализаций для комплексного мониторинга.
    - Пример: Создание дашборда для мониторинга Elasticsearch:
        1. В Kibana → **Dashboard** → **Create Dashboard**.
        2. Добавь визуализации: "Search Rate", "CPU Usage", "Heap Usage".
        3. Настрой фильтры (например, по узлу или индексу) и сохрани дашборд.

- **Поисковые запросы**:
    - Используй **Discover** для интерактивного поиска по данным.
    - Пример: Найти все документы в индексе `pets`, где `type: "cat"`:
        1. В Kibana → **Discover**.
        2. Выбери индекс `pets`.
        3. Введи запрос `type:cat` в строку поиска.
        4. Сохрани запрос для использования в дашбордах.

#### b) Использование Dev Tools для тестирования запросов
- **Dev Tools** — это консоль в Kibana для отправки запросов к Elasticsearch API.
- Пример: Тестирование запроса для поиска котов старше 2 лет:
  ```bash
  POST /pets/_search
  {
    "query": {
      "bool": {
        "filter": [
          { "term": { "type": "cat" } },
          { "range": { "age": { "gte": 2 } } }
        ]
      }
    }
  }
  ```
- **Автодополнение**: Dev Tools поддерживает автодополнение для синтаксиса Query DSL.
- **Массовая отправка**: Можно выполнять несколько запросов подряд:
  ```bash
  GET /_cat/indices?v
  GET /pets/_mapping
  ```

- **Лучшие практики**:
    - Тестируй сложные запросы в Dev Tools перед внедрением в код.
    - Используй `_explain` для анализа, почему документ попал в выборку:
      ```bash
      GET /pets/_explain/1
      {
        "query": { "match": { "name": "кот" } }
      }
      ```
    - Сохраняй часто используемые запросы в **Console Snippets** для повторного использования.

#### Лучшие практики для Kibana
- Используй **Lens** для быстрого создания визуализаций, **Vega** — для сложных кастомных графиков.
- Настрой **алерты** в Kibana для уведомлений о проблемах (например, CPU > 80%):
  ```bash
  Kibana → Alerting → Create Rule → Metric Threshold
  ```
- Ограничивай доступ через **Spaces** и **Roles** для защиты данных:
  ```bash
  Kibana → Management → Security → Roles
  ```
- Храни метрики мониторинга в отдельном кластере для снижения нагрузки.

### Logstash и Beats: Сбор, обработка и отправка данных в Elasticsearch

**Logstash** и **Beats** — это инструменты для сбора, обработки и передачи данных в Elasticsearch. Они используются для работы с логами, метриками, событиями и другими типами данных.

#### a) Logstash
- **Что это?** ETL-инструмент (Extract, Transform, Load) для обработки данных из различных источников (логи, базы данных, Kafka) и отправки в Elasticsearch или другие системы.
- **Компоненты**:
    - **Input**: Источник данных (файлы, HTTP, Kafka).
    - **Filter**: Обработка данных (парсинг, преобразование, обогащение).
    - **Output**: Назначение (Elasticsearch, файл, stdout).

- **Пример конфигурации**:
    - Обработка логов приложения и отправка в Elasticsearch:
      ```logstash
      input {
        file {
          path => "/var/log/app.log"
          start_position => "beginning"
        }
      }
      filter {
        grok {
          match => { "message": "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:loglevel} %{GREEDYDATA:msg}" }
        }
        date {
          match => ["timestamp", "ISO8601"]
        }
      }
      output {
        elasticsearch {
          hosts => ["http://localhost:9200"]
          index => "app-logs-%{+YYYY.MM.dd}"
        }
        stdout { codec => rubydebug }
      }
      ```
    - **Объяснение**:
        - `input`: Читает логи из файла `/var/log/app.log`.
        - `filter`: Парсит логи с помощью `grok` (разбивает на поля `timestamp`, `loglevel`, `msg`) и преобразует `timestamp` в дату.
        - `output`: Отправляет данные в индекс `app-logs-YYYY.MM.dd` и выводит в консоль.

- **Запуск Logstash**:
  ```bash
  bin/logstash -f config/app-logstash.conf
  ```

#### b) Beats
- **Что это?** Лёгкие агенты для сбора данных (логи, метрики, сетевой трафик) и отправки в Elasticsearch или Logstash.
- **Основные модули**:
    - **Filebeat**: Сбор логов из файлов.
    - **Metricbeat**: Сбор системных метрик (CPU, память, диски).
    - **Packetbeat**: Анализ сетевого трафика.
    - **Winlogbeat**: Сбор событий Windows.
    - **Auditbeat**: Мониторинг аудита и безопасности.

- **Пример: Настройка Filebeat для логов**:
    1. Установи Filebeat и настрой `filebeat.yml`:
       ```yaml
       filebeat.inputs:
       - type: log
         paths:
           - /var/log/app.log
       output.elasticsearch:
         hosts: ["http://localhost:9200"]
         index: "app-logs-%{+YYYY.MM.dd}"
       ```
    2. Запусти Filebeat:
       ```bash
       ./filebeat -e
       ```
    - **Эффект**: Filebeat отправляет логи в Elasticsearch, создавая индексы `app-logs-2025.07.10`.

- **Пример: Metricbeat для системных метрик**:
  ```yaml
  metricbeat.modules:
  - module: system
    metricsets: ["cpu", "memory", "diskio"]
    period: 10s
  output.elasticsearch:
    hosts: ["http://localhost:9200"]
    index: "metricbeat-%{+YYYY.MM.dd}"
  ```
    - Запусти:
      ```bash
      ./metricbeat -e
      ```
    - В Kibana создай дашборд для визуализации CPU и памяти.

#### Logstash vs Beats
- **Logstash**: Для сложной обработки данных (парсинг, обогащение, агрегация). Более тяжёлый, требует больше ресурсов.
- **Beats**: Лёгкие агенты для прямого сбора данных. Меньше возможностей обработки, но проще в настройке.
- **Комбинированный подход**:
    - Beats → Logstash → Elasticsearch:
      ```yaml
      # filebeat.yml
      output.logstash:
        hosts: ["localhost:5044"]
      ```
      ```logstash
      # logstash.conf
      input {
        beats { port => 5044 }
      }
      output {
        elasticsearch { hosts => ["http://localhost:9200"] }
      }
      ```

#### Лучшие практики
- Используй **Beats** для лёгкого сбора данных, **Logstash** — для сложной обработки.
- Настрой **индексы с временными метками** (`index: "logs-%{+YYYY.MM.dd}"`) для упрощения управления данными.
- Включи **ILM (Index Lifecycle Management)** для автоматического удаления старых индексов:
  ```bash
  PUT /_ilm/policy/logs_policy
  {
    "policy": {
      "phases": {
        "delete": {
          "min_age": "30d",
          "actions": {
            "delete": {}
          }
        }
      }
    }
  }
  ```
- Тестируй конфигурации Logstash с помощью `bin/logstash -f config.conf --config.test_and_exit`.

### 3. Elastic APM: Мониторинг производительности приложений

**Elastic APM** (Application Performance Monitoring) — это инструмент для мониторинга производительности приложений, отслеживания запросов, ошибок и задержек. Он интегрируется с приложениями через агентов и отправляет данные в Elasticsearch.

#### Как работает?
- **APM-агенты**: Библиотеки для популярных языков (Java, Python, Node.js, Go, .NET и др.), которые собирают метрики (время запросов, ошибки, транзакции).
- **APM-сервер**: Принимает данные от агентов и отправляет их в Elasticsearch.
- **Kibana**: Визуализирует метрики через дашборд APM.

#### Настройка Elastic APM
1. **Установи APM-сервер**:
    - Скачай и настрой `apm-server.yml`:
      ```yaml
      apm-server.host: "0.0.0.0:8200"
      output.elasticsearch:
        hosts: ["http://localhost:9200"]
      ```
    - Запусти:
      ```bash
      ./apm-server -e
      ```

2. **Добавь агента в приложение** (пример для Python/Flask):
    - Установи библиотеку:
      ```bash
      pip install elastic-apm[flask]
      ```
    - Настрой приложение:
      ```python
      from flask import Flask
      from elastic_apm.contrib.flask import ElasticAPM
      app = Flask(__name__)
      apm = ElasticAPM(app, server_url='http://localhost:8200', service_name='my-flask-app')
      ```
    - Запусти приложение, и данные начнут поступать в APM.

3. **Визуализация в Kibana**:
    - В Kibana → **APM**:
        - Просматривай **Services** (список приложений).
        - Анализируй **Transactions** (время выполнения запросов).
        - Отслеживай **Errors** (логи ошибок).
    - Пример: График задержек запросов к `/api/users`.

#### Пример метрик
- **Транзакции**: Время выполнения HTTP-запроса `/api/users` (200 мс).
- **Ошибки**: Стек вызовов для исключения `NullPointerException`.
- **Зависимости**: Задержки при вызове внешнего сервиса (например, базы данных).

#### Лучшие практики
- Используй APM для критических приложений, чтобы отслеживать узкие места.
- Настрой **алерты** в Kibana для уведомлений о высоких задержках или частых ошибках.
- Минимизируй объём собираемых данных, чтобы снизить нагрузку:
  ```yaml
  apm-server:
    transaction_sample_rate: 0.1 # 10% транзакций
  ```
- Интегрируй с **Distributed Tracing** для анализа цепочек вызовов в микросервисах.

### Machine Learning: Анализ аномалий и прогнозирование

**Machine Learning** (ML) в Elastic Stack — это встроенные алгоритмы для анализа данных, выявления аномалий, прогнозирования и классификации. Требуется лицензия Platinum или выше (или пробная версия).

#### Основные возможности
- **Анализ аномалий**: Обнаружение необычного поведения (например, всплесков запросов или ошибок).
- **Прогнозирование**: Предсказание временных рядов (например, будущей нагрузки на сервер).
- **Классификация и регрессия**: Для задач, таких как определение спама или прогнозирование значений.

#### Настройка ML
1. **Включение ML**:
    - Убедись, что ML включён в `elasticsearch.yml`:
      ```yaml
      xpack.ml.enabled: true
      ```
    - Перезапусти кластер.

2. **Создание ML-задания** (пример: анализ аномалий в логах):
    - В Kibana → **Machine Learning** → **Anomaly Detection** → **Create Job**.
    - Выбери индекс `app-logs-*`.
    - Настрой:
        - Детектор: `count` (подсчёт событий).
        - Временной интервал: `15m` (анализ каждые 15 минут).
        - Поле влияния: `loglevel` (группировка по уровню логов).
    - Запусти задание и просмотри результаты в **Anomaly Explorer**.

3. **Пример: Обнаружение аномалий**:
    - Допустим, в логах обычно 100 событий в час, но вдруг их стало 1000.
    - ML выдаст аномалию с высоким **anomaly score** (0–100).
    - В Kibana → **Anomaly Explorer**:
        - Увидишь всплеск на графике.
        - Поле `loglevel: ERROR` покажет, что аномалия связана с ошибками.

4. **Прогнозирование**:
    - Пример: Прогноз поисковых запросов на основе исторических данных.
    - В Kibana → **Machine Learning** → **Data Frame Analytics** → **Create Job** → **Regression**.
    - Выбери индекс `.monitoring-es-*`, поле `search.query_total` для прогнозирования.
    - Результат: Прогноз на следующие 24 часа.

#### Пример ML-запроса через API
- Создание задания для аномалий:
  ```bash
  PUT /_ml/anomaly_detectors/log_anomalies
  {
    "analysis_config": {
      "bucket_span": "15m",
      "detectors": [
        {
          "function": "count",
          "by_field_name": "loglevel"
        }
      ]
    },
    "data_description": { "time_field": "@timestamp" }
  }
  ```
- Запуск задания:
  ```bash
  POST /_ml/anomaly_detectors/log_anomalies/_open
  ```

#### Лучшие практики
- Используй ML для анализа временных рядов (логи, метрики, APM-данные).
- Настрой **bucket_span** в зависимости от данных (например, `15m` для логов, `1h` для метрик).
- Ограничивай количество детекторов и полей влияния для снижения нагрузки.
- Интегрируй ML с **Alerting** для уведомлений об аномалиях:
  ```bash
  Kibana → Alerting → Create Rule → Anomaly Detection
  ```
- Тестируй ML на исторических данных перед продакшеном.


### Итог
- **Kibana**:
    - Создавай визуализации с **Lens** и дашборды для мониторинга.
    - Используй **Dev Tools** для тестирования запросов и **Discover** для поиска.
- **Logstash и Beats**:
    - **Beats** (Filebeat, Metricbeat) для лёгкого сбора данных.
    - **Logstash** для сложной обработки (парсинг, обогащение).
    - Комбинируй для гибкости.
- **Elastic APM**:
    - Мониторинг транзакций, ошибок и задержек приложений.
    - Интегрируй с Kibana для визуализации и алертов.
- **Machine Learning**:
    - Анализ аномалий и прогнозирование временных рядов.
    - Используй для логов, метрик и APM-данных.
      Эти компоненты делают Elastic Stack универсальным решением для логирования, мониторинга, аналитики и визуализации данных!
      
### 18 Практическое использование
Практическое использование **Elastic Stack** охватывает широкий спектр сценариев, от анализа логов до поиска по сайту и аналитики больших данных. Кроме того, Elasticsearch легко интегрируется с клиентскими библиотеками и другими системами, а тестирование маппингов, запросов и производительности позволяет обеспечить стабильность и оптимизацию. Давайте разберём каждый аспект максимально просто и понятно, с примерами и лучшими практиками.

---

### 1. Реальные сценарии использования Elastic Stack

Elastic Stack (Elasticsearch, Kibana, Logstash, Beats) применяется в различных областях. Рассмотрим три ключевых сценария: анализ логов, поиск по сайту и аналитика больших данных.

#### a) Логи: Анализ логов с помощью ELK Stack
**ELK Stack** (Elasticsearch, Logstash, Kibana) идеально подходит для централизованного сбора, обработки и анализа логов.

- **Сценарий**: Мониторинг логов веб-приложения для выявления ошибок и анализа поведения пользователей.
- **Процесс**:
    1. **Сбор логов**:
        - Используй **Filebeat** для чтения логов из файла `/var/log/app.log`:
          ```yaml
          # filebeat.yml
          filebeat.inputs:
          - type: log
            paths:
              - /var/log/app.log
          output.logstash:
            hosts: ["localhost:5044"]
          ```
    2. **Обработка логов**:
        - Настрой **Logstash** для парсинга логов и отправки в Elasticsearch:
          ```logstash
          # app-logstash.conf
          input {
            beats { port => 5044 }
          }
          filter {
            grok {
              match => { "message": "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:loglevel} %{GREEDYDATA:msg}" }
            }
            date {
              match => ["timestamp", "ISO8601"]
            }
          }
          output {
            elasticsearch {
              hosts => ["http://localhost:9200"]
              index => "app-logs-%{+YYYY.MM.dd}"
            }
          }
          ```
    3. **Визуализация в Kibana**:
        - В Kibana → **Discover** настрой индекс `app-logs-*`.
        - Создай визуализацию (например, гистограмму ошибок по времени):
            - В **Lens** выбери метрику `Count` и поле `loglevel:ERROR`.
        - Создай дашборд с графиками: количество ошибок, предупреждений и успешных операций.
    4. **Анализ аномалий**:
        - Используй **Machine Learning** в Kibana для выявления всплесков ошибок:
          ```bash
          PUT /_ml/anomaly_detectors/log_anomalies
          {
            "analysis_config": {
              "bucket_span": "15m",
              "detectors": [{ "function": "count", "by_field_name": "loglevel" }]
            },
            "data_description": { "time_field": "@timestamp" }
          }
          ```

- **Результат**:
    - Логи хранятся в индексах `app-logs-2025.07.10`.
    - Дашборд показывает тренды ошибок и предупреждений.
    - ML уведомляет о всплесках ошибок через алерты в Kibana.

- **Лучшие практики**:
    - Используй **ILM (Index Lifecycle Management)** для автоматического удаления старых логов:
      ```bash
      PUT /_ilm/policy/logs_policy
      {
        "policy": {
          "phases": {
            "hot": { "actions": { "rollover": { "max_age": "7d" } } },
            "delete": { "min_age": "30d", "actions": { "delete": {} } }
          }
        }
      }
      ```
    - Настрой алерты для критических событий (например, `loglevel:ERROR`).

#### b) Поиск по сайту (e-commerce, контентные платформы)
- **Сценарий**: Реализация поиска товаров в интернет-магазине или статей на контентной платформе.
- **Процесс**:
    1. **Создание индекса**:
       ```bash
       PUT /products
       {
         "settings": {
           "analysis": {
             "analyzer": {
               "autocomplete": {
                 "tokenizer": "standard",
                 "filter": ["lowercase", "edge_ngram"]
               }
             },
             "filter": {
               "edge_ngram": { "type": "edge_ngram", "min_gram": 2, "max_gram": 20 }
             }
           }
         },
         "mappings": {
           "properties": {
             "name": {
               "type": "text",
               "analyzer": "autocomplete",
               "search_analyzer": "standard"
             },
             "category": { "type": "keyword" },
             "price": { "type": "float" }
           }
         }
       }
       ```
    2. **Индексация данных**:
       ```bash
       POST /products/_doc/1
       {
         "name": "Смартфон Samsung Galaxy",
         "category": "electronics",
         "price": 599.99
       }
       ```
    3. **Поисковый запрос**:
        - Автодополнение для "sam":
          ```bash
          POST /products/_search
          {
            "query": {
              "match": { "name": "sam" }
            }
          }
          ```
        - Фильтрация по категории и цене:
          ```bash
          POST /products/_search
          {
            "query": {
              "bool": {
                "filter": [
                  { "term": { "category": "electronics" } },
                  { "range": { "price": { "lte": 1000 } } }
                ],
                "must": [
                  { "match": { "name": "samsung" } }
                ]
              }
            }
          }
          ```
    4. **Визуализация в Kibana**:
        - Создай дашборд для анализа популярных запросов:
            - В **Lens** визуализируй `terms` по полю `search.query`.

- **Результат**:
    - Быстрый поиск с автодополнением ("sam" → "Samsung").
    - Фильтрация по категориям и ценам.
    - Дашборд показывает популярные категории и ценовые диапазоны.

- **Лучшие практики**:
    - Используй **edge_ngram** для автодополнения.
    - Настрой **boosting** для повышения релевантности:
      ```bash
      POST /products/_search
      {
        "query": {
          "multi_match": {
            "query": "samsung",
            "fields": ["name^2", "description"]
          }
        }
      }
      ```
    - Оптимизируй производительность с помощью фильтров в `bool`.

#### c) Аналитика больших данных (агрегации, временные ряды)
- **Сценарий**: Анализ метрик сервера (CPU, память) или пользовательской активности для выявления трендов.
- **Процесс**:
    1. **Сбор данных с Metricbeat**:
       ```yaml
       # metricbeat.yml
       metricbeat.modules:
       - module: system
         metricsets: ["cpu", "memory"]
         period: 10s
       output.elasticsearch:
         hosts: ["http://localhost:9200"]
         index: "metricbeat-%{+YYYY.MM.dd}"
       ```
    2. **Агрегации для анализа**:
        - Подсчёт средней загрузки CPU по узлам:
          ```bash
          POST /metricbeat-*/_search
          {
            "query": { "match_all": {} },
            "aggs": {
              "by_node": {
                "terms": { "field": "host.name" },
                "aggs": {
                  "avg_cpu": { "avg": { "field": "system.cpu.total.norm.pct" } }
                }
              }
            }
          }
          ```
    3. **Визуализация временных рядов**:
        - В Kibana → **Lens** создай график CPU по времени:
            - Метрика: `Average` по `system.cpu.total.norm.pct`.
            - Ось X: `@timestamp` (временной интервал).
    4. **Прогнозирование с ML**:
        - Создай ML-задание для прогнозирования CPU:
          ```bash
          PUT /_ml/anomaly_detectors/cpu_forecast
          {
            "analysis_config": {
              "bucket_span": "1h",
              "detectors": [{ "function": "metric", "field_name": "system.cpu.total.norm.pct" }]
            },
            "data_description": { "time_field": "@timestamp" }
          }
          ```

- **Результат**:
    - Данные метрик хранятся в `metricbeat-2025.07.10`.
    - Дашборд показывает тренды CPU и памяти.
    - ML прогнозирует нагрузку и выявляет аномалии.

- **Лучшие практики**:
    - Используй **date_histogram** для временных рядов:
      ```bash
      POST /metricbeat-*/_search
      {
        "aggs": {
          "by_time": {
            "date_histogram": {
              "field": "@timestamp",
              "fixed_interval": "1h"
            },
            "aggs": {
              "avg_cpu": { "avg": { "field": "system.cpu.total.norm.pct" } }
            }
          }
        }
      }
      ```
    - Ограничивай количество бакетов в агрегациях (`size: 10` для `terms`).
    - Настрой ILM для ротации индексов.

    
### Итог
- **Реальные сценарии**:
    - **Логи**: Используй ELK Stack (Filebeat + Logstash + Elasticsearch + Kibana) для анализа логов, с ILM и ML для аномалий.
    - **Поиск по сайту**: Настрой автодополнение с `edge_ngram` и фильтры для e-commerce или контентных платформ.
    - **Аналитика больших данных**: Используй агрегации и временные ряды для метрик, с ML для прогнозирования.

## 19 Отказоустойчивость и масштабирование

Отказоустойчивость и масштабирование в **Elasticsearch** — ключевые аспекты для обеспечения надежности и производительности кластера при росте данных или нагрузки. Это включает настройку резервного копирования через **Snapshot API**, горизонтальное и вертикальное масштабирование, а также управление сбоями с помощью автоматического восстановления шардов и реплик. 

### Резервное копирование и восстановление: Настройка снапшотов и восстановления через Snapshot API

**Snapshot API** позволяет создавать резервные копии индексов (снапшоты) и восстанавливать их в случае сбоев, потери данных или миграции кластера. Снапшоты хранятся во внешнем репозитории (например, S3, HDFS, локальный диск).

#### a) Настройка репозитория для снапшотов
- **Шаг 1: Настройка репозитория**:
    - Пример для локального диска:
      ```bash
      PUT /_snapshot/my_backup
      {
        "type": "fs",
        "settings": {
          "location": "/mnt/backups",
          "compress": true
        }
      }
      ```
    - Для S3 (требуется плагин `repository-s3`):
      ```bash
      PUT /_snapshot/my_s3_backup
      {
        "type": "s3",
        "settings": {
          "bucket": "my-elasticsearch-backups",
          "region": "us-east-1",
          "access_key": "your_access_key",
          "secret_key": "your_secret_key"
        }
      }
      ```
    - **Примечание**: Убедись, что путь `/mnt/backups` доступен всем узлам и имеет права на запись.

- **Шаг 2: Проверка репозитория**:
  ```bash
  GET /_snapshot/my_backup
  ```

#### b) Создание снапшота
- Создай снапшот всех индексов:
  ```bash
  PUT /_snapshot/my_backup/snapshot_2025_07_10
  {
    "indices": "*",
    "ignore_unavailable": true,
    "include_global_state": false
  }
  ```
- Создай снапшот конкретного индекса (`pets`):
  ```bash
  PUT /_snapshot/my_backup/pets_snapshot
  {
    "indices": "pets",
    "ignore_unavailable": true
  }
  ```

- **Асинхронное создание**:
    - Добавь `wait_for_completion=false` для фонового выполнения:
      ```bash
      PUT /_snapshot/my_backup/snapshot_2025_07_10?wait_for_completion=false
      ```

- **Проверка статуса снапшота**:
  ```bash
  GET /_snapshot/my_backup/snapshot_2025_07_10/_status
  ```

#### c) Восстановление из снапшота
- Восстанови индекс `pets`:
  ```bash
  POST /_snapshot/my_backup/pets_snapshot/_restore
  {
    "indices": "pets",
    "rename_pattern": "pets",
    "rename_replacement": "restored_pets"
  }
  ```
- **Примечание**: Индекс должен быть закрыт или удалён перед восстановлением:
  ```bash
  POST /pets/_close
  ```

- **Восстановление всех индексов**:
  ```bash
  POST /_snapshot/my_backup/snapshot_2025_07_10/_restore
  ```

#### d) Автоматизация снапшотов
- Используй **Snapshot Lifecycle Management (SLM)** для автоматического создания снапшотов:
  ```bash
  PUT /_slm/policy/daily-snapshot
  {
    "schedule": "0 0 0 * * ?", // Ежедневно в 00:00
    "name": "<daily-snap-{now/d}>",
    "repository": "my_backup",
    "config": {
      "indices": ["pets", "app-logs-*"],
      "include_global_state": false
    },
    "retention": {
      "expire_after": "30d", // Удалять снапшоты старше 30 дней
      "min_count": 5,
      "max_count": 50
    }
  }
  ```

- **Проверка SLM**:
  ```bash
  GET /_slm/policy/daily-snapshot
  ```

#### Лучшие практики
- Храни снапшоты во **внешнем репозитории** (S3, GCS) для защиты от сбоев кластера.
- Настрой **SLM** для автоматического создания и удаления снапшотов.
- Регулярно тестируй восстановление:
  ```bash
  POST /_snapshot/my_backup/snapshot_2025_07_10/_restore
  {
    "indices": "pets",
    "rename_pattern": "pets",
    "rename_replacement": "test_restore_pets"
  }
  ```
- Убедись, что репозиторий доступен всем узлам и защищён (например, шифрование в S3).
- Используй `include_global_state: false`, если не нужно сохранять глобальные метаданные (например, шаблоны).


### Масштабирование

**Масштабирование** Elasticsearch позволяет справляться с увеличением объёма данных и нагрузки. Оно бывает **горизонтальным** (добавление узлов) и **вертикальным** (увеличение ресурсов узлов).

#### a) Горизонтальное масштабирование (добавление узлов)
- **Что это?** Добавление новых узлов в кластер для распределения данных и нагрузки.
- **Процесс**:
    1. **Добавь новый узел**:
        - Установи Elasticsearch на новом сервере.
        - Настрой `elasticsearch.yml`:
          ```yaml
          cluster.name: my-cluster
          node.name: node-3
          discovery.seed_hosts: ["node1:9300", "node2:9300"]
          cluster.initial_master_nodes: ["node1", "node2"]
          ```
        - Запусти узел:
          ```bash
          ./bin/elasticsearch
          ```
    2. **Проверь состояние кластера**:
       ```bash
       GET /_cat/nodes?v&h=name,role
       ```
        - Убедись, что новый узел появился (роль `data` или другая).
    3. **Перераспредели шарды**:
        - Elasticsearch автоматически балансирует шарды, но можно управлять вручную:
          ```bash
          POST /_cluster/reroute
          {
            "commands": [
              {
                "move": {
                  "index": "pets",
                  "shard": 0,
                  "from_node": "node1",
                  "to_node": "node3"
                }
              }
            ]
          }
          ```
    4. **Увеличь реплики для распределения нагрузки**:
       ```bash
       PUT /pets/_settings
       {
         "number_of_replicas": 2
       }
       ```

- **Преимущества**:
    - Увеличивает пропускную способность для поиска и индексации.
    - Повышает отказоустойчивость за счёт распределения данных.

- **Лучшие практики**:
    - Убедись, что у новых узлов достаточно ресурсов (CPU, RAM, диск).
    - Настрой **дисковые пороги** для предотвращения переполнения:
      ```bash
      PUT /_cluster/settings
      {
        "transient": {
          "cluster.routing.allocation.disk.watermark.low": "85%",
          "cluster.routing.allocation.disk.watermark.high": "90%"
        }
      }
      ```
    - Используй **роли узлов** (data, master, ingest) для оптимизации:
      ```yaml
      node.roles: ["data"]
      ```

#### b) Вертикальное масштабирование (увеличение ресурсов узлов)
- **Что это?** Увеличение CPU, RAM или дискового пространства на существующих узлах.
- **Процесс**:
    1. **Увеличь ресурсы**:
        - Добавь CPU/RAM на сервере (например, увеличь с 4 до 8 CPU, с 16 до 32 ГБ RAM).
        - Настрой JVM heap в `jvm.options` (до 50% RAM, но не более 31 ГБ):
          ```bash
          -Xms16g
          -Xmx16g
          ```
    2. **Перезапусти узел**:
       ```bash
       ./bin/elasticsearch
       ```
    3. **Проверь производительность**:
       ```bash
       GET /_cat/nodes?v&h=name,heap.percent,load_1m
       ```

- **Преимущества**:
    - Увеличивает производительность одного узла (например, для сложных агрегаций).
    - Не требует изменения архитектуры кластера.

- **Ограничения**:
    - Ограниченный предел масштабирования (например, максимум 31 ГБ для JVM heap).
    - Увеличивает стоимость оборудования.

- **Лучшие практики**:
    - Используй SSD вместо HDD для ускорения I/O.
    - Мониторь использование кучи:
      ```bash
      GET /_nodes/stats/jvm?human
      ```
    - Комбинируй с горизонтальным масштабированием для больших кластеров.

#### c) Комбинированный подход
- Для больших кластеров:
    - Добавляй узлы (горизонтальное масштабирование) для распределения шардов.
    - Увеличивай ресурсы на узлах (вертикальное масштабирование) для сложных запросов.
- Пример: Для индекса с 1 ТБ данных:
    - Настрой 20–50 шардов (по 20–50 ГБ на шард).
    - Используй 4–6 узлов с 16 CPU и 64 ГБ RAM каждый.
    - Установи 2 реплики для отказоустойчивости.

### Обработка сбоев

Elasticsearch обеспечивает отказоустойчивость через автоматическое восстановление шардов и использование реплик. Это позволяет минимизировать время простоя при сбоях.

#### a) Настройка автоматического восстановления шардов
- **Как работает?**
    - При сбое узла Elasticsearch автоматически переназначает шарды на другие узлы, используя реплики.
    - Процесс управляется параметрами **Cluster Allocation** и **Recovery**.

- **Настройка**:
    - Включи автоматическое восстановление:
      ```bash
      PUT /_cluster/settings
      {
        "transient": {
          "cluster.routing.allocation.enable": "all"
        }
      }
      ```
    - Настрой параметры восстановления:
      ```bash
      PUT /_cluster/settings
      {
        "transient": {
          "indices.recovery.max_bytes_per_sec": "40mb", // Ограничить скорость восстановления
          "cluster.routing.allocation.node_concurrent_recoveries": 2 // Параллельное восстановление
        }
      }
      ```

- **Проверка восстановления**:
  ```bash
  GET /_cat/recovery?v
  ```
    - Показывает статус восстановления шардов (например, `stage: done`, `bytes_recovered`).

#### b) Управление отказоустойчивостью через реплики
- **Реплики**:
    - Копии первичных шардов, которые обеспечивают доступ к данным при сбое узла.
    - По умолчанию: 1 реплика на шард.
- **Настройка реплик**:
  ```bash
  PUT /pets/_settings
  {
    "number_of_replicas": 2
  }
  ```
- **Как работают при сбое?**
    - Если узел с первичным шардом выходит из строя, реплика становится первичной.
    - Elasticsearch автоматически создаёт новую реплику на другом узле.

- **Проверка статуса**:
  ```bash
  GET /_cat/shards/pets?v&h=index,shard,prirep,state
  ```
    - `prirep`: `p` (primary) или `r` (replica).
    - `state`: `STARTED` (активен), `UNASSIGNED` (не назначен).

- **Управление сбоями**:
    - Если шарды не назначаются, проверь статус кластера:
      ```bash
      GET /_cluster/health
      ```
    - Исправь проблему (например, добавь узел или проверь диск):
      ```bash
      PUT /_cluster/settings
      {
        "transient": {
          "cluster.routing.allocation.disk.watermark.low": "85%",
          "cluster.routing.allocation.disk.watermark.high": "90%"
        }
      }
      ```

#### Лучшие практики
- **Реплики**:
    - Установи минимум 1 реплику для отказоустойчивости, 2–3 для высоконагруженных систем.
    - Распределяй реплики по разным узлам:
      ```yaml
      cluster.routing.allocation.exclude._name: "node1" # Исключить узел для реплик
      ```
- **Восстановление**:
    - Ограничивай скорость восстановления (`max_bytes_per_sec`), чтобы не перегружать сеть.
    - Мониторь процесс восстановления:
      ```bash
      GET /_cat/recovery?v&h=index,shard,stage,bytes_percent
      ```
- **Резервное копирование**:
    - Регулярно создавай снапшоты и проверяй их восстановление.
    - Используй SLM для автоматизации.


### Итог
- **Резервное копирование и восстановление**:
    - Используй **Snapshot API** для создания снапшотов в S3 или на локальном диске.
    - Настрой **SLM** для автоматического управления снапшотами.
    - Тестируй восстановление регулярно.
- **Масштабирование**:
    - **Горизонтальное**: Добавляй узлы для распределения шардов и нагрузки.
    - **Вертикальное**: Увеличивай CPU/RAM, но не превышай 31 ГБ для JVM heap.
    - Комбинируй для больших кластеров.
- **Обработка сбоев**:
    - Установи 1–2 реплики для отказоустойчивости.
    - Настрой автоматическое восстановление шардов с ограничением скорости.
    - Мониторь через Kibana или API (`_cat/recovery`, `_cluster/health`).
      Эти подходы обеспечивают надежность и масштабируемость Elasticsearch, минимизируя риски сбоев и простоев!