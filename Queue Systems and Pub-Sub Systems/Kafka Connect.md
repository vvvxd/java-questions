## Что такое Kafka Connect?

**Kafka Connect** — это фреймворк, встроенный в Apache Kafka, предназначенный для упрощения интеграции Kafka с внешними системами, такими
как базы данных, файловые системы, облачные сервисы, системы хранения и другие. Он позволяет создавать надежные и масштабируемые **конвейеры
данных** (data pipelines) для потоковой обработки данных, минимизируя необходимость написания сложного кода для интеграции.

Kafka Connect решает задачу передачи данных между Kafka и другими системами, предоставляя готовую инфраструктуру для чтения (извлечения)
данных из источников (Source Connectors) и записи данных в целевые системы (Sink Connectors). Это делает его идеальным инструментом для
сценариев, где нужно, например, загружать данные из базы данных в Kafka или отправлять сообщения из Kafka в облачное хранилище.

**Пример сценария**:

- Вы хотите в реальном времени собирать данные из базы данных MySQL (например, новые заказы в интернет-магазине) и отправлять их в Kafka для
  обработки аналитической системой.
- Или наоборот, вы хотите взять сообщения из Kafka и записать их в Elasticsearch для последующей визуализации в Kibana.

---

## Основные компоненты Kafka Connect

Kafka Connect состоит из нескольких ключевых компонентов, которые взаимодействуют для обеспечения передачи данных. Разберем каждый из них:

### 1. **Connectors (Коннекторы)**

Коннекторы — это плагины, которые определяют, как Kafka Connect взаимодействует с внешними системами. Они бывают двух типов:

- **Source Connectors** (Исходные коннекторы): Извлекают данные из внешних систем и отправляют их в топики Kafka.
    - Пример: JDBC Source Connector извлекает данные из базы данных (MySQL, PostgreSQL и т.д.) и публикует их в Kafka.
    - Реальный пример: Вы используете JDBC Source Connector для чтения новых строк из таблицы `orders` в MySQL и отправки их в
      топик `orders_topic`.

 Как работают Source Connectors?

- Source Connector подключается к источнику данных (например, базе данных).
- Он разбивает работу на задачи (Tasks), которые параллельно извлекают данные.
- Данные преобразуются (с помощью Converter) в формат, совместимый с Kafka (например, JSON или Avro), и отправляются в указанный топик.


- **Sink Connectors** (Целевые коннекторы): Читают данные из топиков Kafka и отправляют их во внешние системы.
    - Пример: S3 Sink Connector записывает данные из Kafka в Amazon S3.
    - Реальный пример: Вы отправляете логи из топика `logs_topic` в Amazon S3 для долгосрочного хранения.

- Sink Connector читает сообщения из указанного топика Kafka.
- Задачи (Tasks) распределяют работу по записи данных в целевую систему.
- Данные преобразуются из формата Kafka (например, Avro) в формат, подходящий для целевой системы.

Коннекторы — это готовые или пользовательские реализации, которые можно найти в экосистеме Kafka (например, в Confluent Hub) или написать
самостоятельно, если требуется специфическая интеграция.

### 2. **Tasks (Задачи)**

Задачи — это единицы работы, которые выполняют фактическую передачу данных. Каждый коннектор разбивает свою работу на задачи, которые
выполняются параллельно для повышения производительности.

- **Source Tasks**: Извлекают данные из источника и отправляют их в Kafka.
- **Sink Tasks**: Читают данные из Kafka и отправляют их в целевую систему.
- Количество задач определяется конфигурацией коннектора (например, параметр `tasks.max`). Это позволяет масштабировать обработку данных.

**Пример**: Если у вас есть JDBC Source Connector, который читает данные из очень большой таблицы, вы можете настроить 4
задачи (`tasks.max=4`), чтобы параллельно читать разные партиции таблицы, что ускорит процесс.

### 3. **Workers (Работники)**

Работники — это процессы, которые запускают коннекторы и задачи. Они управляют выполнением и координацией работы.

- **Standalone Mode** (Одиночный режим):
    - Один процесс выполняет все коннекторы и задачи.
    - Подходит для тестирования, разработки или небольших систем.
    - Недостаток: нет отказоустойчивости и масштабируемости.
    - Пример: Вы запускаете Kafka Connect на локальной машине для тестирования передачи данных из файла в топик Kafka.

- **Distributed Mode** (Распределенный режим):
    - Несколько процессов (воркеров) работают вместе в кластере.
    - Подходит для продакшн-сред с высокой нагрузкой.
    - Преимущества: отказоустойчивость (если один воркер падает, другие продолжают работу) и масштабируемость (можно добавлять новые
      воркеры).
    - Пример: В кластере из трех воркеров вы распределяете задачи для обработки данных из 10 баз данных, обеспечивая высокую
      производительность и надежность.

Воркеры обмениваются информацией о состоянии через внутренние топики
Kafka (`config.storage.topic`, `offset.storage.topic`, `status.storage.topic`), что позволяет координировать работу в распределенном режиме.

### 4. **Converters (Конвертеры)**

Конвертеры отвечают за преобразование данных между форматами, чтобы Kafka Connect мог работать с различными типами данных. Например, данные
могут храниться в Kafka в виде JSON, Avro или простых строк.

- **Популярные конвертеры**:
    - **JsonConverter**: Для работы с JSON-данными.
    - **AvroConverter**: Для работы с данными в формате Apache Avro (рекомендуется для продакшн, так как Avro компактнее и поддерживает
      схемы).
    - **StringConverter**: Для работы с простыми строками.

**Пример**: Если вы используете AvroConverter с Confluent Schema Registry, Kafka Connect автоматически проверяет совместимость схем данных,
что предотвращает ошибки при изменении структуры данных.

### 5. **Transformations (Трансформации)**

Single Message Transforms (SMT) — это легковесные преобразования данных, которые можно применять к сообщениям на лету, без необходимости
писать сложный код. Трансформации выполняются в рамках коннектора, до или после передачи данных.

- **Примеры SMT**:
    - **Filter**: Удаляет сообщения, не соответствующие условиям (например, пропускать записи, где поле `status` равно `inactive`).
    - **Cast**: Изменяет тип данных поля (например, преобразует строку в число).
    - **ReplaceField**: Переименовывает или удаляет поля в сообщении.
    - **TimestampConverter**: Преобразует временные метки между форматами.

**Пример**: Вы используете JDBC Source Connector для чтения данных из MySQL, но хотите исключить поле `internal_id` из сообщений,
отправляемых в Kafka. Для этого вы добавляете SMT `ReplaceField` с параметром `exclude=internal_id`.

---

## Режимы работы Kafka Connect

Kafka Connect поддерживает два режима работы, которые определяют, как воркеры и задачи взаимодействуют:

### 1. **Standalone Mode (Одиночный режим)**

- **Описание**: Все коннекторы и задачи выполняются в одном процессе.
- **Когда использовать**:
    - Тестирование или разработка.
    - Небольшие системы с низкой нагрузкой.
    - Сценарии, где не требуется высокая отказоустойчивость.
- **Плюсы**:
    - Простота настройки.
    - Не требует дополнительных ресурсов.
- **Минусы**:
    - Нет отказоустойчивости: если процесс падает, работа останавливается.
    - Ограниченная масштабируемость.
- **Пример конфигурации**:
  ```properties
  bootstrap.servers=localhost:9092
  key.converter=org.apache.kafka.connect.json.JsonConverter
  value.converter=org.apache.kafka.connect.json.JsonConverter
  ```
  Вы запускаете процесс Kafka Connect с файлом конфигурации, указывающим на локальный брокер Kafka.

### 2. **Distributed Mode (Распределенный режим)**

- **Описание**: Несколько воркеров работают вместе, обмениваясь состоянием через внутренние топики Kafka. Это кластерный подход, где задачи
  автоматически распределяются между воркерами.
- **Когда использовать**:
    - Продакшн-среды с высокой нагрузкой.
    - Сценарии, где важна отказоустойчивость и масштабируемость.
- **Плюсы**:
    - Отказоустойчивость: если один воркер выходит из строя, задачи перераспределяются.
    - Масштабируемость: можно добавлять новые воркеры для увеличения производительности.
    - Централизованное управление через REST API.
- **Минусы**:
    - Требует настройки внутренних топиков Kafka.
    - Более сложная инфраструктура.
- **Пример конфигурации**:
  ```properties
  bootstrap.servers=broker1:9092,broker2:9092
  group.id=connect-cluster
  key.converter=io.confluent.connect.avro.AvroConverter
  value.converter=io.confluent.connect.avro.AvroConverter
  config.storage.topic=connect-configs
  offset.storage.topic=connect-offsets
  status.storage.topic=connect-status
  ```
  В этой конфигурации воркеры используют топики Kafka для хранения конфигураций, смещений и статуса задач.

---

## Как работает Kafka Connect: Пример потока данных

Чтобы лучше понять, как Kafka Connect работает, рассмотрим пример:

1. **Сценарий**: Вы хотите передавать данные из PostgreSQL (таблица `users`) в Elasticsearch.
2. **Шаги**:

- **Source Connector**: JDBC Source Connector настроен для чтения новых строк из таблицы `users` (используя инкрементальный столбец,
  например, `last_updated`).
- **Tasks**: Коннектор разбивает работу на 2 задачи, каждая из которых читает часть данных.
- **Converter**: Данные преобразуются в Avro для компактности и поддержки схем.
- **Transformations**: Применяется SMT `Filter`, чтобы исключить пользователей с `status=inactive`.
- **Kafka**: Данные отправляются в топик `users_topic`.
- **Sink Connector**: Elasticsearch Sink Connector читает данные из `users_topic` и записывает их в индекс Elasticsearch.
- **Workers**: В распределенном режиме два воркера обрабатывают задачи для Source и Sink коннекторов.


## Создание собственных коннекторов

Иногда готовых коннекторов недостаточно для специфических нужд, и требуется разработка **кастомного коннектора**. Kafka Connect
предоставляет API для создания собственных Source и Sink Connectors.

### Основы API Kafka Connect

Для создания коннектора нужно реализовать следующие классы:

1. **Connector**: Определяет конфигурацию и разбиение работы на задачи.

- Для Source: `SourceConnector`
- Для Sink: `SinkConnector`

2. **Task**: Выполняет фактическую работу по извлечению или записи данных.

- Для Source: `SourceTask`
- Для Sink: `SinkTask`

3. **ConfigDef**: Определяет параметры конфигурации коннектора (например, URL источника, имя топика).

## Популярные коннекторы

Kafka Connect имеет богатую экосистему готовых коннекторов, многие из которых разработаны Confluent или сообществом. Рассмотрим самые
популярные:

### Confluent Community Connectors

Confluent поддерживает множество коннекторов, доступных через **Confluent Hub**. Примеры:

- **JDBC Connector**:
    - **Тип**: Source и Sink.
    - **Применение**: Интеграция с реляционными базами данных (MySQL, PostgreSQL, SQL Server и т.д.).
    - **Особенности**: Поддерживает инкрементное чтение, bulk-режим и запись в таблицы.
- **S3 Connector**:
    - **Тип**: Sink.
    - **Применение**: Хранение данных в Amazon S3 в форматах JSON, Avro, Parquet.
    - **Особенности**: Поддерживает партиционирование данных по времени или другим ключам.
- **HDFS Connector**:
    - **Тип**: Sink.
    - **Применение**: Запись данных в Hadoop HDFS.
    - **Особенности**: Подходит для интеграции с экосистемой Hadoop (Hive, Spark).

### Debezium

- **Тип**: Source.
- **Что делает**: Реализует Change Data Capture (CDC) для баз данных, таких как MySQL, PostgreSQL, MongoDB, Oracle.
- **Применение**: Отслеживание изменений в базе данных (вставки, обновления, удаления) и отправка их в Kafka в виде событий.
- **Особенности**:
    - Высокая производительность за счет чтения журналов транзакций.
    - Поддержка схем через Confluent Schema Registry.
    - Пример: Отслеживание изменений в таблице `products` для синхронизации с витриной данных.

### MirrorMaker

- **Тип**: Source и Sink.
- **Что делает**: Реплицирует данные между кластерами Kafka.
- **Применение**: Используется для создания географически распределенных систем или резервного копирования данных.
- **Особенности**:
    - MirrorMaker 2.0 (MM2) улучшает оригинальный MirrorMaker, добавляя поддержку синхронизации топиков, партиций и оффсетов.
    - Пример: Репликация топика `events` из кластера в дата-центре A в кластер в дата-центре B.


