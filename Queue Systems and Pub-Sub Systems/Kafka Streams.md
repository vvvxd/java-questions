Для глубокого понимания **Kafka Streams** нужно освоить несколько ключевых концепций, технологий и практических аспектов. Kafka Streams — это библиотека для обработки и анализа потоковых данных в реальном времени на основе Apache Kafka. Вот основные области, которые стоит изучить:

### 2. **Основы Kafka Streams**
Kafka Streams — это Java-библиотека для обработки потоков данных. Нужно разобраться в следующих концепциях:
- **Stream Processing**:
    - Разница между потоковой (stream) и пакетной (batch) обработкой.
    - Принципы обработки событий в реальном времени.
- **DSL и Processor API**:
    - **DSL (Domain-Specific Language)**: Высокоуровневый API для создания потоковых приложений (map, filter, join, aggregate и т.д.).
    - **Processor API**: Низкоуровневый API для более сложной обработки, когда DSL недостаточно.
- **Топологии**:
    - Как Kafka Streams строит граф обработки (topology).
    - Источники (source), процессоры (processor), стоки (sink).
- **KStream и KTable**:
    - **KStream**: Поток записей, где каждая запись обрабатывается независимо.
    - **KTable**: Таблица, представляющая состояние (snapshot) данных с обновлениями по ключу.
    - Разница между event stream и changelog stream.
- **Глобальные таблицы (GlobalKTable)**:
    - Использование для данных, доступных всем задачам в приложении.

### 3. **Состояние и State Stores**
- **Stateful Processing**:
    - Агрегации, группировки, оконные операции (windowing).
    - Управление состоянием (state) в Kafka Streams.
- **State Stores**:
    - Локальные хранилища состояния (in-memory, persistent).
    - Changelog-топики для восстановления состояния.
    - Как использовать RocksDB или кастомные хранилища.
- **Fault Tolerance**:
    - Как Kafka Streams обеспечивает отказоустойчивость через репликацию changelog и standby tasks.

### 4. **Временная обработка (Time and Windows)**
- **Типы времени**:
    - Event time, processing time, ingestion time.
    - Важность временных меток в потоковой обработке.
- **Оконные операции**:
    - Tumbling windows, hopping windows, sliding windows, session windows.
    - Grace period для обработки опоздавших событий (late events).
- **Suppression**:
    - Подавление промежуточных результатов в оконных операциях.

### 5. **Сериализация и десериализация**
- **SerDes**:
    - Понимание сериализаторов и десериализаторов (JSON, Avro, Protobuf).
    - Настройка SerDes для ключей и значений.
- **Schema Registry**:
    - Работа с Confluent Schema Registry для управления схемами данных.

### 6. **Масштабируемость и производительность**
- **Параллелизм**:
    - Как Kafka Streams масштабируется за счёт партиций и задач (tasks).
    - Роль consumer groups в распределении нагрузки.
- **Оптимизация**:
    - Настройка параметров (num.stream.threads, buffer sizes).
    - Кэширование для уменьшения записи в changelog.
    - Балансировка нагрузки между инстансами.
- **Мониторинг и отладка**:
    - Метрики Kafka Streams (JMX, Prometheus).
    - Логирование и обработка ошибок (ProductionExceptionHandler, DeserializationExceptionHandler).

### 7. **Интеграция и экосистема**
- **Kafka Streams и Kafka Connect**:
    - Как интегрировать Kafka Streams с внешними источниками/приёмниками.
- **Интеграция с другими системами**:
    - Использование Kafka Streams с базами данных, кэшами (Redis), поисковыми системами (Elasticsearch).
- **Confluent Platform**:
    - Понимание дополнительных инструментов (kSQL, Control Center) для упрощения работы с Kafka.

### 8. **Практические аспекты**
- **Тестирование**:
    - Использование TopologyTestDriver для юнит-тестов.
    - Интеграционное тестирование с Testcontainers или embedded Kafka.
- **Деплой и эксплуатация**:
    - Деплой приложений Kafka Streams (Docker, Kubernetes).
    - Управление версиями топиков и приложений.
    - Обновление приложений без остановки (rolling updates).
- **Обработка ошибок**:
    - Управление сбоями (dead letter queues).
    - Обработка некорректных данных.

### 9. **Расширенные темы**
- **Exactly-Once Semantics**:
    - Как Kafka Streams обеспечивает точную однократную обработку (EOS).
    - Транзакции в Kafka.
- **Interactive Queries**:
    - Доступ к состоянию приложения через REST API.
    - Использование state stores для интерактивных запросов.
- **Custom Processors**:
    - Создание собственных процессоров для специфичной логики.
- **Stream-Table Joins**:
    - Объединение KStream и KTable/GlobalKTable.
    - Ограничения и оптимизация джойнов.

### 12. **Мягкие навыки**
- **Понимание бизнес-целей**:
    - Как Kafka Streams решает реальные задачи (аналитика, мониторинг, ETL).
- **Коммуникация**:
    - Объяснение архитектуры и решений коллегам.
- **Отладка и профилирование**:
    - Умение находить узкие места и оптимизировать производительность.
