# Операции с сохранением состояния API DSL: Работа с окнами

Узнайте, как работают оконные операции с API Kafka Streams DSL.

Окно — это ключевая функция, которая позволяет выполнять операции на основе времени с потоками данных. В Kafka Streams окно — это фиксированный размер логического сегмента потока, который содержит подмножество записей, попадающих в указанный временной диапазон. Оно позволяет выполнять такие операции, как агрегации и объединения, с записями в определенном временном окне для более точного анализа данных.

## Типы операций с окнами

Давайте рассмотрим различные типы схем окон в Kafka Streams.

### Падающие окна

Временные окна Tumble в Kafka Streams — это тип операции оконной обработки, при которой данные делятся на неперекрывающиеся временные интервалы или окна фиксированного размера. Все записи с временными метками, попадающими в одно и то же окно, обрабатываются вместе.

```java
// Пример использования падающих временных окон
KStream<String, String> clickStream = builder.stream("click-events");
KGroupedStream<String, String> clicksByUser = clickStream.groupByKey();
TimeWindowedKStream<String, String> clicksByUserPerHour = clicksByUser
    .windowedBy(TimeWindows.ofSizeWithNoGrace(Duration.ofHours(1)));
KTable<Windowed<String>, Long> clicksPerHour = clicksByUserPerHour.count();
clicksPerHour.toStream()
    .map((key, value) -> new KeyValue<>(key.key(), value))
    .to("clicks-per-hour", Produced.with(Serdes.String(), Serdes.Long()));
```

**Объяснение**:
- **Строка 2**: Создаем `KStream` событий кликов из темы `click-events`.
- **Строка 5**: Группируем поток по пользователю (ключу) с помощью метода `groupByKey()`.
- **Строки 8–9**: Создаем экземпляр `TimeWindowedKStream` с падающим окном длительностью один час.
- **Строки 12–13**: Подсчитываем количество кликов в час для каждого пользователя и сохраняем результаты в `KTable`.
- **Строка 16**: Выводим результаты в новую тему `clicks-per-hour`.

Это приложение обрабатывает входящие события кликов, группируя их по пользователю и объединяя в почасовые окна.

### Прыгающие окна

Прыгающие временные окна в Kafka Streams — это тип окон, где окно перемещается на фиксированное количество времени, называемое интервалом продвижения. Размер окна фиксирован и называется размером окна. Прыгающие окна отличаются от падающих тем, что они могут перекрываться.

```java
// Пример использования прыгающих временных окон
KStream<String, Long> valueStream = builder.stream("values");
KGroupedStream<String, Long> groupedStream = valueStream.groupByKey();
TimeWindowedKStream<String, Long> windowedStream = groupedStream
    .windowedBy(TimeWindows.ofSizeAndAdvanceBy(Duration.ofMinutes(5), Duration.ofMinutes(1)));
KTable<Windowed<String>, Long> summedValues = windowedStream.reduce(
    (value1, value2) -> value1 + value2
);
summedValues.toStream()
    .map((key, value) -> new KeyValue<>(key.key(), value))
    .to("summed-values", Produced.with(Serdes.String(), Serdes.Long()));
```

**Объяснение**:
- Группируем входные данные `KStream` по ключу, затем используем метод `windowedBy()` для указания прыгающего окна размером 5 минут с интервалом продвижения 1 минута.
- Используем метод `reduce()` для вычисления суммы значений для каждого окна.
- Результатом является `KTable` с ключами типа `Windowed<String>`, которые содержат информацию о времени начала и окончания окна и исходный ключ.

### Окна сеанса

Временные окна сеанса в Kafka Streams используются для группировки записей в сеансы на основе разницы во времени между последовательными записями. Сеанс определяется как период бездействия между записями, больший или равный указанной длительности разрыва.

```java
// Пример использования окон сеанса
KStream<String, Long> activityStream = builder.stream("user-activity");
KGroupedStream<String, Long> groupedStream = activityStream.groupByKey();
KTable<Windowed<String>, Long> sessionCounts = groupedStream
    .windowedBy(SessionWindows.ofInactivityGap(Duration.ofMinutes(30)))
    .count();
sessionCounts.toStream()
    .map((key, value) -> new KeyValue<>(key.key(), value))
    .to("session-counts", Produced.with(Serdes.String(), Serdes.Long()));
```

**Объяснение**:
- Создаем поток событий активности пользователя с ключами типа `String` и значениями типа `Long`.
- Группируем события по идентификатору пользователя в сеансы с временным интервалом в 30 минут с помощью `SessionWindows`.
- Подсчитываем количество событий в каждом сеансе с помощью метода `count`, который возвращает `KTable<Windowed<String>, Long>`.
- Выводим результаты в тему Kafka с помощью метода `to`.

### Скользящие временные окна

Скользящие временные окна разделяют поток на набор окон, которые, в отличие от падающих окон, перекрываются. Это означает, что каждая запись может принадлежать нескольким окнам, что позволяет проводить более детальный анализ данных.

```java
// Пример использования скользящих временных окон
KStream<String, String> eventStream = builder.stream("events");
KGroupedStream<String, String> groupedStream = eventStream.groupByKey();
TimeWindowedKStream<String, String> windowedStream = groupedStream
    .windowedBy(JoinWindows.of(Duration.ofSeconds(10)));
KTable<Windowed<String>, Long> counts = windowedStream.count();
counts.toStream()
    .map((key, value) -> new KeyValue<>(key.key(), value))
    .to("windowed-counts", Produced.with(Serdes.String(), Serdes.Long()));
```

**Объяснение**:
- Используем `JoinWindows` для создания скользящих окон длительностью 10 секунд.
- Подсчитываем количество событий в каждом окне с помощью метода `count`.

## Пример кода

Давайте разберемся с оконным подходом на примере приложения, которое подсчитывает количество ошибок приложения в течение 30-секундного интервала (падающие окна).

```java
package com.example;

import java.time.Duration;
import java.util.Properties;

import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.StreamsConfig;
import org.apache.kafka.streams.kstream.KGroupedStream;
import org.apache.kafka.streams.kstream.KStream;
import org.apache.kafka.streams.kstream.KTable;
import org.apache.kafka.streams.kstream.Produced;
import org.apache.kafka.streams.kstream.TimeWindowedKStream;
import org.apache.kafka.streams.kstream.TimeWindows;
import org.apache.kafka.streams.kstream.Windowed;
import org.apache.kafka.common.serialization.Serdes;

public class KafkaStreamsDSLStatefulOps {

  public static void main(String[] args) {

    Properties configurations = new Properties();
    configurations.put(StreamsConfig.APPLICATION_ID_CONFIG, "window-app");
    configurations.put(StreamsConfig.APPLICATION_SERVER_CONFIG, "localhost:8080");
    configurations.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
    configurations.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass().getName());
    configurations.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass().getName());

    StreamsBuilder builder = new StreamsBuilder();
    // key=app_id, value=error_type (404, 500, etc)
    KStream<String, String> appErrors = builder.stream("app-errors");

    // Группируем поток по ключу
    KGroupedStream<String, String> errorsByAppID = appErrors.groupByKey();

    // Определяем падающее временное окно
    TimeWindowedKStream<String, String> errorsStreamPerThirtySeconds = errorsByAppID
        .windowedBy(TimeWindows.ofSizeWithNoGrace(Duration.ofSeconds(30)));

    // Подсчитываем количество ошибок
    KTable<Windowed<String>, Long> errorsPerThirtySeconds = errorsStreamPerThirtySeconds.count();

    // Преобразуем ключ в String
    KStream<String, Long> transformedStream = errorsPerThirtySeconds.toStream()
        .map((key, value) -> new KeyValue<>(key.key(), value));

    // Выводим результаты в новую тему Kafka
    transformedStream.to("error-rate", Produced.with(Serdes.String(), Serdes.Long()));

    KafkaStreams app = new KafkaStreams(builder.build(), configurations);

    app.start();
    System.out.println("Started kafka streams (windowing) application");
  }
}
```

### Kafka Consumer CLI

Нажмите кнопку «+», чтобы открыть новую вкладку терминала, и введите команду для запуска CLI потребителя Kafka. Это будет ждать сообщений из темы `error-rate`:

```bash
kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic error-rate
```

### Kafka Producer CLI

Нажмите кнопку «+», чтобы открыть новую вкладку терминала, и введите команды для отправки сообщений в тему `app-errors`:

```bash
kafka-console-producer.sh --broker-list localhost:9092 --topic app-errors
```

Введите сообщения в формате `key:value`. Например:

```text
app1:404
app1:500
app2:404
```

### Вывод приложения Kafka Streams

Вернитесь к терминалу потребителя консоли. Вы должны увидеть вывод, аналогичный следующему (вывод может отличаться в зависимости от ввода данных):

```text
app1:2
app2:1
```

## Код пояснения

Вот пошаговая разбивка кода:

1. **Строки 6–19**: Импортируем необходимые пакеты.
2. **Строки 25–30**: Создаем объект `Properties` с именем `configurations`, содержащий параметры конфигурации приложения Kafka Streams, включая идентификатор приложения, сервер Kafka bootstrap, ключ и значения по умолчанию `Serdes`.
3. **Строка 33**: Создаем объект `StreamsBuilder` для определения топологии приложения Kafka Streams.
4. **Строка 35**: Создаем объект `KStream`, вызывая метод `stream()` объекта `builder`, который считывает сообщения из темы `app-errors`.
5. **Строка 38**: Вызываем метод `groupByKey()` для группировки данных в потоке `appErrors` по ключу (имени приложения).
6. **Строка 41**: Используем метод `windowedBy` для создания `TimeWindowedKStream` с падающим окном длительностью 30 секунд.
7. **Строка 45**: Используем метод `count` для подсчета количества ошибок, создаваемых приложением в течение 30-секундного интервала.
8. **Строка 47**: Преобразуем ключ в тип `String` (вместо объекта `Windowed`).
9. **Строка 51**: Отправляем вывод операции подсчета в тему Kafka с именем `error-rate` с помощью метода `to()`.
10. **Строка 53**: Создаем новый объект `KafkaStreams`.
11. **Строка 55**: Вызываем метод `start()` объекта `app` для запуска приложения Kafka Streams.

В этом уроке мы рассмотрели, как работают операции с окнами в Kafka Streams, и подробно изучили их на практических примерах.