# Операции без сохранения состояния DSL API: обзор

Узнайте больше о DSL API в Kafka Streams и поддерживаемых им операциях без сохранения состояния.

## API Kafka Streams DSL

Kafka Streams предоставляет API-интерфейс доменно-специфического языка (DSL), который разработан для создания сложных приложений обработки потоков простым и лаконичным способом. Это связано с тем, что API-интерфейс DSL основан на принципах функционального программирования, что делает его в высокой степени компонуемым и модульным. Он поддерживает широкий спектр операций обработки потоков, включая:

- Преобразования без сохранения состояния (например, отображение и фильтрация)
- Операции с отслеживанием состояния (например, агрегации)
- Операции объединения и создания окон

Давайте кратко рассмотрим эти операции.

## Операции API Kafka Streams DSL

### Преобразования без сохранения состояния

Операции без сохранения состояния в Kafka Streams — это набор операций, которые предназначены для независимой работы с каждой записью данных в потоке. Эти операции не требуют поддержания какого-либо внутреннего состояния в записях данных. Поэтому они идеально подходят для простых преобразований или операций фильтрации. Операции без сохранения состояния в Kafka Streams можно использовать для выполнения широкого спектра преобразований данных, таких как фильтрация, отображение, выравнивание и т. д. Кроме того, операции без сохранения состояния можно легко комбинировать с другими операциями с сохранением состояния в Kafka Streams для создания сложных конвейеров обработки, которые могут выполнять широкий спектр задач обработки данных.

### Операции с отслеживанием состояния

Операции с сохранением состояния в Kafka Streams — это набор операций, требующих сохранения внутреннего состояния в нескольких записях данных. Эти операции обычно используются для более сложных преобразований или агрегаций, требующих обработки данных с течением времени, а не по принципу «запись за записью». Операции с сохранением состояния важны, поскольку они позволяют разработчикам выполнять сложные вычисления над потоками данных, которым требуется контекст и историческая информация. Например, операция агрегации, которая вычисляет среднюю температуру за последний час, требует исторической информации о показаниях температуры за предыдущий час.

### Операции объединения и оконные операции

Операции объединения в Kafka Streams позволяют разработчикам объединять данные из нескольких потоков на основе общего ключа. Они обычно используются в приложениях потоковой обработки для обогащения данных, где данные из нескольких потоков объединяются для создания более полного или полезного набора данных. Популярный шаблон — сделать информацию в базах данных доступной в Kafka с помощью API Kafka Connect. Затем реализуйте приложения, которые используют API Kafka Streams для выполнения быстрых и эффективных локальных объединений таких таблиц и потоков, вместо того чтобы требовать от приложения делать запрос к удаленной базе данных по сети для каждой записи.

Операции с окнами в Kafka Streams позволяют разработчикам группировать записи данных в окна на основе времени для агрегации и анализа. Это позволяет нам контролировать, как группировать записи, имеющие одинаковый ключ для операций с сохранением состояния, таких как агрегации или объединения, в окна, которые отслеживаются по ключу записи. Поддерживаемые типы окон в Kafka Streams включают скачкообразное, временное окно, переворачивающееся временное окно, скользящее временное окно и временные окна сеанса.

## Ключевые интерфейсы DSL API

Эти интерфейсы являются частью пакета `org.apache.kafka.streams.kstream`.

### API KStream

`KStream` представляет собой поток записей в теме Kafka. Это непрерывная, неограниченная последовательность данных, которая обрабатывается в реальном времени. API `KStream` предоставляет функциональный программный интерфейс для обработки потока данных, позволяя разработчикам применять различные преобразования и операции к данным.

### API KTable

`KTable` представляет журнал изменений обновлений потока данных. Это распределенное, отказоустойчивое и масштабируемое представление таблицы, которая непрерывно обновляется в реальном времени. API предоставляет интерфейс, подобный реляционной базе данных, для запроса и обработки данных, позволяя разработчикам выполнять широкий спектр операций объединения и агрегации в потоке. API предназначен для операций с сохранением состояния, требующих внутреннего управления состоянием, таких как обновления базы данных в реальном времени или микросервисы, управляемые событиями.

### API GlobalKTable

В отличие от `KTable`, который разделен на все экземпляры `KafkaStreams`, `GlobalKTable` полностью реплицируется на каждый экземпляр `KafkaStreams`. Каждый раздел базовой темы потребляется каждым `GlobalKTable`, так что полный набор данных доступен в каждом экземпляре `KafkaStreams`. Это позволяет выполнять соединения с `KStream` без повторного разделения входного потока.

## Операции без сохранения состояния KStream

Теперь, когда у нас есть обзор API DSL в Kafka Streams, давайте подробнее рассмотрим операции без сохранения состояния, поддерживаемые API `KStream`.

### Обычные операции

#### `filter`

Эта операция позволяет применять логическое условие к каждой записи в потоке и пропускать только те записи, которые удовлетворяют условию. Эта операция не изменяет ключи или значения записей, а просто удаляет записи, которые не удовлетворяют указанному условию. Метод `filter` принимает `Predicate` в качестве аргумента, представляющего логическое условие, которое должно быть применено к каждой записи.

```java
// Пример операции filter
KStream<String, String> filteredStream = stream.filter((key, value) -> value.contains("important"));
```

Примечание: этот метод также можно использовать как `filterNot`, если необходимо исключить записи на основе определенных критериев.

#### `map`

Эта операция позволяет преобразовывать значения каждой записи в потоке. Эта операция не изменяет ключи записей, а только изменяет значения в соответствии с предоставленной функцией преобразования. Метод `map` принимает `KeyValueMapper` в качестве аргумента, который представляет функцию преобразования, применяемую к каждому значению в потоке.

```java
// Пример операции map
KStream<String, String> mappedStream = stream.map((key, value) -> KeyValue.pair(key, value.toUpperCase()));
```

#### `mapValues`

Эта операция похожа на `map`, но она позволяет преобразовывать только значения каждой записи в потоке. Эта операция не изменяет исходные значения, а создает новый поток с преобразованными ключами и значениями. Метод `mapValues` принимает `ValueMapper` в качестве аргумента, который представляет функцию преобразования, применяемую к каждому значению в потоке.

```java
// Пример операции mapValues
KStream<String, String> mappedValuesStream = stream.mapValues(value -> value.toLowerCase());
```

#### `flatMap`

Эта операция позволяет разделить каждую запись в потоке на несколько записей. Эта операция может быть полезна, когда одну входную запись необходимо преобразовать в несколько выходных записей. Метод `flatMap` принимает `KeyValueMapper` в качестве аргумента, который представляет функцию, применяемую к каждому значению в потоке. Выходные данные этой функции представляют собой итерируемый набор пар ключ-значение, которые будут добавлены в выходной поток.

```java
// Пример операции flatMap
KStream<String, String> flatMappedStream = stream.flatMap((key, value) -> {
    List<KeyValue<String, String>> result = new ArrayList<>();
    String[] words = value.split(" ");
    for (String word : words) {
        result.add(KeyValue.pair(key, word));
    }
    return result;
});
```

### Группировка операций

Если необходимо выполнить агрегацию с сохранением состояния для содержимого `KStream`, сначала нужно сгруппировать его записи по их ключу, чтобы создать `KGroupedStream`. Один из способов сделать это — использовать `groupByKey`.

```java
// Пример операции groupByKey
KGroupedStream<String, String> groupedStream = stream.groupByKey();
```

Обобщенной версией `groupByKey` является `groupBy`, которая позволяет группировать на основе другого ключа с помощью `KeyValueMapper`.

```java
// Пример операции groupBy
KGroupedStream<String, String> groupedByStream = stream.groupBy((key, value) -> value);
```

В обоих случаях (`groupByKey` и `groupBy`), если нужно использовать другой `Serde` (Serializer и Deserializer) вместо стандартных, используется перегруженная версия, которая принимает объект `Grouped`.

### Терминальные операции

Терминальная операция в Kafka Streams — это метод, который возвращает `void` вместо промежуточного значения, такого как другой `KStream` или `KTable`.

#### Метод `to`

Метод `to` используется для записи данных из `KStream` в тему Kafka.

```java
// Пример метода to
stream.to("output-topic");
```

Перегруженная версия метода `to` позволяет указать объект `Produced` для настройки `Serdes` и разделителя.

```java
// Пример метода to (перегруженная версия)
stream.to("output-topic", Produced.with(Serdes.String(), Serdes.String()));
```

#### Метод `print`

Если необходимо регистрировать записи `KStream` для целей отладки, используется метод `print`. Он принимает экземпляр `Printed` для настройки поведения.

```java
// Пример операции print
stream.print(Printed.toSysOut());
```

### Другие операции

#### Операция `peek`

Поскольку метод `print` является терминальной операцией, можно использовать операцию `peek`, которая возвращает тот же экземпляр `KStream`. Она принимает `ForeachAction`, который позволяет указать, что делать с каждой записью, например, записать ключ и значение.

```java
// Пример операции peek
stream.peek((key, value) -> System.out.println("key=" + key + ", value=" + value));
```

#### Метод `through`

При разработке конвейеров обработки с помощью Kafka Streams DSL записи результирующего потока отправляются в выходную тему с помощью метода `to`, а затем создается новый поток из выходной темы. Это можно упростить, используя метод `through`.

```java
// Пример операции through
KStream<String, String> throughStream = stream.through("intermediate-topic");
```

В этом уроке мы рассмотрели операции без сохранения состояния API Kafka Streams DSL, включая многие его операции.