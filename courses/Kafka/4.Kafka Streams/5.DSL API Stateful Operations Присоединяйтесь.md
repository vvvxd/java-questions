# DSL API Stateful Operations: Присоединяйтесь

Узнайте, как работают операции объединения с API Kafka Streams DSL.

Операции объединения объединяют данные из двух или более входных потоков и/или таблиц на основе общего ключа. Kafka Streams предоставляет несколько типов операций объединения, включая внутреннее, левое и внешнее объединение, каждое из которых имеет свои собственные уникальные характеристики и варианты использования. Они используются для объединения связанных потоков данных и выполнения сложных анализов и преобразований полученных данных. Например, объединения могут использоваться для объединения данных о кликах с данными о клиентах для создания более полной картины поведения клиентов или объединения данных с разных датчиков в системе IoT для выявления закономерностей и аномалий.

## Типы операций соединения

Давайте рассмотрим различные типы операций объединения в Kafka Streams.

### KStream к KStream

Операция объединения `KStream` к `KStream` используется для объединения двух входных `KStream` на основе их ключей. В этом типе объединения каждая запись в одном `KStream` сопоставляется с любыми записями в другом `KStream`, имеющими тот же ключ. Условие объединения задается функцией, которая принимает две входные записи и возвращает логическое значение, указывающее, следует ли их объединять.

Допустим, у нас есть два `KStream`: один содержит информацию о действиях пользователя, а другой — о местоположении пользователя. Мы хотим объединить эти два потока на основе идентификатора пользователя, чтобы создать поток обогащенных событий активности пользователя.

```java
// Пример объединения KStream к KStream
KStream<String, String> activityStream = builder.stream("user-activity");
KStream<String, String> locationStream = builder.stream("user-location");
KStream<String, String> joinedStream = activityStream.join(
    locationStream,
    (activity, location) -> activity + ", located in " + location,
    JoinWindows.of(Duration.ofMinutes(5))
);
```

**Объяснение**:
- Лямбда-выражение `ValueJoiner` принимает значения активности и местоположения из двух потоков и возвращает строку, представляющую обогащенное событие.
- В этом случае мы объединяем две строки с дополнительным текстом, чтобы создать обогащенное событие.

### KTable к KTable

Операция объединения `KTable` к `KTable` позволяет объединять два `KTable` на основе их ключей для создания нового `KTable`. Этот тип операции полезен, когда нужно объединить две таблицы данных на основе общего ключа, например, объединить таблицу с информацией о пользователе с таблицей истории покупок для анализа поведения клиента.

```java
// Пример объединения KTable к KTable
KTable<String, String> ordersTable = builder.table("orders");
KTable<String, String> usersTable = builder.table("users");
KTable<String, String> joinedTable = ordersTable.join(
    usersTable,
    (order, user) -> user + ", order: " + order
);
```

**Объяснение**:
- Функция `ValueJoiner` объединяет соответствующие значения в строку, содержащую имя пользователя и информацию о заказе.
- Результатом является `KTable`, содержащий запись для каждого заказа, с объединенными данными пользователя и заказа.

### KTable к KTable (объединение по внешнему ключу)

API Kafka Streams DSL также предоставляет способ объединения двух `KTable` на основе внешнего ключа. В этом типе объединения записи в левой таблице (родительской таблице) имеют внешний ключ, который совпадает с первичным ключом записей в правой таблице (дочерней таблице).

```java
// Пример объединения KTable к KTable по внешнему ключу
KTable<String, String> userTable = builder.table("users");
KTable<String, String> purchaseTable = builder.table("purchases");
KTable<String, String> joinedTable = userTable.join(
    purchaseTable,
    user -> user, // Функция выбора ключа (внешний ключ)
    (user, purchase) -> user + ", purchase: " + purchase
);
```

**Объяснение**:
- Метод `join` вызывается для объекта `userTable` с передачей объекта `purchaseTable` в качестве второго аргумента.
- Указывается функция выбора ключа, которая выбирает ключ идентификатора пользователя из `userTable`, и функция объединения значений, которая объединяет информацию о пользователе и покупке в одну строку.

### KStream к KTable

Этот тип соединения полезен в сценариях, где нужно обогатить потоковые данные информацией из справочной таблицы. `KStream` действует как поток событий, а `KTable` — как справочная таблица. Каждое событие в `KStream` сопоставляется с соответствующей записью в `KTable` на основе их ключей.

```java
// Пример объединения KStream к KTable
KStream<String, String> clickStream = builder.stream("clicks");
KTable<String, String> registrationTable = builder.table("registrations");
KStream<String, String> joinedStream = clickStream.join(
    registrationTable,
    (click, registration) -> click + ", registered by: " + registration
);
```

**Объяснение**:
- Объединяем `KStream` событий кликов с `KTable` записей регистрации на основе идентификатора пользователя.
- Результатом является `KStream` строк, содержащих информацию о каждом клике, включая данные из записи регистрации.

### KStream к GlobalKTable

Этот тип операции соединения позволяет потоку обогащаться данными из `GlobalKTable`. Каждая запись в потоке соединяется с соответствующей записью в глобальной таблице на основе общего ключа. Это похоже на объединение `KStream` к `KTable`, за исключением того, что глобальная таблица реплицируется во всех экземплярах приложения.

```java
// Пример объединения KStream к GlobalKTable
KStream<String, String> clickStream = builder.stream("clicks");
GlobalKTable<String, String> userInfoTable = builder.globalTable("user-info");
KStream<String, String> joinedStream = clickStream.join(
    userInfoTable,
    (key, value) -> key, // Функция выбора ключа
    (click, userInfo) -> click + ", user: " + userInfo
);
```

## Пример кода

Давайте разберемся с различными методами объединения с помощью приложения, которое объединяет потоки данных для предоставления информации о пользователях, взаимодействующих с рекламой.

```java
package com.example;

import java.time.Duration;
import java.util.Properties;

import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.StreamsConfig;
import org.apache.kafka.streams.kstream.KStream;
import org.apache.kafka.streams.kstream.KTable;
import org.apache.kafka.streams.kstream.Produced;
import org.apache.kafka.common.serialization.Serdes;

public class KafkaStreamsDSLStatefulOps {

  public static void main(String[] args) {

    Properties configurations = new Properties();
    configurations.put(StreamsConfig.APPLICATION_ID_CONFIG, "join-app");
    configurations.put(StreamsConfig.APPLICATION_SERVER_CONFIG, "localhost:8080");
    configurations.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
    configurations.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass().getName());
    configurations.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass().getName());

    StreamsBuilder builder = new StreamsBuilder();

    // Поток кликов: key=userid, value=ad_id
    KStream<String, String> clicksStream = builder.stream("clicks");

    // Информация о пользователях: key=userid, value=name
    KTable<String, String> userInfo = builder.table("users");

    KStream<String, String> joinedStream = clicksStream.join(
        userInfo,
        (ad, user) -> user + " clicked " + ad
    );

    joinedStream.to("clicks-by-users", Produced.with(Serdes.String(), Serdes.String()));

    KafkaStreams app = new KafkaStreams(builder.build(), configurations);

    app.start();
    System.out.println("Started kafka streams (join) application");
  }
}
```

### Kafka Consumer CLI

Нажмите кнопку «+», чтобы открыть новую вкладку терминала, и введите команду для запуска CLI потребителя Kafka. Это будет ждать сообщений из темы `clicks-by-users`:

```bash
kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic clicks-by-users
```

### Kafka Producer CLI (Users)

Нажмите кнопку «+», чтобы открыть новую вкладку терминала, и введите команды для заполнения данных пользователей:

```bash
kafka-console-producer.sh --broker-list localhost:9092 --topic users
```

Введите сообщения в формате `key:value`. Например:

```text
user1:Alice
user2:Bob
user3:Charlie
```

### Kafka Producer CLI (Clicks)

Нажмите кнопку «+», чтобы открыть новую вкладку терминала, и введите команды для имитации кликов по рекламе:

```bash
kafka-console-producer.sh --broker-list localhost:9092 --topic clicks
```

Введите сообщения в формате `key:value`. Например:

```text
user1:ad_123
user2:ad_456
user1:ad_789
```

### Вывод приложения Kafka Streams

Вернитесь к терминалу потребителя консоли. Вы должны увидеть вывод, аналогичный следующему:

```text
Alice clicked ad_123
Bob clicked ad_456
Alice clicked ad_789
```

## Код пояснения

Вот пошаговая разбивка кода:

1. **Строки 6–15**: Импортируем необходимые пакеты.
2. **Строки 21–26**: Создаем объект `Properties` с именем `configurations`, содержащий параметры конфигурации приложения Kafka Streams, включая идентификатор приложения, сервер Kafka bootstrap, ключ и значения по умолчанию `Serdes`.
3. **Строка 28**: Создаем объект `StreamsBuilder` для определения топологии приложения Kafka Streams.
4. **Строка 31**: Создаем объект `KStream`, вызывая метод `stream()` объекта `builder`, который считывает сообщения из темы `clicks`.
5. **Строка 34**: Создаем объект `KTable`, который считывает сообщения из темы `users`.
6. **Строки 36–38**: Используем операцию `join` для объединения потока кликов (`KStream`) с пользовательскими данными (`KTable`).
7. **Строка 40**: Отправляем вывод операции соединения в тему `clicks-by-users` с помощью метода `to()`.
8. **Строка 42**: Создаем новый объект `KafkaStreams`.
9. **Строка 44**: Вызываем метод `start()` объекта `app` для запуска приложения Kafka Streams.

На этом уроке мы продолжили изучать вычисления с отслеживанием состояния API Kafka Streams DSL и рассмотрели операции соединения на практических примерах.