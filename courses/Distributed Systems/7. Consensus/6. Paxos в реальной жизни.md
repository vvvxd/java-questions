
# Paxos в реальной жизни

Давайте рассмотрим некоторые детали Paxos, которые не были освещены в оригинальной статье.

> Как мы уже видели, протокол **Paxos** хорошо специфицирован. Однако существуют некоторые мелкие детали и оптимизации, которые оригинальная
> статья не смогла охватить. Некоторые из этих тем были рассмотрены в последующих работах. Этот урок кратко осветит некоторые из этих тем.

## К запуску нескольких экземпляров Paxos

Базовый протокол *Paxos* описывает, как распределённая система из нескольких узлов может прийти к согласию по одному значению.

Однако выбор всего лишь одного значения сам по себе имел бы ограниченное практическое применение.

Для создания более полезных систем нам необходимо иметь возможность непрерывно выбирать значения.

Этого можно достичь, запуская несколько экземпляров Paxos, где экземпляр — это выполнение протокола, приводящее к решению по одному
значению. Эти экземпляры могут работать независимо и параллельно, но они также должны быть пронумерованы.

В зависимости от необходимой функциональности могут применяться различные правила, например, не возвращать результат экземпляра клиенту,
пока все предыдущие экземпляры также не будут завершены.

> Мы подробнее остановимся на этой теме в следующем уроке.

## Paxos, возвращающий текущее состояние системы

Ещё одна распространенная потребность — это возможность запрашивать текущее состояние системы.

Конечно, клиенты системы узнают о выбранных значениях, поэтому они могли бы отслеживать состояние на своей стороне. Но всегда будут случаи,
когда некоторым клиентам потребуется получить некоторые из ранее выбранных значений, например, если это клиенты, которые только что были
введены в эксплуатацию.

### Операция чтения

*Paxos* также должен поддерживать **операции чтения**, которые возвращают решения ранее завершённых экземпляров, наряду с операциями записи,
которые запускают новые экземпляры протокола.

Эти *операции чтения* должны направляться текущему лидеру системы, то есть, по сути, узлу, который успешно завершил последнее предложение.

Важно отметить, что этот узел не может ответить клиенту, используя свою локальную копию.

Причина этого в том, что другой узел мог тем временем сделать предложение (став новым лидером), что означает, что ответ не будет отражать
последнее состояние системы.

> Это означало бы, что операции консенсуса чтения/записи не были бы линеаризуемыми. Обратите внимание, что в контексте консенсуса операции,
> такие как предложения, считаются операциями над одним объектом. В результате нет необходимости в гарантиях изоляции.

В результате этому узлу придётся выполнить чтение с большинства узлов, чтобы по сути увидеть любое потенциальное новое предложение от
другого узла.

> К настоящему моменту мы должны понимать, как мажоритарный кворум может это гарантировать. Если нет, то, вероятно, было бы хорошей идеей
> пересмотреть урок о кворумах и их свойствах пересечения.

Это означает, что чтение может стать довольно медленным, поскольку оно должно будет выполняться в две фазы.

### Аренда лидерства (Leader leases)

Согласно Лэмсону (Lampson), «альтернативным вариантом, который работает как оптимизация, является использование техники, называемой *
*арендой (leases)**».

Используя этот подход, узел может взять в аренду, запустив экземпляр *Paxos*, установив момент времени, до которого он гарантированно будет
считаться лидером, и никакой другой узел не сможет его оспорить. Это означает, что этот узел может затем обслуживать операции чтения
локально.

Однако при реализации этого подхода необходимо учитывать **рассинхронизацию часов (clock skew)** и помнить, что он будет безопасен только
при наличии верхней границы рассинхронизации часов.

## Проблема при использовании нескольких экземпляров Paxos

По той же логике можно утверждать, что избрание лидера в каждом экземпляре протокола Paxos не является максимально эффективным и значительно
снижает **производительность** в нормальных условиях без большого количества сбоев.

Действительно, это так!

## Решение с помощью Multi-Paxos

Существует немного изменённая реализация *Paxos*, названная **Multi-Paxos** Дэвидом и соавторами (David et al.), которая решает эту
проблему.

В этом подходе узел, выполнивший последнее успешное предложение, считается текущим выделенным предлагающим (distinguished proposer). Это
означает, что узел может выполнить полный экземпляр *Paxos*, а затем для последующих экземпляров переходить сразу ко второй фазе, используя
тот же номер предложения, который был принят ранее.

Остальные узлы знают, какой узел в данный момент является лидером, основываясь на том, какой узел сделал последнее успешное предложение. Они
могут выполнять периодические проверки работоспособности. Если они считают, что этот узел вышел из строя, они могут инициировать запрос на
подготовку, чтобы выполнить успешное предложение и стать выделенным предлагающим.

По сути, это означает, что протокол гораздо более эффективен в стабильных условиях, поскольку имеет только одну фазу. При возникновении
сбоев протокол возвращается к обычному *Paxos*.

## Динамическое обновление узлов

Еще одна распространенная потребность — это способ динамического обновления узлов, являющихся членами системы. Ответ на это требование может
показаться знакомым благодаря элегантности протокола; информация о членстве может быть просто распространена как новое предложение Paxos!

Узлы, являющиеся членами системы, могут иметь свой собственный способ выявления сбоев других узлов (например, периодические проверки
работоспособности) и соответствующие политики того, когда узел следует считать вышедшим из строя. Когда узел считается вышедшим из строя,
один из узлов, обнаруживших это, может запустить новый экземпляр Paxos. Затем он предлагает новый список членов, который представляет собой
предыдущий список за вычетом вышедшего из строя узла. Как только это предложение будет завершено, все последующие экземпляры Paxos должны
использовать обновлённый список членов.