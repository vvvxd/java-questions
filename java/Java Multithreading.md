# Оглавление

1.  [Что такое Поток?](#что-такое-поток)
2.  [Почему создание потоков дорогостоящее?](#почему-создание-потоков-дорогостоящее)
3.  [Почему переключение между потоками дорогостоящее?](#почему-переключение-между-потоками-дорогостоящее)
4.  [Какие есть Cистемные потоки JVM?](#какие-есть-cистемные-потоки-jvm)
5.  [Что такое Программный счётчик (ПС)](#что-такое-программный-счетчик-пс)
6.  [Что такое Стек](#что-такое-стек)
7.  [Что такое Native стек](#что-такое-native-стек)
8.  [Что такое Ограничения стека](#что-такое-ограничения-стека)
9.  [Что такое Фрейм?](#что-такое-фрейм)
10. [Что такое Массив локальных переменных?](#что-такое-массив-локальных-переменных)
11. [Что такое Стек операндов?](#что-такое-стек-операндов)
12. [Что такое Constant Pool?](#что-такое-constant-pool)
13. [Что такое Run-Time Constant Pool?](#что-такое-run-time-constant-pool)
14. [В каком порядке выполняеться код?](#в-каком-порядке-выполняеться-код)
15. [Какие гарантии выполнения кода есть?](#какие-гарантии-выполнения-кода-есть)
16. [Расскажи про кеш в процесоре?](#расскажи-про-кеш-в-процесоре)
17. [Расскажите про Cache Coherence?](#расскажите-про-cache-coherence)
18. [Что происходит когда любое ядро хочет прочитать какой-нибудь адрес в памяти?](#что-происходит-когда-любое-ядро-хочет-прочитать-какой-нибудь-адрес-в-памяти)
19. [visibility проблемы на уровне процессора не существует?](#visibility-проблемы-на-уровне-процессора-не-существует)
20. [Что такое Store Buffer в процессоре?](#что-такое-store-buffer-в-процессоре)
21. [Благодаря Cache Coherence нам гарантируется eventual visibility?](#благодаря-cache-coherence-нам-гарантируется-eventual-visibility)
22. [Расскажите о модели памяти Java?](#расскажите-о-модели-памяти-java)
23. [Расскажите про Memory Ordering?](#расскажите-про-memory-ordering)
24. [Memory Ordering vs Instructions Ordering?](#memory-ordering-vs-instructions-ordering)
25. [Что такое Sequential Consistency?](#что-такое-sequential-consistency)
26. [Что такое Sequential Consistency-Data Race Free?](#что-такое-sequential-consistency-data-race-free)
27. [Что такое Data race в рамках JMM?](#что-такое-data-race-в-рамках-jmm)
28. [Расскажите про Happens-before?](#расскажите-про-happens-before)
29. [Расскажите про Monitor lock и как работает synchronized?](#расскажите-про-monitor-lock-и-как-работает-synchronized)
30. [Как работает synchronized?](#как-работает-synchronized)
31. [Расскажите про Memory Barriers?](#расскажите-про-memory-barriers)
32. [Расскажите про Volatile?](#расскажите-про-volatile)
33. [Расскажите про Atomicity и как это работает изнутри?](#расскажите-про-atomicity-и-как-это-работает-изнутри)
34. [Какие виды Atomic есть в java?](#какие-виды-atomic-есть-в-java)
35. [Атомарность базовых действий в JMM?](#атомарность-базовых-действий-в-jmm)
36. [В чём заключаются различия между java.util.concurrent.Atomic*.compareAndSwap() и java.util.concurrent.Atomic*.weakCompareAndSwap()](#в-чем-заключаются-различия-между-java-util-concurrent-atomic-compareandswap-и-java-util-concurrent-atomic-weakcompareandswap)
37. [Что такое «потокобезопасность»?](#что-такое-потокобезопасность)
38. [Что такое «кооперативная многозадачность»? Какой тип многозадачности использует Java? Чем обусловлен этот выбор?](#что-такое-кооперативная-многозадачность-какой-тип-многозадачности-использует-java-чем-обусловлен-этот-выбор)
39. [Чем отличается процесс от потока?](#чем-отличается-процесс-от-потока)
40. [Что такое «зелёные потоки» и есть ли они в Java?](#что-такое-зеленые-потоки-и-есть-ли-они-в-java)
41. [Каким образом можно создать поток?](#каким-образом-можно-создать-поток)
42. [Чем различаются Thread и Runnable?](#чем-различаются-thread-и-runnable)
43. [В чём заключается разница между методами start() и run()?](#в-чем-заключается-разница-между-методами-start-и-run)
44. [Как принудительно запустить поток?](#как-принудительно-запустить-поток)
45. [Дайте определение понятию «синхронизация».](#дайте-определение-понятию-синхронизация)
46. [В каких состояниях может находиться поток?](#в-каких-состояниях-может-находиться-поток)
47. [Можно ли создавать новые экземпляры класса, пока выполняется static synchronized метод?](#можно-ли-создавать-новые-экземпляры-класса-пока-выполняется-static-synchronized-метод)
48. [Зачем может быть нужен private мьютекс?](#зачем-может-быть-нужен-private-мьютекс)
49. [Как работают методы wait() и notify()/notifyAll()?](#как-работают-методы-wait-и-notify-notifyall)
50. [Чем отличаются методы Thread.sleep() и Thread.yield()?](#чем-отличаются-методы-thread-sleep-и-thread-yield)
51. [Как работает метод Thread.join()?](#как-работает-метод-thread-join)
52. [Как проверить, удерживает ли поток монитор определённого ресурса?](#как-проверить-удерживает-ли-поток-монитор-определенного-ресурса)
53. [Что значит «приоритет потока»?](#что-значит-приоритет-потока)
54. [Что такое «потоки-демоны»?](#что-такое-потоки-демоны)
55. [Можно ли сделать основной поток программы демоном?](#можно-ли-сделать-основной-поток-программы-демоном)
56. [Что значит «усыпить» поток?](#что-значит-усыпить-поток)
57. [Что такое Callable?](#что-такое-callable)
58. [Что такое FutureTask?](#что-такое-futuretask)
59. [Как остановить поток?](#как-остановить-поток)
60. [Почему не рекомендуется использовать метод Thread.stop()?](#почему-не-рекомендуется-использовать-метод-thread-stop)
61. [Что происходит, когда в потоке выбрасывается исключение?](#что-происходит-когда-в-потоке-выбрасывается-исключение)
62. [В чем разница между interrupted() и isInterrupted()?](#в-чем-разница-между-interrupted-и-isinterrupted)
63. [В чем заключаются различия между cтеком (stack) и кучей (heap) с точки зрения многопоточности?](#в-чем-заключаются-различия-между-cтеком-stack-и-кучей-heap-с-точки-зрения-многопоточности)
64. [Как получить дамп потока?](#как-получить-дамп-потока)
65. [Что такое ThreadLocal?](#что-такое-threadlocal)
66. [Как это работает "под капотом"? (ThreadLocal)](#как-это-работает-под-капотом)
67. [Утечки памяти и remove() (ThreadLocal)](#утечки-памяти-и-remove)
68. [Что такое «блокирующий метод»?](#что-такое-блокирующий-метод)
69. [Чем полезны неизменяемые объекты?](#чем-полезны-неизменяемые-объекты)
70. [Что такое busy spin?](#что-такое-busy-spin)
71. [Перечислите принципы, которым вы следуете в многопоточном программировании?](#перечислите-принципы-которым-вы-следуете-в-многопоточном-программировании)
72. [С какими распространенными проблемами вы столкнулись в многопоточной среде?](#с-какими-распространенными-проблемами-вы-столкнулись-в-многопоточной-среде)
73. [Разница между зеленым потоком и собственным потоком в Java?](#разница-между-зеленым-потоком-и-собственным-потоком-в-java)
74. [Может ли конструктор быть синхронизирован?](#может-ли-конструктор-быть-синхронизирован)
75. [Если два потока одновременно вызывают синхронизированный метод для разных экземпляров объекта, может ли один из этих потоков блокировать?](#если-два-потока-одновременно-вызывают-синхронизированный-метод-для-разных-экземпляров-объекта-может-ли-один-из-этих-потоков-блокировать)
76. [Расскажи про Future?](#расскажи-про-future)
77. [Расскажи про CompletableFuture?](#расскажи-про-completablefuture)
78. [Какие Синхронизаторы есть в java?](#какие-синхронизаторы-есть-в-java)
79. [Объект синхронизации Semaphore?](#объект-синхронизации-semaphore)
80. [Объект синхронизации CountDownLatch](#объект-синхронизации-countdownlatch)
81. [Объект синхронизации CyclicBarrier](#объект-синхронизации-cyclicbarrier)
82. [Объект синхронизации Exchanger](#объект-синхронизации-exchanger)
83. [Объект синхронизации Phaser](#объект-синхронизации-phaser)
84. [Расскажи на чем основаны обьекты синхранизации?](#расскажи-на-чем-основаны-обьекты-синхранизации)
85. [Что такое Lock?](#что-такое-lock)
86. [Что такое ReentrantLock?](#что-такое-reentrantlock)
87. [Как использовать ReadWriteLock?](#как-использовать-readwritelock)
88. [Когда используется StampedLock?](#когда-используется-stampedlock)
89. [Зачем выбирать ReentrantLock вместо synchronized?](#зачем-выбирать-reentrantlock-вместо-synchronized)
90. [Что такое Executor?](#что-такое-executor)
91. [Что такое ExecutorService?](#что-такое-executorservice)
92. [Что такое ThreadPoolExecutor и зачем он нужен?](#что-такое-threadpoolexecutor-и-зачем-он-нужен)
93. [Расскажи про FixedThreadPool?](#расскажи-про-fixedthreadpool)
94. [Расскажи про Executors.newCachedThreadPool()?](#расскажи-про-executors-newcachedthreadpool)
95. [Расскажи про SingleThreadExecutor?](#расскажи-про-singlethreadexecutor)
96. [Зачем нужен ScheduledExecutorService?](#зачем-нужен-scheduledexecutorservice)
97. [Что делает метод shutdown() и shutdownNow() у ExecutorService?](#что-делает-метод-shutdown-и-shutdownnow-у-executorservice)
98. [Какого размера должен быть пул потоков?](#какого-размера-должен-быть-пул-потоков)
99. [Что будет, если очередь пула потоков уже заполнена, но подаётся новая задача?](#что-будет-если-очередь-пула-потоков-уже-заполнена-но-подается-новая-задача)
100. [В чём заключается различие между методами submit() и execute() у пула потоков?](#в-чем-заключается-различие-между-методами-submit-и-execute-у-пула-потоков)
101. [Какими коллекциями пользоваться в многопоточной среде?](#какими-коллекциями-пользоваться-в-многопоточной-среде)
102. [Как внутри работает CopyOnWriteArrayList?](#как-внутри-работает-copyonwritearraylist)
103. [Как внутри работает CopyOnWriteArraySet?](#как-внутри-работает-copyonwritearrayset)
104. [Как ConcurrentHashMap работал до java 8?](#как-concurrenthashmap-работал-до-java-8)
105. [Как внутри работает ConcurrentHashMap?](#как-внутри-работает-concurrenthashmap)
106. [Как внутри работает ConcurrentSkipListMap?](#как-внутри-работает-concurrentskiplistmap)
107. [Как внутри работает ConcurrentLinkedDeque?](#как-внутри-работает-concurrentlinkeddeque)
108. [Как внутри работает ArrayBlockingQueue?](#как-внутри-работает-arrayblockingqueue)
109. [Даны 3 потока Т1, Т2 и Т3? Как реализовать выполнение в последовательности Т1, Т2, Т3?](#даны-3-потока-т1-т2-и-т3-как-реализовать-выполнение-в-последовательности-т1-т2-т3)
110. [Напишите минимальный неблокирующий стек (всего два метода — push() и pop()).](#напишите-минимальный-неблокирующий-стек-всего-два-метода-push-и-pop)
111. [Напишите минимальный неблокирующий стек (всего два метода — push() и pop()) с использованием Semaphore.](#напишите-минимальный-неблокирующий-стек-всего-два-метода-push-и-pop-с-использованием-semaphore)
112. [Напишите минимальный неблокирующий ArrayList (всего четыре метода — add(), get(), remove(), size()).](#напишите-минимальный-неблокирующий-arraylist-всего-четыре-метода-add-get-remove-size)
113. [Напишите потокобезопасную реализацию класса с неблокирующим методом BigInteger next(), который возвращает элементы последовательности: [1, 2, 4, 8, 16, ...].](#напишите-потокобезопасную-реализацию-класса-с-неблокирующим-методом-biginteger-next-который-возвращает-элементы-последовательности-1-2-4-8-16-)
114. [Напишите простейший многопоточный ограниченный буфер с использованием synchronized.](#напишите-простейший-многопоточный-ограниченный-буфер-с-использованием-synchronized)
115. [Напишите простейший многопоточный ограниченный буфер с использованием ReentrantLock.](#напишите-простейший-многопоточный-ограниченный-буфер-с-использованием-reentrantlock)
116. [Что такое double checked locking Singleton?](#что-такое-double-checked-locking-singleton)
117. [Как создать потокобезопасный Singleton?](#как-создать-потокобезопасный-singleton)


---

## Что такое Поток?

[⬆️ К оглавлению](#оглавление)

Поток — это поток выполнения программы. JVM позволяет приложению иметь несколько потоков выполнения одновременно (concurrently). В Hotspot JVM существует прямое соответствие между Java потоком и native потоком операционной системы. После подготовки всех компонентов Java потока таких как thread‑local хранилище, allocations буферы, объекты синхронизации, стеки и программные счётчики будет создан native поток. Native поток (операционной системы) освобождается как только Java поток завершается1. Операционная система ответственна за планировку и распределение потоков на любом доступном процессоре. Как только native поток инициализирован он вызывает метод run() в Java потоке. Когда run() метод возвращает значение, обрабатываются неперехваченные исключения, потом native поток подтверждает нужно ли завершить работу JVM (needs to be terminated) после завершения потока (напр. последний non‑daemon thread — main). Когда поток завершается все ресурсы native потока и Java потока освобождаются.

---

## Почему создание потоков дорогостоящее?

[⬆️ К оглавлению](#оглавление)

Создание потока (`Thread`) в Java влечёт значительные затраты ресурсов по следующим причинам:

1.  **Выделение памяти для стека потока**:
    *   Каждый поток в JVM имеет собственный стек вызовов (thread stack), который используется для хранения локальных переменных, кадров вызовов методов и другой информации о выполнении.
    *   По умолчанию размер стека потока в Java составляет 1 МБ (можно настроить с помощью флага `-Xss`, например, `-Xss512k`). Выделение этой памяти требует обращения к операционной системе, что является дорогостоящей операцией.
    *   Пример: Если создать 1000 потоков с размером стека 1 МБ, это потребует 1 ГБ памяти только для стеков, не считая других ресурсов.

2.  **Инициализация системных ресурсов**:
    *   Создание потока в Java (через `new Thread()`) приводит к созданию нативного потока в операционной системе (OS thread). Это требует системных вызовов (например, `pthread_create` в Linux или аналогов в других ОС).
    *   ОС должна:
        *   Зарегистрировать поток в своём планировщике.
        *   Выделить дескрипторы (handles) и другие системные ресурсы.
        *   Инициализировать структуры данных для управления потоком.
    *   Эти операции требуют времени и ресурсов, особенно если ОС работает под высокой нагрузкой.

3.  **Инициализация JVM-структур**:
    *   JVM создаёт внутренние структуры для каждого потока, такие как `Thread` объект, который содержит метаданные (имя потока, приоритет, состояние и т.д.).
    *   Также JVM выполняет дополнительные действия, такие как регистрация потока в пуле потоков или настройка контекста выполнения.

4.  **Кэш-память и процессорные ресурсы**:
    *   Новый поток не имеет "тёплого" кэша процессора (cache misses), что приводит к дополнительным затратам на загрузку данных в кэш.
    *   Если поток начинает выполняться на новом процессорном ядре, это может вызвать затраты на синхронизацию кэшей между ядрами (cache coherence).

**Итог**: Создание одного потока может занять от **нескольких микросекунд до десятков микросекунд** (в зависимости от системы), а также требует значительного объёма памяти и системных ресурсов. Создание тысяч потоков может быстро исчерпать ресурсы системы, особенно в средах с ограниченной памятью.

---

## Почему переключение между потоками дорогостоящее?

[⬆️ К оглавлению](#оглавление)

Переключение контекста между потоками (context switching) также является ресурсоёмкой операцией. Основные причины:

1.  **Сохранение и восстановление состояния потока**:
    *   При переключении между потоками ОС должна сохранить текущее состояние одного потока (регистры процессора, указатель стека, программный счётчик) и восстановить состояние другого потока.
    *   Это включает:
        *   Сохранение регистров CPU (например, регистры общего назначения, указатели).
        *   Обновление указателя стека и других системных структур.
        *   Переключение адресного пространства (в некоторых случаях, если потоки принадлежат разным процессам).
    *   Эти операции выполняются на уровне ядра ОС и требуют времени (обычно 1–10 мкс на современных системах).

2.  **Потеря кэша процессора**:
    *   Когда поток приостанавливается, данные в кэше процессора (L1, L2, L3) могут стать недействительными (cache invalidation).
    *   Новый поток, вероятно, будет работать с другими данными, что приводит к кэш-промахам (cache misses) и необходимости загрузки данных из оперативной памяти, что значительно медленнее.

3.  **Планирование потоков (Scheduling)**:
    *   Планировщик ОС решает, какой поток будет выполняться на процессорном ядре. Это требует:
        *   Проверки приоритетов потоков.
        *   Управления очередями потоков (ready queue, waiting queue).
        *   Обработки прерываний от таймера ОС.
    *   Планирование добавляет оверхед, особенно если много потоков конкурируют за процессорное время.

4.  **Синхронизация и конкуренция**:
    *   Если потоки используют общие ресурсы (например, замки или общую память), переключение контекста может сопровождаться синхронизацией, что увеличивает затраты.
    *   Например, попытка захватить замок (`synchronized` или `ReentrantLock`) может привести к приостановке потока, если замок занят, что вызывает дополнительное переключение контекста.

5.  **NUMA и многопроцессорные системы**:
    *   В системах с NUMA (Non-Uniform Memory Access) переключение потока на другое ядро или процессор может привести к доступу к памяти, расположенной на другом узле, что увеличивает задержки.

**Итог**: Переключение контекста обычно занимает **1–10 микросекунд**, но при высокой конкуренции за ресурсы (много потоков, частые переключения) затраты могут значительно возрастать, снижая производительность приложения.

---

## Какие есть Cистемные потоки JVM?

[⬆️ К оглавлению](#оглавление)

Если использовать jconsole или любой отладчик, то можно увидеть несколько потоков запущенных в фоновом режиме. Эти фоновые потоки запускаются в дополнении к основному потоку, который создаётся как часть вызова
public static void main(String[]) и любого потока созданного основным потоком.

Вот данные в формате таблицы Markdown:

| Вид потока | Описание |
| - | - |
| Потоки виртуальной машины | Ожидают появления операций, которые нужны JVM для достижения безопасной точки (safe-point). Причина, по которой эти операции должны выполняться в отдельном потоке, заключается в том, что все они требуют, чтобы JVM находилась в безопасной точке, где модификации кучи не могут произойти. Тип операций, выполняемых этим потоком сборка мусора "stop-the-world", дамп стека потока, приостановка потока (thread suspension) и biased locking revocation. |
| Поток периодической задачи | Отвечает за события таймера (прерывания), которые используются для планирования выполнения периодических задач. |
| GC | Сборки мусора различного типа, которые появляются в JVM |
| Потоки компилятора | Компилируют байт-код в машинный код при выполнении программы (runtime) |
| Поток диспетчера сигналов (signal dispatcher thread) | Получает сигналы отправленные JVM процессу и обрабатывает их внутри JVM, вызывая соответствующие JVM методы. |

---

## Что такое Программный счётчик (ПС)

[⬆️ К оглавлению](#оглавление)

Если текущий метод является native методом, тогда ПС не определён, иначе содержит адрес текущей инструкции (или опкод). Все процессоры имеют программный счётчик, обычно ПС инкрементируется после каждой инструкции и, таким образом, хранит адрес следующей инструкции, которая должна быть выполнена. JVM использует ПС для отслеживания того, где она выполняет инструкции, ПС на самом деле будет указывать на адрес памяти в области методов.

---

## Что такое Стек

[⬆️ К оглавлению](#оглавление)

Каждый поток имеет свой собственный стек, в котором хранится фрейм для каждого метода, выполняющегося в этом потоке. Стек это LIFO (Last In First Out — последний пришел, первый вышел) структура данных, поэтому текущий выполняющийся метод находится на вершине стека. При каждом вызове метода создаётся новый фрейм.

Напрямую стек не модифицируют, кроме как добавления (push) и удаления (pop) объектов фрейма и поэтому объекты фрейма могут быть аллоцированы в куче (Heap) и нет необходимости в том, чтобы память под эти объекты была непрерывной (contiguous).

---

## Что такое Native стек

[⬆️ К оглавлению](#оглавление)

Не все JVM поддерживают native методы, однако те, которые поддерживают обычно создают native стек на каждый Java поток. Если JVM была реализована используя C‑linkage модель для Java Native Invocation (JNI) тогда native стек будет как в Си. В этом случае порядок аргументов и возвращаемое значение будет точно такие же как и в обычной программе на языке Си. Native метод обычно может (зависит от реализации JVM) вызывать Java метод в JVM. Такой вызов будет происходить на Java стеке. Поток покинет native стек и создаст новый фрейм в Java стеке.

---

## Что такое Ограничения стека

[⬆️ К оглавлению](#оглавление)

Стек может быть фиксированного или переменного размера. В случае когда поток запрашивает стек большего размера, чем разрешено, то произойдёт ошибка StackOverflowError. Если поток запрашивает новый фрейм, а памяти для его выделения не хватает, тогда произойдёт ошибка OutOfMemoryError.

---

## Что такое Фрейм?

[⬆️ К оглавлению](#оглавление)

Новый фрейм создаётся и добавляется (pushed) на вершину стека при каждом вызове метода. Фрейм удаляется (popped), когда метод штатно завершается, или, если во время выполнения метода возникло необработанное исключение. Более подробная информация по обработке исключений будет дана в Таблице Исключений.

Каждый фрейм содержит:

*   Массив локальных переменных
*   Возвращаемое значение
*   Стек операндов
*   Ссылку на runtime constant pool для класса текущего метода

---

## Что такое Массив локальных переменных?

[⬆️ К оглавлению](#оглавление)

Массив локальных переменных содержит все переменные, которые нужны при выполнении метода, включая ссылку на this, все параметры метода и другие локальные переменные. Для методов класса (статических методов) параметры метода отсчитываются от нуля, однако для метода экземпляра класса нулевой слот зарезервирован для this.

Локальные переменные могут иметь следующий тип: boolean, byte, char, long, short, int, float, double, ссылка (reference), возвращаемый адрес (returnAddress).

Все типы занимают один слот в массиве локальных переменных, исключая long и double, которые занимают два последовательных слота так как эти типы имеют размер 64 бита, вместо 32 бит.

---

## Что такое Стек операндов?

[⬆️ К оглавлению](#оглавление)

Cтек операндов используется во время выполнения инструкций байт‑кода и работает подобно регистрам общего назначения в процессоре. Большая часть JVM байт‑кода содержит операции со стеком операндов, добавляя (push), удаляя(pop), дублируя, меняя местами (swap) или выполняя операции, которые производят или потребляют значения. Таким образом, инструкции, которые перемещают значения между массивом локальных переменных и стеком операндов очень часто встречаются в байт‑коде. Например, простая инициализация переменной будет представлена в виде двух инструкций байт‑кода, которые взаимодействуют со стеком операндов.

int i; компилируется в следующий байт-код:

```java
0: iconst_0  // добавить 0 на вершину стека операндов
1: istore_1  // считать значение из стека операндов и сохранить как локальную переменную с номером 1.
```

За более детальным объяснением взаимодействия между массивом локальных переменных, стеком операндов и runtime constant pool обращайтесь к секции Структура Файла Класса ниже.

---

## Что такое Constant Pool?

[⬆️ К оглавлению](#оглавление)

**Constant Pool** — это статическая таблица констант, которая создаётся компилятором Java (javac) и хранится в файле `.class` для каждого класса или интерфейса. Она содержит все константы, используемые в коде класса, такие как строковые литералы, числовые значения, ссылки на классы, методы и поля.

*   **Где находится**: В `.class`-файле, сразу после заголовка (magic number, версии и т.д.).
*   **Формат**: Таблица, где каждая запись имеет:
    *   Тег (1 байт), определяющий тип константы.
    *   Данные, зависящие от типа.
*   **Типы записей**:
    *   `CONSTANT_Utf8`: Строки (имена классов, методов, строковые литералы).
    *   `CONSTANT_Integer`, `CONSTANT_Float`, `CONSTANT_Long`, `CONSTANT_Double`: Числовые константы.
    *   `CONSTANT_Class`: Ссылка на класс.
    *   `CONSTANT_String`: Строковый литерал, ссылающийся на `CONSTANT_Utf8`.
    *   `CONSTANT_Fieldref`, `CONSTANT_Methodref`, `CONSTANT_InterfaceMethodref`: Ссылки на поля, методы и методы интерфейсов.
    *   `CONSTANT_NameAndType`: Пары имя/дескриптор.
    *   `CONSTANT_MethodHandle`, `CONSTANT_MethodType`, `CONSTANT_InvokeDynamic` (с Java 7): Для динамических языковых конструкций.
*   **Назначение**: Хранит символические ссылки (symbolic references) и константы, которые JVM использует для выполнения программы.
*   **Пример**: Для строки `"Hello"` в коде в Constant Pool будет `CONSTANT_String`, ссылающийся на `CONSTANT_Utf8` с содержимым `"Hello"`.

Constant Pool неизменяем и создаётся на этапе компиляции.

---

## Что такое Run-Time Constant Pool?

[⬆️ К оглавлению](#оглавление)

**Run-Time Constant Pool** — это динамическая структура в памяти JVM, создаваемая на основе Constant Pool при загрузке класса в **Method Area** (или **Metaspace** в Java 8+). Она используется во время выполнения программы и может изменяться.

*   **Где находится**: В памяти JVM, в Metaspace.
*   **Создание**: Формируется при загрузке класса загрузчиком классов (ClassLoader) на основе Constant Pool из `.class`-файла.
*   **Особенности**:
    *   **Динамическое разрешение ссылок**: Символические ссылки (например, `CONSTANT_Methodref`) преобразуются в прямые ссылки на объекты, методы или поля в памяти. Этот процесс называется **resolution**.
    *   **Интернирование строк**: Строковые литералы из `CONSTANT_String` помещаются в **String Pool** (часть Run-Time Constant Pool), что позволяет экономить память.
    *   **Поддержка динамических конструкций**: Содержит данные для `invokedynamic` (например, для lambda-выражений).
*   **Назначение**:
    *   Предоставляет JVM быстрый доступ к константам.
    *   Обеспечивает динамическое связывание (dynamic linking) классов, методов и полей.
    *   Хранит интернированные строки и разрешённые ссылки.
*   **Пример**: Если в коде есть вызов метода `System.out.println`, Run-Time Constant Pool сначала содержит символическую ссылку на `println`, а после разрешения — прямой адрес метода в памяти.

---

## В каком порядке выполняеться код?

[⬆️ К оглавлению](#оглавление)

В современном мире код часто выполняется не в том порядке, в котором он был написан в программе. Он часто переупорядочивается на уровне:

*   Компилятора байткода (в частности, javac)
*   Компилятора машинного кода (в частности, JIT компилятор HotSpot C1/C2). Например, среди компиляторов широко распространена такая оптимизация как Instruction scheduling
*   Процессора. Например, в мире процессоров широко распространены такие практики как Out-of-order execution, Branch Prediction + Speculation, Prefetching, а также многие другие

Также в современных процессорах каждое ядро имеет собственный локальный кэш, который не видим другим ядрам. Более того, записи могут удерживаться в регистрах процессора, а не сбрасываться в память. Это ведет к тому, что поток может не видеть изменений, сделанных из других потоков.

Все эти оптимизации делаются с целью повысить производительность программ:

*   Переупорядочивание необходимо для того, чтобы найти самый оптимальный путь к выполнению кода, учитывая стоимость выполнения процессорных инструкций. Например, процессор может инициировать загрузку значения из памяти заранее, даже если в порядке программы это чтение идет позднее. Операции чтения из памяти стоят дорого, поэтому эта оптимизация позволяет максимально эффективно утилизировать процессор, избежав простаивания, когда это чтение действительно понадобится
*   Чтение из регистра и кэша стоит сильно дешевле, чем чтение из памяти. Более того, локальный кэш необходим для того, чтобы ядра не простаивали в ожидании доступа к общему кэшу, а могли работать с кэшем независимо друг от друга

---

## Какие гарантии выполнения кода есть?

[⬆️ К оглавлению](#оглавление)

Java дает гарантию as-if-serial выполнения кода — вне зависимости от используемой JDK итоговый результат выполнения будет не отличим от такого порядка, как если бы действия выполнялись действительно последовательно согласно порядку в коде
Процессоры тоже делают только такие переупорядочивания, которые не изменят итогового результата выполнения инструкций
Процессоры имеют Cache Coherence механизм, который гарантирует консистентность данных среди локальных кэшей: как только значение попадает в локальный кэш одного ядра, оно будет видно всем остальным ядрам

Но есть проблемы в многопоточной среде

Java дает as-if-serial гарантию только для единственного треда в изоляции. Это означает, что в многопоточной программе при работе с shared данными мы можем не увидеть записи там, где полагаемся на порядок выполнения действий в коде другого треда. Другими словами, для первого треда в изоляции валидно переупорядочивать инструкции местами, если это не повлияет на его результат выполнения, но переупорядочивание может повлиять на другие треды
Процессор также дает гарантию только для единственного ядра в изоляции
Cache Coherence действительно гарантирует чтение актуальных значений, но пропагация записи происходит не мгновенно, а с некоторой задержкой

---
## Расскажи про кеш в процесоре?

[⬆️ К оглавлению](#оглавление)

![img.png](img/Кеш.png)

Процессор никогда не работает с памятью напрямую — все операции чтения и записи проходят через кэш. Когда процессор хочет загрузить значение из памяти, то он обращается в кэш. Если значения там нет, то кэш сам ответственнен за выгрузку значения из памяти с последующим сохранением в кэше. Когда процессор хочет записать значение в память, то он записывает значение в кэш, который в свою очередь ответственен за сброс значения в память
Кэш состоит из множества "линий" (cache line) фиксированного размера, в которые кладутся значения из памяти. Размер линий варьируется от 16 до 256 байт в зависимости от архитектуры процессора. Кэш сам знает, как мапить адрес линии кэша в адрес памяти
Кэш имеет фиксированный размер, поэтому может хранить ограниченное количество записей. Например, если размер кэша 64 KB, а размер линии кэша 64 байт, то всего кэш может содержать 1024 линии. Поэтому, если при выгрузке нового значения места в кэше не хватает, то из кэша вымещается одно из значений
Большинство современных архитектур процессоров имеют несколько уровней кэша: обычно это L1, L2, и L3. Верхние уровни кэша (L1, L2) являются локальными — каждое ядро процессора имеет собственный, отдельный от других ядер кэш. Кэш на самом нижнем уровне (L3) является общим и шарится между всеми ядрами
Доступ к каждому последующему уровню кэша стоит дороже, чем к предыдущему. Например, доступ к L1 может стоить 3 цикла, L2 — 12 циклов, а к L3 — 38 циклов
Каждый последующий кэш имеет больший размер, чем предыдущий. Например, L1 может иметь размер 80 KB, L2 — 1.25 MB, а L3 — 24 MB

Из-за того, что ядра имеют собственный локальный кэш, возникает потенциальная проблема чтения неактуальных значений. Например, пусть два ядра прочитали одно и то же значение из памяти и сохранили в свой локальный кэш. Затем первое ядро записывает новое значение в свой локальный кэш, но другое ядро не видит этого изменения и продолжает читать устаревшее значение. Как итог, данные среди локальных кэшей не консистентны. Если бы в процессоре существовал только общий кэш, то проблемы чтения неактуальных значений просто не существовало бы: так как все записи и чтения проходят через кэш, а не идут напрямую в память, то общий кэш по сути был бы master копией памяти, где всегда лежали бы актуальные значения. Но это сильно ударило бы по производительности процессора, так как кэш может обрабатывать только один цикл единовременно, а значит ядра простаивали бы в очереди. Более того, локальный кэш распаян физически ближе к ядру, поэтому доступ к нему стоит дешевле. Именно поэтому и необходим локальный кэш, чтобы каждое ядро могло эффективно работать с кэшем независимо от других ядер.

---
## Расскажите про Cache Coherence?

[⬆️ К оглавлению](#оглавление)

На самом деле, процессоры умеют поддерживать консистентность данных среди локальных кэшей так, что любое из ядер всегда читает актуальное значение одного и того же адреса памяти.

Cache Coherence (когерентность кэша) — это механизм процессора, гарантирующий, что любое ядро всегда читает самое актуальное значение из кэша. Данным механизмом обладают многие современные архитектуры процессоров в той или иной имплементации. Самый популярный из протоколов — это MESI протокол и его производные. Например, Intel использует MESIF, а AMD — MOESI протокол.

В MESI протоколе линия кэша может находиться в одном из следующих состояний:

*   Invalid — линия кэша устарела (содержит неактуальные значения), поэтому из нее нельзя читать
*   Shared — линия кэша актуальна и эквивалентна памяти. Процессор может только читать из такой линии кэша, но не писать в нее. Если несколько ядер читают один и тот же адрес памяти, то эта линия кэша будет реплицирована сразу в несколько локальных кэшей, отсюда и название "shared"
*   Exclusive — линия кэша актуальна и эквивалентна памяти. Однако как только одно из ядер процессора переводит линию кэша в это состояние, никакое другое ядро не может держать эту линию кэша у себя, отсюда и название "exclusive". Когда значение из памяти только первые загружается в кэш, то линия кэша устанавливается именно в это состояние. Если одно из ядер процессора хочет перевести линию кэша из shared в exclusive состояние, то все остальные ядра должны пометить свою копию как invalid
*   Modified — линия кэша была изменена (dirty), то есть ядро записало в нее новое значение. Именно в это состояние переходит exclusive линия кэша после записи в нее. Аналогично, только одно из ядер процессора может держать линию кэша в Modified состоянии. Если линия вымещается из кэша, то кэш ответственен за то, чтобы записать новое значение в память перед выгрузкой

Когда одно из ядер процессора хочет изменить линию кэша, то оно должно установить exclusive доступ к ней. Для этого ядро посылает всем остальным ядрам сообщение о том, что указанную линию кэша необходимо пометить как invalid в их локальном кэше. Только после того, как ядра обработают запрос, пометив свою копию как invalid, ядро сможет записать новое значение вместе с этим помечая линию кэша как modified. Таким образом, при записи только одно ядро может удерживать значение в локальном кэше, а значит неконсистентность данных просто невозможна.

---
## Что происходит когда любое ядро хочет прочитать какой-нибудь адрес в памяти?

[⬆️ К оглавлению](#оглавление)

Ядро обращается в L1 кэш и проверяет, присутствует ли там искомое значение. Если линия кэша присутствует и находится в состоянии Shared, Exclusive или Modified, то происходит ее чтение. Если значение в локальном кэше не обнаружено (или линия кэша находится в состоянии Invalid), то говорится, что произошел (local) "cache miss"
По специальной общей шине всем остальным ядрам передается запрос на чтение значения. Все остальные ядра видят этот запрос, и если одно из ядер содержит искомое значение в состоянии Shared, Exclusive или Modified, то оно отдает актуальное значение в ответ.
Если линия кэша была установлена в Modified состояние, то перед тем как отдать значение, измененное значение сбрасывается в память, а затем линия кэша переводится в Shared состояние
Если значение не обнаружено ни в одном из локальных кэшей, то происходит чтение из памяти
Вне зависимости от того, где мы нашли значение, читающее ядро сохраняет данные в свой локальный кэш, помечая линию кэша как shared

Это очень упрощенное описание работы кэша — я опустил многие детали, но надеюсь, что примерная картина вам понятна. Скажу сразу, что я не претендую на полную корректность вышенаписанного: где-то я мог и соврать, ибо не являюсь специалистом в такой низкоуровневой теме как процессоры. Более того, многие моменты могут отличаться в зависимости от микроархитектуры процессора и используемого Cache Coherence протокола. В конце статьи я приведу ссылки на другие полезные источники, где вы сможете узнать подробнее о работе кэша.

Таким образом, как только значение попадает в локальный кэш, оно сразу же становится видно другим ядрам.

---
## visibility проблемы на уровне процессора не существует?

[⬆️ К оглавлению](#оглавление)

Когда ядро получает запрос на инвалидацию записи в кэше, он может быть обработан не сразу, а поставиться в очередь Invalidation Queue (IQ). Эта оптимизация необходима по следующим причинам: во-первых, ядро может быть занято другой работой, и во-вторых, мы хотим, чтобы при большом количестве запросов ядро не заблокировалось на долгое время в их обработке, а обработало все постепенно. Таким образом, можно сказать, что invalidate запросы являются асинхронными

Проблема в том, что мы рискуем не прочитать самое актуальное значение просто потому, что запрос в invalidation queue еще не был обработан, а в кэше лежало еще не инвалидированное, но уже устаревшее значение.

---
## Что такое Store Buffer в процессоре?

[⬆️ К оглавлению](#оглавление)

![img.png](img/full_cache.png)

В некоторых микро-архитектурах (как x86) каждое ядро имеет локальный FIFO Store Buffer (SB, write buffer), который является прослойкой между CPU и кэшем. В этот буфер ядро кладет все записи, которые будут ожидать там сброса в локальный кэш до тех пор, пока все остальные ядра не инвалидируют эту запись в своем кэше и не пришлют acknowledgement. Эта оптимизация требуется для того, чтобы не задерживать работу пишущего ядра, пока остальные ядра обрабатывают запрос на инвалидацию. При чтении ядро сперва смотрит в свой SB перед тем, как идти в локальный кэш, чтобы избежать чтения неактуальных значений и таким образом поддержать as-if-serial гарантию внутри одного ядра

Проблема в том, что другие ядра не увидят новой записи, пока пишущее ядро не сбросит запись из SB в локальный кэш, так как SB — это часть ядра, но не кэша. Другими словами, Cache Coherence механизм не распространяется на Store Buffer. Соответственно, некоторый промежуток времени пишущее ядро будет оперировать актуальным значением, но все остальные — устаревшим.

---
## Благодаря Cache Coherence нам гарантируется eventual visibility?

[⬆️ К оглавлению](#оглавление)

Можно наивно предположить, что благодаря Cache Coherence нам гарантируется eventual visibility и на уровне Java для обычных записей и чтений, то есть не связанных happens-before. Однако, это не правда, так как мы работаем на уровне языка, а не процессора. Компилятор может оптимизировать код так, что запись никогда не станет видна другому треду. Яркий пример — это такой busy wait, где в бесконечном цикле проверяется значение shared переменной.

---
## Расскажите о модели памяти Java?

[⬆️ К оглавлению](#оглавление)

Модель памяти Java (Java Memory Model, JMM) описывает поведение потоков в среде исполнения Java. Это часть семантики языка Java, набор правил, описывающий выполнение многопоточных программ и правил, по которым потоки могут взаимодействовать друг с другом посредством основной памяти.
Формально модель памяти определяет набор действий межпоточного взаимодействия (эти действия включают в себя, в частности, чтение и запись переменной, захват и освобождений монитора, чтение и запись volatile переменной, запуск нового потока), а также модель памяти определяет отношение между этими действиями -happens-before - абстракции обозначающей, что если операция X связана отношением happens-before с операцией Y, то весь код следуемый за операцией Y, выполняемый в одном потоке, видит все изменения, сделанные другим потоком, до операции X.

---
## Расскажите про Memory Ordering?

[⬆️ К оглавлению](#оглавление)

Memory Ordering описывает наблюдаемый программой порядок, в котором происходят действия с памятью.

Смотрите: со стороны программы есть только действия записи/чтения и их порядок в коде. Также со стороны программы кажется, что мы имеем единую общую память, записи в которую становятся сразу видны другим тредам. Программа не подозревает ни о каких instruction scheduling reordering/out-of-order execution/caching/register allocation и прочих оптимизациях под капотом. Если по какой-то причине мы наблюдаем результат, не консистентный с порядком в программе, то со стороны программы (высокоуровнево) это выглядит так, что действия c памятью просто были переупорядочены. Другими словами, порядок взаимодействия с памятью (memory order) может отличаться от порядка действий в коде (program order).

Для большего понимания давайте взглянем на уже знакомую нам программу с точки зрения Memory Ordering:

```
Thread 0    Thread 1
x = 1       y = 1
r1 = y      r2 = x
```

В случае результата выполнения (r1, r2) = (0, 0) мы можем просто сказать, что произошел StoreLoad memory reordering, то есть запись произошла после чтения. Не важно, по какой низкоуровневой причине это случилось, а важно лишь то, что в итоге со стороны программы действия с памятью были выполнены в неконсистентном порядке.

Таким образом, в многопоточной программе нам важно знать ответы на следующие вопросы:

*   Как сохраняется порядок программы при работе с памятью?
*   Валиден ли наблюдаемый memory order?

Дать ответ на каждый из вопросов — это и есть задача модели памяти. Java Memory Model разрешает все возможные переупорядочивания в отсутствие синхронизации, поэтому ответ на эти вопросы такой:

*   Если программа не синхронизирована, то разрешены все переупорядочивания. Если программа правильно синхронизирована, запрещены все переупорядочивания
*   Если программа не синхронизирована, то memory order, неконсистентный с program order, валиден с точки зрения JMM. Если программа правильно синхронизирована, то валиден только консистентный порядок

Ваша программа отрабатывает в одном из порядков, валидных с точки зрения JMM. Таким образом, если программа не правильно синхронизирована, не стоит удивляться некорретному результату выполнения. Ведь важно то, валиден ли результат выполнения с точки зрения модели памяти, а не то, валиден он или нет для вас как пользователя.

Однако то, что какой-то неконсистентный порядок валиден, еще не значит, что вы всегда получите некорректный результат, ведь и консистентный порядок возможен в отсутствие синхронизации — это вы могли видеть по jcstress тесту, который является вероятностным. Понятно, что вы не хотите надеяться на волю случая, поэтому необходимо ограничить возможный сет порядков выполнения до только консистентных. А для этого необходимо использовать предоставляемые моделью примитивы синхронизации, которые мы рассмотрим позднее.

В свою очередь, Memory Reordering — это высокоуровневое понятие, которое абстрагирует и обобщает низкоуровневые проблемы, которые мы рассматривали выше. Всего существует 4 типа memory reordering:

*   LoadLoad: переупорядочивание чтений с другими чтениями. Например, действия r1, r2 могут выполниться в порядке r2, r1
*   LoadStore: переупорядочивание чтений с записями, идущими позже в порядке программы. Например, действия r, w могут выполниться в порядке w, r
*   StoreStore: переупорядочивание записей с другими записями. Например, действия w1, w2 могут выполниться в порядке w2, w1
*   StoreLoad: переупорядочивание записей с чтениями, идущими позже в порядке программы. Например, действия w, r могут выполниться в порядке r, w

В дальнейшем, когда я буду говорить "переупорядочивание" или "reordering", я буду иметь в виду именно Memory Reordering, если не сказано обратное.

Memory Model описывает, какие переупорядочивания возможны. В зависимости от строгости модели памяти подразделяются на следующие типы:

*   Sequential Consistency: запрещены все переупорядочивания
*   Relaxed Consistency: разрешены некоторые переупорядочивания
*   Weak Consistency: разрешены все переупорядочивания

Модель памяти существует как на уровне языка, так и на уровне процессора, но они не связаны напрямую. Модель языка может предоставлять как более слабые, так и более строгие гарантии, чем модель процессора.

В частности, как уже было сказано выше, Java Memory Model не дает никаких гарантий, пока не использованы необходимые примитивы синхронизации. И напротив, посмотрите на главу Memory Ordering из Intel Software Developer’s Manual:

*   Reads are not reordered with other reads \[запрещает LoadLoad reordering]
*   Writes are not reordered with older reads \[запрещает LoadStore reordering]
*   Writes to memory are not reordered with other writes \[запрещает StoreStore reordering]
*   Reads may be reordered with older writes to different locations but not with older writes to the same location \[разрешает StoreLoad reordering]

Как видите, Intel разрешает только StoreLoad переупорядочивания, а все остальные запрещены. Да, модель памяти x86 достаточно строга, но есть и намного более слабые модели памяти процессоров — например, ARM разрешает все переупорядочивания.

Однако даже если вы пишете программу под x86, вам все равно необходимо считаться с более слабой Java Memory Model, так как последняя разрешает все переупорядочивания на уровне компилятора. Модель памяти языка — прежде всего.

---
## Memory Ordering vs Instructions Ordering?

[⬆️ К оглавлению](#оглавление)

Memory Ordering и Instructions Ordering — это не одно и то же. Инструкции могут переупорядочиваться под капотом как угодно, но их memory effect должен подчиняться некоторым Memory Ordering правилам, которые гарантируются (или не гарантируются) Memory Model. Наконец, memory ordering — это высокоуровневое понятие, созданное для простоты понимания работы с памятью.

Например, Intel запрещает LoadLoad переупорядочивания, но под капотом все равно делает спекулятивные чтения. Как это возможно? Дело в том, что процессор следит за тем, чтобы результат выполнения инструкций не нарушал memory ordering правил. Если какое-то правило нарушается, то процессор возвращается к более раннему состоянию: результат чтения отбрасывается, а записи не коммитятся в память.

---
## Что такое Sequential Consistency?

[⬆️ К оглавлению](#оглавление)

Sequential Consistency Model (SC) — это очень строгая модель памяти, которая гарантирует отсутствие переупорядочиваний.

Интуитивно SC можно понять очень просто: возьмите действия тредов, как они идут в порядке программы, и просто выполните их последовательно, возможно переключаясь между тредами.

Формальное определение SC также достаточно простое:

\[Lamport, 1979 — How to Make a Multiprocessor Computer That Correctly Executes Multiprocess Programs] ...the result of any execution is the same as if the operations of all the processors were executed in some sequential order, and the operations of each individual processor appear in this sequence in the order specified by its program.
Давайте разберем SC на примере. Возьмем все тот же Dekker lock, который мы рассматривали выше:

```
Thread 0    Thread 1
x = 1       y = 1
r1 = y      r2 = x
```

В SC модели могут быть следующие memory order и никакие больше:

*   write(x, 1) -> write(y, 1) -> read(y):1 -> read(x):1
*   write(x, 1) -> write(y, 1) -> read(x):1 -> read(y):1
*   write(x, 1) -> read(y):0 -> write(y, 1) -> read(x):1

*   write(y, 1) -> write(x, 1) -> read(x):1 -> read(y):1
*   write(y, 1) -> write(x, 1) -> read(y):1 -> read(x):1
*   write(y, 1) -> read(x):0 -> write(x, 1) -> read(y):1

Назовем такие порядки "sequentially consistent memory orders".

А вот такой memory order, где присутствуют StoreLoad переупорядочивания и которые дают нам результат (r1, r2) = (0, 0), запрещен в SC:

*   read(y):0 -> read(x):0 -> write(x, 1) -> write(y, 1)

---
## Что такое Sequential Consistency-Data Race Free?

[⬆️ К оглавлению](#оглавление)

Java Memory Model — это Sequential Consistency-Data Race Free (SC-DRF) модель: нам предоставляется sequential consistency, но только в том случае, если мы избавимся от всех data race в программе — про это мы еще поговорим далее.

---
## Что такое Data race в рамках JMM?

[⬆️ К оглавлению](#оглавление)

Data race возникает тогда, когда с shared данными работает одновременно два или больше тредов, где как минимум один из них пишет и их действия не синхронизированы. Для действий в гонке не гарантируется никакого консистентного memory order, поэтому не стоит удивляться неожиданным результатам.

Data race в рамках JMM — это ключевая вещь, которая формально отличает SC и не-SC выполнения: если мы докажем, что никакое выполнение нашей программы не имеет гонок, то результат выполнения программы будет всегда объясним с точки зрения одного из sequentially consistent порядков.

Избавиться от гонок можно двумя способами:

*   Связать все действия с shared данными в synchronization order
*   Связать все действия с shared данными в happens-before order

---
## Расскажите про Happens-before?

[⬆️ К оглавлению](#оглавление)

Happens-before определяется как отношение между двумя действиями:

*   Пусть есть поток T1 и поток T2 (необязательно отличающийся от потока T1) и действия x и y, выполняемые в потоках T1 и T2 соответственно
*   Если x happens-before y, то во время выполнения y треду T2 будут видны все изменения, выполняемые в x тредом T1

Happens-before — это еще один способ, с помощью которого мы добьемся sequential consistency.

Смотрите:

*   Если мы свяжем conflicting доступ к shared переменной с помощью happens-before, то избавимся от data race
*   Если мы избавимся от data race, то получим sequential consistency
*   Если мы получим sequential consistency, то наша программа всегда будет выдавать консистентный с порядком в программе результат

Давайте сразу проясним один момент: нет, happens-before не означает, что инструкции под капотом будут действительно выполняться в таком порядке. Если переупорядочивание инструкций все равно приводит к консистентному результату, то такое переупорядочивание инструкций не запрещено. JLS:

Правила Happens-Before в JMM:

*   Program Order Rule: Каждая операция в потоке happens-before следующей операции в этом же потоке.
*   Monitor Lock Rule: Разблокировка монитора happens-before последующей блокировкой этого же монитора в другом потоке.
*   Volatile Variable Rule: Запись в volatile переменную happens-before последующего чтения этой же переменной.
*   Thread Start Rule: Вызов Thread.start() happens-before любой операции в запущенном потоке.
*   Thread Termination Rule: Любая операция в потоке happens-before его завершением (например, Thread.join()).
*   Transitivity: Если A happens-before B, а B happens-before C, то A happens-before C.

---
## Расскажите про Monitor lock и как работает synchronized?

[⬆️ К оглавлению](#оглавление)

Monitor lock не только предоставляет happens-before между освобождением и взятием лока, но также является и мьютексом, который позволяет обеспечить эксклюзивный доступ к критической секции. Каждый объект в Java содержит внутри себя такой лок, но его нельзя использовать напрямую — чтобы воспользоваться им, необходимо применить keyword synchronized (отсюда и альтернативное название intrinsic lock).

---
## Как работает synchronized?

[⬆️ К оглавлению](#оглавление)

`synchronized` основан на концепции **монитора** — механизма, который обеспечивает, что только один поток может владеть монитором объекта в определённый момент времени. Монитор можно представить как замок, который поток должен захватить, чтобы выполнить синхронизированный код. Если монитор занят, другие потоки блокируются и ждут его освобождения.

`synchronized` используется в двух формах:
*   **Синхронизированный метод**:
    Для нестатического метода монитором является объект `this`. Для статического метода — объект `Class`.

*   **Синхронизированный блок**:
    Здесь монитором является объект та который направлена блокировка`.

### 2. Как это работает на уровне JVM
JVM реализует `synchronized` с помощью механизма **монитора**, встроенного в объект. Каждый объект в Java имеет связанный с ним монитор, который используется для синхронизации. Вот как это происходит:

#### 2.1. Захват и освобождение монитора
*   Когда поток входит в синхронизированный блок или метод, он вызывает операцию **monitorenter** (на уровне байт-кода JVM).
    *   Если монитор свободен, поток захватывает его и продолжает выполнение.
    *   Если монитор занят, поток переходит в состояние **Blocked** и помещается в очередь ожидания монитора (monitor’s entry set).
*   После завершения синхронизированного кода (или при выбросе исключения) поток вызывает операцию **monitorexit**, освобождая монитор.
*   После освобождения монитора другой поток из очереди ожидания может захватить его.

#### 2.2. Структура монитора
Монитор в JVM хранит следующую информацию:
*   **Владелец** (owner): поток, который в данный момент владеет монитором.
*   **Счётчик входов** (entry count): для поддержки реентерабельности (reentrancy). Если поток повторно входит в синхронизированный блок того же монитора, счётчик увеличивается.
*   **Очередь ожидания** (entry set): потоки, ожидающие захвата монитора.
*   **Ожидающие потоки** (wait set): потоки, вызвавшие `wait()` на этом мониторе.

#### 2.3. Реентерабельность
`synchronized` поддерживает **реентерабельность** (reentrant locking). Это значит, что поток, уже владеющий монитором, может повторно войти в синхронизированный блок или метод, использующий тот же монитор, без блокировки самого себя. JVM увеличивает счётчик входов при каждом входе и уменьшает его при каждом выходе. Монитор освобождается, только когда счётчик достигает нуля.

#### 3.2. Оптимизации JVM
Современные JVM (например, HotSpot) используют несколько оптимизаций для `synchronized`, чтобы уменьшить накладные расходы:
*   **Biased Locking** (смещённая блокировка): если объект обычно используется только одним потоком, JVM минимизирует затраты на захват монитора, "привязывая" его к этому потоку.
*   **Lightweight Locking** (лёгкая блокировка): если конкуренция за монитор низкая, JVM использует атомарные операции (например, CAS — Compare-And-Swap) вместо тяжёлых системных вызовов.
*   **Heavyweight Locking** (тяжёлая блокировка): при высокой конкуренции JVM прибегает к системным вызовам, что включает переключение контекста и взаимодействие с ОС.
*   **Lock Elimination**: JIT-компилятор может удалить ненужные блокировки, если анализ показывает, что объект недоступен другим потокам.
*   **Lock Coarsening**: JVM может объединить несколько синхронизированных блоков в один, чтобы уменьшить количество операций `monitorenter`/`monitorexit`.

### 5. Нюансы и подводные камни
1.  **Выбор объекта монитора**:
    *   Используйте объект, который логически связан с защищаемым ресурсом. Неправильный выбор (например, `this` вместо специального объекта) может привести к ненужной блокировке.
    *   Никогда не используйте примитивные типы (`Integer`, `String` и т.д.) как мониторы, так как они могут быть интернированы и использоваться в других частях программы.

2.  **Deadlock**:
    *   Если два потока пытаются захватить мониторы в разном порядке, может возникнуть взаимная блокировка. Например:
        Решение: всегда захватывайте мониторы в одном и том же порядке.

3.  **Производительность**:
    *   Чрезмерное использование `synchronized` может привести к узким местам в производительности, особенно при высокой конкуренции.
    *   Для высокопроизводительных приложений лучше использовать более гибкие механизмы из пакета `java.util.concurrent` (например, `ReentrantLock`, `ConcurrentHashMap`).

4.  **Ограничения**:
    *   `synchronized` не предоставляет таймаутов или условной блокировки, в отличие от `ReentrantLock`.
    *   Нет возможности прервать поток, ожидающий монитор.

5.  **Статическая vs нестатическая синхронизация**:
    *   Статические синхронизированные методы блокируют весь класс, что может быть слишком грубым подходом.
    *   Нестатические методы блокируют только конкретный экземпляр объекта.

---
## Расскажите про Memory Barriers?

[⬆️ К оглавлению](#оглавление)

Процессор может переупорядочивать выполняемые им инструкции, даже если на уровне компилятора мы обеспечили необходимый порядок. Хотя процессор делает только такие переупорядочивания, которые не меняют итогового результата, но это гарантируется только для единственного ядра в изоляции, поэтому переупорядочивание может повлиять на другие ядра. Более того, все еще существует проблема видимости изменений, которую мы обсудили выше. Именно поэтому JMM ответственна и за синхронизацию на уровне процессора.
Для решения этих проблем Java использует готовые низкоуровневые механизмы синхронизации под названием "memory barrier", предоставляемые самим процессором. Задача барьеров памяти — запретить (memory) переупорядочивания, которые обычно разрешены моделью памяти процессора. Таким образом, точно так же как мы используем примитивы синхронизации volatile/synchronized в высокоуровневом коде, сама Java под капотом тоже использует похожие низкоуровневые примитивы синхронизации.
Memory barrier (memory fence, барьер памяти) — это тип процессорной инструкции, которая заставляет процессор гарантировать memory ordering для инструкций, работающих с памятью.
Всего существует 4 типа барьеров памяти — они напрямую матчатся в возможные memory reordering и запрещают каждый из них:

*   **LoadLoad Barrier**:
    *   Гарантирует, что операции чтения до барьера завершатся до операций чтения после барьера.
    *   Пример: Чтение двух volatile переменных подряд требует, чтобы первое чтение завершилось до второго.
*   **StoreStore Barrier**:
    *   Гарантирует, что операции записи до барьера завершатся до операций записи после барьера.
    *   Пример: Запись в две volatile переменные подряд.
*   **LoadStore Barrier**:
    *   Гарантирует, что операции чтения до барьера завершатся до операций записи после барьера.
    *   Используется, чтобы предотвратить переупорядочивание чтения и записи.
*   **StoreLoad Barrier**:
    *   Самый "тяжёлый" барьер, предотвращающий переупорядочивание записи и последующего чтения.
    *   Пример: Запись в volatile переменную, за которой следует чтение другой volatile переменной.

**volatile и Memory Barriers**
*   Запись в volatile переменную:
    *   JVM вставляет Store Barrier (или StoreStore и StoreLoad барьеры) после записи.
    *   Это гарантирует, что значение записывается в основную память и все предшествующие операции завершаются до записи.
    *   Пример: `volatileVar = 42` завершает все предыдущие записи в память, делая их видимыми другим потокам.
*   Чтение volatile переменной:
    *   JVM вставляет Load Barrier (или LoadLoad и LoadStore барьеры) перед чтением.
    *   Это обновляет локальный кэш из основной памяти, обеспечивая актуальность данных.
*   Happens-before: Запись в volatile переменную создаёт happens-before отношение с последующим чтением этой переменной, что реализуется через комбинацию барьеров.

**synchronized и Memory Barriers**
*   Вход в synchronized блок/метод:
    *   JVM использует Acquire Barrier (аналог Load Barrier), чтобы гарантировать, что все последующие операции видят актуальные данные.
    *   Это соответствует захвату монитора (monitorenter).
*   Выход из synchronized блока/метода:
    *   JVM использует Release Barrier (аналог Store Barrier), чтобы сбросить все изменения в основную память.
    *   Это соответствует освобождению монитора (monitorexit).
*   Full Barrier: В некоторых случаях JVM может использовать полный барьер для обеспечения строгой синхронизации.

---
## Расскажите про Volatile?

[⬆️ К оглавлению](#оглавление)

Ключевое слово `volatile` в Java используется для управления видимостью и упорядочиванием операций с переменными в многопоточной среде. Оно решает проблемы, связанные с кэшированием данных потоками и оптимизациями компилятора, но не обеспечивает взаимоисключение, как `synchronized`.

### 1. Основы `volatile`
Ключевое слово `volatile` применяется к переменным и гарантирует:
*   **Видимость**: Все потоки видят актуальное значение переменной. Если один поток изменяет `volatile` переменную, другие потоки немедленно получают её обновлённое значение.
*   **Упорядочивание**: Операции с `volatile` переменной не переупорядочиваются компилятором или процессором относительно других операций, что обеспечивает определённый порядок выполнения.

`volatile` полезен в ситуациях, когда несколько потоков читают и/или пишут общую переменную, но не требуется сложная синхронизация, как при использовании `synchronized`.

### 3. Как работает `volatile` на уровне JVM
`volatile` опирается на модель памяти Java (Java Memory Model, JMM), которая определяет, как потоки взаимодействуют с памятью. Вот ключевые аспекты:

#### 3.1. Видимость (Visibility)
*   Когда поток записывает в `volatile` переменную, JVM гарантирует, что значение записывается напрямую в **основную память** (main memory), а не только в локальный кэш потока.
*   При чтении `volatile` переменной поток всегда читает значение из основной памяти, игнорируя локальный кэш.
*   Это достигается с помощью **memory barriers** (барьеров памяти), которые предотвращают кэширование и обеспечивают синхронизацию данных.

#### 3.2. Упорядочивание (Ordering)
*   JMM определяет правило **happens-before** для `volatile`:
    *   Если поток A записывает в `volatile` переменную, а поток B читает её, то все изменения, сделанные потоком A до записи в `volatile` переменную, будут видны потоку B после чтения.
    *   Это предотвращает переупорядочивание операций: инструкции до записи в `volatile` переменную не могут быть перемещены после неё, а инструкции после чтения — до него.

*   Запись `flag = true` создаёт happens-before отношение, гарантируя, что `x = 1` будет видно в `reader()`.

#### 3.3. Реализация на низком уровне
На уровне процессора `volatile` использует:
*   **Барьеры памяти**:
    *   **Store Barrier** (при записи): Сбрасывает изменения из кэша в основную память.
    *   **Load Barrier** (при чтении): Обновляет локальный кэш из основной памяти.
*   **Атомарность записи**: Запись в `volatile` переменную является атомарной (но только для самой переменной, не для операций вроде `i++`).
*   В современных JVM (например, HotSpot) для `volatile` часто используются инструкции процессора, такие как `LOCK` (на x86) или эквивалентные для других архитектур, чтобы обеспечить согласованность.

### 4. Ограничения `volatile`
1.  **Нет взаимоисключения**:
    *   `volatile` не предотвращает одновременный доступ нескольких потоков к переменной. Например, операции вроде `volatileVar++` не атомарны, так как состоят из чтения, инкремента и записи.
    *   Для атомарных операций используйте `AtomicInteger`, `AtomicReference` или `synchronized`.

2.  **Подходит только для простых сценариев**:
    *   `volatile` полезен для флагов, счётчиков или состояний, где достаточно гарантировать видимость и упорядочивание.
    *   Для сложной синхронизации (например, защиты критической секции) нужен `synchronized` или `Lock`.

3.  **Ограниченная атомарность**:
    *   Только чтение и запись самой `volatile` переменной атомарны. Составные операции (например, `volatileVar = volatileVar + 1`) требуют дополнительной синхронизации.

### 6. Низкоуровневые оптимизации
Современные JVM оптимизируют работу с `volatile`:
*   **Элиминация избыточных барьеров**: Если JVM определяет, что `volatile` переменная используется только одним потоком, она может устранить ненужные барьеры памяти.
*   **Кэширование в регистрах**: На некоторых архитектурах JVM может использовать кэш процессора, но с гарантией синхронизации при записи.
*   **Поддержка 64-битных операций**: Начиная с Java 5, `volatile` поддерживает атомарные операции с 64-битными типами (`long` и `double`), которые ранее могли быть неатомарными на 32-битных системах.

---
## Расскажите про Atomicity и как это работает изнутри?

[⬆️ К оглавлению](#оглавление)

Рассмотрим на примере `AtomicInteger`

В Java классы из пакета `java.util.concurrent.atomic`, такие как `AtomicInteger`, предоставляют атомарные операции для безопасной работы с переменными в многопоточной среде без явных блокировок (`synchronized`). Атомарность гарантирует, что операции выполняются как единое, неделимое действие, исключая состояния гонки.

### Что такое `AtomicInteger`
`AtomicInteger` — это класс для работы с целочисленными значениями, поддерживающий атомарные операции, такие как инкремент, декремент, обновление и сравнение. Он широко применяется в многопоточных приложениях для реализации счетчиков, аккумуляторов и других структур данных.

### Основные методы `AtomicInteger`
*   `get()`: Возвращает текущее значение.
*   `set(int newValue)`: Устанавливает новое значение.
*   `incrementAndGet()`: Атомарно увеличивает значение на 1 и возвращает новое значение.
*   `decrementAndGet()`: Атомарно уменьшает значение на 1 и возвращает новое значение.
*   `getAndIncrement()`: Возвращает текущее значение и увеличивает его на 1.
*   `compareAndSet(int expect, int update)`: Если текущее значение равно `expect`, атомарно устанавливает `update`. Возвращает `true` при успехе, иначе `false`.
*   `addAndGet(int delta)`: Атомарно прибавляет `delta` и возвращает новое значение.
*   В новых версиях Java (начиная с Java 9) добавлены методы, такие как `getAndUpdate(IntUnaryOperator)` и `updateAndGet(IntUnaryOperator)`, которые позволяют применять пользовательские функции атомарно.

### Как работает `AtomicInteger` изнутри
`AtomicInteger` использует низкоуровневые механизмы JVM, основанные на аппаратных инструкциях процессора, в первую очередь **Compare-And-Swap (CAS)**. В новых версиях Java (например, 17, 21) реализация была оптимизирована, но базовый принцип остался прежним. Рассмотрим ключевые аспекты.

#### Поле и волатильность
`AtomicInteger` хранит значение в поле `value`, помеченном как `volatile`:
```java
private volatile int value;
```
Модификатор `volatile` обеспечивает **видимость**: изменения значения сразу видны всем потокам, предотвращая кэширование в локальной памяти потока. В Java 9+ модель памяти (JMM) была уточнена, и `volatile` дополнительно поддерживает операции с улучшенной семантикой (например, для работы с VarHandle).

#### Compare-And-Swap (CAS) и VarHandle
Начиная с Java 9, реализация `AtomicInteger` перешла с использования `sun.misc.Unsafe` на **VarHandle**, который предоставляет более безопасный и поддерживаемый API для низкоуровневых операций. `VarHandle` — это абстракция, введенная в Java 9 (JEP 193), которая позволяет выполнять атомарные операции над полями объекта.

Пример внутренней реализации `AtomicInteger`:
```java
private static final VarHandle VALUE;

static {
    try {
        VALUE = MethodHandles.lookup().findVarHandle(AtomicInteger.class, "value", int.class);
    } catch (ReflectiveOperationException e) {
        throw new ExceptionInInitializerError(e);
    }
}
```
`VarHandle` заменяет `Unsafe` для операций вроде CAS, обеспечивая:
*   **Безопасность**: VarHandle проверяет доступ к полям на уровне JVM.
*   **Гибкость**: Поддерживает различные режимы доступа (volatile, non-volatile, acquire, release).
*   **Портативность**: Работает на разных архитектурах процессоров.

#### Реализация CAS
CAS — это атомарная инструкция, которая:
1.  Сравнивает текущее значение с ожидаемым (`expect`).
2.  Если они совпадают, заменяет значение на новое (`update`) и возвращает `true`.
3.  Если не совпадают, возвращает `false`.

Пример метода `compareAndSet`:
```java
public final boolean compareAndSet(int expectedValue, int newValue) {
    return VALUE.compareAndSet(this, expectedValue, newValue);
}
```
Здесь `VALUE` — это `VarHandle`, который вызывает нативную инструкцию CAS (например, `cmpxchg` на x86).

#### Реализация `incrementAndGet`
Метод `incrementAndGet` использует CAS в цикле (оптимистическая блокировка):
```java
public final int incrementAndGet() {
    return (int) VALUE.getAndAdd(this, 1) + 1;
}
```
Внутри `getAndAdd` реализует цикл:
1.  Получает текущее значение (`oldValue`) с помощью `getVolatile`.
2.  Вычисляет новое значение (`oldValue + 1`).
3.  Пытается выполнить CAS через `VarHandle`.
4.  Если CAS не удался (значение изменилось другим потоком), повторяет попытку.

#### Пример работы CAS
Предположим, `AtomicInteger` имеет значение `10`, и два потока вызывают `incrementAndGet`:
1.  Поток 1 читает `10`, вычисляет `11`, выполняет CAS (`10 -> 11`).
2.  Поток 2 читает `10`, вычисляет `11`, но видит, что значение уже `11` (изменил поток 1). CAS не срабатывает.
3.  Поток 2 повторяет цикл: читает `11`, вычисляет `12`, выполняет CAS (`11 -> 12`).
4.  Итог: значение становится `12`, оба инкремента выполнены корректно.

### Оптимизации в новых версиях Java
1.  **VarHandle вместо Unsafe**: В Java 9+ `AtomicInteger` использует `VarHandle`, что делает код более безопасным и переносимым. `VarHandle` поддерживает различные режимы доступа (например, `acquire`/`release` для оптимизации производительности).
2.  **Улучшения JMM**: Java Memory Model в новых версиях (например, Java 17) уточняет поведение `volatile` и атомарных операций, улучшая оптимизации компилятора.
3.  **Поддержка новых архитектур**: На современных процессорах (например, ARM64) JVM оптимизирует CAS, используя аппаратные инструкции, такие как Load-Link/Store-Conditional (LL/SC).
4.  **Функциональные методы**: Начиная с Java 9, `AtomicInteger` поддерживает методы вроде `updateAndGet(IntUnaryOperator)`, которые позволяют атомарно применять произвольные функции:

---
## Какие виды Atomic есть в java?

[⬆️ К оглавлению](#оглавление)

Основные классы атомиков
1.  **AtomicInteger**
    *   **Описание**: Хранит целое число (`int`) и поддерживает атомарные операции, такие как инкремент, декремент, сложение, сравнение и замена.
    *   **Основные методы**: `get()`, `set(int)`, `incrementAndGet()`, `decrementAndGet()`, `compareAndSet(int, int)`, `addAndGet(int)`, `updateAndGet(IntUnaryOperator)`.
    *   **Применение**: Счетчики, индексы, аккумуляторы в многопоточных приложениях.
    *   **Пример**:
        ```java
        AtomicInteger counter = new AtomicInteger(0);
        counter.incrementAndGet(); // Атомарно увеличивает на 1
        ```

2.  **AtomicLong**
    *   **Описание**: Аналог `AtomicInteger`, но для работы с 64-битными целыми числами (`long`).
    *   **Основные методы**: Те же, что у `AtomicInteger`, но с типом `long`, например, `incrementAndGet()`, `compareAndSet(long, long)`, `addAndGet(long)`.
    *   **Применение**: Подходит для работы с большими значениями, например, для временных меток или идентификаторов.
    *   **Пример**:
        ```java
        AtomicLong timestamp = new AtomicLong(System.currentTimeMillis());
        timestamp.getAndIncrement();
        ```

3.  **AtomicBoolean**
    *   **Описание**: Хранит булево значение (`true`/`false`) и поддерживает атомарные операции над ним.
    *   **Основные методы**: `get()`, `set(boolean)`, `compareAndSet(boolean, boolean)`, `getAndSet(boolean)`.
    *   **Применение**: Флаги, переключатели состояния (например, для включения/выключения функционала).
    *   **Пример**:
        ```java
        AtomicBoolean flag = new AtomicBoolean(false);
        flag.compareAndSet(false, true); // Атомарно меняет false на true
        ```

4.  **AtomicReference<V>**
    *   **Описание**: Хранит ссылку на объект типа `V` и поддерживает атомарные операции над ссылкой.
    *   **Основные методы**: `get()`, `set(V)`, `compareAndSet(V, V)`, `getAndUpdate(UnaryOperator<V>)`.
    *   **Применение**: Управление ссылками на объекты в многопоточной среде, например, для атомарного обновления сложных структур данных.
    *   **Пример**:
        ```java
        AtomicReference<String> ref = new AtomicReference<>("initial");
        ref.compareAndSet("initial", "updated");
        ```

5.  **AtomicIntegerArray**
    *   **Описание**: Массив целых чисел (`int`), где каждая операция над элементом массива выполняется атомарно.
    *   **Основные методы**: `get(int index)`, `set(int index, int newValue)`, `compareAndSet(int index, int expect, int update)`, `incrementAndGet(int index)`.
    *   **Применение**: Для работы с массивами, где требуется атомарное обновление отдельных элементов.
    *   **Пример**:
        ```java
        AtomicIntegerArray array = new AtomicIntegerArray(10);
        array.incrementAndGet(5); // Увеличивает элемент с индексом 5
        ```

6.  **AtomicLongArray**
    *   **Описание**: Аналог `AtomicIntegerArray`, но для массива 64-битных чисел (`long`).
    *   **Основные методы**: Те же, что у `AtomicIntegerArray`, но с типом `long`.
    *   **Применение**: Массивы больших чисел, например, для хранения временных меток.
    *   **Пример**:
        ```java
        AtomicLongArray array = new AtomicLongArray(10);
        array.addAndGet(3, 100L);
        ```

7.  **AtomicReferenceArray<E>**
    *   **Описание**: Массив ссылок на объекты типа `E`, с атомарными операциями над элементами.
    *   **Основные методы**: `get(int index)`, `set(int index, E newValue)`, `compareAndSet(int index, E expect, E update)`.
    *   **Применение**: Для массивов объектов, где требуется атомарное обновление ссылок.
    *   **Пример**:
        ```java
        AtomicReferenceArray<String> array = new AtomicReferenceArray<>(10);
        array.compareAndSet(0, null, "value");
        ```

8.  **AtomicDouble** (начиная с Java 21, экспериментально)
    *   **Описание**: Хранит значение с плавающей точкой (`double`) и поддерживает атомарные операции. Введен как часть Project Valhalla (JEP 425) для улучшения работы с примитивами.
    *   **Основные методы**: `get()`, `set(double)`, `compareAndSet(double, double)`, `addAndGet(double)`.
    *   **Применение**: Подходит для численных вычислений, требующих атомарности, например, финансовые расчеты.
    *   **Примечание**: Доступность зависит от версии JVM и может быть помечена как предварительная.
    *   **Пример**:
        ```java
        AtomicDouble sum = new AtomicDouble(0.0);
        sum.addAndGet(1.5);
        ```

9.  **AtomicMarkableReference<V>**
    *   **Описание**: Хранит ссылку на объект типа `V` вместе с булевым "маркером" (например, для пометки объекта как удаленного).
    *   **Основные методы**: `getReference()`, `get(boolean[] markHolder)`, `compareAndSet(V expectedReference, V newReference, boolean expectedMark, boolean newMark)`.
    *   **Применение**: Алгоритмы, где нужно отслеживать состояние объекта (например, в неблокирующих структурах данных).
    *   **Пример**:
        ```java
        AtomicMarkableReference<String> ref = new AtomicMarkableReference<>("data", false);
        ref.attemptMark("data", true); // Устанавливает маркер
        ```

10. **AtomicStampedReference<V>**
    *   **Описание**: Хранит ссылку на объект типа `V` вместе с целочисленным "штампом" (stamp), который может использоваться как версия или счетчик.
    *   **Основные методы**: `getReference()`, `getStamp()`, `compareAndSet(V expectedReference, V newReference, int expectedStamp, int newStamp)`.
    *   **Применение**: Алгоритмы, требующие отслеживания версий, например, для решения проблемы ABA в CAS.
    *   **Пример**:
        ```java
        AtomicStampedReference<String> ref = new AtomicStampedReference<>("data", 0);
        ref.compareAndSet("data", "newData", 0, 1);
        ```

---
## Атомарность базовых действий в JMM?

[⬆️ К оглавлению](#оглавление)

*   Чтения и записи reference переменных (ссылок) являются атомарными
*   Чтения и записи примитивов (кроме long/double) являются атомарными
*   Чтения и записи long/double переменных, помеченных как volatile, являются атомарными

Что же нам дают эти свойства в многопоточной среде? Нам гарантируется, что при shared чтении переменной мы увидим или значение по умолчанию (0, false, null), или полное консистентное значение, но не половинное значение. Даже если в переменную пишут одновременно несколько тредов, то мы увидим результат записи одного из них, но не будет такой ситуации, что чтение увидит первую половину битов из одной записи, а вторую половину из другой записи.

Но почему мы вообще могли бы прочитать половинное значение? Дело в том, что некоторые типы в языке имеют размер (в битах) больший, чем длина машинного слова процессора. Например, 32-х битный процессор оперирует словами по 32 бита, но тип long/double содержит 64 бита. Соответственно, языку требуется совершить 2 записи по 32 бит, чтобы полностью записать значение.

---
## В чём заключаются различия между java.util.concurrent.Atomic\*.compareAndSwap() и java.util.concurrent.Atomic\*.weakCompareAndSwap()

[⬆️ К оглавлению](#оглавление)

*   weakCompareAndSwap() не создает memory barrier и не дает гарантии happens-before;
*   weakCompareAndSwap() сильно зависит от кэша/CPU, и может возвращать false без видимых причин;
*   weakCompareAndSwap(), более легкая, но поддерживаемая далеко не всеми архитектурами и не всегда эффективная операция.

---
## Что такое «потокобезопасность»?

[⬆️ К оглавлению](#оглавление)

Потокобезопасность - свойство объекта или кода, которое гарантирует, что при исполнении или использовании несколькими потоками, код будет вести себя, как предполагается. Например потокобезопасный счётчик не пропустит ни один счёт, даже если один и тот же экземпляр этого счётчика будет использоваться несколькими потоками.

---
## Что такое «кооперативная многозадачность»? Какой тип многозадачности использует Java? Чем обусловлен этот выбор?

[⬆️ К оглавлению](#оглавление)

Кооперативная многозадачность - это способ деления процессорного времени между потоками, при котором каждый поток обязан отдавать управление следующему добровольно.
Преимущества такого подхода - простота реализации, меньшие накладные расходы на переключение контекста.
Недостатки - если один поток завис или ведет себя некорректно, то зависает целиком вся система и другие потоки никогда не получат управление.
Java использует вытесняющую многозадачность, при которой решение о переключении между потоками процесса принимает операционная система.
В отличие от кооперативной многозадачности управление операционной системе передаётся вне зависимости от состояния работающих приложений, благодаря чему, отдельные зависшие потоки процесса, как правило, не «подвешивают» всю систему целиком. За счёт регулярного переключения между задачами также улучшается отзывчивость приложения и повышается оперативность освобождения ресурсов, которые больше не используются.
В реализации вытесняющая многозадачность отличается от кооперативной, в частности, тем, что требует обработки системного прерывания от аппаратного таймера.

---
## Чем отличается процесс от потока?

[⬆️ К оглавлению](#оглавление)

Процесс — экземпляр программы во время выполнения, независимый объект, которому выделены системные ресурсы (например, процессорное время и память). Каждый процесс выполняется в отдельном адресном пространстве: один процесс не может получить доступ к переменным и структурам данных другого. Если процесс хочет получить доступ к чужим ресурсам, необходимо использовать межпроцессное взаимодействие. Это могут быть конвейеры, файлы, каналы связи между компьютерами и многое другое.
Для каждого процесса ОС создает так называемое «виртуальное адресное пространство», к которому процесс имеет прямой доступ. Это пространство принадлежит процессу, содержит только его данные и находится в полном его распоряжении. Операционная система же отвечает за то, как виртуальное пространство процесса проецируется на физическую память.
Поток(thread) — определенный способ выполнения процесса, определяющий последовательность исполнения кода в процессе. Потоки всегда создаются в контексте какого-либо процесса, и вся их жизнь проходит только в его границах. Потоки могут исполнять один и тот же код и манипулировать одними и теми же данными, а также совместно использовать описатели объектов ядра, поскольку таблица описателей создается не в отдельных потоках, а в процессах. Так как потоки расходуют существенно меньше ресурсов, чем процессы, в процессе выполнения работы выгоднее создавать дополнительные потоки и избегать создания новых процессов.

---
## Что такое «зелёные потоки» и есть ли они в Java?

[⬆️ К оглавлению](#оглавление)

Зелёные (легковесные) потоки(green threads) - потоки эмулируемые виртуальной машиной или средой исполнения. Создание зелёного потока не подразумевает под собой создание реального потока ОС.
Виртуальная машина Java берёт на себя заботу о переключении между разными green threads, а сама машина работает как один поток ОС. Это даёт несколько преимуществ. Потоки ОС относительно дороги в большинстве POSIX-систем. Кроме того, переключение между native threads гораздо медленнее, чем между green threads.
Это всё означает, что в некоторых ситуациях green threads гораздо выгоднее, чем native threads. Система может поддерживать гораздо большее количество green threads, чем потоков OС. Например, гораздо практичнее запускать новый green thread для нового HTTP-соединения к веб-серверу, вместо создания нового native thread.
Однако есть и недостатки. Самый большой заключается в том, что вы не можете исполнять два потока одновременно. Поскольку существует только один native thread, только он и вызывается планировщиком ОС. Даже если у вас несколько процессоров и несколько green threads, только один процессор может вызывать green thread. И всё потому, что с точки зрения планировщика заданий ОС всё это выглядит одним потоком.
Начиная с версии 1.2 Java поддерживает native threads, и с тех пор они используются по умолчанию.

---
## Каким образом можно создать поток?

[⬆️ К оглавлению](#оглавление)

*   Создать потомка класса Thread и переопределить его метод run();
*   Создать объект класса Thread, передав ему в конструкторе экземпляр класса, реализующего интерфейс Runnable. Эти интерфейс содержит метод run(), который будет выполняться в новом потоке. Поток закончит выполнение, когда завершится его метод run().
*   Вызвать метод submit() у экземпляра класса реализующего интерфейс ExecutorService, передав ему в качестве параметра экземпляр класса реализующего интерфейс Runnable или Callable (содержит метод call(), в котором описывается логика выполнения).

---
## Чем различаются Thread и Runnable?

[⬆️ К оглавлению](#оглавление)

### **`Thread`**
`Thread` — это класс в пакете `java.lang`, представляющий поток выполнения в Java. Каждый поток является отдельной единицей выполнения, которая позволяет программе выполнять несколько задач параллельно. Класс `Thread` предоставляет функциональность для создания, управления и выполнения потоков.

#### Основные характеристики `Thread`:
*   **Наследование**: `Thread` — это класс, который можно расширить (наследовать), чтобы создать собственный поток.
*   **Жизненный цикл потока**:
    *   **New**: Поток создан, но не запущен (до вызова `start()`).
    *   **Runnable**: Поток готов к выполнению (после вызова `start()`).
    *   **Running**: Поток выполняется (метод `run()`).
    *   **Blocked/Waiting**: Поток приостановлен (например, ожидает монитор или вызов `wait()`).
    *   **Terminated**: Поток завершил выполнение.
*   **Ключевые методы**:
    *   `start()`: Запускает поток, переводя его в состояние `Runnable`. Вызывает метод `run()` в новом потоке.
    *   `run()`: Содержит код, который выполняется в потоке. Если вы наследуете `Thread`, переопределяете этот метод.
    *   `sleep(long millis)`: Приостанавливает выполнение потока на указанное время.
    *   `join()`: Заставляет вызывающий поток ждать завершения текущего потока.
    *   `interrupt()`: Прерывает поток (устанавливает флаг прерывания).
    *   `isAlive()`: Проверяет, активен ли поток.
    *   `setPriority(int priority)`: Устанавливает приоритет потока (от 1 до 10, где 10 — максимальный).
*   **Ограничения**:
    *   Наследование от `Thread` ограничивает возможность наследовать другие классы, так как Java не поддерживает множественное наследование.
    *   Код, переопределяющий `run()`, жестко привязан к классу `Thread`.

#### Когда использовать `Thread`:
*   Когда нужно создать поток с минимальной настройкой.
*   Когда требуется доступ к специфическим методам класса `Thread`, например, управление приоритетом или именем потока.
*   Подходит для простых задач, где нет необходимости в гибкости.

### **`Runnable`**
`Runnable` — это функциональный интерфейс в пакете `java.lang`, который определяет задачу, выполняемую потоком. Он содержит единственный метод `run()`.

#### Основные характеристики `Runnable`:
*   **Функциональный интерфейс**:
    ```java
    @FunctionalInterface
    public interface Runnable {
        void run();
    }
    ```
    Это делает `Runnable` совместимым с лямбда-выражениями (начиная с Java 8).
*   **Гибкость**:
    *   Реализация `Runnable` позволяет отделить задачу (логику потока) от механизма управления потоком.
    *   Вы можете передать объект `Runnable` в конструктор `Thread` или использовать его с пулами потоков (`ExecutorService`).
*   **Отсутствие ограничений на наследование**:
    *   Так как `Runnable` — интерфейс, класс, реализующий его, может наследовать другой класс.
*   **Переиспользование**:
    *   Один и тот же объект `Runnable` можно передать в несколько потоков для выполнения одной и той же задачи.

---
## В чём заключается разница между методами start() и run()?

[⬆️ К оглавлению](#оглавление)

### **`run()`**
*   **Что это**: Метод `run()` — это обычный метод класса `Thread`, который содержит логику, выполняемую потоком. Он является точкой входа для выполнения задачи потока.
*   **Как работает**:
    *   Если вы создаете класс, наследующий `Thread`, или передаете объект `Runnable` в конструктор `Thread`, то именно метод `run()` определяет, что будет выполняться в потоке.
    *   При прямом вызове `run()` он выполняется **в текущем потоке** (том, который его вызывает), а не в новом отдельном потоке.
    *   Никакого многопоточного поведения при прямом вызове `run()` не происходит — это просто обычный метод.
*   **Когда вызывается**:
    *   Прямым вызовом: `thread.run()` — выполняется синхронно в текущем потоке.
    *   Косвенно: через вызов `start()`, который автоматически запускает `run()` в новом потоке.

### **`start()`**
*   **Что это**: Метод `start()` используется для создания нового потока выполнения и запуска метода `run()` в этом новом потоке.
*   **Как работает**:
    *   Вызов `start()` инициирует создание нового потока в JVM, переводит его в состояние `Runnable`, и планировщик потоков операционной системы решает, когда выполнить метод `run()`.
    *   `start()` передает управление JVM, которая создает нативный поток (на уровне ОС) и вызывает метод `run()` в этом новом потоке.
    *   Повторный вызов `start()` на том же объекте `Thread` приведет к исключению `IllegalThreadStateException`, так как поток нельзя запустить повторно.
*   **Когда вызывается**:
    *   Только для запуска нового потока. Это единственный способ создать многопоточное выполнение с использованием класса `Thread`.

---
## Как принудительно запустить поток?

[⬆️ К оглавлению](#оглавление)

Никак. В Java не существует абсолютно никакого способа принудительного запуска потока. Это контролируется JVM и Java не предоставляет никакого API для управления этим процессом.

---
## Дайте определение понятию «синхронизация».

[⬆️ К оглавлению](#оглавление)

Синхронизация - это процесс, который позволяет выполнять потоки параллельно.
В Java все объекты имеют одну блокировку, благодаря которой только один поток одновременно может получить доступ к критическому коду в объекте. Такая синхронизация помогает предотвратить повреждение состояния объекта. Если поток получил блокировку, ни один другой поток не может войти в синхронизированный код, пока блокировка не будет снята. Когда поток, владеющий блокировкой, выходит из синхронизированного кода, блокировка снимается. Теперь другой поток может получить блокировку объекта и выполнить синхронизированный код. Если поток пытается получить блокировку объекта, когда другой поток владеет блокировкой, поток переходит в состояние Блокировки до тех пор, пока блокировка не снимется.

---
## В каких состояниях может находиться поток?

[⬆️ К оглавлению](#оглавление)

В Java поток (`Thread`) может находиться в нескольких состояниях в течение своего жизненного цикла. Эти состояния определены в перечислении `Thread.State` и описывают, что происходит с потоком в определенный момент времени

1.  **NEW (Новый)**:
    *   **Описание**: Поток создан (объект `Thread` инициализирован), но метод `start()` еще не вызван. В этом состоянии поток еще не начал выполнение.
    *   **Когда возникает**:
        *   После создания объекта `Thread` или класса, наследующего `Thread`, но до вызова `start()`.
    *   **Особенности**:
        *   Поток не выполняется и не потребляет ресурсов.
        *   Вызов `start()` переводит поток в состояние `RUNNABLE`.

2.  **RUNNABLE (Готов к выполнению / Выполняется)**:
    *   **Описание**: Поток находится в состоянии, когда он готов к выполнению или уже выполняется. Это состояние объединяет два подэтапа:
        *   Готов к выполнению: Поток ждет, пока планировщик потоков (scheduler) выделит ему процессорное время.
        *   Выполняется: Поток активно выполняет код в методе `run()`.
    *   **Когда возникает**:
        *   После вызова `start()`.
        *   Поток может временно покидать это состояние (например, при блокировке) и возвращаться в него.
    *   **Особенности**:
        *   Это основное состояние для активных потоков.
        *   Поток в состоянии `RUNNABLE` может быть прерван или приостановлен.

3.  **BLOCKED (Заблокирован)**:
    *   **Описание**: Поток заблокирован и ожидает освобождения монитора (lock) для входа в синхронизированный блок или метод.
    *   **Когда возникает**:
        *   Когда поток пытается войти в блок `synchronized`, но монитор уже захвачен другим потоком.
    *   **Особенности**:
        *   Поток не выполняет код, пока не получит доступ к монитору.
        *   Как только монитор освобождается, поток возвращается в `RUNNABLE`.

4.  **WAITING (Ожидание)**:
    *   **Описание**: Поток ожидает другого потока, который должен выполнить определенное действие, без ограничения по времени. Поток в этом состоянии не выполняется и не потребляет процессорное время.
    *   **Когда возникает**:
        *   При вызове методов:
            *   `Object.wait()` (без таймаута).
            *   `Thread.join()` (без таймаута).
            *   `LockSupport.park()`.
        *   Поток остается в этом состоянии, пока другой поток не вызовет `notify()`, `notifyAll()` или не завершится ожидаемый поток (для `join()`).
    *   **Особенности**:
        *   Поток может быть разбужен через `notify()` или `notifyAll()`.
        *   Если поток прерывается (`interrupt()`), он выходит из `WAITING` с `InterruptedException`.

5.  **TIMED_WAITING (Ожидание с таймаутом)**:
    *   **Описание**: Поток ожидает определенное время или событие от другого потока. Аналогично `WAITING`, но с заданным временным лимитом.
    *   **Когда возникает**:
        *   При вызове методов:
            *   `Thread.sleep(long millis)`: Поток спит указанное время.
            *   `Object.wait(long timeout)`: Ожидание с таймаутом.
            *   `Thread.join(long millis)`: Ожидание завершения другого потока с таймаутом.
            *   `LockSupport.parkNanos()` или `LockSupport.parkUntil()`.
    *   **Особенности**:
        *   Поток автоматически возвращается в `RUNNABLE` по истечении времени или при наступлении события (например, `notify()`).
        *   Прерывание (`interrupt()`) также может вывести поток из этого состояния.

6.  **TERMINATED (Завершен)**:
    *   **Описание**: Поток завершил выполнение — либо успешно (метод `run()` завершился), либо из-за необработанного исключения.
    *   **Когда возникает**:
        *   После завершения метода `run()`.
        *   При возникновении необработанного исключения в потоке.
    *   **Особенности**:
        *   Поток в этом состоянии больше не может быть перезапущен (повторный вызов `start()` вызовет `IllegalThreadStateException`).
        *   Ресурсы, связанные с потоком, освобождаются JVM.

---
## Можно ли создавать новые экземпляры класса, пока выполняется static synchronized метод?

[⬆️ К оглавлению](#оглавление)

Да, можно создавать новые экземпляры класса, так как статические поля не принадлежат к экземплярам класса.

---
## Зачем может быть нужен private мьютекс?

[⬆️ К оглавлению](#оглавление)

Объект для синхронизации делается private, чтобы сторонний код не мог на него синхронизироваться и случайно получить взаимную блокировку.

---
## Как работают методы wait() и notify()/notifyAll()?

[⬆️ К оглавлению](#оглавление)

Методы `wait()`, `notify()` и `notifyAll()` в Java являются частью механизма синхронизации, встроенного в каждый объект (через класс `Object`). Они используются для координации работы потоков в многопоточной среде, позволяя потокам ожидать определенных условий и уведомлять друг друга о выполнении этих условий. Эти методы тесно связаны с монитором объекта (monitor), который используется для обеспечения взаимоисключения (mutual exclusion) и синхронизации. Рассмотрим их работу углубленно, включая внутренние механизмы, поведение в JVM и примеры использования.

### 1. **Основы работы `wait()`, `notify()` и `notifyAll()`**
*   **Монитор объекта**: Каждый объект в Java имеет связанный с ним монитор — внутренний механизм, обеспечивающий взаимоисключение. Только один поток может владеть монитором объекта в определенный момент времени. Монитор захватывается при входе в блок `synchronized` или при вызове синхронизированного метода.
*   **Где определены**: Методы `wait()`, `notify()` и `notifyAll()` определены в классе `Object`, поэтому доступны для любого объекта в Java.
*   **Требование синхронизации**: Эти методы должны вызываться только внутри блока `synchronized` или синхронизированного метода для объекта, монитор которого используется. В противном случае будет выброшено исключение `IllegalMonitorStateException`.

### 2. **Метод `wait()`**
*   **Назначение**: Метод `wait()` заставляет текущий поток приостановить выполнение и освободить монитор объекта, переходя в состояние ожидания (waiting), пока другой поток не вызовет `notify()` или `notifyAll()` на том же объекте или пока не истечет таймаут (если используется `wait(long timeout)`).
*   **Варианты метода**:
    *   `wait()`: Ожидает бесконечно, пока не будет вызван `notify()` или `notifyAll()`.
    *   `wait(long timeout)`: Ожидает указанное время (в миллисекундах).
    *   `wait(long timeout, int nanos)`: Ожидает с точностью до наносекунд (используется редко).
*   **Как работает**:
    1.  Поток, вызывающий `wait()`, должен владеть монитором объекта (например, через `synchronized(obj)`).
    2.  При вызове `wait()`:
        *   Поток освобождает монитор объекта.
        *   Поток переводится в состояние **WAITING** (или **TIMED_WAITING** для версии с таймаутом) и помещается в **wait set** (множество ожидающих потоков) объекта.
        *   Поток приостанавливается и не потребляет процессорное время.
    3.  Поток может возобновить выполнение в следующих случаях:
        *   Другой поток вызывает `notify()` или `notifyAll()` на том же объекте.
        *   Истекает таймаут (если указан).
        *   Поток прерывается вызовом `Thread.interrupt()`, что приводит к выбросу `InterruptedException`.
    4.  После пробуждения поток должен снова захватить монитор объекта, прежде чем продолжить выполнение. Это означает, что пробуждение не гарантирует немедленного продолжения работы — поток может ждать, пока монитор не станет свободным.

*   **Важные детали**:
    *   `wait()` не возвращает управление автоматически — поток должен быть явно пробужден.
    *   После пробуждения поток продолжает выполнение с места, где был вызван `wait()`.
    *   Рекомендуется вызывать `wait()` в цикле (паттерн "guarded block"), чтобы проверять условие, так как пробуждение может быть "ложным" (spurious wakeup — редкое явление, когда поток пробуждается без явного вызова `notify()` или `notifyAll()`).

### 3. **Методы `notify()` и `notifyAll()`**
*   **Назначение**:
    *   `notify()`: Пробуждает **один** поток, находящийся в состоянии ожидания (`wait()`) на мониторе объекта. Если в wait set несколько потоков, выбор потока не детерминирован (зависит от реализации JVM).
    *   `notifyAll()`: Пробуждает **все** потоки, находящиеся в состоянии ожидания на мониторе объекта.
*   **Как работают**:
    1.  Поток, вызывающий `notify()` или `notifyAll()`, должен владеть монитором объекта (через `synchronized`).
    2.  При вызове `notify()`:
        *   Один поток из wait set объекта переводится в состояние **RUNNABLE**.
        *   Этот поток не начинает выполнение немедленно — он должен дождаться, пока текущий поток освободит монитор (например, выйдет из блока `synchronized`).
    3.  При вызове `notifyAll()`:
        *   Все потоки из wait set переводятся в состояние **RUNNABLE**.
        *   Все пробужденные потоки начинают конкурировать за захват монитора, но только один из них получит его и продолжит выполнение.
    4.  Пробужденные потоки возвращаются к точке, где был вызван `wait()`, и продолжают выполнение.

*   **Важные детали**:
    *   `notify()` не гарантирует, какой именно поток будет пробужден, поэтому его использование может быть непредсказуемым в системах с несколькими ожидающими потоками.
    *   `notifyAll()` предпочтительнее, если несколько потоков ожидают на одном объекте, и вы не уверены, какой именно поток должен быть пробужден.
    *   Пробуждение не передает данные — оно лишь сигнализирует, что поток может проверить условие и продолжить выполнение.

### 4. **Внутренняя реализация в JVM**
*   **Монитор объекта**:
    *   Каждый объект в Java имеет связанный монитор, который реализован на уровне JVM (обычно через нативные структуры, такие как мьютексы или семафоры в операционной системе).
    *   Монитор хранит два ключевых компонента:
        *   **Lock**: Обеспечивает взаимоисключение (только один поток может владеть монитором).
        *   **Wait Set**: Множество потоков, ожидающих на вызове `wait()` для этого объекта.
*   **Механизм `wait()`**:
    *   Когда поток вызывает `wait()`, JVM:
        1.  Освобождает монитор объекта (разблокирует мьютекс).
        2.  Переводит поток в состояние WAITING/TIMED_WAITING и добавляет его в wait set.
        3.  Приостанавливает поток через системный вызов (например, `park()` в реализации HotSpot JVM).
    *   При пробуждении (через `notify()`/`notifyAll()` или таймаут):
        1.  Поток удаляется из wait set.
        2.  JVM переводит поток в состояние RUNNABLE.
        3.  Поток пытается снова захватить монитор (через системный вызов, например, `unpark()` в HotSpot).
*   **Механизм `notify()` и `notifyAll()`**:
    *   `notify()` выбирает один поток из wait set (реализация зависит от JVM, например, HotSpot может использовать FIFO или произвольный выбор).
    *   `notifyAll()` переводит все потоки из wait set в состояние RUNNABLE.
    *   Пробужденные потоки конкурируют за монитор, что реализуется через системные примитивы синхронизации (мьютексы).

*   **Реализация в HotSpot JVM**:
    *   В HotSpot JVM мониторы реализованы через структуру `ObjectMonitor`, которая содержит:
        *   `_owner`: Указывает на поток, владеющий монитором.
        *   `_WaitSet`: Список потоков, ожидающих на `wait()`.
        *   `_EntryList`: Список потоков, ожидающих захвата монитора.
    *   Операции `wait()` и `notify()` используют нативные вызовы (`park`/`unpark`) из библиотеки `java.util.concurrent.locks.LockSupport`.
    *   В новых версиях Java (например, Java 21) мониторы оптимизированы для работы с виртуальными потоками (Project Loom), что снижает накладные расходы.

---
## Чем отличаются методы Thread.sleep() и Thread.yield()?

[⬆️ К оглавлению](#оглавление)

Метод yield() служит причиной того, что поток переходит из состояния работающий (running) в состояние работоспособный (runnable), давая возможность другим потокам активизироваться. Но следующий выбранный для запуска поток может и не быть другим.
Метод sleep() вызывает засыпание текущего потока на заданное время, состояние изменяется с работающий (running) на ожидающий (waiting).

---
## Как работает метод Thread.join()?

[⬆️ К оглавлению](#оглавление)

Метод `Thread.join()` в Java используется для синхронизации потоков, позволяя одному потоку дождаться завершения выполнения другого потока. Этот метод блокирует вызывающий поток, пока целевой поток не завершит свою работу или не истечет заданное время ожидания (если используется вариант с таймаутом).

### **Назначение `Thread.join()`**
*   **Цель**: Заставляет вызывающий поток (например, главный поток `main`) ждать, пока указанный поток (на котором вызывается `join()`) не завершит выполнение (перейдет в состояние `TERMINATED`).
*   **Состояние потока**:
    *   Вызывающий поток переходит в состояние `WAITING` (без таймаута) или `TIMED_WAITING` (с таймаутом) до завершения целевого потока.
    *   Целевой поток продолжает выполнение, не затрагиваясь вызовом `join()`.
*   **Использование**: Часто применяется, когда результат работы одного потока нужен другому, или для обеспечения последовательного выполнения задач.

### **Как работает `Thread.join()`**
*   **Механизм**:
    *   Когда вызывается `thread.join()`, JVM приостанавливает выполнение текущего потока (того, который вызвал `join()`) и ожидает, пока поток `thread` не завершит выполнение метода `run()` и не перейдет в состояние `TERMINATED`.
    *   Если целевой поток уже завершен на момент вызова `join()`, метод немедленно возвращает управление, и вызывающий поток продолжает выполнение.
    *   Если указан таймаут (`join(long millis)`), вызывающий поток ждет либо завершения целевого потока, либо истечения времени.
*   **Синхронизация**:
    *   `join()` использует внутренний монитор объекта `Thread`. Вызывающий поток блокируется, ожидая уведомления о завершении целевого потока.
    *   Метод не освобождает мониторы, удерживаемые вызывающим потоком.
*   **Прерывание**:
    *   Если вызывающий поток прерывается (через `Thread.interrupt()`), `join()` выбросит `InterruptedException`, и вызывающий поток продолжит выполнение.

---
## Как проверить, удерживает ли поток монитор определённого ресурса?

[⬆️ К оглавлению](#оглавление)

Метод Thread.holdsLock(lock) возвращает true, когда текущий поток удерживает монитор у определённого объекта.

---
## Что значит «приоритет потока»?

[⬆️ К оглавлению](#оглавление)

Приоритеты потоков используются планировщиком потоков для принятия решений о том, когда какому из потоков будет разрешено работать. Теоретически высокоприоритетные потоки получают больше времени процессора, чем низкоприоритетные. Практически объем времени процессора, который получает поток, часто зависит от нескольких факторов помимо его приоритета.
Чтобы установить приоритет потока, используется метод класса Thread: final void setPriority(int level). Значение level изменяется в пределах от Thread.MIN_PRIORITY = 1 до Thread.MAX_PRIORITY = 10. Приоритет по умолчанию - Thread.NORM_PRlORITY = 5.
Получить текущее значение приоритета потока можно вызвав метод: final int getPriority() у экземпляра класса Thread

---
## Что такое «потоки-демоны»?

[⬆️ К оглавлению](#оглавление)

Потоки-демоны работают в фоновом режиме вместе с программой, но не являются неотъемлемой частью программы. Если какой-либо процесс может выполняться на фоне работы основных потоков выполнения и его деятельность заключается в обслуживании основных потоков приложения, то такой процесс может быть запущен как поток-демон с помощью метода setDaemon(boolean value), вызванного у потока до его запуска. Метод boolean isDaemon() позволяет определить, является ли указанный поток демоном или нет. Базовое свойство потоков-демонов заключается в возможности основного потока приложения завершить выполнение потока-демона (в отличие от обычных потоков) с окончанием кода метода main(), не обращая внимания на то, что поток-демон еще работает.

---
## Можно ли сделать основной поток программы демоном?

[⬆️ К оглавлению](#оглавление)

Нет. Потоки-демоны позволяют описывать фоновые процессы, которые нужны только для обслуживания основных потоков выполнения и не могут существовать без них.

---
## Что значит «усыпить» поток?

[⬆️ К оглавлению](#оглавление)

Это значит приостановить его на определенный промежуток времени, вызвав в ходе его выполнения статический метод Thread.sleep() передав в качестве параметра необходимое количество времени в миллисекундах. До истечения этого времени поток может быть выведен из состояния ожидания вызовом interrupt() с выбрасыванием InterruptedException.

---
## Что такое Callable?

[⬆️ К оглавлению](#оглавление)

`Callable<V>` — это функциональный интерфейс, определённый в пакете `java.util.concurrent`. Он представляет задачу, которая выполняется в отдельном потоке (или пуле потоков) и возвращает результат типа `V`. Также `Callable` позволяет выбрасывать исключения, что делает его более гибким по сравнению с `Runnable`.

Сигнатура интерфейса `Callable`:
```java
@FunctionalInterface
public interface Callable<V> {
    V call() throws Exception;
}
```
*   **Метод `call()`**: Единственный метод интерфейса, который выполняет задачу и возвращает результат типа `V`. Может выбрасывать любое исключение (`Exception`), что позволяет обрабатывать как проверяемые, так и непроверяемые исключения.
*   **Тип `V`**: Обобщённый тип возвращаемого значения. Если задача не возвращает результат, можно использовать `Callable<Void>`.

### Основные отличия `Callable` от `Runnable`

| **Характеристика**       | **Callable**                              | **Runnable**                              |
|--------------------------|-------------------------------------------|-------------------------------------------|
| **Метод**                | `call()`                                 | `run()`                                  |
| **Возвращаемое значение**| Возвращает результат типа `V`            | Не возвращает результат (`void`)         |
| **Исключения**           | Может выбрасывать `Exception`            | Не может выбрасывать проверяемые исключения |
| **Использование**        | Используется с `ExecutorService`         | Используется с `Thread` или `ExecutorService` |
| **Сценарий**             | Задачи с результатом или сложной логикой | Простые задачи без возврата результата   |

### Как использовать `Callable` в Java?

`Callable` обычно используется совместно с `ExecutorService`, который управляет пулом потоков и предоставляет методы для выполнения задач и получения результатов. Результат выполнения `Callable` оборачивается в объект `Future`, который позволяет:
*   Получить результат выполнения задачи.
*   Проверить, завершена ли задача.
*   Отменить задачу.
*   Обрабатывать исключения.

#### Основные шаги работы с `Callable`:
1.  Создайте класс, реализующий `Callable<V>`, или используйте лямбда-выражение.
2.  Передайте задачу в `ExecutorService` с помощью методов `submit()` или `invokeAll()`.
3.  Получите результат через объект `Future`.

---
## Что такое FutureTask?

[⬆️ К оглавлению](#оглавление)

FutureTask представляет собой отменяемое асинхронное вычисление в параллельном Java приложении. Этот класс предоставляет базовую реализацию Future, с методами для запуска и остановки вычисления, методами для запроса состояния вычисления и извлечения результатов. Результат может быть получен только когда вычисление завершено, метод получения будет заблокирован, если вычисление ещё не завершено. Объекты FutureTask могут быть использованы для обёртки объектов Callable и Runnable. Так как FutureTask реализует Runnable, его можно передать в Executor на выполнение.

---
## Как остановить поток?

[⬆️ К оглавлению](#оглавление)

На данный момент в Java принят уведомительный порядок остановки потока (хотя JDK 1.0 и имеет несколько управляющих выполнением потока методов, например stop(), suspend() и resume() - в следующих версиях JDK все они были помечены как deprecated из-за потенциальных угроз взаимной блокировки).
Для корректной остановки потока можно использовать метод класса Thread - interrupt(). Этот метод выставляет некоторый внутренний флаг-статус прерывания. В дальнейшем состояние этого флага можно проверить с помощью метода isInterrupted() или Thread.interrupted() (для текущего потока). Метод interrupt() также способен вывести поток из состояния ожидания или спячки. Т.е. если у потока были вызваны методы sleep() или wait() - текущее состояние прервется и будет выброшено исключение InterruptedException. Флаг в этом случае не выставляется.
Схема действия при этом получается следующей:
Реализовать поток.
В потоке периодически проводить проверку статуса прерывания через вызов isInterrupted().
Если состояние флага изменилось или было выброшено исключение во время ожидания/спячки, следовательно поток пытаются остановить извне.
Принять решение - продолжить работу (если по каким-то причинам остановиться невозможно) или освободить заблокированные потоком ресурсы и закончить выполнение.
Возможная проблема, которая присутствует в этом подходе - блокировки на потоковом вводе-выводе. Если поток заблокирован на чтении данных - вызов interrupt() из этого состояния его не выведет. Решения тут различаются в зависимости от типа источника данных. Если чтение идет из файла - долговременная блокировка крайне маловероятна и тогда можно просто дождаться выхода из метода read(). Если же чтение каким-то образом связано с сетью - стоит использовать неблокирующий ввод-вывод из Java NIO.
Второй вариант реализации метода остановки (а также и приостановки) - сделать собственный аналог interrupt(). Т.е. объявить в классе потока флаги - на остановку и/или приостановку и выставлять их путем вызова заранее определённых методов извне. Методика действия при этом остаётся прежней - проверять установку флагов и принимать решения при их изменении. Недостатки такого подхода. Во-первых, потоки в состоянии ожидания таким способом не «оживить». Во-вторых, выставление флага одним потоком совсем не означает, что второй поток тут же его увидит. Для увеличения производительности виртуальная машина использует кеш данных потока, в результате чего обновление переменной у второго потока может произойти через неопределенный промежуток времени (хотя допустимым решением будет объявить переменную-флаг как volatile).

---
## Почему не рекомендуется использовать метод Thread.stop()?

[⬆️ К оглавлению](#оглавление)

При принудительной остановке (приостановке) потока, stop() прерывает поток в недетерменированном месте выполнения, в результате становится совершенно непонятно, что делать с принадлежащими ему ресурсами. Поток может открыть сетевое соединение - что в таком случае делать с данными, которые еще не вычитаны? Где гарантия, что после дальнейшего запуска потока (в случае приостановки) он сможет их дочитать? Если поток блокировал разделяемый ресурс, то как снять эту блокировку и не переведёт ли принудительное снятие к нарушению консистентности системы? То же самое можно расширить и на случай соединения с базой данных: если поток остановят посередине транзакции, то кто ее будет закрывать? Кто и как будет разблокировать ресурсы?

---
## Что происходит, когда в потоке выбрасывается исключение?

[⬆️ К оглавлению](#оглавление)

Если исключение не поймано - поток «умирает» (переходит в состяние мёртв (dead)).
Если установлен обработчик непойманных исключений, то он возьмёт управление на себя. Thread.UncaughtExceptionHandler - интерфейс, определённый как вложенный интерфейс для других обработчиков, вызываемых, когда поток внезапно останавливается из-за непойманного исключения. В случае, если поток собирается остановиться из-за непойманного исключения, JVM проверяет его на наличие UncaughtExceptionHandler, используя Thread.getUncaughtExceptionHandler(), и если такой обработчик найдет, то вызовет у него метод uncaughtException(), передав этот поток и исключение в виде аргументов.

---
## В чем разница между interrupted() и isInterrupted()?

[⬆️ К оглавлению](#оглавление)

Механизм прерывания работы потока в Java реализован с использованием внутреннего флага, известного как статус прерывания. Прерывание потока вызовом Thread.interrupt() устанавливает этот флаг. Методы Thread.interrupted() и isInterrupted() позволяют проверить, является ли поток прерванным.
Когда прерванный поток проверяет статус прерывания, вызывая статический метод Thread.interrupted(), статус прерывания сбрасывается.
Нестатический метод isInterrupted() используется одним потоком для проверки статуса прерывания у другого потока, не изменяя флаг прерывания.

---
## В чем заключаются различия между cтеком (stack) и кучей (heap) с точки зрения многопоточности?

[⬆️ К оглавлению](#оглавление)

Cтек - участок памяти, тесно связанный с потоками. У каждого потока есть свой стек, которые хранит локальные переменные, параметры методов и стек вызовов. Переменная, хранящаяся в стеке одного потока, не видна для другого.
Куча - общий участок памяти, который делится между всеми потоками. Объекты, неважно локальные или любого другого уровня, создаются в куче. Для улучшения производительности, поток обычно кэширует значения из кучи в свой стек, в этом случае для того, чтобы указать потоку, что переменную следует читать из кучи используется ключевое слово volatile.

---
## Как получить дамп потока?

[⬆️ К оглавлению](#оглавление)

Среды исполнения Java на основе HotSpot генерируют только дамп в формате HPROF. В распоряжении разработчика имеется несколько интерактивных методов генерации дампов и один метод генерации дампов на основе событий.
Интерактивные методы:

*   Использование Ctrl+Break: если для исполняющегося приложения установлена опция командной строки -XX:+HeapDumpOnCtrlBreak, то дамп формата HPROF генерируется вместе с дампом потока при наступлении события Ctrl+Break или SIGQUIT (обычно генерируется с помощью kill -3), которое инициируется посредством консоли. Эта опция может быть недоступна в некоторых версиях. В этом случае можно попытаться использовать следующую опцию: -Xrunhprof:format=b,file=heapdump.hprof
*   Использование инструмента jmap: утилита jmap, поставляемая в составе каталога /bin/ комплекта JDK, позволяет запрашивать дамп HPROF из исполняющегося процесса.
*   Использование операционной системы: Для создания файла ядра можно воспользоваться неразрушающей командой gcore или разрушающими командами kill -6 или kill -11. Затем извлечь дамп кучи из файла ядра с помощью утилиты jmap.
*   Использование инструмента JConsole. Операция dumpHeap предоставляется в JConsole как MBean-компонент HotSpotDiagnostic. Эта операция запрашивает генерацию дампа в формате HPROF.

Метод на основе событий:

*   Событие OutOfMemoryError: Если для исполняющегося приложения установлена опция командной строки -XX:+HeapDumpOnOutOfMemoryError, то при возникновении ошибки OutOfMemoryError генерируется дамп формата HPROF. Это идеальный метод для «production» систем, поскольку он практически обязателен для диагностирования проблем памяти и не сопровождается постоянными накладными расходами с точки зрения производительности. В старых выпусках сред исполнения Java на базе HotSpot для этого события не устанавливается предельное количество дампов кучи в пересчете на одну JVM; в более новых выпусках допускается не более одного дампа кучи для этого события на каждый запуск JVM.

---
## Что такое ThreadLocal?

[⬆️ К оглавлению](#оглавление)

`ThreadLocal` — это специальный класс в Java, который позволяет создавать переменные, доступные только для одного конкретного потока (thread). Каждый поток, обращающийся к `ThreadLocal` переменной, будет видеть свою собственную, независимо инициализированную копию этой переменной.

Проще говоря, если у вас есть `ThreadLocal<String> myVar;`, то:
*   Поток A, установив `myVar.set("Hello from A")`, будет видеть "Hello from A" при вызове `myVar.get()`.
*   Поток B, установив `myVar.set("Bonjour de B")`, будет видеть "Bonjour de B" при вызове `myVar.get()`.
*   Значение, установленное потоком A, не будет видно потоку B, и наоборот.

Это принципиально отличается от обычных переменных (экземпляра или статических), которые являются общими для всех потоков, если только не предприняты специальные меры по синхронизации.

**Зачем нужны ThreadLocal?**

1.  **Хранение контекста потока:** Часто возникает необходимость хранить информацию, специфичную для текущего потока, например:
    *   ID пользователя или транзакции.
    *   Соединение с базой данных (хотя современные пулы соединений обычно справляются с этим лучше).
    *   Экземпляры не потокобезопасных классов, таких как `SimpleDateFormat` или `Random` (хотя для `Random` есть `ThreadLocalRandom`).
    *   Контекст безопасности или локализации.

2.  **Избежание передачи параметров через множество методов:** Если некий объект или значение нужно многим методам в стеке вызовов одного потока, вместо того чтобы передавать его как параметр через каждый метод, можно поместить его в `ThreadLocal`.

3.  **Достижение потокобезопасности для изменяемого состояния:** Если каждый поток работает со своей копией объекта, то проблемы синхронизации доступа к этому объекту отпадают.

---
## Как это работает "под капотом"? (ThreadLocal)

[⬆️ К оглавлению](#оглавление)

Магия `ThreadLocal` не в самом объекте `ThreadLocal`, а в том, как он взаимодействует с классом `Thread`.

1.  **`Thread.threadLocals` и `Thread.inheritableThreadLocals`:**
    Каждый объект `Thread` в Java имеет два поля типа `ThreadLocal.ThreadLocalMap` (это внутренний статический класс `ThreadLocal`):
    *   `threadLocals`: для обычных `ThreadLocal` переменных.
    *   `inheritableThreadLocals`: для `InheritableThreadLocal` переменных (о них чуть позже).

2.  **`ThreadLocalMap`:**
    *   Это специализированная хэш-карта.
    *   **Ключами** в этой карте являются сами экземпляры `ThreadLocal` (точнее, слабые ссылки на них - `WeakReference<ThreadLocal<?>>`).
    *   **Значениями** являются фактические данные, которые мы хотим сохранить для данного потока (например, строка "Hello from A").

3.  **Методы `ThreadLocal`:**
    *   **`set(T value)`:**
        1.  Получает текущий поток (`Thread.currentThread()`).
        2.  Получает `ThreadLocalMap` из этого потока.
        3.  Если карта еще не существует, она создается и присваивается полю `threadLocals` текущего потока.
        4.  В эту карту помещается пара: `this` (текущий экземпляр `ThreadLocal`) в качестве ключа и `value` в качестве значения.

    *   **`get()`:**
        1.  Получает текущий поток.
        2.  Получает `ThreadLocalMap` из этого потока.
        3.  Если карта существует и содержит запись для `this` (текущего `ThreadLocal`), возвращает соответствующее значение.
        4.  Если карта не существует или не содержит записи для `this`, вызывается метод `initialValue()`. Результат этого метода сохраняется в карте (если ее не было, она создается) и возвращается.

    *   **`remove()`:**
        1.  Получает текущий поток.
        2.  Получает `ThreadLocalMap` из этого потока.
        3.  Если карта существует, удаляет из нее запись, соответствующую `this` (текущему `ThreadLocal`). Это **очень важный** метод для предотвращения утечек памяти.

    *   **`initialValue()`:**
        1.  Защищенный метод, который по умолчанию возвращает `null`.
        2.  Его можно переопределить в анонимном классе или подклассе `ThreadLocal` для предоставления начального значения переменной, если `get()` вызывается до `set()`.

---
## Утечки памяти и `remove()` (ThreadLocal)

[⬆️ К оглавлению](#оглавление)

Представим типичный сценарий в веб-приложении:

1.  **Запрос 1 приходит:** Поток из пула (назовем его `Thread-A`) берется для обработки запроса.
2.  **`ThreadLocal` используется:** В коде обработки запроса создается некий большой объект (например, `UserData` с информацией о пользователе) и помещается в `ThreadLocal`:
    ```java
    // Допустим, userSessionData - это статическая ThreadLocal переменная
    userSessionData.set(new UserData(...)); // UserData - потенциально большой объект
    ```
3.  **Запрос 1 завершается:** Логика обработки запроса завершена. **НО! Разработчик забыл вызвать `userSessionData.remove()`.**
4.  **Поток возвращается в пул:** `Thread-A` не уничтожается, а возвращается в пул потоков. Его `ThreadLocalMap` все еще существует и содержит запись:
    *   Ключ: `WeakReference` на объект `userSessionData` (сам `ThreadLocal`).
    *   Значение: Сильная ссылка на объект `UserData`, созданный для Запроса 1.
5.  **Объект `UserData` не может быть собран сборщиком мусора:** Поскольку `Thread-A` жив и его `ThreadLocalMap` все еще ссылается (сильно) на объект `UserData`, этот объект не может быть удален сборщиком мусора, даже если он больше никому не нужен для логики приложения.
6.  **Запрос 2 приходит:** `Thread-A` (или другой поток) снова берется из пула. Если это `Thread-A`, он может перезаписать значение в `userSessionData`, но старый объект `UserData` от Запроса 1 все еще может оставаться в памяти, если не произошли определенные внутренние очистки в `ThreadLocalMap` (о них ниже). Если это другой поток, он создаст свою запись.
7.  **Накопление:** С каждым новым запросом, который обрабатывается потоками из пула и для которого не вызывается `remove()`, в `ThreadLocalMap` этих потоков накапливаются "бесхозные" объекты. Это приводит к постепенному росту потребления памяти кучи (heap) и в конечном итоге к `OutOfMemoryError`.

**Почему явный `remove()` так важен:**

Когда вы вызываете `threadLocalVariable.remove()`:

1.  Находится текущий поток.
2.  Из его `ThreadLocalMap` удаляется запись, соответствующая `threadLocalVariable`.
3.  Это приводит к тому, что сильная ссылка из `ThreadLocalMap.Entry` на ваше значение (например, `UserData`) удаляется.
4.  Если на объект `UserData` больше нет других сильных ссылок, он становится доступным для сборки мусора.

---
## Что такое «блокирующий метод»?

[⬆️ К оглавлению](#оглавление)

Блокирующий метод - метод, который блокируется, до тех пор, пока задание не выполнится, например метод accept() у ServerSocket блокируется в ожидании подключения клиента. Здесь блокирование означает, что контроль не вернётся к вызывающему методу до тех пор, пока не выполнится задание. Так же существуют асинхронные или неблокирующиеся методы, которые могут завершится до выполнения задачи.

---
## Чем полезны неизменяемые объекты?

[⬆️ К оглавлению](#оглавление)

Неизменяемость (immutability) помогает облегчить написание многопоточного кода. Неизменяемый объект может быть использован без какой-либо синхронизации. К сожалению, в Java нет аннотации @Immutable, которая делает объект неизменяемым, для этого разработчикам нужно самим создавать класс с необходимыми характеристиками. Для этого необходимо следовать некоторым общим принципам: инициализация всех полей только в конструкторе, отсутствие методов setX() вносящих изменения в поля класса, отсутствие утечек ссылки, организация отдельного хранилища копий изменяемых объектов и т.д.

---
## Что такое busy spin?

[⬆️ К оглавлению](#оглавление)

Busy spin — это подход, при котором поток в цикле проверяет состояние переменной (например, флага), пока не выполнится определённое условие. В отличие от блокирующих механизмов, таких как synchronized или Lock, busy spin не переводит поток в состояние ожидания, что позволяет избежать оверхеда переключения контекста, но увеличивает нагрузку на CPU.

---
## Перечислите принципы, которым вы следуете в многопоточном программировании?

[⬆️ К оглавлению](#оглавление)

При написании многопоточных программ следует придерживаться определённых правил, которые помогают обеспечить достойную производительность приложения в сочетании с удобной отладкой и простотой дальнейшей поддержки кода.

*   Всегда давайте значимые имена своим потокам. Процесс отладки, нахождения ошибок или отслеживание исключения в многопоточном коде - довольно сложная задача. OrderProcessor, QuoteProcessor или TradeProcessor намного информативнее, чем Thread1, Thread2 и Thread3. Имя должно отражать задачу, выполняемую данным потоком.
*   Избегайте блокировок или старайтесь уменьшить масштабы синхронизации. Блокировка затратна, а переключение контекста ещё более ресурсоёмко. Пытайтесь избегать синхронизации и блокировки насколько это возможно, и организуйте критическую секцию в минимально необходимом объёме. Поэтому синхронизированный блок всегда предпочительней синхронизированного метода, дополнительно наделяя возможностью абсолютного контроля над масштабом блокировки.
*   Обрабатывайте прерывание потока с особой тщательностью. Нет ничего хуже оставшегося заблокированным ресурса или системы в неконстистентном, по причине неподтверждённой транзакции, состоянии.
*   Помните об обработке исключений. Выброшенные InterruptedException должны быть адекватно обработаны, а не просто подавлены. Так же не стоит пренебрегать Thread.UncaughtExceptionHandler. При использовании пула потоков необходимо помнить, что он зачастую просто «проглатывает» исключения. Так, если вы отправили на выполнение Runnable нужно обязательно поместить код выполнения задачи внутрь блока try-catch. Если в очередь пула помещается Callable, необходимо удостоверится, что результат выполнения всегда изымается помощью блокирующего get(), чтобы в случае возникновения существовала возможнотсь заново выбросить произошедшее исключение.
*   Между синхронизаторами и wait() и notify() следует выбирать синхронизаторы. Во-первых, синхронизаторы, типа CountDownLatch, Semaphore, CyclicBarrier или Exchanger упрощают написание кода. Очень сложно реализовывать комплексный управляющий поток, используя wait() и notify(). Во-вторых, эти классы написаны и поддерживаются настоящими мастерами своего дела и есть шанс, что в последующих версиях JDK они будут оптимизированы изнутри или заменены более производительной внешней реализацией.
*   Почти всегда использование Concurrent сollection выгоднее использования Synchronized сollection, т.к. первые более современны (используют все доступные на момент их написания новшества языка) и масштабируемы, чем их синхронизированые аналоги.

---
## С какими распространенными проблемами вы столкнулись в многопоточной среде?

[⬆️ К оглавлению](#оглавление)

| Название | Описание | Пример сценария |
| - | - | - |
| Deadlock (Взаимная блокировка) | Возникает, когда два или более потока бесконечно ждут друг друга, чтобы освободить ресурсы, которые они удерживают. Это приводит к полной остановке всех задействованных потоков. | Поток 1 удерживает `lock1` и ждёт `lock2`. Поток 2 удерживает `lock2` и ждёт `lock1`. |
| Livelock | Ситуация, когда потоки активно выполняют действия, чтобы избежать конфликта, но зацикливаются, не достигая прогресса. | Два потока пытаются захватить два замка, но каждый освобождает свой замок, если не может захватить второй, что приводит к бесконечному циклу. |
| Race Condition (Состояние гонки) | Возникает, когда результат выполнения программы зависит от порядка выполнения потоков, что приводит к непредсказуемому поведению. | Два потока увеличивают общий счётчик без синхронизации, что приводит к потере обновлений. |
| Starvation (Голодание) | Возникает, когда один или несколько потоков не могут получить доступ к ресурсам из-за того, что другие потоки постоянно занимают их. | Поток с низким приоритетом не может захватить замок, так как потоки с высоким приоритетом постоянно его удерживают. |
| Thread Contention (Конкуренция потоков) | Возникает, когда множество потоков соревнуются за доступ к общему ресурсу, что приводит к снижению производительности. | Множество потоков пытаются захватить один `synchronized` блок, вызывая задержки. |
| Memory Consistency Errors (Ошибки согласованности памяти) | Эти ошибки возникают, когда разные потоки видят разные значения одной и той же переменной из-за отсутствия правильной синхронизации. | Один поток обновляет переменную, но другой поток видит устаревшее значение. |
| Thread Leaks (Утечки потоков) | Возникают, когда потоки создаются, но не завершаются должным образом, что приводит к накоплению активных потоков и потреблению ресурсов. | Пул потоков не закрывается с помощью `shutdown()`, или потоки создаются без контроля. |
| Excessive Synchronization (Избыточная синхронизация) | Слишком частое или широкое использование синхронизации может привести к снижению производительности, так как потоки будут часто ждать друг друга. | Синхронизация всего метода, когда достаточно защитить только критическую секцию. |
| InterruptedException и неправильная обработка прерываний | Неправильная обработка `InterruptedException` может привести к тому, что потоки не реагируют на сигналы прерывания, что усложняет их остановку или отмену. | Игнорирование `InterruptedException` или неправильное восстановление состояния прерывания. |
| Performance Overhead (Издержки производительности) | Неправильное использование многопоточности может привести к снижению производительности. | Создание нового потока для каждой задачи вместо использования пула потоков. |

---
## Разница между зеленым потоком и собственным потоком в Java?

[⬆️ К оглавлению](#оглавление)

Зеленые потоки относятся к модели, в которой сама виртуальная машина Java создает, управляет и переключает контекст всех потоков Java в рамках одного процесса операционной системы. Библиотека потоков операционной системы не используется.

Под собственными потоками понимается объект, в котором виртуальная машина Java создает потоки Java и управляет ими с помощью библиотеки потоков операционной системы — с именем libthread в UnixWare — и каждый поток Java отображается в один поток библиотеки потоков.

---
## Может ли конструктор быть синхронизирован?

[⬆️ К оглавлению](#оглавление)

Нет, конструктор не может быть синхронизирован. Причина, по которой это приводит к синтаксической ошибке, заключается в том, что только конструирующий поток должен иметь доступ к создаваемому объекту.

---
## Если два потока одновременно вызывают синхронизированный метод для разных экземпляров объекта, может ли один из этих потоков блокировать?

[⬆️ К оглавлению](#оглавление)

Оба метода блокируют один и тот же монитор. Следовательно, вы не можете одновременно выполнять их на одном и том же объекте из разных потоков (один из двух методов будет блокироваться, пока другой не будет завершен).

---
## Расскажи про Future?

[⬆️ К оглавлению](#оглавление)

`Future<V>` — это интерфейс, представляющий результат асинхронной задачи, где `V` — тип возвращаемого значения. Он позволяет:
*   Получить результат выполнения задачи, когда он станет доступен.
*   Проверить, завершена ли задача.
*   Отменить задачу.
*   Обрабатывать исключения, возникшие во время выполнения.

Сигнатура интерфейса:
```java
public interface Future<V> {
    boolean cancel(boolean mayInterruptIfRunning);
    boolean isCancelled();
    boolean isDone();
    V get() throws InterruptedException, ExecutionException;
    V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;
}
```

**Ключевые характеристики**:
*   **Асинхронность**: `Future` позволяет основному потоку продолжить выполнение, пока задача выполняется в фоновом режиме.
*   **Однократный результат**: Результат задачи можно получить только один раз, после чего он кэшируется.
*   **Обработка исключений**: Если задача выбрасывает исключение, оно оборачивается в `Exception` при вызове `get()`.

`Future` обычно используется с `ExecutorService`, который запускает задачи (`Callable` или `Runnable`) и возвращает объект `Future` для управления их выполнением.

### Основные методы `Future`

1.  **`V get() throws InterruptedException, ExecutionException`**:
    *   Блокирует вызывающий поток до завершения задачи и возвращает результат типа `V`.
    *   Выбрасывает:
        *   `InterruptedException` — если поток был прерван во время ожидания.
        *   `Exception` — если задача завершилась с исключением.

2.  **`V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException`**:
    *   Блокирует поток до завершения задачи или истечения таймаута.
    *   Выбрасывает `TimeoutException`, если время ожидания истекло.

3.  **`boolean cancel(boolean mayInterruptIfRunning)`**:
    *   Пытается отменить задачу:
        *   Если задача ещё не началась, она не будет выполнена.
        *   Если `mayInterruptIfRunning = true` и задача выполняется, поток может быть прерван (если задача обрабатывает `Thread.interrupted()`).
        *   Возвращает `true`, если отмена удалась, и `false`, если задача уже завершена или не может быть отменена.

4.  **`boolean isCancelled()`**:
    *   Возвращает `true`, если задача была отменена до завершения.

5.  **`boolean isDone()`**:
    *   Возвращает `true`, если задача завершена (успешно, с исключением или отменена).

### Как работает `Future`?

`Future` создаётся, когда задача отправляется на выполнение через `ExecutorService`. Например:
*   Метод `ExecutorService.submit(Callable)` возвращает `Future` для задачи `Callable`.
*   Метод `ExecutorService.submit(Runnable, V)` возвращает `Future` для задачи `Runnable` с заданным результатом `V`.

`Future` действует как "обещание" (promise), что результат будет доступен позже. Вызывающий поток может:
*   Продолжить выполнение и проверить результат позже через `get()`.
*   Периодически проверять статус с помощью `isDone()` или `isCancelled()`.

---
## Расскажи про CompletableFuture?

[⬆️ К оглавлению](#оглавление)

`CompletableFuture` — это мощный класс в Java, введённый в Java 8 в пакете `java.util.concurrent`. Он расширяет функциональность интерфейса `Future`, предоставляя более гибкий и удобный способ работы с асинхронными вычислениями. `CompletableFuture` поддерживает функциональный стиль программирования, цепочки операций, обработку исключений и композицию задач, что делает его предпочтительным выбором для современных многопоточных приложений по сравнению с `Future`. Он также позволяет работать в неблокирующем режиме, что особенно полезно для высокопроизводительных систем.

### Что такое `CompletableFuture`?

`CompletableFuture<V>` реализует два интерфейса:
*   **`Future<V>`**: Позволяет получать результат асинхронной задачи (как и обычный `Future`).
*   **`CompletionStage<V>`**: Предоставляет методы для создания цепочек асинхронных операций, обработки результатов и исключений в функциональном стиле.

`CompletableFuture` решает основные ограничения `Future`:
*   **Блокировка**: `Future.get()` блокирует поток, тогда как `CompletableFuture` поддерживает неблокирующие callback’и.
*   **Композиция**: Позволяет создавать цепочки операций (например, преобразование результата, запуск новых задач).
*   **Обработка исключений**: Упрощает работу с ошибками через методы, такие как `exceptionally` или `handle`.

**Ключевые особенности**:
*   **Асинхронность**: Задачи выполняются в пуле потоков (по умолчанию `ForkJoinPool.commonPool()`), но можно указать свой `Executor`.
*   **Функциональный стиль**: Методы, такие как `thenApply`, `thenCompose`, позволяют строить цепочки операций.
*   **Ручное завершение**: Можно вручную завершить задачу с помощью `complete` или `completeExceptionally`.

### Основные методы `CompletableFuture`

`CompletableFuture` предоставляет множество методов, которые можно разделить на несколько категорий:

#### 1. **Создание `CompletableFuture`**
*   **`static <U> CompletableFuture<U> supplyAsync(Supplier<U> supplier)`**:
    *   Запускает асинхронную задачу, возвращающую результат типа `U`.
*   **`static CompletableFuture<Void> runAsync(Runnable runnable)`**:
    *   Запускает асинхронную задачу без возвращаемого результата.
*   **`static <U> CompletableFuture<U> completedFuture(U value)`**:
    *   Создаёт уже завершённый `CompletableFuture` с заданным результатом.
*   **Передача `Executor`**:
    *   Все методы `supplyAsync` и `runAsync` имеют перегрузки, принимающие `Executor` для выполнения задачи в указанном пуле потоков:
        ```java
        supplyAsync(() -> "Результат", executor);
        ```

#### 2. **Цепочки операций (CompletionStage)**
*   **`thenApply(Function<T, U>)`**:
    *   Применяет функцию к результату и возвращает новый `CompletableFuture<U>`.
*   **`thenAccept(Consumer<T>)`**:
    *   Выполняет действие с результатом, не возвращая значения.
*   **`thenRun(Runnable)`**:
    *   Выполняет действие без использования результата.
*   **`thenCompose(Function<T, CompletableFuture<U>>)`**:
    *   Позволяет создавать цепочку, где результат одной задачи используется для запуска другой асинхронной задачи.
*   **`thenCombine(CompletionStage<U>, BiFunction<T, U, V>)`**:
    *   Комбинирует результаты двух `CompletableFuture`.

#### 3. **Обработка исключений**
*   **`exceptionally(Function<Throwable, T>)`**:
    *   Обрабатывает исключение и возвращает запасное значение.
*   **`handle(BiFunction<T, Throwable, U>)`**:
    *   Обрабатывает результат или исключение, возвращая новый результат.

#### 4. **Управление завершением**
*   **`complete(T value)`**:
    *   Ручное завершение задачи с указанным результатом.
*   **`completeExceptionally(Throwable ex)`**:
    *   Ручное завершение задачи с исключением.
*   **`cancel(boolean mayInterruptIfRunning)`**:
    *   Отменяет задачу (аналогично `Future.cancel`).

#### 5. **Проверка статуса**
*   **`isDone()`**:
    *   Возвращает `true`, если задача завершена.
*   **`isCancelled()`**:
    *   Возвращает `true`, если задача была отменена.
*   **`isCompletedExceptionally()`**:
    *   Возвращает `true`, если задача завершилась с исключением.

### Сравнение с `Future`

| **Характеристика**       | **Future**                               | **CompletableFuture**                    |
|--------------------------|------------------------------------------|------------------------------------------|
| **Блокировка**           | `get()` блокирует                       | Неблокирующие методы (`thenApply`, etc.) |
| **Цепочки операций**     | Не поддерживает                         | Поддерживает функциональный стиль        |
| **Создание**             | Через `ExecutorService`                 | Через `supplyAsync`, `runAsync`, вручную |
| **Обработка исключений** | Через `ExecutionException`              | Через `exceptionally`, `handle`          |
| **Отмена**               | Ограниченная (`cancel`)                 | Более гибкая (`completeExceptionally`)   |

---
## Какие Синхронизаторы есть в java?

[⬆️ К оглавлению](#оглавление)

| Название         | Описание                                                                 |
|------------------|--------------------------------------------------------------------------|
| **Semaphore**    | Объект синхронизации, ограничивающий количество потоков, которые могут «войти» в заданный участок кода. |
| **CountDownLatch** | Объект синхронизации, разрешающий вход в заданный участок кода при выполнении определенных условий. |
| **CyclicBarrier** | Объект синхронизации типа «барьер», блокирующий выполнение определенного кода для заданного количества потоков. |
| **Exchanger**    | Объект синхронизации, позволяющий провести обмен данными между двумя потоками. |
| **Phaser**       | Объект синхронизации типа «барьер», но в отличие от `CyclicBarrier`, предоставляет больше гибкости. |

---
## Объект синхронизации Semaphore?

[⬆️ К оглавлению](#оглавление)

**Semaphore** в Java — это объект-счетчик, который позволяет ограниченному количеству потоков одновременно выполнять определенный участок
кода или получать доступ к ресурсу.
![Alt Text](img/Semaphore.gif)

`Semaphore` управляет доступом к ресурсам с помощью счётчика разрешений (permits). Основные характеристики:
*   **Счётчик разрешений**: Указывает, сколько потоков могут одновременно получить доступ к ресурсу.
*   **Приобретение (acquire)**: Поток запрашивает разрешение; если разрешений нет, поток блокируется до их появления.
*   **Освобождение (release)**: Поток возвращает разрешение, позволяя другим потокам получить доступ.
*   **Гибкость**: Поддерживает как справедливую (fair), так и несправедливую (non-fair) политику выдачи разрешений.

`Semaphore` часто используется для:
*   Ограничения числа одновременно выполняющихся задач (например, ограничение числа соединений к базе данных).
*   Реализации пула ресурсов.
*   Координации потоков (например, в сценариях producer-consumer).

#### **Ключевые методы**
*   **`acquire(int permits)`**: Запрашивает указанное количество разрешений. Если их недостаточно, поток блокируется.
*   **`release(int permits)`**: Освобождает указанное количество разрешений, позволяя другим потокам продолжить.
*   **`tryAcquire(int permits, long timeout, TimeUnit unit)`**: Пытается получить разрешения с таймаутом.
*   **`availablePermits()`**: Возвращает текущее число доступных разрешений.
*   **`drainPermits()`**: Забирает все доступные разрешения, возвращая их количество.
---
## Объект синхронизации CountDownLatch

[⬆️ К оглавлению](#оглавление)

**CountDownLatch** в Java — это объект синхронизации, который позволяет одному или нескольким потокам ждать, пока заданное количество
операций, выполняемых в других потоках, не будет завершено.

![Alt Text](img/CountDownLatch.gif)

### **Что такое CountDownLatch?**

`CountDownLatch` — это синхронизационный примитив, который:
*   Инициализируется с заданным количеством событий (счётчиком).
*   Позволяет потокам **ожидать** (`await`), пока счётчик не станет равным нулю.
*   Уменьшает счётчик с помощью метода `countDown()`, вызываемого при завершении каждого события.
*   "Открывает защёлку", когда счётчик достигает нуля, позволяя ожидающим потокам продолжить выполнение.

**Основные сценарии использования**:
*   Ожидание завершения нескольких задач перед продолжением (например, инициализация системы).
*   Координация старта нескольких потоков (например, запуск теста одновременно).
*   Синхронизация в стиле "все или ничего" (все потоки должны завершить работу, прежде чем главный поток продолжит).

#### **Ключевые методы**
*   **`await()`**: Блокирует вызывающий поток, пока счётчик не станет равным нулю.
*   **`await(long timeout, TimeUnit unit)`**: Ожидает с таймаутом; возвращает `true`, если счётчик достиг нуля, или `false`, если время ожидания истекло.
*   **`countDown()`**: Уменьшает счётчик на 1. Если счётчик становится равным 0, все ожидающие потоки разблокируются.
*   **`getCount()`**: Возвращает текущее значение счётчика.

#### **Атомарность**
*   Все операции с счётчиком (`state`) выполняются атомарно через CAS, что обеспечивает потокобезопасность без необходимости явных блокировок.
*   Например, метод `countDown()` использует `compareAndSetState` для уменьшения счётчика.

#### **Одноразовость**
*   После того как счётчик достигает нуля, защёлка остаётся открытой навсегда.
*   Последующие вызовы `countDown()` не изменяют состояние, а вызовы `await()` завершаются немедленно.
    Если нужен многоразовый барьер, где потоки могут собираться вместе несколько раз, для этого есть другой инструмент — CyclicBarrier.
---
## Объект синхронизации CyclicBarrier

[⬆️ К оглавлению](#оглавление)

**CyclicBarrier** (Циклический барьер) — это точка синхронизации (сбора), в которой группа потоков должна дождаться друг друга, прежде чем
продолжить выполнение вместе. После того как все потоки собрались и были "отпущены", барьер автоматически сбрасывается и может быть
использован снова для следующей точки сбора.
![Alt Text](img/CyclicBarrier.gif)

`CyclicBarrier` позволяет заданному числу потоков (участников) синхронизироваться в точке барьера. Каждый поток, достигая барьера, вызывает метод `await()` и блокируется, пока все участники не достигнут барьера. После этого барьер "открывается", все потоки разблокируются, и может быть выполнен опциональный действие барьера (`barrierAction`). Поскольку барьер многоразовый, он сбрасывается и может быть использован снова для следующего цикла.

**Основные характеристики**:
*   **Число участников**: Задаётся при создании барьера (`parties`) и определяет, сколько потоков должны достичь барьера для его открытия.
*   **Многоразовость**: После открытия барьер сбрасывается и готов к следующему использованию.
*   **Опциональное действие**: Можно указать `Runnable`, выполняемый при открытии барьера.
*   **Обработка исключений**: Поддерживает механизмы для обработки сбоев (например, прерывания или таймаута).

**Сценарии использования**:
*   Параллельные вычисления с несколькими фазами (например, итеративные алгоритмы).
*   Тестирование, где несколько потоков должны стартовать одновременно.
*   Моделирование процессов, где этапы выполнения требуют синхронизации всех участников.

#### **Ключевые методы**
*   **`await()`**: Блокирует поток, пока все `parties` потоков не вызовут `await()`. Возвращает индекс прибытия потока (от 0 до `parties-1`).
*   **`await(long timeout, TimeUnit unit)`**: Ожидает с таймаутом; выбрасывает `TimeoutException`, если время ожидания истекло.
*   **`reset()`**: Сбрасывает барьер в исходное состояние, ломая текущий цикл и создавая новый.
*   **`isBroken()`**: Проверяет, сломан ли барьер (например, из-за прерывания или таймаута).
*   **`getNumberWaiting()`**: Возвращает текущее число потоков, ожидающих на барьере.
*   **`getParties()`**: Возвращает общее число участников барьера.

#### **Обработка сбоев**
*   Если поток прерывается во время `await()`, барьер становится "сломанным" (`broken = true`), и все ожидающие потоки получают `BrokenBarrierException`.
*   Если таймаут истекает в `await(long timeout, TimeUnit unit)`, поток также вызывает "ломку" барьера.
*   Сломанный барьер можно сбросить с помощью `reset()`.

#### **Потокобезопасность**
*   Все операции (`await`, `reset`, `getNumberWaiting`) защищены `ReentrantLock`, что обеспечивает атомарность и отсутствие гонок данных.
*   `Condition trip` позволяет эффективно управлять ожиданием и уведомлением потоков.

---
## Объект синхронизации Exchanger

[⬆️ К оглавлению](#оглавление)

**Exchanger** в Java — `Exchanger` предоставляет точку синхронизации, где два потока могут обменяться объектами. Каждый поток вызывает
метод `exchange()` и передаёт свой объект, затем блокируется, пока второй поток не вызовет `exchange()` и не предоставит свой объект. После
этого потоки обмениваются данными и продолжают выполнение.

![Alt Text](img/Exchanger.gif)


**Основные характеристики**:
*   **Парный обмен**: Работает только с двумя потоками одновременно.
*   **Блокировка**: Поток, вызвавший `exchange()`, ждёт, пока второй поток не достигнет точки обмена.
*   **Многоразовость**: `Exchanger` можно использовать многократно для повторных обменов.
*   **Обработка исключений**: Поддерживает прерывания и таймауты.

**Сценарии использования**:
*   Обмен данными между двумя потоками (например, буферами в паттерне producer-consumer).
*   Алгоритмы, такие как генетические алгоритмы или сортировка, где потоки обмениваются промежуточными результатами.
*   Тестирование, где два потока должны синхронизировать свои действия.

#### **Ключевые компоненты**

1.  **Node**:
    *   Внутренний класс, представляющий узел, связанный с потоком, который ожидает обмена.
    *   Содержит:
        *   `item`: Объект, который поток предлагает для обмена.
        *   `match`: Ссылка на объект, полученный от другого потока.
        *   `parked`: Ссылка на поток, который заблокирован в ожидании (`Thread`).
        *   `hole`: Атомарная ссылка (`AtomicReference`) для управления состоянием узла.

2.  **Arena**:
    *   Массив (`arena`) из атомарных ссылок (`AtomicReference`), используемый для предотвращения конфликтов при конкурентном доступе.
    *   Введён в Java 9 для повышения производительности на многоядерных системах, где конкуренция за одну точку обмена может вызывать узкие места.
    *   Каждый элемент массива представляет "слот" для обмена, и потоки распределяются по слотам для минимизации конфликтов.

3.  **AtomicReference и CAS**:
    *   `Exchanger` использует `AtomicReference` для атомарного обновления состояния (например, для установки узлов или обмена данными).
    *   CAS-операции (`compareAndSet`) обеспечивают потокобезопасность без явных блокировок.

4.  **spinCount и bound**:
    *   `spinCount`: Количество итераций спин-блокировки (активного ожидания) перед использованием блокировки (`LockSupport.park()`).
    *   `bound`: Параметр для управления размером `arena`, связанный с количеством процессоров (`Runtime.getRuntime().availableProcessors()`).

5.  **arenaBuffer**:
    *   Специальный объект-заглушка, используемый для инициализации и очистки слотов в `arena`.

#### **Ключевые методы**
*   **`exchange(V x)`**: Вызывается потоком для обмена объектом `x`. Блокирует поток, пока второй поток не вызовет `exchange()`. Возвращает объект, полученный от второго потока.
*   **`exchange(V x, long timeout, TimeUnit unit)`**: То же, что и `exchange(V x)`, но с таймаутом. Выбрасывает `TimeoutException`, если второй поток не достиг точки обмена в указанное время.
*   **Исключения**:
    *   `InterruptedException`: Если поток прерывается во время ожидания.
    *   `TimeoutException`: Если истекает таймаут в версии с ограничением времени.

---
## Объект синхронизации Phaser

[⬆️ К оглавлению](#оглавление)

**Phaser** позволяет синхронизировать потоки, работающие в фазах, где каждая фаза завершается, когда все зарегистрированные участники
достигают точки синхронизации (барьера). После завершения фазы потоки могут продолжить выполнение следующей фазы, а `Phaser` может выполнять
опциональное действие. В отличие от `CyclicBarrier`, `Phaser` поддерживает динамическое изменение числа участников и может быть завершён
явно.

![Alt Text](img/Phaser.gif)

`Phaser` оперирует двумя основными понятиями: **фазы (phases)** и **участники (parties)**.

* **Фаза:** Это просто номер итерации, который начинается с 0. Когда все участники текущей фазы собрались у барьера, номер фазы
  увеличивается, и начинается следующая.
* **Участник:** Это поток, зарегистрированный в `Phaser`.

#### Основные методы

Вместо одного `await()` у `Phaser` есть целый набор методов для "прибытия" к барьеру:

1. `arriveAndAwaitAdvance()`: **"Я пришел и буду ждать всех остальных"**.
   Это самый распространенный метод, аналог `CyclicBarrier.await()`. Поток прибывает и блокируется, пока все остальные зарегистрированные
   участники не прибудут.

2. `arrive()`: **"Я пришел, но ждать не буду, у меня еще дела"**.
   Поток сообщает о своем прибытии (уменьшая счетчик необходимых прибытий для текущей фазы), но **не блокируется**. Он может продолжить
   выполнять какую-то другую работу. Это полезно для потоков-координаторов.

3. `arriveAndDeregister()`: **"Я пришел, выполнил свою работу и покидаю группу"**.
   Это главная "фишка". Поток прибывает к барьеру и одновременно сообщает, что в следующей фазе он участвовать не будет. `Phaser`
   автоматически уменьшит количество ожидаемых участников для всех будущих фаз.

#### Регистрация и завершение

* **Регистрация:**
    * `new Phaser(int parties)`: Создать `Phaser` и сразу зарегистрировать в нем `parties` участников.
    * `register()`: Зарегистрировать нового участника. Теперь `Phaser` будет ждать еще одного.
    * `bulkRegister(int parties)`: Зарегистрировать сразу несколько новых участников.

* **Завершение (Termination):**
    * `onAdvance(int phase, int registeredParties)`: Это метод, который можно переопределить. Он вызывается автоматически, когда одна фаза
      завершается, но до того, как потоки будут отпущены. Если этот метод возвращает `true`, то `Phaser` переходит в состояние "завершен" (
      terminated) и больше не работает. Это позволяет гиду сказать: "Так, мы посетили все города, тур окончен!".

---
## Расскажи на чем основаны обьекты синхранизации? (AbstractQueuedSynchronizer)

[⬆️ К оглавлению](#оглавление)

**AbstractQueuedSynchronizer (AQS)** — это каркас для создания блокировщиков и синхронизаторов. Он берет на себя всю сложную работу по
управлению очередью ждущих потоков, а от вас требует реализовать только простую логику: **"Можно ли сейчас захватить ресурс?"** и **"Что
происходит при освобождении ресурса?"**.

### Из чего состоит AQS? Три кита

1. **Состояние (`state`)**
   Это простое число (`int`), которое вы используете для своих целей. AQS не знает, что оно означает, это решаете вы.
    * Для `ReentrantLock`: `state` — это количество раз, которое один и тот же поток захватил замок (для reentrant-логики). 0 — свободен,
      1 — захвачен 1 раз, 2 — захвачен 2 раза и т.д.
    * Для `Semaphore`: `state` — это количество доступных разрешений. `new Semaphore(10)` установит `state` в 10.
    * Для `CountDownLatch`: `state` — это значение счетчика, который нужно уменьшить до нуля.

2. **Очередь Ожидания (Wait Queue)**
   Это самое сердце AQS. Когда поток пытается захватить ресурс, но не может, AQS автоматически:
    * Создает "узел" (`Node`) для этого потока.
    * Ставит этот узел в конец очень эффективной FIFO-очереди (она называется CLH queue).
    * "Паркует" (усыпляет) поток, чтобы он не тратил процессорное время.
    * Когда ресурс освобождается, AQS берет первый поток из очереди, "будит" его, и тот снова пытается захватить ресурс.

3. **Методы для реализации (та самая "пустая страница")**
   AQS просит вас реализовать всего несколько методов. Основных два типа:

    * **Эксклюзивный режим (Exclusive Mode):** Ресурс может быть захвачен только одним потоком. (Как `ReentrantLock`).
        * `protected boolean tryAcquire(int arg)`: Попытаться захватить ресурс. Вернуть `true`, если получилось, `false` — если нет.
        * `protected boolean tryRelease(int arg)`: Попытаться освободить ресурс.
        * `protected boolean isHeldExclusively()`: Захвачен ли ресурс текущим потоком?

    * **Общий режим (Shared Mode):** Ресурс может быть захвачен несколькими потоками. (Как `Semaphore`).
        * `protected int tryAcquireShared(int arg)`: Попытаться захватить ресурс в общем режиме. Вернуть неотрицательное число, если
          получилось, и отрицательное, если нет.
        * `protected boolean tryReleaseShared(int arg)`: Попытаться освободить ресурс в общем режиме.

---
## Что такое Lock?

[⬆️ К оглавлению](#оглавление)

`Lock` это интерфейс из пакета `java.util.concurrent.locks`, введённый в Java 5 предоставляет явный механизм блокировки, где поток должен явно захватить блокировку (`lock()`) перед доступом к критической секции и освободить её (`unlock()`) после завершения. Это контрастирует с `synchronized`, где блокировка и освобождение происходят автоматически при входе и выходе из блока или метода.

Основные характеристики:
*   **Явное управление**: Поток сам решает, когда захватить и освободить блокировку.
*   **Гибкость**: Поддерживает различные стратегии захвата (блокирующий, неблокирующий, с таймаутом, прерываемый).
*   **Условия (`Condition`)**: Позволяет создавать объекты `Condition` для координации потоков (аналог `wait()`/`notify()`).
*   **Потокобезопасность**: Гарантирует, что только один поток может владеть блокировкой в данный момент.

Ключевой интерфейс `Lock`:
```java
public interface Lock {
    void lock(); // Блокирующий захват
    void lockInterruptibly() throws InterruptedException; // Прерываемый захват
    boolean tryLock(); // Неблокирующая попытка захвата
    boolean tryLock(long time, TimeUnit unit) throws InterruptedException; // Попытка с таймаутом
    void unlock(); // Освобождение блокировки
    Condition newCondition(); // Создание объекта Condition
}
```

---
## Что такое ReentrantLock?

[⬆️ К оглавлению](#оглавление)

`ReentrantLock` — Он предоставляет потокобезопасный механизм синхронизации, позволяющий управлять доступом к общим ресурсам в многопоточной
среде. `ReentrantLock` является более гибкой альтернативой встроенному механизму `synchronized`, обеспечивая такие возможности, как
прерываемость, таймауты, неблокирующие попытки захвата и поддержка условий (`Condition`). Название "reentrant" отражает его способность
поддерживать **повторный вход** (reentrancy), то есть поток, уже владеющий блокировкой, может захватить её снова без блокировки самого себя.

`ReentrantLock` позволяет потоку явно захватывать блокировку (`lock()`) для выполнения критической секции кода и освобождать её (`unlock()`) после завершения. Основные характеристики:
*   **Явное управление**: В отличие от `synchronized`, где блокировка и освобождение происходят автоматически, `ReentrantLock` требует ручного вызова `lock()` и `unlock()`.
*   **Повторный вход**: Поток, уже владеющий блокировкой, может захватить её снова, увеличивая счётчик входов.
*   **Гибкость**: Поддерживает неблокирующие попытки (`tryLock`), прерываемые блокировки (`lockInterruptibly`), таймауты и справедливый режим (fair mode).
*   **Условия (`Condition`)**: Позволяет создавать объекты `Condition` для координации потоков, аналогично `wait()`/`notify()`.

#### **Условия (`Condition`)**
*   Метод `newCondition()` создаёт объект `Condition`, связанный с `ReentrantLock`.
*   `Condition` используется для координации потоков:
    *   `await()`: Освобождает блокировку и переводит поток в ожидание.
    *   `signal()`/`signalAll()`: Разбуживает один или все ожидающие потоки.
*   Используется, например, в `ArrayBlockingQueue` для ожидания непустой (`notEmpty`) или незаполненной (`notFull`) очереди.

---
## Как использовать ReadWriteLock?

[⬆️ К оглавлению](#оглавление)

`ReadWriteLock` — это интерфейс в Java из пакета `java.util.concurrent.locks`, введённый в Java 5, который предоставляет механизм синхронизации, разделяющий доступ к ресурсу на два типа блокировок: **чтение** (`readLock`) и **запись** (`writeLock`). Он предназначен для сценариев, где операции чтения значительно преобладают над операциями записи, позволяя множеству потоков одновременно читать данные, но только одному потоку выполнять запись. Это обеспечивает более высокую конкурентность по сравнению с обычной блокировкой, такой как `ReentrantLock`, которая эксклюзивно блокирует доступ для всех операций. Основная реализация `ReadWriteLock` — это класс `ReentrantReadWriteLock`.

`ReadWriteLock` разделяет доступ к ресурсу на:
*   **Read Lock** (`readLock`): Позволяет множеству потоков одновременно читать данные, если нет активной записи. Это повышает производительность в сценариях с частым чтением.
*   **Write Lock** (`writeLock`): Эксклюзивная блокировка, позволяющая только одному потоку выполнять запись, блокируя все операции чтения и другие записи.

Ключевые характеристики:
*   **Многопоточное чтение**: Несколько потоков могут удерживать `readLock` одновременно, если нет активного `writeLock`.
*   **Эксклюзивная запись**: Только один поток может удерживать `writeLock`, и он блокирует все операции чтения и записи.
*   **Потокобезопасность**: Гарантирует отсутствие состояний гонки при конкурентном доступе.
*   **Гибкость**: Поддерживает повторный вход (reentrancy), справедливый режим (fairness) и условия (`Condition`) для `writeLock`.

### **Основная реализация: `ReentrantReadWriteLock`**
`ReentrantReadWriteLock` — это основная реализация `ReadWriteLock`, которая:
*   Поддерживает повторный вход: поток, удерживающий `readLock` или `writeLock`, может снова захватить ту же блокировку.
*   Использует **AbstractQueuedSynchronizer (AQS)** для управления состоянием и очередью ожидающих потоков.
*   Поддерживает два режима:
    *   **Nonfair** (по умолчанию): Новый поток может захватить блокировку, даже если другие ждут, что повышает производительность, но может привести к голоданию.
    *   **Fair**: Потоки получают блокировку в порядке очереди, минимизируя голодание, но снижая производительность.

#### **Условия (`Condition`)**
*   `writeLock` поддерживает создание объектов `Condition` через `writeLock().newCondition()`.
*   `readLock` не поддерживает `Condition`, так как это редко нужно для операций чтения.
*   `Condition` используется для ожидания определённых условий, как в `ReentrantLock`.

---
## Когда используется StampedLock?

[⬆️ К оглавлению](#оглавление)

`StampedLock` — предоставляет более гибкий и производительный механизм синхронизации по сравнению с `ReentrantLock`
и `ReentrantReadWriteLock`. Он предназначен для сценариев, где требуется высокая конкурентность, особенно при большом количестве операций
чтения и редких операциях записи. В отличие от других блокировок, `StampedLock` поддерживает **оптимистическое чтение** (optimistic read),
что позволяет минимизировать блокировки в сценариях с низкой вероятностью конфликтов. Однако он не реализует интерфейс `Lock`, что делает
его использование менее стандартным, но более эффективным в определённых случаях.

`StampedLock` предоставляет три типа доступа к ресурсу:
*   **Write Lock**: Эксклюзивная блокировка для записи, аналогичная `writeLock` в `ReentrantReadWriteLock`. Только один поток может удерживать её, блокируя все другие операции.
*   **Read Lock**: Блокировка для чтения, позволяющая множеству потоков читать одновременно, если нет активной записи. Аналогична `readLock` в `ReentrantReadWriteLock`.
*   **Optimistic Read**: Неблокирующий режим чтения, который проверяет, не было ли изменений данных во время чтения, без захвата блокировки.

Ключевые характеристики:
*   **Штампы (stamps)**: Каждая операция блокировки возвращает `long` (штамп), который используется для проверки или освобождения блокировки.
*   **Оптимистичное чтение**: Позволяет читать данные без блокировки, проверяя их консистентность позже, что повышает производительность в сценариях с редкими конфликтами.
*   **Не reentrant**: В отличие от `ReentrantLock` и `ReentrantReadWriteLock`, `StampedLock` не поддерживает повторный вход (reentrancy), что делает его менее интуитивным, но более лёгким.
*   **Высокая производительность**: Оптимизирован для сценариев с преобладанием чтения, минимизируя накладные расходы на синхронизацию.

---
## Зачем выбирать ReentrantLock вместо synchronized?

[⬆️ К оглавлению](#оглавление)

| Характеристика            | `ReentrantLock`                          | `synchronized`                          |
|---------------------------|------------------------------------------|----------------------------------------|
| **Тип блокировки**        | Явная, ручное управление                 | Неявная, автоматическое управление     |
| **Повторный вход**        | Поддерживается                           | Поддерживается                         |
| **Прерываемость**         | Да (`lockInterruptibly`)                 | Нет                                    |
| **Неблокирующая попытка** | Да (`tryLock`)                           | Нет                                    |
| **Таймаут**               | Да (`tryLock(time, unit)`)               | Нет                                    |
| **Условия**               | Множественные `Condition`                | Ограничено `wait()`/`notify()`         |
| **Справедливость**        | Настраиваемая (`fair`)                   | Нет (несправедливая)                   |
| **Производительность**    | Гибкая, но сложнее                       | Простая, оптимизирована JVM            |

---
## Что такое Executor?

[⬆️ К оглавлению](#оглавление)

`Executor` — это интерфейс, определённый в пакете `java.util.concurrent`. Его основная задача — отделить выполнение задач от их непосредственного запуска в потоках. Вместо того чтобы вручную создавать и управлять потоками (`Thread`), вы передаёте задачу (в виде объекта `Runnable` или `Callable`) в `Executor`, а он решает, как и когда её выполнить.

Интерфейс `Executor` очень прост и содержит всего один метод:
```java
void execute(Runnable command);
```

*   **`command`** — это задача, представленная в виде объекта, реализующего интерфейс `Runnable`. Задача не возвращает результата (void).
*   `Executor` сам решает, в каком потоке или контексте будет выполнена задача.

Пример простого использования:
```java
Executor executor = Executors.newSingleThreadExecutor();
executor.execute(() -> System.out.println("Задача выполняется в отдельном потоке"));
```

---
## Что такое ExecutorService?

[⬆️ К оглавлению](#оглавление)

**ExecutorService** — это интерфейс в Java из пакета `java.util.concurrent`, расширяющий базовый интерфейс `Executor`. Он предоставляет более продвинутые возможности для управления выполнением задач и жизненным циклом пулов потоков по сравнению с простым `Executor`. `ExecutorService` является ключевой частью **Executor Framework**, предназначенного для упрощения работы с многопоточностью.
В отличие от `Runnable`, задачи `Callable` могут возвращать результат и выбрасывать проверяемые исключения.

**Расширение Executor**:
*   Наследует метод `execute(Runnable)` от `Executor`.
*   Добавляет методы для более сложных операций, таких как выполнение задач с возвратом результата, управление жизненным циклом пула и массовое выполнение задач.

**Ключевые методы**:
*   **`submit(Runnable/Callable)`**: Запускает задачу и возвращает объект `Future`, через который можно получить результат выполнения (для `Callable`) или проверить статус задачи.
*   **`invokeAll(Collection<Callable>)`**: Выполняет список задач и возвращает список `Future` с результатами.
*   **`invokeAny(Collection<Callable>)`**: Выполняет список задач и возвращает результат первой успешно завершённой.
*   **`shutdown()`**: Инициирует плавное завершение пула, позволяя выполнить все задачи в очереди, но не принимая новые.
*   **`shutdownNow()`**: Пытается немедленно остановить пул, прерывая выполняющиеся задачи.
*   **`isShutdown()` / `isTerminated()`**: Проверяют состояние пула.
*   **`awaitTermination()`**: Ожидает завершения всех задач в течение заданного времени.

### Основные реализации
`ExecutorService` обычно создаётся через утилитный класс `Executors`:
*   **`Executors.newFixedThreadPool(int n)`**: Пул с фиксированным числом потоков.
*   **`Executors.newCachedThreadPool()`**: Пул, создающий потоки по мере необходимости, с переиспользованием неактивных.
*   **`Executors.newSingleThreadExecutor()`**: Один поток для последовательного выполнения задач.
*   **`Executors.newScheduledThreadPool(int n)`**: Пул для задач с планированием (расширяет `ScheduledExecutorService`).

Также можно создать кастомный пул с помощью класса `ThreadPoolExecutor`, позволяющего настроить параметры (число потоков, очередь задач, политику отклонения).

---
## Что такое ThreadPoolExecutor и зачем он нужен?

[⬆️ К оглавлению](#оглавление)

**ThreadPoolExecutor** — это класс в Java из пакета `java.util.concurrent`, реализующий интерфейс `ExecutorService`. Он предоставляет гибкий и настраиваемый пул потоков для выполнения задач, позволяя разработчикам контролировать такие аспекты, как количество потоков, очередь задач, обработка переполнения и поведение при завершении. Это основа большинства реализаций пулов потоков, создаваемых через утилитный класс `Executors`, но `ThreadPoolExecutor` даёт больше возможностей для тонкой настройки.

`ThreadPoolExecutor` — это реализация пула потоков, которая:
*   Управляет набором рабочих потоков (worker threads), выполняющих задачи (`Runnable` или `Callable`).
*   Хранит задачи в очереди, если все потоки заняты.
*   Позволяет настраивать параметры пула, такие как минимальное и максимальное число потоков, время жизни неактивных потоков и политику обработки переполнения.

Основное преимущество `ThreadPoolExecutor` — возможность оптимизировать выполнение задач под конкретные потребности приложения, избегая накладных расходов на создание новых потоков и управляя ресурсами.

Основной конструктор `ThreadPoolExecutor` выглядит так:
```java
ThreadPoolExecutor(int corePoolSize,
                   int maximumPoolSize,
                   long keepAliveTime,
                   TimeUnit unit,
                   BlockingQueue<Runnable> workQueue,
                   ThreadFactory threadFactory,
                   RejectedExecutionHandler handler)
```
*   **`corePoolSize`**: Минимальное количество потоков, которые всегда активны в пуле, даже если нет задач.
*   **`maximumPoolSize`**: Максимальное количество потоков, которое может быть создано при переполнении очереди.
*   **`keepAliveTime`**: Время (в единицах `unit`), в течение которого неактивные потоки сверх `corePoolSize` будут жить перед удалением.
*   **`unit`**: Единица измерения времени для `keepAliveTime` (например, `TimeUnit.SECONDS`).
*   **`workQueue`**: Очередь для хранения задач, ожидающих выполнения.
*   **`threadFactory`**: Фабрика для создания новых потоков (обычно `Executors.defaultThreadFactory()`).
*   **`handler`**: Политика обработки задач, которые не могут быть приняты (например, при переполнении очереди и достижении `maximumPoolSize`).

#### **Основные компоненты**
1.  **Пул потоков**:
    *   Состоит из рабочих потоков (`Worker`), которые выполняют задачи.
    *   Каждый `Worker` — это внутренний класс, представляющий поток, который берёт задачи из очереди и выполняет их.
    *   Пул поддерживает от `corePoolSize` до `maximumPoolSize` потоков.

2.  **Очередь задач (`workQueue`)**:
    *   Используется для хранения задач, если все потоки заняты.
    *   Типы очередей:
        *   **`LinkedBlockingQueue`**: Неограниченная очередь (по умолчанию в `FixedThreadPool`).
        *   **`ArrayBlockingQueue`**: Ограниченная очередь с фиксированным размером.
        *   **`SynchronousQueue`**: Очередь без буфера, передающая задачи напрямую потокам (используется в `CachedThreadPool`).
        *   **`PriorityBlockingQueue`**: Очередь с приоритетами для задач.

3.  **Политика выполнения задач**:
    *   Когда задача подаётся через `execute(Runnable)`:
        1.  Если число активных потоков меньше `corePoolSize`, создаётся новый поток.
        2.  Если число потоков равно `corePoolSize`, задача помещается в очередь.
        3.  Если очередь заполнена и число потоков меньше `maximumPoolSize`, создаётся дополнительный поток.
        4.  Если очередь заполнена и достигнут `maximumPoolSize`, применяется `RejectedExecutionHandler`.

4.  **RejectedExecutionHandler**:
    *   Определяет, что делать с задачей, если она не может быть принята. Стандартные политики:
        *   **`AbortPolicy`**: Выбрасывает `RejectedExecutionException` (по умолчанию).
        *   **`CallerRunsPolicy`**: Выполняет задачу в потоке вызывающего кода.
        *   **`DiscardPolicy`**: Тихо отбрасывает задачу.
        *   **`DiscardOldestPolicy`**: Удаляет самую старую задачу из очереди и добавляет новую.

    **ThreadFactory**:
    *   Отвечает за создание новых потоков.
    *   Позволяет настраивать параметры потоков (например, имена, приоритет, демонические потоки).

#### **Жизненный цикл пула**
`ThreadPoolExecutor` имеет несколько состояний:
*   **RUNNING**: Принимает новые задачи и выполняет существующие.
*   **SHUTDOWN**: Не принимает новые задачи, но завершает существующие.
*   **STOP**: Не принимает новые задачи и пытается прервать выполняющиеся.
*   **TIDYING**: Все задачи завершены, потоки освобождены.
*   **TERMINATED**: Пул полностью завершён.

Методы управления:
*   `shutdown()`: Переводит в состояние `SHUTDOWN`.
*   `shutdownNow()`: Переводит в состояние `STOP`.
*   `awaitTermination()`: Ожидает перехода в `TERMINATED`.

#### **Внутренний механизм Worker**
*   Каждый рабочий поток (`Worker`) — это объект, реализующий `Runnable` и содержащий `Thread`.
*   `Worker` циклически берёт задачи из `workQueue` с помощью метода `getTask()` и выполняет их.
*   Если задача не найдена (например, очередь пуста и истекло `keepAliveTime`), поток может быть удалён, если число потоков превышает `corePoolSize`.

### **Ключевые внутренние механизмы**

1.  **Управление потоками**:
    *   Потоки создаются только при необходимости (до `corePoolSize` или `maximumPoolSize`).
    *   Неактивные потоки сверх `corePoolSize` удаляются после `keepAliveTime`.

2.  **Очередь задач**:
    *   `workQueue` блокирует потоки, если задач нет (используется `BlockingQueue.take()`).
    *   Если очередь заполнена, создаются дополнительные потоки (до `maximumPoolSize`).

3.  **Обработка исключений**:
    *   Исключения в задачах не влияют на пул, но могут быть пойманы через `Future.get()` или переопределение метода `afterExecute`.

4.  **Метрики и мониторинг**:
    *   Методы, такие как `getActiveCount()`, `getPoolSize()`, `getQueue().size()`, позволяют отслеживать состояние пула.

5.  **Кастомизация**:
    *   Переопределение методов `beforeExecute`, `afterExecute`, `terminated` позволяет добавлять пользовательскую логику (например, логирование или обработку ошибок).

### **Отличия от других реализаций ExecutorService**

*   **`FixedThreadPool`**: Эквивалент `ThreadPoolExecutor` с `corePoolSize = maximumPoolSize` и неограниченной очередью.
*   **`CachedThreadPool`**: Использует `SynchronousQueue` и `maximumPoolSize = Integer.MAX_VALUE`.
*   **`SingleThreadExecutor`**: `ThreadPoolExecutor` с `corePoolSize = maximumPoolSize = 1`.

`ThreadPoolExecutor` предоставляет более детальный контроль, чем эти реализации, но требует ручной настройки.

---
## Расскажи про FixedThreadPool?

[⬆️ К оглавлению](#оглавление)

**Executors.newFixedThreadPool(int n)** — это статический метод утилитного класса `Executors` из пакета `java.util.concurrent`, который создаёт пул потоков с фиксированным количеством потоков (`n`). Этот пул является реализацией интерфейса `ExecutorService` и основан на классе `ThreadPoolExecutor`. Он предназначен для выполнения задач в многопоточной среде с ограниченным числом потоков, что делает его подходящим для приложений с предсказуемой нагрузкой.

### **Что делает Executors.newFixedThreadPool(int n)?**

Метод `Executors.newFixedThreadPool(int n)` создаёт объект `ExecutorService`, который:
*   Поддерживает ровно `n` рабочих потоков для выполнения задач.
*   Хранит задачи, превышающие количество доступных потоков, в неограниченной очереди (`LinkedBlockingQueue`).
*   Переиспользует существующие потоки для выполнения новых задач, минимизируя накладные расходы на создание потоков.
*   Не создаёт дополнительные потоки сверх `n`, даже при высокой нагрузке.

Возвращаемый объект является экземпляром `ThreadPoolExecutor` с фиксированной конфигурацией:
*   `corePoolSize` = `maximumPoolSize` = `n`.
*   `keepAliveTime` = 0 (потоки не завершаются, пока пул не будет явно закрыт).
*   `workQueue` = `LinkedBlockingQueue` (неограниченная очередь).
*   `threadFactory` = `Executors.defaultThreadFactory()` (стандартная фабрика для создания потоков).
*   `handler` = `AbortPolicy` (выбрасывает исключение при переполнении, но в данном случае переполнение невозможно из-за неограниченной очереди).

### **Внутренняя реализация**

`Executors.newFixedThreadPool(int n)` эквивалентен следующей ручной настройке `ThreadPoolExecutor`:
```java
new ThreadPoolExecutor(n, n, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue<Runnable>());
```

**Ключевые аспекты**:
*   **Фиксированное число потоков**: Пул всегда содержит ровно `n` потоков. Если все потоки заняты, новые задачи помещаются в очередь.
*   **Неограниченная очередь**: Используется `LinkedBlockingQueue`, которая может расти без ограничений (теоретически до исчерпания памяти).
*   **Отсутствие завершения потоков**: Поскольку `corePoolSize` равно `maximumPoolSize` и `keepAliveTime` равно 0, потоки не завершаются, пока пул активен.
*   **Обработка задач**: Задачи, поданные через `execute(Runnable)` или `submit(Callable)`, выполняются в одном из `n` потоков или ожидают в очереди.

### **Как работает FixedThreadPool?**

1.  **Инициализация**:
    *   Создаётся пул с `n` потоками. Изначально потоки неактивны, пока не поступят задачи.
    *   Каждый поток является объектом `Worker` (внутренний класс `ThreadPoolExecutor`), который циклически берёт задачи из `LinkedBlockingQueue`.

2.  **Подача задач**:
    *   Когда вызывается `execute(Runnable)` или `submit(Callable)`:
        *   Если есть свободный поток (число активных потоков меньше `n`), задача выполняется немедленно.
        *   Если все `n` потоков заняты, задача добавляется в очередь `LinkedBlockingQueue`.
    *   Как только поток завершает задачу, он берёт следующую из очереди.

3.  **Завершение**:
    *   Пул продолжает работать, пока не вызван `shutdown()` (плавное завершение, выполняет все задачи в очереди) или `shutdownNow()` (немедленное прерывание).
    *   Метод `awaitTermination()` позволяет ждать завершения всех задач.

---

## Расскажи про Executors.newCachedThreadPool()?


[⬆️ К оглавлению](#оглавление)

**`Executors.newCachedThreadPool()`** — это статический метод утилитного класса `Executors` из пакета `java.util.concurrent`, который создаёт пул потоков с динамическим количеством потоков. Этот пул является реализацией интерфейса `ExecutorService` и основан на классе `ThreadPoolExecutor`. Он предназначен для выполнения множества короткоживущих задач, автоматически создавая и переиспользуя потоки по мере необходимости. Давайте разберёмся углублённо в его назначение, внутреннюю реализацию, особенности и сценарии использования.

### **Что делает `Executors.newCachedThreadPool()`?**

Метод `Executors.newCachedThreadPool()` создаёт объект `ExecutorService`, который:
- **Динамически создаёт потоки**: Если все существующие потоки заняты, создаётся новый поток для выполнения задачи.
- **Переиспользует неактивные потоки**: Потоки, которые не используются в течение определённого времени (по умолчанию 60 секунд), завершаются и удаляются из пула.
- **Использует очередь без буфера**: Задачи передаются напрямую потокам без хранения в очереди, что минимизирует задержки.
- **Подходит для лёгких задач**: Идеален для приложений с большим количеством коротких асинхронных задач, где создание нового потока не создаёт значительных накладных расходов.

Возвращаемый объект — это `ThreadPoolExecutor` с следующей конфигурацией:
- `corePoolSize` = 0 (нет минимального числа потоков).
- `maximumPoolSize` = `Integer.MAX_VALUE` (практически неограниченное число потоков).
- `keepAliveTime` = 60 секунд (неактивные потоки завершаются через 60 секунд).
- `workQueue` = `SynchronousQueue` (очередь без буфера, передающая задачи напрямую потокам).
- `threadFactory` = `Executors.defaultThreadFactory()` (стандартная фабрика для создания потоков).
- `handler` = `AbortPolicy` (выбрасывает `RejectedExecutionException`, если создание нового потока невозможно).

### **Внутренняя реализация**

`Executors.newCachedThreadPool()` эквивалентен следующей ручной настройке `ThreadPoolExecutor`:
```java
new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue<Runnable>());
```

**Ключевые аспекты**:
- **Динамическое масштабирование**: Пул начинает с нуля потоков и создаёт новый поток для каждой задачи, если нет свободных.
- **`SynchronousQueue`**: Это не очередь в традиционном смысле, а механизм передачи задач напрямую от вызывающего потока к рабочему потоку. Если нет свободного потока, создаётся новый.
- **Время жизни потоков**: Неиспользуемые потоки завершаются через 60 секунд, что позволяет освобождать ресурсы при снижении нагрузки.
- **Неограниченное число потоков**: Теоретически пул может создать до `Integer.MAX_VALUE` потоков, что может привести к проблемам при очень высокой нагрузке.

### **Как работает `CachedThreadPool`?**

1.  **Инициализация**:
    - Пул создаётся без активных потоков (`corePoolSize = 0`).
    - При поступлении задачи создаётся новый поток, если нет доступных.

2.  **Подача задач**:
    - Когда вызывается `execute(Runnable)` или `submit(Callable)`:
        - Если есть свободный поток (неиспользуемый из пула), он берёт задачу.
        - Если свободных потоков нет, задача передаётся через `SynchronousQueue`, и создаётся новый поток.
        - Если создание потока невозможно (например, из-за системных ограничений), применяется `AbortPolicy` (выбрасывается `RejectedExecutionException`).
    - После выполнения задачи поток остаётся в пуле и ждёт новую задачу в течение 60 секунд. Если задача не поступает, поток завершается.

3.  **Завершение**:
    - Пул продолжает работать, пока не вызван `shutdown()` (выполняет все задачи) или `shutdownNow()` (пытается прервать текущие задачи).
    - Метод `awaitTermination()` позволяет дождаться завершения всех задач.

---

## Расскажи про SingleThreadExecutor?


[⬆️ К оглавлению](#оглавление)

**`Executors.newSingleThreadExecutor()`** — это статический метод утилитного класса `Executors` из пакета `java.util.concurrent`, который создаёт пул потоков, содержащий ровно один рабочий поток. Этот пул является реализацией интерфейса `ExecutorService` и основан на классе `ThreadPoolExecutor`. Он предназначен для последовательного выполнения задач в одном потоке, обеспечивая их строгую очерёдность (FIFO — first-in, first-out). Давайте разберёмся углублённо в его назначение, внутреннюю реализацию, особенности и сценарии использования.

### **Что делает `Executors.newSingleThreadExecutor()`?**

Метод `Executors.newSingleThreadExecutor()` создаёт объект `ExecutorService`, который:
- Использует **один поток** для выполнения всех задач.
- Гарантирует **последовательное выполнение**: задачи выполняются в том порядке, в котором они были поданы.
- Хранит задачи, ожидающие выполнения, в **неограниченной очереди** (`LinkedBlockingQueue`).
- Переиспользует один и тот же поток для всех задач, минимизируя накладные расходы на создание потоков.
- Подходит для задач, которые должны выполняться строго по очереди или в контексте, где многопоточность нежелательна.

Возвращаемый объект — это `ThreadPoolExecutor` с фиксированной конфигурацией:
- `corePoolSize` = `maximumPoolSize` = 1 (всегда один поток).
- `keepAliveTime` = 0 (поток не завершается, пока пул активен).
- `workQueue` = `LinkedBlockingQueue` (неограниченная очередь для хранения задач).
- `threadFactory` = `Executors.defaultThreadFactory()` (стандартная фабрика для создания потока).
- `handler` = `AbortPolicy` (выбрасывает исключение при переполнении, но в данном случае переполнение невозможно из-за неограниченной очереди).

### **Внутренняя реализация**

`Executors.newSingleThreadExecutor()` эквивалентен следующей ручной настройке `ThreadPoolExecutor`:
```java
new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue<Runnable>());
```

**Ключевые аспекты**:
- **Один поток**: Пул содержит ровно один рабочий поток (`Worker`), который выполняет задачи по очереди.
- **Неограниченная очередь**: Если поток занят, новые задачи помещаются в `LinkedBlockingQueue`, которая может расти без ограничений (теоретически до исчерпания памяти).
- **Сохранение потока**: Поскольку `corePoolSize` = 1 и `keepAliveTime` = 0, поток не завершается, пока пул активен.
- **Последовательность**: Задачи выполняются строго в порядке подачи, что эквивалентно выполнению в одном потоке без параллелизма.

### **Как работает `SingleThreadExecutor`?**

1.  **Инициализация**:
    - Пул создаётся с одним потоком. Поток активируется при поступлении первой задачи.
    - Поток представлен объектом `Worker` (внутренний класс `ThreadPoolExecutor`), который циклически берёт задачи из `LinkedBlockingQueue`.

2.  **Подача задач**:
    - Когда вызывается `execute(Runnable)` или `submit(Callable)`:
        - Если поток свободен, задача выполняется немедленно.
        - Если поток занят, задача добавляется в очередь `LinkedBlockingQueue`.
    - После завершения задачи поток берёт следующую задачу из очереди. Если очередь пуста, поток блокируется, ожидая новую задачу.

3.  **Завершение**:
    - Пул продолжает работать, пока не вызван `shutdown()` (выполняет все задачи в очереди) или `shutdownNow()` (пытается прервать текущую задачу и игнорирует очередь).
    - Метод `awaitTermination()` позволяет дождаться завершения всех задач.

---

## Зачем нужен ScheduledExecutorService?


[⬆️ К оглавлению](#оглавление)

**`Executors.newScheduledThreadPool(int n)`** — это статический метод утилитного класса `Executors` из пакета `java.util.concurrent`, который создаёт пул потоков с фиксированным количеством потоков (`n`), предназначенный для выполнения задач по расписанию. Этот пул является реализацией интерфейса `ScheduledExecutorService`, который расширяет `ExecutorService`, добавляя функциональность для планирования задач с задержкой или периодическим выполнением. Он основан на классе `ScheduledThreadPoolExecutor`, который, в свою очередь, является специализированной версией `ThreadPoolExecutor`. Давайте разберёмся углублённо в его назначение, внутреннюю реализацию, особенности и сценарии использования.

### **Что делает `Executors.newScheduledThreadPool(int n)`?**

Метод `Executors.newScheduledThreadPool(int n)` создаёт объект `ScheduledExecutorService`, который:
- Поддерживает **фиксированное количество потоков** (`n`) для выполнения задач.
- Позволяет **планировать задачи** для выполнения:
    - Через определённую задержку (`schedule`).
    - Периодически с фиксированной частотой (`scheduleAtFixedRate`).
    - Периодически с фиксированной задержкой между задачами (`scheduleWithFixedDelay`).
- Хранит задачи в **приоритетной очереди**, основанной на времени выполнения.
- Переиспользует потоки для минимизации накладных расходов на их создание.
- Подходит для задач, которые требуют выполнения по расписанию, таких как периодические обновления, таймеры или задачи с отложенным запуском.

Возвращаемый объект — это `ScheduledThreadPoolExecutor` с конфигурацией:
- `corePoolSize` = `n` (фиксированное число потоков).
- `maximumPoolSize` = `n` (не масштабируется сверх заданного числа).
- `keepAliveTime` = 0 (потоки не завершаются, пока пул активен).
- `workQueue` = `DelayedWorkQueue` (внутренняя очередь с приоритетами, основанная на времени выполнения задач).
- `threadFactory` = `Executors.defaultThreadFactory()` (стандартная фабрика для создания потоков).
- `handler` = `AbortPolicy` (выбрасывает исключение при переполнении, но переполнение маловероятно из-за структуры очереди).

### **Внутренняя реализация**

`Executors.newScheduledThreadPool(int n)` эквивалентен созданию:
```java
new ScheduledThreadPoolExecutor(n);
```

**Ключевые аспекты**:
- **`ScheduledThreadPoolExecutor`**: Это подкласс `ThreadPoolExecutor`, специализированный для задач с планированием. Он использует `DelayedWorkQueue` — внутреннюю реализацию очереди, основанную на приоритетной куче (`PriorityQueue`), которая упорядочивает задачи по времени их выполнения.
- **Фиксированное число потоков**: Пул поддерживает ровно `n` потоков. Если все потоки заняты, задачи ждут в очереди до освобождения потока.
- **`DelayedWorkQueue`**: Очередь хранит задачи в порядке их запланированного времени выполнения. Задачи извлекаются, только когда наступает время их запуска.
- **Периодические задачи**: Для `scheduleAtFixedRate` и `scheduleWithFixedDelay` задачи автоматически повторно добавляются в очередь после выполнения, с учётом заданного интервала или задержки.

### **Как работает `ScheduledThreadPool`?**

1.  **Инициализация**:
    - Пул создаётся с `n` потоками. Потоки активируются по мере поступления задач.
    - Каждый поток представлен объектом `Worker`, который берёт задачи из `DelayedWorkQueue`.

2.  **Подача задач**:
    - Поддерживаются три типа планирования:
        - **`schedule(Runnable/Callable, long delay, TimeUnit unit)`**: Выполняет задачу один раз после указанной задержки.
        - **`scheduleAtFixedRate(Runnable, long initialDelay, long period, TimeUnit unit)`**: Выполняет задачу периодически с фиксированной частотой (период между началами выполнения).
        - **`scheduleWithFixedDelay(Runnable, long initialDelay, long delay, TimeUnit unit)`**: Выполняет задачу периодически с фиксированной задержкой между концом одной задачи и началом следующей.
    - Задачи помещаются в `DelayedWorkQueue`, которая упорядочивает их по времени выполнения.
    - Если все `n` потоков заняты, задачи ждут в очереди, пока не наступит их время и не освободится поток.

3.  **Завершение**:
    - Пул продолжает работать, пока не вызван `shutdown()` (выполняет все запланированные задачи) или `shutdownNow()` (пытается прервать текущие задачи и игнорирует очередь).
    - Периодические задачи продолжают выполняться, пока пул не завершён или задача не отменена через `Future.cancel()`.

---

## Что делает метод shutdown() и shutdownNow() у ExecutorService?


[⬆️ К оглавлению](#оглавление)

**`shutdown()`**
Вызов метода инициирует остановку `ExecutorService`. Все задачи, которые уже были отправлены на обработку, будут завершены, новые задачи приниматься не будут.

**`List<Runnable> shutdownNow()`**
Вызов метода инициирует остановку `ExecutorService`. Все задачи, которые уже были отправлены на обработку, получат команду `Thread.interrupt()`. Задачи, находящиеся в очереди, возвращаются в виде списка как результат вызова метода.
Метод не ожидает завершения всех задач, которые находятся "в работе" на момент вызова метода.

---

## Какого размера должен быть пул потоков?


[⬆️ К оглавлению](#оглавление)

Настраивая размер пула потоков, важно избежать двух ошибок: слишком мало потоков (очередь на выполнение будет расти, потребляя много памяти) или слишком много потоков (замедление работы всей систему из-за частых переключений контекста).
Оптимальный размер пула потоков зависит от количества доступных процессоров и природы задач в рабочей очереди. На N-процессорной системе для рабочей очереди, которая будет выполнять исключительно задачи с ограничением по скорости вычислений, можно достигнуть максимального использования CPU с пулом потоков, в котором содержится N или N+1 поток. Для задач, которые могут ждать осуществления I/O (ввода - вывода) - например, задачи, считывающей HTTP-запрос из сокета - может понадобиться увеличение размера пула свыше количества доступных процессоров, потому, что не все потоки будут работать все время. Используя профилирование, можно оценить отношение времени ожидания (WT) ко времени обработки (ST) для типичного запроса. Если назвать это соотношение WT/ST, то для N-процессорной системе понадобится примерно N*(1 + WT/ST) потоков для полной загруженности процессоров.
Использование процессора - не единственный фактор, важный при настройке размера пула потоков. По мере возрастания пула потоков, можно столкнуться с ограничениями планировщика, доступной памяти, или других системных ресурсов, таких, как количество сокетов, дескрипторы открытого файла, или каналы связи базы данных.

---

## Что будет, если очередь пула потоков уже заполнена, но подаётся новая задача?


[⬆️ К оглавлению](#оглавление)

Если очередь пула потоков заполнилась, то поданная задача будет «отклонена». Например - метод `submit()` у `ThreadPoolExecutor` выкидывает `RejectedExecutionException`, после которого вызывается `RejectedExecutionHandler`.

---

## В чём заключается различие между методами submit() и execute() у пула потоков?


[⬆️ К оглавлению](#оглавление)

Оба метода являются способами подачи задачи в пул потоков, но между ними есть небольшая разница.
- `execute(Runnable command)` определён в интерфейсе `Executor` и выполняет поданную задачу и ничего не возвращает.
- `submit()` - перегруженный метод, определённый в интерфейсе `ExecutorService`. Способен принимать задачи типов `Runnable` и `Callable` и возвращать объект `Future`, который можно использовать для контроля и управления процессом выполнения, получения его результата.

---

## Какими коллекциями пользоваться в многопоточной среде?


[⬆️ К оглавлению](#оглавление)

Первый вариант - превратить в синхронизированную обычную коллекцию, вызвав соответствующий ее типу метод `Collections.synchronized*()`. Самый общий и самый примитивный способ, создает обертку с синхронизацией всех операций с помощью `synchronized`.

Если работа с коллекцией состоит в основном из чтения, лучшая в плане производительности альтернатива - `CopyOnWriteArrayList`, и содержащий его в реализации `CopyOnWriteArraySet`.
Потокобезопасность достигается копированием внутреннего массива при любой модификации, оригинальный массив остается immutable.
Program order достигается модификатором `volatile` на внутреннем массиве.

Третий вариант - использование Concurrent-коллекций:
-   Неблокирующие хэш-таблицы `ConcurrentSkipListMap`, `ConcurrentHashMap` и `ConcurrentSkipListSet` (хэш-таблица в основе реализации)
-   Неблокирующие очереди `ConcurrentLinkedQueue` и `ConcurrentLinkedDeque`
-   Большой набор различных блокирующих очередей `ArrayBlockingQueue`, `LinkedBlockingQueue`

---

## Как внутри работает CopyOnWriteArrayList?

[⬆️ К оглавлению](#оглавление)

`CopyOnWriteArrayList` основан на концепции "копирование при записи" (copy-on-write). Это означает, что:
- Внутренние данные хранятся в массиве (`Object[]`).
- При любой модификации (добавление, удаление, обновление) создаётся **новая копия массива**, в которую вносятся изменения, а исходный массив остаётся неизменным.
- Операции чтения (например, `get`, итерация) выполняются на текущем массиве без блокировок, так как он не изменяется во время чтения.

Этот подход обеспечивает:
- **Потокобезопасность**: Все операции чтения и записи безопасны без необходимости явной синхронизации со стороны пользователя.
- **Консистентность данных**: Итераторы работают со "снимком" данных на момент их создания, не видя последующих изменений.
- **Высокую производительность чтения**: Чтение не требует блокировок, что делает его быстрым в многопоточной среде.

Однако за это приходится платить:
- Высокая стоимость операций записи из-за копирования массива.
- Большое потребление памяти при частых модификациях, особенно для больших списков.

### **Внутренняя структура**
`CopyOnWriteArrayList` использует следующие ключевые элементы:

- **Массив `Object[] array`**: Основное хранилище данных. Все элементы списка хранятся в этом массиве.
- **`ReentrantLock lock`**: Используется для синхронизации операций записи, чтобы предотвратить одновременное изменение массива несколькими потоками.
- **`Volatile` поле для массива**: Ссылка на массив помечена как `volatile`, чтобы гарантировать видимость изменений для всех потоков после завершения записи.

---

## Как внутри работает CopyOnWriteArraySet?


[⬆️ К оглавлению](#оглавление)

### **Основной принцип работы**
`CopyOnWriteArraySet` — это обёртка над `CopyOnWriteArrayList`, которая обеспечивает функциональность множества (Set), то есть гарантирует уникальность элементов. Основные характеристики:
- Внутренне хранит элементы в `CopyOnWriteArrayList`.
- Потокобезопасность достигается за счёт создания новой копии внутреннего массива при каждой операции модификации (добавление, удаление).
- Операции чтения выполняются без блокировок, так как работают с неизменяемым "снимком" данных.
- Подходит для сценариев с редкими модификациями и частым чтением.

### **Внутренняя структура**
`CopyOnWriteArraySet` не хранит данные напрямую, а делегирует это `CopyOnWriteArrayList`. Ключевые компоненты:
- **Поле `CopyOnWriteArrayList<E> al`**: Единственное поле класса, которое хранит все элементы множества.
- **`ReentrantLock`** (унаследован от `CopyOnWriteArrayList`): Используется для синхронизации операций записи.
- **`Volatile` массив** (унаследован от `CopyOnWriteArrayList`): Внутренний массив `Object[]` в `CopyOnWriteArrayList`, помеченный как `volatile` для гарантии видимости изменений.

---

## Как внутри работает ConcurrentHashMap?


[⬆️ К оглавлению](#оглавление)

`ConcurrentHashMap` оптимизирован для конкурентного доступа, обеспечивая:
- **Высокую производительность чтения**: Операции чтения (например, `get`) обычно выполняются без блокировок, благодаря использованию `volatile` полей и атомарных операций.
- **Конкурентные записи**: Операции записи (например, `put`, `remove`) используют блокировки, но только на уровне отдельных сегментов (или
  бакетов), а не всей структуры. Если бакет пуст, новый узел добавляется атомарно через CAS (без блокировки). Если бакет занят,
  используется `synchronized` на первом узле бакета
- **Отсутствие полной блокировки**: В отличие от `Hashtable` или `Collections.synchronizedMap`, которые блокируют всю карту, `ConcurrentHashMap` применяет сегментированную блокировку (lock striping) или неблокирующие алгоритмы (в Java 8+).
- **Потокобезопасность без `null`**: Не допускает `null` в ключах или значениях, чтобы избежать неоднозначностей при конкурентном доступе.

Ключевой принцип: **разделение данных на сегменты (бакеты)** и использование минимально необходимых блокировок для обеспечения конкурентности.

### **Внутренняя структура**
`ConcurrentHashMap` хранит данные в массиве бакетов (таблице), где каждый бакет может содержать связный список или красно-чёрное дерево (в случае высокой коллизии). Основные компоненты:

- **Массив `Node[] table`**: Основное хранилище, где каждый элемент (бакет) — это либо `Node` (для связного списка), либо `TreeBin` (для красно-чёрного дерева).
- **`Volatile` поля**: Поля, такие как `table` и `nextTable` в узлах, помечены как `volatile` для обеспечения видимости изменений между потоками.
- **CAS-операции** (Compare-And-Swap): Используются для атомарных обновлений, например, при инициализации таблицы или изменении размера.
- **`CounterCells`**: Специальная структура для подсчёта количества элементов (`size`) в многопоточной среде.

Упрощённая структура (на основе исходного кода JDK):
```java
public class ConcurrentHashMap<K,V> extends AbstractMap<K,V> implements ConcurrentMap<K,V>, Serializable {
    // Основной массив бакетов
    private transient volatile Node<K,V>[] table;
    // Временный массив для ресайзинга
    private transient volatile Node<K,V>[] nextTable;
    // Счётчик элементов (для size())
    private transient volatile long baseCount;
    // Массив для конкурентного подсчёта
    private transient volatile CounterCell[] counterCells;
    // Состояние ресайзинга и инициализации
    private transient volatile int sizeCtl;
}

static class Node<K,V> implements Map.Entry<K,V> {
    final int hash;
    final K key;
    volatile V val; // Значение помечено как volatile
    volatile Node<K,V> next; // Ссылка на следующий узел
}
```

---

## Как внутри работает ConcurrentSkipListMap?


[⬆️ К оглавлению](#оглавление)

### **Основной принцип работы**
`ConcurrentSkipListMap` использует **skip list** — вероятностную структуру данных, которая обеспечивает эффективный поиск, вставку и удаление (в среднем O(log n)) за счёт многоуровневой организации узлов. Основные характеристики:
- **Потокобезопасность**: Операции чтения и записи выполняются без полной блокировки, используя атомарные операции (Compare-And-Swap, CAS) и `volatile` поля.
- **Упорядоченность**: Ключи хранятся в отсортированном порядке (по естественному порядку или с использованием компаратора).
- **Конкурентность**: Поддерживает высокую степень параллелизма благодаря отсутствию глобальных блокировок и использованию неблокирующих алгоритмов.
- **Отсутствие `null`**: Не допускает `null` в ключах или значениях для устранения неоднозначностей при конкурентном доступе.

Ключевой принцип: **skip list** сочетает простоту связного списка с эффективностью поиска, близкой к бинарному дереву, а потокобезопасность достигается через атомарные обновления и логические удаления.

### **Внутренняя структура**
`ConcurrentSkipListMap` основана на структуре skip list, которая представляет собой многоуровневый связный список, где каждый уровень ускоряет поиск за счёт "пропуска" части узлов. Основные компоненты:

- **Узлы (`Node`)**: Хранят пары ключ-значение и ссылки на следующий узел на том же уровне.
- **Индексные узлы (`Index`)**: Формируют дополнительные уровни skip list, указывая на узлы нижних уровней и ускоряя поиск.
- **Голова (`HeadIndex`)**: Указатель на верхний уровень skip list, с которого начинается обход.
- **`Volatile` поля**: Используются для обеспечения видимости изменений между потоками.
- **CAS-операции**: Применяются для атомарного обновления ссылок и значений.

Упрощённая структура (на основе исходного кода JDK):
```java
public class ConcurrentSkipListMap<K,V> extends AbstractMap<K,V>
    implements ConcurrentNavigableMap<K,V>, Cloneable, Serializable {
    // Голова skip list (указатель на верхний уровень)
    private transient volatile HeadIndex<K,V> head;

    // Компаратор для сортировки ключей
    final Comparator<? super K> comparator;

    // Базовый узел, хранящий ключ и значение
    static final class Node<K,V> {
        final K key;
        volatile Object value; // Значение или маркер удаления
        volatile Node<K,V> next; // Ссылка на следующий узел
    }

    // Индексный узел для уровней skip list
    static final class Index<K,V> {
        final Node<K,V> node; // Связь с базовым узлом
        final Index<K,V> down; // Ссылка на нижний уровень
        volatile Index<K,V> right; // Ссылка на следующий индекс на том же уровне
    }

    // Голова skip list
    static final class HeadIndex<K,V> extends Index<K,V> {
        final int level; // Уровень в skip list
    }
}
```

- **Skip List**: Каждый узел может быть связан с несколькими уровнями. Верхние уровни содержат меньше узлов, что ускоряет поиск.
- **Вероятностная структура**: Новые узлы получают случайный уровень (обычно с геометрическим распределением, где вероятность добавления на следующий уровень = 1/2).
- **Маркер удаления**: Вместо физического удаления узлов используется логическое удаление (значение узла помечается как `null` или специальный маркер).

### **Как работает Skip List**
Skip list — это многоуровневый связный список, где:
- **Нижний уровень (уровень 0)**: Содержит все узлы в порядке сортировки, как обычный связный список.
- **Высшие уровни**: Содержат подмножество узлов, что позволяет "перепрыгивать" через узлы при поиске, приближая сложность к O(log n).
- **Вероятностное распределение**: Каждый узел случайным образом получает высоту (количество уровней), что обеспечивает балансировку без сложных операций, как в деревьях.

Пример структуры skip list:
```
Level 3:  Head ----> [10] ----------------> [50]
Level 2:  Head ----> [10] ----> [30] ----> [50]
Level 1:  Head ----> [10] -> [20] -> [30] -> [50]
Level 0:  Head -> [5] -> [10] -> [15] -> [20] -> [30] -> [40] -> [50]
```

- Поиск начинается с верхнего уровня, переходя на нижний, если следующий узел на текущем уровне слишком далеко.

---

## Как внутри работает ConcurrentLinkedDeque?


[⬆️ К оглавлению](#оглавление)

`ConcurrentLinkedDeque` представляет собой двусвязный список, где элементы можно добавлять или удалять с обоих концов (head и tail). Основные характеристики:
- **Потокобезопасность**: Все операции (добавление, удаление, чтение) выполняются без блокировок, используя CAS для атомарного обновления ссылок.
- **Двусторонняя очередь**: Поддерживает операции с начала (`head`) и конца (`tail`) очереди, такие как `addFirst`, `addLast`, `pollFirst`, `pollLast`.
- **Неограниченный размер**: Очередь не имеет фиксированного размера, растёт по мере добавления элементов.
- **Отсутствие `null`**: Не допускает `null` элементы для устранения неоднозначностей при конкурентном доступе.
- **Lock-free алгоритм**: Использует CAS для координации изменений, что минимизирует конкуренцию между потоками.

Ключевой принцип: **неблокирующий двусвязный список**, где атомарные операции обеспечивают корректность изменений даже при одновременном доступе множества потоков.

### **Внутренняя структура**
`ConcurrentLinkedDeque` основана на двусвязном списке, где каждый узел содержит элемент и ссылки на предыдущий и следующий узлы. Основные компоненты:

- **Узлы (`Node`)**: Хранят элемент и ссылки на соседние узлы (`prev` и `next`).
- **`Head` и `Tail`**: Указатели на первый и последний узлы списка, обновляемые атомарно.
- **`Volatile` поля**: Ссылки в узлах (`item`, `prev`, `next`) помечены как `volatile` для обеспечения видимости изменений.
- **CAS-операции**: Используются для атомарного обновления ссылок и элементов.

Упрощённая структура (на основе исходного кода JDK):
```java
public class ConcurrentLinkedDeque<E> extends AbstractCollection<E> implements Deque<E>, Serializable {
    // Указатели на начало и конец списка
    private transient volatile Node<E> head;
    private transient volatile Node<E> tail;

    // Узел двусвязного списка
    private static final class Node<E> {
        volatile E item; // Элемент (или null для удалённых узлов)
        volatile Node<E> prev; // Ссылка на предыдущий узел
        volatile Node<E> next; // Ссылка на следующий узел
    }
}
```

- **`Head` и `Tail`**: Указывают на первый и последний активные узлы, но могут временно быть несогласованными из-за конкурентных операций.
- **`Node`**: Каждый узел хранит элемент и ссылки, причём `item` может быть `null` для обозначения логически удалённого узла.
- **CAS**: Используется через `Unsafe` или `VarHandle` для атомарного обновления полей `prev`, `next` и `item`.

---

## Как внутри работает ArrayBlockingQueue?


[⬆️ К оглавлению](#оглавление)

`ArrayBlockingQueue` — это ограниченная очередь (bounded queue), которая:
- Хранит элементы в массиве фиксированного размера, заданного при создании.
- Поддерживает FIFO (First-In-First-Out) порядок.
- Использует **одну блокировку** (`ReentrantLock`) для синхронизации всех операций (чтения и записи).
- Применяет **условия** (`Condition`) для блокировки потоков, когда очередь полна (для `put`) или пуста (для `poll`).
- Обеспечивает потокобезопасность, но с меньшей конкурентностью по сравнению с lock-free структурами, такими как `ConcurrentLinkedDeque`.

Ключевой принцип: **блокирующая очередь с фиксированным размером**, где операции добавления и извлечения синхронизируются через одну блокировку, а потоки могут ожидать выполнения условий (например, появления свободного места или элементов).

### **Внутренняя структура**
`ArrayBlockingQueue` использует циклический массив (circular buffer) для хранения элементов, что позволяет эффективно переиспользовать пространство. Основные компоненты:

- **Массив `Object[] items`**: Фиксированного размера, хранит элементы очереди.
- **Индексы**:
    - `takeIndex`: Индекс, указывающий на следующий элемент для извлечения (голова очереди).
    - `putIndex`: Индекс, указывающий на место для добавления следующего элемента (хвост очереди).
- **Счётчик `count`**: Количество элементов в очереди.
- **`ReentrantLock lock`**: Единая блокировка для всех операций.
- **`Condition notEmpty`, `notFull`**: Условия для координации потоков (сигнализируют, когда очередь становится непустой или незаполненной).
- **`Volatile` поля**: Поля, такие как `count`, могут быть помечены как `volatile` для видимости изменений, хотя основная синхронизация идёт через `lock`.


### **Как работает циклический массив**
`ArrayBlockingQueue` использует циклический массив, где:
- Элементы добавляются в `putIndex`, который увеличивается и оборачивается (modulo размер массива), если достигает конца.
- Элементы извлекаются из `takeIndex`, который также оборачивается.
- Это позволяет эффективно использовать фиксированный массив без необходимости сдвига элементов.

Пример:
```
items: [A, B, C, null, null]
takeIndex: 0 (указывает на A)
putIndex: 3 (указывает на следующее свободное место)
count: 3
capacity: 5
```

После добавления `D`:
```
items: [A, B, C, D, null]
takeIndex: 0
putIndex: 4
count: 4
```

После извлечения `A` и добавления `E`:
```
items: [E, B, C, D, null]
takeIndex: 1
putIndex: 0 (обернулся)
count: 4
```

---

## Даны 3 потока Т1, Т2 и Т3? Как реализовать выполнение в последовательности Т1, Т2, Т3?


[⬆️ К оглавлению](#оглавление)

Такой последовательности выполнения можно достичь многими способами, например просто воспользоваться методом `join()`, чтобы запустить поток в момент, когда другой уже закончит своё выполнение. Для реализации заданной последовательности, нужно запустить последний поток первым, и затем вызывать метод `join()` в обратном порядке, то есть Т3 вызывает Т2.join, а Т2 вызывает Т1.join, таким образом Т1 закончит выполнение первым, а Т3 последним.

---

## Напишите минимальный неблокирующий стек (всего два метода — push() и pop()).


[⬆️ К оглавлению](#оглавление)

```java
class NonBlockingStack<T> {
    private final AtomicReference<Element<T>> head = new AtomicReference<>(null);

    Stack<T> push(final T value) {
        final Element<T> current = new Element<>();
        current.value = value;
        Element<T> recent;
        do {
            recent = head.get();
            current.previous = recent;
        } while (!head.compareAndSet(recent, current));
        return this;
    }

    T pop() {
        Element<T> result;
        Element<T> previous;
        do {
            result = head.get();
            if (result == null) {
                return null;
            }
            previous = result.previous;
        } while (!head.compareAndSet(result, previous));
        return result.value;
    }

    private static class Element<T> {
        private T value;
        private Element<T> previous;
    }
}
```

---

## Напишите минимальный неблокирующий стек (всего два метода — push() и pop()) с использованием Semaphore.


[⬆️ К оглавлению](#оглавление)

```java
import java.util.concurrent.Semaphore;

class SemaphoreStack<T> {
    private final Semaphore semaphore = new Semaphore(1);
    private Node<T> head = null;

    SemaphoreStack<T> push(T value) {
        semaphore.acquireUninterruptibly();
        try {
            head = new Node<>(value, head);
        } finally {
            semaphore.release();
        }
        return this;
    }

    T pop() {
        semaphore.acquireUninterruptibly();
        try {
            Node<T> current = head;
            if (current != null) {
                head = head.next;
                return current.value;
            }
            return null;
        } finally {
            semaphore.release();
        }
    }

    private static class Node<E> {
        private final E value;
        private final Node<E> next;

        private Node(E value, Node<E> next) {
            this.value = value;
            this.next = next;
        }
    }
}
```

---

## Напишите минимальный неблокирующий ArrayList (всего четыре метода — add(), get(), remove(), size()).


[⬆️ К оглавлению](#оглавление)

```java
import java.util.Arrays;

class NonBlockingArrayList<T> {
    private volatile Object[] content = new Object[0];

    NonBlockingArrayList<T> add(T item) {
        return add(content.length, item);
    }

    NonBlockingArrayList<T> add(int index, T item) {
        if (index < 0) {
            throw new IllegalArgumentException();
        }
        Object[] currentContent = content; // Read volatile field once
        boolean needsModification = index >= currentContent.length; // Check if index is out of bounds for adding
                                                               // or if it is within bounds and needs modification

        if (!needsModification && index < currentContent.length) { // Only check for modification if index is within current bounds
            if (item == null) {
                needsModification = currentContent[index] != null;
            } else {
                needsModification = !item.equals(currentContent[index]); // Corrected logic: modify if not equal
            }
        } else if (index >= currentContent.length && item == null) { // If adding null at new extended position
             needsModification = true; // Always needs modification to extend and set null
        } else if (index >= currentContent.length && item != null) {
             needsModification = true; // Always needs modification to extend and set item
        }


        if (needsModification) {
            final Object[] newContent;
            if (index >= currentContent.length) { // Extending the array
                newContent = Arrays.copyOf(currentContent, index + 1);
            } else { // Modifying within existing bounds or adding at the end (index == currentContent.length)
                newContent = Arrays.copyOf(currentContent, Math.max(currentContent.length, index + 1));
            }
            newContent[index] = item;
            content = newContent; // Single volatile write
        }
        return this;
    }

    NonBlockingArrayList<T> remove(int index) {
        Object[] currentContent = content; // Read volatile field once
        if (index < 0 || index >= currentContent.length) {
            throw new IllegalArgumentException();
        }
        int newSize = currentContent.length - 1;
        if (newSize < 0) newSize = 0; // Should not happen if length check is correct
        final Object[] newContent = new Object[newSize];
        System.arraycopy(currentContent, 0, newContent, 0, index);
        if (index < newSize) { // Corrected condition: only copy if there are elements after the removed one
            System.arraycopy(currentContent, index + 1, newContent, index, currentContent.length - (index + 1));
        }
        content = newContent; // Single volatile write
        return this;
    }

    @SuppressWarnings("unchecked")
    T get(int index) {
        Object[] currentContent = content; // Read volatile field once
        if (index < 0 || index >= currentContent.length) { // Added bounds check for get
             throw newArrayIndexOutOfBoundsException(index);
        }
        return (T) currentContent[index];
    }

    private static ArrayIndexOutOfBoundsException newArrayIndexOutOfBoundsException(int index) {
        return new ArrayIndexOutOfBoundsException("Index " + index + " out of bounds for length " + 0); // Placeholder length
    }


    int size() {
        return content.length; // Direct read of volatile field is fine for size
    }
}
```
*Примечание: представленный `NonBlockingArrayList` является упрощенной иллюстрацией. Для реального использования такой структуры требуется более тщательное рассмотрение гонок состояний, особенно в методе `add` при одновременных операциях. `CopyOnWriteArrayList` из `java.util.concurrent` является стандартной и более надежной реализацией этой концепции.*

---

## Напишите потокобезопасную реализацию класса с неблокирующим методом BigInteger next(), который возвращает элементы последовательности: [1, 2, 4, 8, 16, ...].


[⬆️ К оглавлению](#оглавление)

```java
import java.math.BigInteger;
import java.util.concurrent.atomic.AtomicReference;

class PowerOfTwo {
    private final AtomicReference<BigInteger> current = new AtomicReference<>(null);

    BigInteger next() {
        BigInteger recent, nextValue;
        do {
            recent = current.get();
            nextValue = (recent == null) ? BigInteger.ONE : recent.shiftLeft(1);
        } while (!current.compareAndSet(recent, nextValue));
        return nextValue;
    }
}
```

---

## Напишите простейший многопоточный ограниченный буфер с использованием synchronized.


[⬆️ К оглавлению](#оглавление)

```java
class QueueSynchronized<T> {
    private volatile int size = 0;
    private final Object[] content;
    private final int capacity;
    private int out; // Index of the next element to take
    private int in;  // Index of the next position to put

    // Separate lock objects for wait/notify can lead to missed signals or complex logic.
    // It's generally safer and simpler to use the queue instance itself or a dedicated lock object
    // for all condition waits. Here, we'll use this instance as the monitor for wait/notify.
    // private final Object isEmpty = new Object(); // Not recommended for this pattern
    // private final Object isFull = new Object(); // Not recommended for this pattern

    QueueSynchronized(final int capacity) {
        if (capacity <= 0) {
            throw new IllegalArgumentException("Capacity must be positive");
        }
        this.capacity = capacity;
        content = new Object[this.capacity];
        out = 0;
        in = 0;
        size = 0;
    }

    private int cycleInc(int index) {
        return (++index == capacity) ? 0 : index;
    }

    @SuppressWarnings("unchecked")
    T get() throws InterruptedException {
        synchronized (this) {
            while (size == 0) {
                // Wait for an item to become available
                this.wait();
            }
            final Object value = content[out];
            content[out] = null; // Help GC
            out = cycleInc(out);
            size--;
            // Notify threads waiting to put an item
            this.notifyAll(); // Notify all, as either condition (not empty or not full) might change
            return (T) value;
        }
    }

    QueueSynchronized<T> put(T value) throws InterruptedException {
        if (value == null) throw new NullPointerException(); // Or handle as per requirements
        synchronized (this) {
            while (size == capacity) {
                // Wait for space to become available
                this.wait();
            }
            content[in] = value;
            in = cycleInc(in);
            size++;
            // Notify threads waiting to get an item
            this.notifyAll(); // Notify all, as either condition (not empty or not full) might change
            return this;
        }
    }

    // Optional: method to get current size (synchronized for consistency)
    public synchronized int getSize() {
        return size;
    }
}
```

---

## Напишите простейший многопоточный ограниченный буфер с использованием ReentrantLock.


[⬆️ К оглавлению](#оглавление)

```java
import java.util.concurrent.locks.Condition;
import java.util.concurrent.locks.ReentrantLock;

class QueueReentrantLock<T> {
    private volatile int size = 0; // count of elements
    private final Object[] content;
    private final int capacity;
    private int out; // content[out] is the next item to be taken
    private int in;  // content[in] is the next position to put item

    private final ReentrantLock lock = new ReentrantLock();
    private final Condition notEmpty = lock.newCondition(); // For waiting when queue is empty
    private final Condition notFull = lock.newCondition();  // For waiting when queue is full

    QueueReentrantLock(int capacity) {
        if (capacity <= 0) {
            throw new IllegalArgumentException("Capacity must be positive");
        }
        // No need to lock in constructor unless shared state is accessed by other threads
        // during construction, which is not the case here.
        this.capacity = capacity;
        content = new Object[capacity];
        out = 0;
        in = 0;
        // size is already initialized to 0
    }

    private int cycleInc(int index) {
        return (++index == capacity) ? 0 : index;
    }

    @SuppressWarnings("unchecked")
    T get() throws InterruptedException {
        lock.lockInterruptibly();
        try {
            while (size == 0) {
                notEmpty.await(); // Wait until queue is not empty
            }
            final Object value = content[out];
            content[out] = null; // Help GC
            out = cycleInc(out);
            size--;
            notFull.signal(); // Signal that the queue is no longer full
            return (T) value;
        } finally {
            lock.unlock();
        }
    }

    QueueReentrantLock<T> put(T value) throws InterruptedException {
        if (value == null) throw new NullPointerException(); // Or handle as per requirements

        lock.lockInterruptibly();
        try {
            while (size == capacity) {
                notFull.await(); // Wait until queue is not full
            }
            content[in] = value;
            in = cycleInc(in);
            size++;
            notEmpty.signal(); // Signal that the queue is no longer empty
            return this;
        } finally {
            lock.unlock();
        }
    }

    // Optional: method to get current size (needs lock for consistent read)
    public int getSize() {
        lock.lock();
        try {
            return size;
        } finally {
            lock.unlock();
        }
    }
}
```

---

## Что такое double checked locking Singleton?


[⬆️ К оглавлению](#оглавление)

Double checked locking Singleton - это один из способов создания потокобезопасного класса реализующего шаблон Одиночка. Данный метод пытается оптимизировать производительность, блокируясь только случае, когда экземпляр одиночки создаётся впервые.

```java
class DoubleCheckedLockingSingleton {
    private static volatile DoubleCheckedLockingSingleton instance;

    static DoubleCheckedLockingSingleton getInstance() {
        DoubleCheckedLockingSingleton current = instance; // Первая проверка (без блокировки)
        if (current == null) {
            synchronized (DoubleCheckedLockingSingleton.class) {
                current = instance; // Вторая проверка (с блокировкой)
                if (current == null) {
                    instance = current = new DoubleCheckedLockingSingleton();
                }
            }
        }
        return current;
    }
}
```

Следует заметить, что требование `volatile` обязательно. Проблема Double Checked Lock заключается в модели памяти Java, точнее в порядке создания объектов, когда возможна ситуация, при которой другой поток может получить и начать использовать (на основании условия, что указатель не нулевой) не полностью сконструированный объект. Хотя эта проблема была частично решена в JDK 1.5, однако рекомендация использовать `volatile` для Double Cheсked Lock остаётся в силе.

---

## Как создать потокобезопасный Singleton?


[⬆️ К оглавлению](#оглавление)

**Static field (Eager initialization)**
```java
public class Singleton {
    public static final Singleton INSTANCE = new Singleton();
    private Singleton() {} // Private constructor
}
```

**Enum Singleton**
```java
public enum Singleton {
    INSTANCE;
    // Можно добавить методы и поля
    public void doSomething() {
        // ...
    }
}
```
*Этот подход считается наиболее надежным и простым для реализации потокобезопасного Singleton, а также обеспечивает защиту от сериализации и рефлексии.*

**Synchronized Accessor (Lazy initialization)**
```java
public class Singleton {
    private static Singleton instance;
    private Singleton() {} // Private constructor

    public static synchronized Singleton getInstance() {
        if (instance == null) {
            instance = new Singleton();
        }
        return instance;
    }
}
```
*Простой, но может быть неэффективным из-за синхронизации при каждом вызове `getInstance()`.*

**Double Checked Locking & volatile (Lazy initialization)**
```java
public class Singleton {
    private static volatile Singleton instance;
    private Singleton() {} // Private constructor

    public static Singleton getInstance() {
        Singleton localInstance = instance;
        if (localInstance == null) {
            synchronized (Singleton.class) {
                localInstance = instance;
                if (localInstance == null) {
                    instance = localInstance = new Singleton();
                }
            }
        }
        return localInstance;
    }
}
```
*Более производительный, чем Synchronized Accessor, но требует `volatile` для корректной работы в Java 5+.*

**On Demand Holder Idiom (Lazy initialization)**
```java
public class Singleton {
    private Singleton() {} // Private constructor

    private static class SingletonHolder {
        public static final Singleton HOLDER_INSTANCE = new Singleton();
    }

    public static Singleton getInstance() {
        return SingletonHolder.HOLDER_INSTANCE;
    }
}
```
*Ленивая инициализация, потокобезопасность обеспечивается загрузчиком классов Java. Считается одним из лучших подходов.*
