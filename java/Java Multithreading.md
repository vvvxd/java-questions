Что такое Поток?
Поток — это поток выполнения программы. JVM позволяет приложению иметь несколько потоков выполнения одновременно (concurrently). В Hotspot JVM существует прямое соответствие между Java потоком и native потоком операционной системы. После подготовки всех компонентов Java потока таких как thread‑local хранилище, allocations буферы, объекты синхронизации, стеки и программные счётчики будет создан native поток. Native поток (операционной системы) освобождается как только Java поток завершается1. Операционная система ответственна за планировку и распределение потоков на любом доступном процессоре. Как только native поток инициализирован он вызывает метод run() в Java потоке. Когда run() метод возвращает значение, обрабатываются неперехваченные исключения, потом native поток подтверждает нужно ли завершить работу JVM (needs to be terminated) после завершения потока (напр. последний non‑daemon thread — main). Когда поток завершается все ресурсы native потока и Java потока освобождаются.
--------------------------------------------------------------------------------------------------------------------
Какие есть Cистемные потоки JVM?

Если использовать jconsole или любой отладчик, то можно увидеть несколько потоков запущенных в фоновом режиме. Эти фоновые потоки запускаются в дополнении к основному потоку, который создаётся как часть вызова
public static void main(String[]) и любого потока созданного основным потоком.

Вот данные в формате таблицы Markdown:

| Вид потока | Описание |
| - | - |
| Потоки виртуальной машины | Ожидают появления операций, которые нужны JVM для достижения безопасной точки (safe-point). Причина, по которой эти операции должны выполняться в отдельном потоке, заключается в том, что все они требуют, чтобы JVM находилась в безопасной точке, где модификации кучи не могут произойти. Тип операций, выполняемых этим потоком сборка мусора "stop-the-world", дамп стека потока, приостановка потока (thread suspension) и biased locking revocation. |
| Поток периодической задачи | Отвечает за события таймера (прерывания), которые используются для планирования выполнения периодических задач. |
| GC | Сборки мусора различного типа, которые появляются в JVM |
| Потоки компилятора | Компилируют байт-код в машинный код при выполнении программы (runtime) |
| Поток диспетчера сигналов (signal dispatcher thread) | Получает сигналы отправленные JVM процессу и обрабатывает их внутри JVM, вызывая соответствующие JVM методы. |

--------------------------------------------------------------------------------------------------------------------
Что такое Программный счётчик (ПС)

Если текущий метод является native методом, тогда ПС не определён, иначе содержит адрес текущей инструкции (или опкод). Все процессоры имеют программный счётчик, обычно ПС инкрементируется после каждой инструкции и, таким образом, хранит адрес следующей инструкции, которая должна быть выполнена. JVM использует ПС для отслеживания того, где она выполняет инструкции, ПС на самом деле будет указывать на адрес памяти в области методов.

--------------------------------------------------------------------------------------------------------------------

Что такое Стек

Каждый поток имеет свой собственный стек, в котором хранится фрейм для каждого метода, выполняющегося в этом потоке. Стек это LIFO (Last In First Out — последний пришел, первый вышел) структура данных, поэтому текущий выполняющийся метод находится на вершине стека. При каждом вызове метода создаётся новый фрейм.

Напрямую стек не модифицируют, кроме как добавления (push) и удаления (pop) объектов фрейма и поэтому объекты фрейма могут быть аллоцированы в куче (Heap) и нет необходимости в том, чтобы память под эти объекты была непрерывной (contiguous).

--------------------------------------------------------------------------------------------------------------------

Что такое Native стек

Не все JVM поддерживают native методы, однако те, которые поддерживают обычно создают native стек на каждый Java поток. Если JVM была реализована используя C‑linkage модель для Java Native Invocation (JNI) тогда native стек будет как в Си. В этом случае порядок аргументов и возвращаемое значение будет точно такие же как и в обычной программе на языке Си. Native метод обычно может (зависит от реализации JVM) вызывать Java метод в JVM. Такой вызов будет происходить на Java стеке. Поток покинет native стек и создаст новый фрейм в Java стеке.

--------------------------------------------------------------------------------------------------------------------

Что такое Ограничения стека

Стек может быть фиксированного или переменного размера. В случае когда поток запрашивает стек большего размера, чем разрешено, то произойдёт ошибка StackOverflowError. Если поток запрашивает новый фрейм, а памяти для его выделения не хватает, тогда произойдёт ошибка OutOfMemoryError.

--------------------------------------------------------------------------------------------------------------------

Что такое Фрейм?

Новый фрейм создаётся и добавляется (pushed) на вершину стека при каждом вызове метода. Фрейм удаляется (popped), когда метод штатно завершается, или, если во время выполнения метода возникло необработанное исключение. Более подробная информация по обработке исключений будет дана в Таблице Исключений.

Каждый фрейм содержит:

Массив локальных переменных

Возвращаемое значение

Стек операндов

Ссылку на runtime constant pool для класса текущего метода

--------------------------------------------------------------------------------------------------------------------

Что такое Массив локальных переменных?

Массив локальных переменных содержит все переменные, которые нужны при выполнении метода, включая ссылку на this, все параметры метода и другие локальные переменные. Для методов класса (статических методов) параметры метода отсчитываются от нуля, однако для метода экземпляра класса нулевой слот зарезервирован для this.

Локальные переменные могут иметь следующий тип: boolean, byte, char, long, short, int, float, double, ссылка (reference), возвращаемый адрес (returnAddress).

Все типы занимают один слот в массиве локальных переменных, исключая long и double, которые занимают два последовательных слота так как эти типы имеют размер 64 бита, вместо 32 бит.

--------------------------------------------------------------------------------------------------------------------

Что такое Стек операндов?

Cтек операндов используется во время выполнения инструкций байт‑кода и работает подобно регистрам общего назначения в процессоре. Большая часть JVM байт‑кода содержит операции со стеком операндов, добавляя (push), удаляя(pop), дублируя, меняя местами (swap) или выполняя операции, которые производят или потребляют значения. Таким образом, инструкции, которые перемещают значения между массивом локальных переменных и стеком операндов очень часто встречаются в байт‑коде. Например, простая инициализация переменной будет представлена в виде двух инструкций байт‑кода, которые взаимодействуют со стеком операндов.

int i; компилируется в следующий байт-код:

0: iconst_0  // добавить 0 на вершину стека операндов
1: istore_1  // считать значение из стека операндов и сохранить как локальную переменную с номером 1.
За более детальным объяснением взаимодействия между массивом локальных переменных, стеком операндов и runtime constant pool обращайтесь к секции Структура Файла Класса ниже.
--------------------------------------------------------------------------------------------------------------------

### Что такое Constant Pool?

**Constant Pool** — это статическая таблица констант, которая создаётся компилятором Java (javac) и хранится в файле `.class` для каждого класса или интерфейса. Она содержит все константы, используемые в коде класса, такие как строковые литералы, числовые значения, ссылки на классы, методы и поля.

- **Где находится**: В `.class`-файле, сразу после заголовка (magic number, версии и т.д.).
- **Формат**: Таблица, где каждая запись имеет:
    - Тег (1 байт), определяющий тип константы.
    - Данные, зависящие от типа.
- **Типы записей**:
    - `CONSTANT_Utf8`: Строки (имена классов, методов, строковые литералы).
    - `CONSTANT_Integer`, `CONSTANT_Float`, `CONSTANT_Long`, `CONSTANT_Double`: Числовые константы.
    - `CONSTANT_Class`: Ссылка на класс.
    - `CONSTANT_String`: Строковый литерал, ссылающийся на `CONSTANT_Utf8`.
    - `CONSTANT_Fieldref`, `CONSTANT_Methodref`, `CONSTANT_InterfaceMethodref`: Ссылки на поля, методы и методы интерфейсов.
    - `CONSTANT_NameAndType`: Пары имя/дескриптор.
    - `CONSTANT_MethodHandle`, `CONSTANT_MethodType`, `CONSTANT_InvokeDynamic` (с Java 7): Для динамических языковых конструкций.
- **Назначение**: Хранит символические ссылки (symbolic references) и константы, которые JVM использует для выполнения программы.
- **Пример**: Для строки `"Hello"` в коде в Constant Pool будет `CONSTANT_String`, ссылающийся на `CONSTANT_Utf8` с содержимым `"Hello"`.

Constant Pool неизменяем и создаётся на этапе компиляции.

---

### Что такое Run-Time Constant Pool?

**Run-Time Constant Pool** — это динамическая структура в памяти JVM, создаваемая на основе Constant Pool при загрузке класса в **Method Area** (или **Metaspace** в Java 8+). Она используется во время выполнения программы и может изменяться.

- **Где находится**: В памяти JVM, в Metaspace.
- **Создание**: Формируется при загрузке класса загрузчиком классов (ClassLoader) на основе Constant Pool из `.class`-файла.
- **Особенности**:
    - **Динамическое разрешение ссылок**: Символические ссылки (например, `CONSTANT_Methodref`) преобразуются в прямые ссылки на объекты, методы или поля в памяти. Этот процесс называется **resolution**.
    - **Интернирование строк**: Строковые литералы из `CONSTANT_String` помещаются в **String Pool** (часть Run-Time Constant Pool), что позволяет экономить память.
    - **Поддержка динамических конструкций**: Содержит данные для `invokedynamic` (например, для lambda-выражений).
- **Назначение**:
    - Предоставляет JVM быстрый доступ к константам.
    - Обеспечивает динамическое связывание (dynamic linking) классов, методов и полей.
    - Хранит интернированные строки и разрешённые ссылки.
- **Пример**: Если в коде есть вызов метода `System.out.println`, Run-Time Constant Pool сначала содержит символическую ссылку на `println`, а после разрешения — прямой адрес метода в памяти.

--------------------------------------------------------------------------------------------------------------------
В каком порядке выполняеться код?

В современном мире код часто выполняется не в том порядке, в котором он был написан в программе. Он часто переупорядочивается на уровне:


Компилятора байткода (в частности, javac)
Компилятора машинного кода (в частности, JIT компилятор HotSpot C1/C2). Например, среди компиляторов широко распространена такая оптимизация как Instruction scheduling
Процессора. Например, в мире процессоров широко распространены такие практики как Out-of-order execution, Branch Prediction + Speculation, Prefetching, а также многие другие

Также в современных процессорах каждое ядро имеет собственный локальный кэш, который не видим другим ядрам. Более того, записи могут удерживаться в регистрах процессора, а не сбрасываться в память. Это ведет к тому, что поток может не видеть изменений, сделанных из других потоков.


Все эти оптимизации делаются с целью повысить производительность программ:


Переупорядочивание необходимо для того, чтобы найти самый оптимальный путь к выполнению кода, учитывая стоимость выполнения процессорных инструкций. Например, процессор может инициировать загрузку значения из памяти заранее, даже если в порядке программы это чтение идет позднее. Операции чтения из памяти стоят дорого, поэтому эта оптимизация позволяет максимально эффективно утилизировать процессор, избежав простаивания, когда это чтение действительно понадобится
Чтение из регистра и кэша стоит сильно дешевле, чем чтение из памяти. Более того, локальный кэш необходим для того, чтобы ядра не простаивали в ожидании доступа к общему кэшу, а могли работать с кэшем независимо друг от друга

--------------------------------------------------------------------------------------------------------------------
Какие гарантии выполнения кода есть?

Java дает гарантию as-if-serial выполнения кода — вне зависимости от используемой JDK итоговый результат выполнения будет не отличим от такого порядка, как если бы действия выполнялись действительно последовательно согласно порядку в коде
Процессоры тоже делают только такие переупорядочивания, которые не изменят итогового результата выполнения инструкций
Процессоры имеют Cache Coherence механизм, который гарантирует консистентность данных среди локальных кэшей: как только значение попадает в локальный кэш одного ядра, оно будет видно всем остальным ядрам

Но есть проблемы в многопоточной среде

Java дает as-if-serial гарантию только для единственного треда в изоляции. Это означает, что в многопоточной программе при работе с shared данными мы можем не увидеть записи там, где полагаемся на порядок выполнения действий в коде другого треда. Другими словами, для первого треда в изоляции валидно переупорядочивать инструкции местами, если это не повлияет на его результат выполнения, но переупорядочивание может повлиять на другие треды
Процессор также дает гарантию только для единственного ядра в изоляции
Cache Coherence действительно гарантирует чтение актуальных значений, но пропагация записи происходит не мгновенно, а с некоторой задержкой

-------------------------------------
Расскажи про кеш в процесоре?

![img.png](img/Кеш.png)

Процессор никогда не работает с памятью напрямую — все операции чтения и записи проходят через кэш. Когда процессор хочет загрузить значение из памяти, то он обращается в кэш. Если значения там нет, то кэш сам ответственнен за выгрузку значения из памяти с последующим сохранением в кэше. Когда процессор хочет записать значение в память, то он записывает значение в кэш, который в свою очередь ответственен за сброс значения в память
Кэш состоит из множества "линий" (cache line) фиксированного размера, в которые кладутся значения из памяти. Размер линий варьируется от 16 до 256 байт в зависимости от архитектуры процессора. Кэш сам знает, как мапить адрес линии кэша в адрес памяти
Кэш имеет фиксированный размер, поэтому может хранить ограниченное количество записей. Например, если размер кэша 64 KB, а размер линии кэша 64 байт, то всего кэш может содержать 1024 линии. Поэтому, если при выгрузке нового значения места в кэше не хватает, то из кэша вымещается одно из значений
Большинство современных архитектур процессоров имеют несколько уровней кэша: обычно это L1, L2, и L3. Верхние уровни кэша (L1, L2) являются локальными — каждое ядро процессора имеет собственный, отдельный от других ядер кэш. Кэш на самом нижнем уровне (L3) является общим и шарится между всеми ядрами
Доступ к каждому последующему уровню кэша стоит дороже, чем к предыдущему. Например, доступ к L1 может стоить 3 цикла, L2 — 12 циклов, а к L3 — 38 циклов
Каждый последующий кэш имеет больший размер, чем предыдущий. Например, L1 может иметь размер 80 KB, L2 — 1.25 MB, а L3 — 24 MB

Из-за того, что ядра имеют собственный локальный кэш, возникает потенциальная проблема чтения неактуальных значений. Например, пусть два ядра прочитали одно и то же значение из памяти и сохранили в свой локальный кэш. Затем первое ядро записывает новое значение в свой локальный кэш, но другое ядро не видит этого изменения и продолжает читать устаревшее значение. Как итог, данные среди локальных кэшей не консистентны. Если бы в процессоре существовал только общий кэш, то проблемы чтения неактуальных значений просто не существовало бы: так как все записи и чтения проходят через кэш, а не идут напрямую в память, то общий кэш по сути был бы master копией памяти, где всегда лежали бы актуальные значения. Но это сильно ударило бы по производительности процессора, так как кэш может обрабатывать только один цикл единовременно, а значит ядра простаивали бы в очереди. Более того, локальный кэш распаян физически ближе к ядру, поэтому доступ к нему стоит дешевле. Именно поэтому и необходим локальный кэш, чтобы каждое ядро могло эффективно работать с кэшем независимо от других ядер.

-------------------------------------

Расскажите про Cache Coherence?

На самом деле, процессоры умеют поддерживать консистентность данных среди локальных кэшей так, что любое из ядер всегда читает актуальное значение одного и того же адреса памяти.


Cache Coherence (когерентность кэша) — это механизм процессора, гарантирующий, что любое ядро всегда читает самое актуальное значение из кэша. Данным механизмом обладают многие современные архитектуры процессоров в той или иной имплементации. Самый популярный из протоколов — это MESI протокол и его производные. Например, Intel использует MESIF, а AMD — MOESI протокол.


В MESI протоколе линия кэша может находиться в одном из следующих состояний:


Invalid — линия кэша устарела (содержит неактуальные значения), поэтому из нее нельзя читать
Shared — линия кэша актуальна и эквивалентна памяти. Процессор может только читать из такой линии кэша, но не писать в нее. Если несколько ядер читают один и тот же адрес памяти, то эта линия кэша будет реплицирована сразу в несколько локальных кэшей, отсюда и название "shared"
Exclusive — линия кэша актуальна и эквивалентна памяти. Однако как только одно из ядер процессора переводит линию кэша в это состояние, никакое другое ядро не может держать эту линию кэша у себя, отсюда и название "exclusive". Когда значение из памяти только первые загружается в кэш, то линия кэша устанавливается именно в это состояние. Если одно из ядер процессора хочет перевести линию кэша из shared в exclusive состояние, то все остальные ядра должны пометить свою копию как invalid
Modified — линия кэша была изменена (dirty), то есть ядро записало в нее новое значение. Именно в это состояние переходит exclusive линия кэша после записи в нее. Аналогично, только одно из ядер процессора может держать линию кэша в Modified состоянии. Если линия вымещается из кэша, то кэш ответственен за то, чтобы записать новое значение в память перед выгрузкой

Когда одно из ядер процессора хочет изменить линию кэша, то оно должно установить exclusive доступ к ней. Для этого ядро посылает всем остальным ядрам сообщение о том, что указанную линию кэша необходимо пометить как invalid в их локальном кэше. Только после того, как ядра обработают запрос, пометив свою копию как invalid, ядро сможет записать новое значение вместе с этим помечая линию кэша как modified. Таким образом, при записи только одно ядро может удерживать значение в локальном кэше, а значит неконсистентность данных просто невозможна.
-------------------------------------

Что происходит когда любое ядро хочет прочитать какой-нибудь адрес в памяти?

Ядро обращается в L1 кэш и проверяет, присутствует ли там искомое значение. Если линия кэша присутствует и находится в состоянии Shared, Exclusive или Modified, то происходит ее чтение. Если значение в локальном кэше не обнаружено (или линия кэша находится в состоянии Invalid), то говорится, что произошел (local) "cache miss"
По специальной общей шине всем остальным ядрам передается запрос на чтение значения. Все остальные ядра видят этот запрос, и если одно из ядер содержит искомое значение в состоянии Shared, Exclusive или Modified, то оно отдает актуальное значение в ответ.
Если линия кэша была установлена в Modified состояние, то перед тем как отдать значение, измененное значение сбрасывается в память, а затем линия кэша переводится в Shared состояние
Если значение не обнаружено ни в одном из локальных кэшей, то происходит чтение из памяти
Вне зависимости от того, где мы нашли значение, читающее ядро сохраняет данные в свой локальный кэш, помечая линию кэша как shared

Это очень упрощенное описание работы кэша — я опустил многие детали, но надеюсь, что примерная картина вам понятна. Скажу сразу, что я не претендую на полную корректность вышенаписанного: где-то я мог и соврать, ибо не являюсь специалистом в такой низкоуровневой теме как процессоры. Более того, многие моменты могут отличаться в зависимости от микроархитектуры процессора и используемого Cache Coherence протокола. В конце статьи я приведу ссылки на другие полезные источники, где вы сможете узнать подробнее о работе кэша.

Таким образом, как только значение попадает в локальный кэш, оно сразу же становится видно другим ядрам.

-------------------------------------

visibility проблемы на уровне процессора не существует?

Когда ядро получает запрос на инвалидацию записи в кэше, он может быть обработан не сразу, а поставиться в очередь Invalidation Queue (IQ). Эта оптимизация необходима по следующим причинам: во-первых, ядро может быть занято другой работой, и во-вторых, мы хотим, чтобы при большом количестве запросов ядро не заблокировалось на долгое время в их обработке, а обработало все постепенно. Таким образом, можно сказать, что invalidate запросы являются асинхронными

Проблема в том, что мы рискуем не прочитать самое актуальное значение просто потому, что запрос в invalidation queue еще не был обработан, а в кэше лежало еще не инвалидированное, но уже устаревшее значение.

-------------------------------------
Что такое Store Buffer в процессоре?

![img.png](img/full_cache.png)

В некоторых микро-архитектурах (как x86) каждое ядро имеет локальный FIFO Store Buffer (SB, write buffer), который является прослойкой между CPU и кэшем. В этот буфер ядро кладет все записи, которые будут ожидать там сброса в локальный кэш до тех пор, пока все остальные ядра не инвалидируют эту запись в своем кэше и не пришлют acknowledgement. Эта оптимизация требуется для того, чтобы не задерживать работу пишущего ядра, пока остальные ядра обрабатывают запрос на инвалидацию. При чтении ядро сперва смотрит в свой SB перед тем, как идти в локальный кэш, чтобы избежать чтения неактуальных значений и таким образом поддержать as-if-serial гарантию внутри одного ядра

Проблема в том, что другие ядра не увидят новой записи, пока пишущее ядро не сбросит запись из SB в локальный кэш, так как SB — это часть ядра, но не кэша. Другими словами, Cache Coherence механизм не распространяется на Store Buffer. Соответственно, некоторый промежуток времени пишущее ядро будет оперировать актуальным значением, но все остальные — устаревшим.

-------------------------------------
Благодаря Cache Coherence нам гарантируется eventual visibility?

Можно наивно предположить, что благодаря Cache Coherence нам гарантируется eventual visibility и на уровне Java для обычных записей и чтений, то есть не связанных happens-before. Однако, это не правда, так как мы работаем на уровне языка, а не процессора. Компилятор может оптимизировать код так, что запись никогда не станет видна другому треду. Яркий пример — это такой busy wait, где в бесконечном цикле проверяется значение shared переменной.

-------------------------------------
Расскажите о модели памяти Java?

Модель памяти Java (Java Memory Model, JMM) описывает поведение потоков в среде исполнения Java. Это часть семантики языка Java, набор правил, описывающий выполнение многопоточных программ и правил, по которым потоки могут взаимодействовать друг с другом посредством основной памяти.
Формально модель памяти определяет набор действий межпоточного взаимодействия (эти действия включают в себя, в частности, чтение и запись переменной, захват и освобождений монитора, чтение и запись volatile переменной, запуск нового потока), а также модель памяти определяет отношение между этими действиями -happens-before - абстракции обозначающей, что если операция X связана отношением happens-before с операцией Y, то весь код следуемый за операцией Y, выполняемый в одном потоке, видит все изменения, сделанные другим потоком, до операции X.
--------------------------------------------------------------------------------------------------------------------
Расскажите про Memory Ordering?

Memory Ordering описывает наблюдаемый программой порядок, в котором происходят действия с памятью.


Смотрите: со стороны программы есть только действия записи/чтения и их порядок в коде. Также со стороны программы кажется, что мы имеем единую общую память, записи в которую становятся сразу видны другим тредам. Программа не подозревает ни о каких instruction scheduling reordering/out-of-order execution/caching/register allocation и прочих оптимизациях под капотом. Если по какой-то причине мы наблюдаем результат, не консистентный с порядком в программе, то со стороны программы (высокоуровнево) это выглядит так, что действия c памятью просто были переупорядочены. Другими словами, порядок взаимодействия с памятью (memory order) может отличаться от порядка действий в коде (program order).


Для большего понимания давайте взглянем на уже знакомую нам программу с точки зрения Memory Ordering:


Thread 0	Thread 1
x = 1	y = 1
r1 = y	r2 = x

В случае результата выполнения (r1, r2) = (0, 0) мы можем просто сказать, что произошел StoreLoad memory reordering, то есть запись произошла после чтения. Не важно, по какой низкоуровневой причине это случилось, а важно лишь то, что в итоге со стороны программы действия с памятью были выполнены в неконсистентном порядке.


Таким образом, в многопоточной программе нам важно знать ответы на следующие вопросы:


Как сохраняется порядок программы при работе с памятью?
Валиден ли наблюдаемый memory order?

Дать ответ на каждый из вопросов — это и есть задача модели памяти. Java Memory Model разрешает все возможные переупорядочивания в отсутствие синхронизации, поэтому ответ на эти вопросы такой:


Если программа не синхронизирована, то разрешены все переупорядочивания. Если программа правильно синхронизирована, запрещены все переупорядочивания
Если программа не синхронизирована, то memory order, неконсистентный с program order, валиден с точки зрения JMM. Если программа правильно синхронизирована, то валиден только консистентный порядок

Ваша программа отрабатывает в одном из порядков, валидных с точки зрения JMM. Таким образом, если программа не правильно синхронизирована, не стоит удивляться некорретному результату выполнения. Ведь важно то, валиден ли результат выполнения с точки зрения модели памяти, а не то, валиден он или нет для вас как пользователя.


Однако то, что какой-то неконсистентный порядок валиден, еще не значит, что вы всегда получите некорректный результат, ведь и консистентный порядок возможен в отсутствие синхронизации — это вы могли видеть по jcstress тесту, который является вероятностным. Понятно, что вы не хотите надеяться на волю случая, поэтому необходимо ограничить возможный сет порядков выполнения до только консистентных. А для этого необходимо использовать предоставляемые моделью примитивы синхронизации, которые мы рассмотрим позднее.


В свою очередь, Memory Reordering — это высокоуровневое понятие, которое абстрагирует и обобщает низкоуровневые проблемы, которые мы рассматривали выше. Всего существует 4 типа memory reordering:


LoadLoad: переупорядочивание чтений с другими чтениями. Например, действия r1, r2 могут выполниться в порядке r2, r1
LoadStore: переупорядочивание чтений с записями, идущими позже в порядке программы. Например, действия r, w могут выполниться в порядке w, r
StoreStore: переупорядочивание записей с другими записями. Например, действия w1, w2 могут выполниться в порядке w2, w1
StoreLoad: переупорядочивание записей с чтениями, идущими позже в порядке программы. Например, действия w, r могут выполниться в порядке r, w

В дальнейшем, когда я буду говорить "переупорядочивание" или "reordering", я буду иметь в виду именно Memory Reordering, если не сказано обратное.


Memory Model описывает, какие переупорядочивания возможны. В зависимости от строгости модели памяти подразделяются на следующие типы:


Sequential Consistency: запрещены все переупорядочивания
Relaxed Consistency: разрешены некоторые переупорядочивания
Weak Consistency: разрешены все переупорядочивания

Модель памяти существует как на уровне языка, так и на уровне процессора, но они не связаны напрямую. Модель языка может предоставлять как более слабые, так и более строгие гарантии, чем модель процессора.


В частности, как уже было сказано выше, Java Memory Model не дает никаких гарантий, пока не использованы необходимые примитивы синхронизации. И напротив, посмотрите на главу Memory Ordering из Intel Software Developer’s Manual:


Reads are not reordered with other reads [запрещает LoadLoad reordering]
Writes are not reordered with older reads [запрещает LoadStore reordering]
Writes to memory are not reordered with other writes [запрещает StoreStore reordering]
Reads may be reordered with older writes to different locations but not with older writes to the same location [разрешает StoreLoad reordering]

Как видите, Intel разрешает только StoreLoad переупорядочивания, а все остальные запрещены. Да, модель памяти x86 достаточно строга, но есть и намного более слабые модели памяти процессоров — например, ARM разрешает все переупорядочивания.

Однако даже если вы пишете программу под x86, вам все равно необходимо считаться с более слабой Java Memory Model, так как последняя разрешает все переупорядочивания на уровне компилятора. Модель памяти языка — прежде всего.

--------------------------------------------------------------------------------------------------------------------

Memory Ordering vs Instructions Ordering?

Memory Ordering и Instructions Ordering — это не одно и то же. Инструкции могут переупорядочиваться под капотом как угодно, но их memory effect должен подчиняться некоторым Memory Ordering правилам, которые гарантируются (или не гарантируются) Memory Model. Наконец, memory ordering — это высокоуровневое понятие, созданное для простоты понимания работы с памятью.


Например, Intel запрещает LoadLoad переупорядочивания, но под капотом все равно делает спекулятивные чтения. Как это возможно? Дело в том, что процессор следит за тем, чтобы результат выполнения инструкций не нарушал memory ordering правил. Если какое-то правило нарушается, то процессор возвращается к более раннему состоянию: результат чтения отбрасывается, а записи не коммитятся в память.

--------------------------------------------------------------------------------------------------------------------

Что такое Sequential Consistency?

Sequential Consistency Model (SC) — это очень строгая модель памяти, которая гарантирует отсутствие переупорядочиваний.


Интуитивно SC можно понять очень просто: возьмите действия тредов, как они идут в порядке программы, и просто выполните их последовательно, возможно переключаясь между тредами.


Формальное определение SC также достаточно простое:


[Lamport, 1979 — How to Make a Multiprocessor Computer That Correctly Executes Multiprocess Programs] ...the result of any execution is the same as if the operations of all the processors were executed in some sequential order, and the operations of each individual processor appear in this sequence in the order specified by its program.
Давайте разберем SC на примере. Возьмем все тот же Dekker lock, который мы рассматривали выше:


Thread 0	Thread 1
x = 1	y = 1
r1 = y	r2 = x

В SC модели могут быть следующие memory order и никакие больше:


write(x, 1) -> write(y, 1) -> read(y):1 -> read(x):1
write(x, 1) -> write(y, 1) -> read(x):1 -> read(y):1
write(x, 1) -> read(y):0 -> write(y, 1) -> read(x):1

write(y, 1) -> write(x, 1) -> read(x):1 -> read(y):1
write(y, 1) -> write(x, 1) -> read(y):1 -> read(x):1
write(y, 1) -> read(x):0 -> write(x, 1) -> read(y):1

Назовем такие порядки "sequentially consistent memory orders".


А вот такой memory order, где присутствуют StoreLoad переупорядочивания и которые дают нам результат (r1, r2) = (0, 0), запрещен в SC:


read(y):0 -> read(x):0 -> write(x, 1) -> write(y, 1)


--------------------------------------------------------------------------------------------------------------------

Что такое Sequential Consistency-Data Race Free?

Java Memory Model — это Sequential Consistency-Data Race Free (SC-DRF) модель: нам предоставляется sequential consistency, но только в том случае, если мы избавимся от всех data race в программе — про это мы еще поговорим далее.

--------------------------------------------------------------------------------------------------------------------

Что такое Data race в рамках JMM?

Data race возникает тогда, когда с shared данными работает одновременно два или больше тредов, где как минимум один из них пишет и их действия не синхронизированы. Для действий в гонке не гарантируется никакого консистентного memory order, поэтому не стоит удивляться неожиданным результатам.


Data race в рамках JMM — это ключевая вещь, которая формально отличает SC и не-SC выполнения: если мы докажем, что никакое выполнение нашей программы не имеет гонок, то результат выполнения программы будет всегда объясним с точки зрения одного из sequentially consistent порядков.

Избавиться от гонок можно двумя способами:

Связать все действия с shared данными в synchronization order
Связать все действия с shared данными в happens-before order

--------------------------------------------------------------------------------------------------------------------

Расскажите про Happens-before?

Happens-before определяется как отношение между двумя действиями:


Пусть есть поток T1 и поток T2 (необязательно отличающийся от потока T1) и действия x и y, выполняемые в потоках T1 и T2 соответственно
Если x happens-before y, то во время выполнения y треду T2 будут видны все изменения, выполняемые в x тредом T1

Happens-before — это еще один способ, с помощью которого мы добьемся sequential consistency. 

Смотрите:

Если мы свяжем conflicting доступ к shared переменной с помощью happens-before, то избавимся от data race
Если мы избавимся от data race, то получим sequential consistency
Если мы получим sequential consistency, то наша программа всегда будет выдавать консистентный с порядком в программе результат

Давайте сразу проясним один момент: нет, happens-before не означает, что инструкции под капотом будут действительно выполняться в таком порядке. Если переупорядочивание инструкций все равно приводит к консистентному результату, то такое переупорядочивание инструкций не запрещено. JLS:

Правила Happens-Before в JMM:

Program Order Rule: Каждая операция в потоке happens-before следующей операции в этом же потоке.
Monitor Lock Rule: Разблокировка монитора happens-before последующей блокировкой этого же монитора в другом потоке.
Volatile Variable Rule: Запись в volatile переменную happens-before последующего чтения этой же переменной.
Thread Start Rule: Вызов Thread.start() happens-before любой операции в запущенном потоке.
Thread Termination Rule: Любая операция в потоке happens-before его завершением (например, Thread.join()).
Transitivity: Если A happens-before B, а B happens-before C, то A happens-before C.
--------------------------------------------------------------------------------------------------------------------

Расскажите про Monitor lock и как работает synchronized?

Monitor lock не только предоставляет happens-before между освобождением и взятием лока, но также является и мьютексом, который позволяет обеспечить эксклюзивный доступ к критической секции. Каждый объект в Java содержит внутри себя такой лок, но его нельзя использовать напрямую — чтобы воспользоваться им, необходимо применить keyword synchronized (отсюда и альтернативное название intrinsic lock).

--------------------------------------------------------------------------------------------------------------------
Как работает synchronized?

`synchronized` основан на концепции **монитора** — механизма, который обеспечивает, что только один поток может владеть монитором объекта в определённый момент времени. Монитор можно представить как замок, который поток должен захватить, чтобы выполнить синхронизированный код. Если монитор занят, другие потоки блокируются и ждут его освобождения.

`synchronized` используется в двух формах:
- **Синхронизированный метод**:
  Для нестатического метода монитором является объект `this`. Для статического метода — объект `Class`.

- **Синхронизированный блок**:
  Здесь монитором является объект та который направлена блокировка`.

### 2. Как это работает на уровне JVM
JVM реализует `synchronized` с помощью механизма **монитора**, встроенного в объект. Каждый объект в Java имеет связанный с ним монитор, который используется для синхронизации. Вот как это происходит:

#### 2.1. Захват и освобождение монитора
- Когда поток входит в синхронизированный блок или метод, он вызывает операцию **monitorenter** (на уровне байт-кода JVM).
  - Если монитор свободен, поток захватывает его и продолжает выполнение.
  - Если монитор занят, поток переходит в состояние **Blocked** и помещается в очередь ожидания монитора (monitor’s entry set).
- После завершения синхронизированного кода (или при выбросе исключения) поток вызывает операцию **monitorexit**, освобождая монитор.
- После освобождения монитора другой поток из очереди ожидания может захватить его.

#### 2.2. Структура монитора
Монитор в JVM хранит следующую информацию:
- **Владелец** (owner): поток, который в данный момент владеет монитором.
- **Счётчик входов** (entry count): для поддержки реентерабельности (reentrancy). Если поток повторно входит в синхронизированный блок того же монитора, счётчик увеличивается.
- **Очередь ожидания** (entry set): потоки, ожидающие захвата монитора.
- **Ожидающие потоки** (wait set): потоки, вызвавшие `wait()` на этом мониторе.

#### 2.3. Реентерабельность
`synchronized` поддерживает **реентерабельность** (reentrant locking). Это значит, что поток, уже владеющий монитором, может повторно войти в синхронизированный блок или метод, использующий тот же монитор, без блокировки самого себя. JVM увеличивает счётчик входов при каждом входе и уменьшает его при каждом выходе. Монитор освобождается, только когда счётчик достигает нуля.

#### 3.2. Оптимизации JVM
Современные JVM (например, HotSpot) используют несколько оптимизаций для `synchronized`, чтобы уменьшить накладные расходы:
- **Biased Locking** (смещённая блокировка): если объект обычно используется только одним потоком, JVM минимизирует затраты на захват монитора, "привязывая" его к этому потоку.
- **Lightweight Locking** (лёгкая блокировка): если конкуренция за монитор низкая, JVM использует атомарные операции (например, CAS — Compare-And-Swap) вместо тяжёлых системных вызовов.
- **Heavyweight Locking** (тяжёлая блокировка): при высокой конкуренции JVM прибегает к системным вызовам, что включает переключение контекста и взаимодействие с ОС.
- **Lock Elimination**: JIT-компилятор может удалить ненужные блокировки, если анализ показывает, что объект недоступен другим потокам.
- **Lock Coarsening**: JVM может объединить несколько синхронизированных блоков в один, чтобы уменьшить количество операций `monitorenter`/`monitorexit`.

### 5. Нюансы и подводные камни
1. **Выбор объекта монитора**:
  - Используйте объект, который логически связан с защищаемым ресурсом. Неправильный выбор (например, `this` вместо специального объекта) может привести к ненужной блокировке.
  - Никогда не используйте примитивные типы (`Integer`, `String` и т.д.) как мониторы, так как они могут быть интернированы и использоваться в других частях программы.

2. **Deadlock**:
  - Если два потока пытаются захватить мониторы в разном порядке, может возникнуть взаимная блокировка. Например:
    Решение: всегда захватывайте мониторы в одном и том же порядке.

3. **Производительность**:
  - Чрезмерное использование `synchronized` может привести к узким местам в производительности, особенно при высокой конкуренции.
  - Для высокопроизводительных приложений лучше использовать более гибкие механизмы из пакета `java.util.concurrent` (например, `ReentrantLock`, `ConcurrentHashMap`).

4. **Ограничения**:
  - `synchronized` не предоставляет таймаутов или условной блокировки, в отличие от `ReentrantLock`.
  - Нет возможности прервать поток, ожидающий монитор.

5. **Статическая vs нестатическая синхронизация**:
  - Статические синхронизированные методы блокируют весь класс, что может быть слишком грубым подходом.
  - Нестатические методы блокируют только конкретный экземпляр объекта.
--------------------------------------------------------------------------------------------------------------------

Расскажите про Memory Barriers?

Процессор может переупорядочивать выполняемые им инструкции, даже если на уровне компилятора мы обеспечили необходимый порядок. Хотя процессор делает только такие переупорядочивания, которые не меняют итогового результата, но это гарантируется только для единственного ядра в изоляции, поэтому переупорядочивание может повлиять на другие ядра. Более того, все еще существует проблема видимости изменений, которую мы обсудили выше. Именно поэтому JMM ответственна и за синхронизацию на уровне процессора.
Для решения этих проблем Java использует готовые низкоуровневые механизмы синхронизации под названием "memory barrier", предоставляемые самим процессором. Задача барьеров памяти — запретить (memory) переупорядочивания, которые обычно разрешены моделью памяти процессора. Таким образом, точно так же как мы используем примитивы синхронизации volatile/synchronized в высокоуровневом коде, сама Java под капотом тоже использует похожие низкоуровневые примитивы синхронизации.
Memory barrier (memory fence, барьер памяти) — это тип процессорной инструкции, которая заставляет процессор гарантировать memory ordering для инструкций, работающих с памятью.
Всего существует 4 типа барьеров памяти — они напрямую матчатся в возможные memory reordering и запрещают каждый из них:

LoadLoad Barrier:
Гарантирует, что операции чтения до барьера завершатся до операций чтения после барьера.
Пример: Чтение двух volatile переменных подряд требует, чтобы первое чтение завершилось до второго.
StoreStore Barrier:
Гарантирует, что операции записи до барьера завершатся до операций записи после барьера.
Пример: Запись в две volatile переменные подряд.
LoadStore Barrier:
Гарантирует, что операции чтения до барьера завершатся до операций записи после барьера.
Используется, чтобы предотвратить переупорядочивание чтения и записи.
StoreLoad Barrier:
Самый "тяжёлый" барьер, предотвращающий переупорядочивание записи и последующего чтения.
Пример: Запись в volatile переменную, за которой следует чтение другой volatile переменной.

volatile и Memory Barriers
Запись в volatile переменную:
JVM вставляет Store Barrier (или StoreStore и StoreLoad барьеры) после записи.
Это гарантирует, что значение записывается в основную память и все предшествующие операции завершаются до записи.
Пример: volatileVar = 42 завершает все предыдущие записи в память, делая их видимыми другим потокам.
Чтение volatile переменной:
JVM вставляет Load Barrier (или LoadLoad и LoadStore барьеры) перед чтением.
Это обновляет локальный кэш из основной памяти, обеспечивая актуальность данных.
Happens-before: Запись в volatile переменную создаёт happens-before отношение с последующим чтением этой переменной, что реализуется через комбинацию барьеров.

synchronized и Memory Barriers
Вход в synchronized блок/метод:
JVM использует Acquire Barrier (аналог Load Barrier), чтобы гарантировать, что все последующие операции видят актуальные данные.
Это соответствует захвату монитора (monitorenter).
Выход из synchronized блока/метода:
JVM использует Release Barrier (аналог Store Barrier), чтобы сбросить все изменения в основную память.
Это соответствует освобождению монитора (monitorexit).
Full Barrier: В некоторых случаях JVM может использовать полный барьер для обеспечения строгой синхронизации.

--------------------------------------------------------------------------------------------------------------------

Расскажите про Volatile?

Ключевое слово `volatile` в Java используется для управления видимостью и упорядочиванием операций с переменными в многопоточной среде. Оно решает проблемы, связанные с кэшированием данных потоками и оптимизациями компилятора, но не обеспечивает взаимоисключение, как `synchronized`.

### 1. Основы `volatile`
Ключевое слово `volatile` применяется к переменным и гарантирует:
- **Видимость**: Все потоки видят актуальное значение переменной. Если один поток изменяет `volatile` переменную, другие потоки немедленно получают её обновлённое значение.
- **Упорядочивание**: Операции с `volatile` переменной не переупорядочиваются компилятором или процессором относительно других операций, что обеспечивает определённый порядок выполнения.

`volatile` полезен в ситуациях, когда несколько потоков читают и/или пишут общую переменную, но не требуется сложная синхронизация, как при использовании `synchronized`.


### 3. Как работает `volatile` на уровне JVM
`volatile` опирается на модель памяти Java (Java Memory Model, JMM), которая определяет, как потоки взаимодействуют с памятью. Вот ключевые аспекты:

#### 3.1. Видимость (Visibility)
- Когда поток записывает в `volatile` переменную, JVM гарантирует, что значение записывается напрямую в **основную память** (main memory), а не только в локальный кэш потока.
- При чтении `volatile` переменной поток всегда читает значение из основной памяти, игнорируя локальный кэш.
- Это достигается с помощью **memory barriers** (барьеров памяти), которые предотвращают кэширование и обеспечивают синхронизацию данных.

#### 3.2. Упорядочивание (Ordering)
- JMM определяет правило **happens-before** для `volatile`:
  - Если поток A записывает в `volatile` переменную, а поток B читает её, то все изменения, сделанные потоком A до записи в `volatile` переменную, будут видны потоку B после чтения.
  - Это предотвращает переупорядочивание операций: инструкции до записи в `volatile` переменную не могут быть перемещены после неё, а инструкции после чтения — до него.
  
- Запись `flag = true` создаёт happens-before отношение, гарантируя, что `x = 1` будет видно в `reader()`.

#### 3.3. Реализация на низком уровне
На уровне процессора `volatile` использует:
- **Барьеры памяти**:
  - **Store Barrier** (при записи): Сбрасывает изменения из кэша в основную память.
  - **Load Barrier** (при чтении): Обновляет локальный кэш из основной памяти.
- **Атомарность записи**: Запись в `volatile` переменную является атомарной (но только для самой переменной, не для операций вроде `i++`).
- В современных JVM (например, HotSpot) для `volatile` часто используются инструкции процессора, такие как `LOCK` (на x86) или эквивалентные для других архитектур, чтобы обеспечить согласованность.


### 4. Ограничения `volatile`
1. **Нет взаимоисключения**:
  - `volatile` не предотвращает одновременный доступ нескольких потоков к переменной. Например, операции вроде `volatileVar++` не атомарны, так как состоят из чтения, инкремента и записи.
  - Для атомарных операций используйте `AtomicInteger`, `AtomicReference` или `synchronized`.

2. **Подходит только для простых сценариев**:
  - `volatile` полезен для флагов, счётчиков или состояний, где достаточно гарантировать видимость и упорядочивание.
  - Для сложной синхронизации (например, защиты критической секции) нужен `synchronized` или `Lock`.

3. **Ограниченная атомарность**:
  - Только чтение и запись самой `volatile` переменной атомарны. Составные операции (например, `volatileVar = volatileVar + 1`) требуют дополнительной синхронизации.


### 6. Низкоуровневые оптимизации
Современные JVM оптимизируют работу с `volatile`:
- **Элиминация избыточных барьеров**: Если JVM определяет, что `volatile` переменная используется только одним потоком, она может устранить ненужные барьеры памяти.
- **Кэширование в регистрах**: На некоторых архитектурах JVM может использовать кэш процессора, но с гарантией синхронизации при записи.
- **Поддержка 64-битных операций**: Начиная с Java 5, `volatile` поддерживает атомарные операции с 64-битными типами (`long` и `double`), которые ранее могли быть неатомарными на 32-битных системах.


--------------------------------------------------------------------------------------------------------------------

Расскажите про Atomicity и как это работает изнутри?

Рассмотрим на примере `AtomicInteger`

В Java классы из пакета `java.util.concurrent.atomic`, такие как `AtomicInteger`, предоставляют атомарные операции для безопасной работы с переменными в многопоточной среде без явных блокировок (`synchronized`). Атомарность гарантирует, что операции выполняются как единое, неделимое действие, исключая состояния гонки. 

### Что такое `AtomicInteger`
`AtomicInteger` — это класс для работы с целочисленными значениями, поддерживающий атомарные операции, такие как инкремент, декремент, обновление и сравнение. Он широко применяется в многопоточных приложениях для реализации счетчиков, аккумуляторов и других структур данных.

### Основные методы `AtomicInteger`
- `get()`: Возвращает текущее значение.
- `set(int newValue)`: Устанавливает новое значение.
- `incrementAndGet()`: Атомарно увеличивает значение на 1 и возвращает новое значение.
- `decrementAndGet()`: Атомарно уменьшает значение на 1 и возвращает новое значение.
- `getAndIncrement()`: Возвращает текущее значение и увеличивает его на 1.
- `compareAndSet(int expect, int update)`: Если текущее значение равно `expect`, атомарно устанавливает `update`. Возвращает `true` при успехе, иначе `false`.
- `addAndGet(int delta)`: Атомарно прибавляет `delta` и возвращает новое значение.
- В новых версиях Java (начиная с Java 9) добавлены методы, такие как `getAndUpdate(IntUnaryOperator)` и `updateAndGet(IntUnaryOperator)`, которые позволяют применять пользовательские функции атомарно.

### Как работает `AtomicInteger` изнутри
`AtomicInteger` использует низкоуровневые механизмы JVM, основанные на аппаратных инструкциях процессора, в первую очередь **Compare-And-Swap (CAS)**. В новых версиях Java (например, 17, 21) реализация была оптимизирована, но базовый принцип остался прежним. Рассмотрим ключевые аспекты.

#### Поле и волатильность
`AtomicInteger` хранит значение в поле `value`, помеченном как `volatile`:
```java
private volatile int value;
```
Модификатор `volatile` обеспечивает **видимость**: изменения значения сразу видны всем потокам, предотвращая кэширование в локальной памяти потока. В Java 9+ модель памяти (JMM) была уточнена, и `volatile` дополнительно поддерживает операции с улучшенной семантикой (например, для работы с VarHandle).

#### Compare-And-Swap (CAS) и VarHandle
Начиная с Java 9, реализация `AtomicInteger` перешла с использования `sun.misc.Unsafe` на **VarHandle**, который предоставляет более безопасный и поддерживаемый API для низкоуровневых операций. `VarHandle` — это абстракция, введенная в Java 9 (JEP 193), которая позволяет выполнять атомарные операции над полями объекта.

Пример внутренней реализации `AtomicInteger`:
```java
private static final VarHandle VALUE;

static {
    try {
        VALUE = MethodHandles.lookup().findVarHandle(AtomicInteger.class, "value", int.class);
    } catch (ReflectiveOperationException e) {
        throw new ExceptionInInitializerError(e);
    }
}
```
`VarHandle` заменяет `Unsafe` для операций вроде CAS, обеспечивая:
- **Безопасность**: VarHandle проверяет доступ к полям на уровне JVM.
- **Гибкость**: Поддерживает различные режимы доступа (volatile, non-volatile, acquire, release).
- **Портативность**: Работает на разных архитектурах процессоров.

#### Реализация CAS
CAS — это атомарная инструкция, которая:
1. Сравнивает текущее значение с ожидаемым (`expect`).
2. Если они совпадают, заменяет значение на новое (`update`) и возвращает `true`.
3. Если не совпадают, возвращает `false`.

Пример метода `compareAndSet`:
```java
public final boolean compareAndSet(int expectedValue, int newValue) {
    return VALUE.compareAndSet(this, expectedValue, newValue);
}
```
Здесь `VALUE` — это `VarHandle`, который вызывает нативную инструкцию CAS (например, `cmpxchg` на x86).

#### Реализация `incrementAndGet`
Метод `incrementAndGet` использует CAS в цикле (оптимистическая блокировка):
```java
public final int incrementAndGet() {
    return (int) VALUE.getAndAdd(this, 1) + 1;
}
```
Внутри `getAndAdd` реализует цикл:
1. Получает текущее значение (`oldValue`) с помощью `getVolatile`.
2. Вычисляет новое значение (`oldValue + 1`).
3. Пытается выполнить CAS через `VarHandle`.
4. Если CAS не удался (значение изменилось другим потоком), повторяет попытку.


#### Пример работы CAS
Предположим, `AtomicInteger` имеет значение `10`, и два потока вызывают `incrementAndGet`:
1. Поток 1 читает `10`, вычисляет `11`, выполняет CAS (`10 -> 11`).
2. Поток 2 читает `10`, вычисляет `11`, но видит, что значение уже `11` (изменил поток 1). CAS не срабатывает.
3. Поток 2 повторяет цикл: читает `11`, вычисляет `12`, выполняет CAS (`11 -> 12`).
4. Итог: значение становится `12`, оба инкремента выполнены корректно.

### Оптимизации в новых версиях Java
1. **VarHandle вместо Unsafe**: В Java 9+ `AtomicInteger` использует `VarHandle`, что делает код более безопасным и переносимым. `VarHandle` поддерживает различные режимы доступа (например, `acquire`/`release` для оптимизации производительности).
2. **Улучшения JMM**: Java Memory Model в новых версиях (например, Java 17) уточняет поведение `volatile` и атомарных операций, улучшая оптимизации компилятора.
3. **Поддержка новых архитектур**: На современных процессорах (например, ARM64) JVM оптимизирует CAS, используя аппаратные инструкции, такие как Load-Link/Store-Conditional (LL/SC).
4. **Функциональные методы**: Начиная с Java 9, `AtomicInteger` поддерживает методы вроде `updateAndGet(IntUnaryOperator)`, которые позволяют атомарно применять произвольные функции:

--------------------------------------------------------------------------------------------------------------------
Какие виды Atomic есть в java?

Основные классы атомиков
1. **AtomicInteger**
  - **Описание**: Хранит целое число (`int`) и поддерживает атомарные операции, такие как инкремент, декремент, сложение, сравнение и замена.
  - **Основные методы**: `get()`, `set(int)`, `incrementAndGet()`, `decrementAndGet()`, `compareAndSet(int, int)`, `addAndGet(int)`, `updateAndGet(IntUnaryOperator)`.
  - **Применение**: Счетчики, индексы, аккумуляторы в многопоточных приложениях.
  - **Пример**:
    ```java
    AtomicInteger counter = new AtomicInteger(0);
    counter.incrementAndGet(); // Атомарно увеличивает на 1
    ```

2. **AtomicLong**
  - **Описание**: Аналог `AtomicInteger`, но для работы с 64-битными целыми числами (`long`).
  - **Основные методы**: Те же, что у `AtomicInteger`, но с типом `long`, например, `incrementAndGet()`, `compareAndSet(long, long)`, `addAndGet(long)`.
  - **Применение**: Подходит для работы с большими значениями, например, для временных меток или идентификаторов.
  - **Пример**:
    ```java
    AtomicLong timestamp = new AtomicLong(System.currentTimeMillis());
    timestamp.getAndIncrement();
    ```

3. **AtomicBoolean**
  - **Описание**: Хранит булево значение (`true`/`false`) и поддерживает атомарные операции над ним.
  - **Основные методы**: `get()`, `set(boolean)`, `compareAndSet(boolean, boolean)`, `getAndSet(boolean)`.
  - **Применение**: Флаги, переключатели состояния (например, для включения/выключения функционала).
  - **Пример**:
    ```java
    AtomicBoolean flag = new AtomicBoolean(false);
    flag.compareAndSet(false, true); // Атомарно меняет false на true
    ```

4. **AtomicReference<V>**
  - **Описание**: Хранит ссылку на объект типа `V` и поддерживает атомарные операции над ссылкой.
  - **Основные методы**: `get()`, `set(V)`, `compareAndSet(V, V)`, `getAndUpdate(UnaryOperator<V>)`.
  - **Применение**: Управление ссылками на объекты в многопоточной среде, например, для атомарного обновления сложных структур данных.
  - **Пример**:
    ```java
    AtomicReference<String> ref = new AtomicReference<>("initial");
    ref.compareAndSet("initial", "updated");
    ```

5. **AtomicIntegerArray**
  - **Описание**: Массив целых чисел (`int`), где каждая операция над элементом массива выполняется атомарно.
  - **Основные методы**: `get(int index)`, `set(int index, int newValue)`, `compareAndSet(int index, int expect, int update)`, `incrementAndGet(int index)`.
  - **Применение**: Для работы с массивами, где требуется атомарное обновление отдельных элементов.
  - **Пример**:
    ```java
    AtomicIntegerArray array = new AtomicIntegerArray(10);
    array.incrementAndGet(5); // Увеличивает элемент с индексом 5
    ```

6. **AtomicLongArray**
  - **Описание**: Аналог `AtomicIntegerArray`, но для массива 64-битных чисел (`long`).
  - **Основные методы**: Те же, что у `AtomicIntegerArray`, но с типом `long`.
  - **Применение**: Массивы больших чисел, например, для хранения временных меток.
  - **Пример**:
    ```java
    AtomicLongArray array = new AtomicLongArray(10);
    array.addAndGet(3, 100L);
    ```

7. **AtomicReferenceArray<E>**
  - **Описание**: Массив ссылок на объекты типа `E`, с атомарными операциями над элементами.
  - **Основные методы**: `get(int index)`, `set(int index, E newValue)`, `compareAndSet(int index, E expect, E update)`.
  - **Применение**: Для массивов объектов, где требуется атомарное обновление ссылок.
  - **Пример**:
    ```java
    AtomicReferenceArray<String> array = new AtomicReferenceArray<>(10);
    array.compareAndSet(0, null, "value");
    ```

8. **AtomicDouble** (начиная с Java 21, экспериментально)
  - **Описание**: Хранит значение с плавающей точкой (`double`) и поддерживает атомарные операции. Введен как часть Project Valhalla (JEP 425) для улучшения работы с примитивами.
  - **Основные методы**: `get()`, `set(double)`, `compareAndSet(double, double)`, `addAndGet(double)`.
  - **Применение**: Подходит для численных вычислений, требующих атомарности, например, финансовые расчеты.
  - **Примечание**: Доступность зависит от версии JVM и может быть помечена как предварительная.
  - **Пример**:
    ```java
    AtomicDouble sum = new AtomicDouble(0.0);
    sum.addAndGet(1.5);
    ```

9. **AtomicMarkableReference<V>**
  - **Описание**: Хранит ссылку на объект типа `V` вместе с булевым "маркером" (например, для пометки объекта как удаленного).
  - **Основные методы**: `getReference()`, `get(boolean[] markHolder)`, `compareAndSet(V expectedReference, V newReference, boolean expectedMark, boolean newMark)`.
  - **Применение**: Алгоритмы, где нужно отслеживать состояние объекта (например, в неблокирующих структурах данных).
  - **Пример**:
    ```java
    AtomicMarkableReference<String> ref = new AtomicMarkableReference<>("data", false);
    ref.attemptMark("data", true); // Устанавливает маркер
    ```

10. **AtomicStampedReference<V>**
  - **Описание**: Хранит ссылку на объект типа `V` вместе с целочисленным "штампом" (stamp), который может использоваться как версия или счетчик.
  - **Основные методы**: `getReference()`, `getStamp()`, `compareAndSet(V expectedReference, V newReference, int expectedStamp, int newStamp)`.
  - **Применение**: Алгоритмы, требующие отслеживания версий, например, для решения проблемы ABA в CAS.
  - **Пример**:
    ```java
    AtomicStampedReference<String> ref = new AtomicStampedReference<>("data", 0);
    ref.compareAndSet("data", "newData", 0, 1);
    ```
--------------------------------------------------------------------------------------------------------------------
Атомарность базовых действий в JMM?

Чтения и записи reference переменных (ссылок) являются атомарными
Чтения и записи примитивов (кроме long/double) являются атомарными
Чтения и записи long/double переменных, помеченных как volatile, являются атомарными

Что же нам дают эти свойства в многопоточной среде? Нам гарантируется, что при shared чтении переменной мы увидим или значение по умолчанию (0, false, null), или полное консистентное значение, но не половинное значение. Даже если в переменную пишут одновременно несколько тредов, то мы увидим результат записи одного из них, но не будет такой ситуации, что чтение увидит первую половину битов из одной записи, а вторую половину из другой записи.


Но почему мы вообще могли бы прочитать половинное значение? Дело в том, что некоторые типы в языке имеют размер (в битах) больший, чем длина машинного слова процессора. Например, 32-х битный процессор оперирует словами по 32 бита, но тип long/double содержит 64 бита. Соответственно, языку требуется совершить 2 записи по 32 бит, чтобы полностью записать значение.

--------------------------------------------------------------------------------------------------------------------

Что такое «потокобезопасность»?

Потокобезопасность - свойство объекта или кода, которое гарантирует, что при исполнении или использовании несколькими потоками, код будет вести себя, как предполагается. Например потокобезопасный счётчик не пропустит ни один счёт, даже если один и тот же экземпляр этого счётчика будет использоваться несколькими потоками.

--------------------------------------------------------------------------------------------------------------------
В чём разница между «конкуренцией» и «параллелизмом»?

Конкуренция — это способ одновременного решения множества задач.
Признаки:
Наличие нескольких потоков управления (например, Thread в Java, корутина в Kotlin), если поток управления один, то конкурентного выполнения быть не может
Недетерминированный результат выполнения. Результат зависит от случайных событий, реализации и того, как была проведена синхронизация. Даже если каждый поток полностью детерминированный, итоговый результат будет недетерминированным

Параллелизм — это способ выполнения разных частей одной задачи.
Признаки:
Необязательно имеет несколько потоков управления
Может приводить к детерминированному результату, так, например, результат умножения каждого элемента массива на число, не изменится, если умножать его по частям параллельно.
--------------------------------------------------------------------------------------------------------------------
Что такое «кооперативная многозадачность»? Какой тип многозадачности использует Java? Чем обусловлен этот выбор?

Кооперативная многозадачность - это способ деления процессорного времени между потоками, при котором каждый поток обязан отдавать управление следующему добровольно.
Преимущества такого подхода - простота реализации, меньшие накладные расходы на переключение контекста.
Недостатки - если один поток завис или ведет себя некорректно, то зависает целиком вся система и другие потоки никогда не получат управление.
Java использует вытесняющую многозадачность, при которой решение о переключении между потоками процесса принимает операционная система.
В отличие от кооперативной многозадачности управление операционной системе передаётся вне зависимости от состояния работающих приложений, благодаря чему, отдельные зависшие потоки процесса, как правило, не «подвешивают» всю систему целиком. За счёт регулярного переключения между задачами также улучшается отзывчивость приложения и повышается оперативность освобождения ресурсов, которые больше не используются.
В реализации вытесняющая многозадачность отличается от кооперативной, в частности, тем, что требует обработки системного прерывания от аппаратного таймера.
--------------------------------------------------------------------------------------------------------------------
Что такое ordering, as-if-serial semantics, sequential consistency, visibility, atomicity, happens-before, mutual exclusion, safe publication?

ordering механизм, который определяет, когда один поток может увидеть out-of-order (неверный) порядок исполнения инструкций другого потока. CPU для для повышения производительности может переупорядочивать процессорные инструкции и выполнять их в произвольном порядке до тех пор пока для потока внутри не будет видно никаких отличий. Гарантия, предоставляемая этим механизмом, называется as-if-serial semantics.

sequential consistency - то же что и as-if-serial semantics, гарантия того, что в рамках одного потока побочные эффекты от всех операций будут такие, как будто все операции выполняются последовательно.
visibility определяет, когда действия в одном потоке становятся видны из другого потока.

happens-before - логическое ограничение на порядок выполнения инструкций программы. Если указывается, что запись в переменную и последующее ее чтение связаны через эту зависимость, то как бы при выполнении не переупорядочивались инструкции, в момент чтения все связанные с процессом записи результаты уже зафиксированы и видны.

atomicity — атомарность операций. Атомарная операция выглядит единой и неделимой командой процессора, которая может быть или уже выполненной или ещё невыполненной.

mutual exclusion (взаимоисключающая блокировка, семафор с одним состоянием) - механизм, гарантирующий потоку исключительный доступ к ресурсу. Используется для предотвращения одновременного доступа к общему ресурсу. В каждый момент времени таким ресурсом может владеть только один поток. Простейший пример:
synchronized(obj) { ... }.
safe publication? - показ объектов другим потокам из текущего, не нарушая ограничений visibility. Способы такой публикации в Java:
static{} инициализатор;
volatile переменные;
atomic переменные;
сохранение в разделяемой переменной, корректно защищенной с использованием synchronized(), синхронизаторов или других конструкций, создающих read/write memory barrier;
final переменные в разделяемом объекте, который был корректно проинициализирован.
--------------------------------------------------------------------------------------------------------------------
Чем отличается процесс от потока?

Процесс — экземпляр программы во время выполнения, независимый объект, которому выделены системные ресурсы (например, процессорное время и память). Каждый процесс выполняется в отдельном адресном пространстве: один процесс не может получить доступ к переменным и структурам данных другого. Если процесс хочет получить доступ к чужим ресурсам, необходимо использовать межпроцессное взаимодействие. Это могут быть конвейеры, файлы, каналы связи между компьютерами и многое другое.
Для каждого процесса ОС создает так называемое «виртуальное адресное пространство», к которому процесс имеет прямой доступ. Это пространство принадлежит процессу, содержит только его данные и находится в полном его распоряжении. Операционная система же отвечает за то, как виртуальное пространство процесса проецируется на физическую память.
Поток(thread) — определенный способ выполнения процесса, определяющий последовательность исполнения кода в процессе. Потоки всегда создаются в контексте какого-либо процесса, и вся их жизнь проходит только в его границах. Потоки могут исполнять один и тот же код и манипулировать одними и теми же данными, а также совместно использовать описатели объектов ядра, поскольку таблица описателей создается не в отдельных потоках, а в процессах. Так как потоки расходуют существенно меньше ресурсов, чем процессы, в процессе выполнения работы выгоднее создавать дополнительные потоки и избегать создания новых процессов.
--------------------------------------------------------------------------------------------------------------------
Что такое «зелёные потоки» и есть ли они в Java?

Зелёные (легковесные) потоки(green threads) - потоки эмулируемые виртуальной машиной или средой исполнения. Создание зелёного потока не подразумевает под собой создание реального потока ОС.
Виртуальная машина Java берёт на себя заботу о переключении между разными green threads, а сама машина работает как один поток ОС. Это даёт несколько преимуществ. Потоки ОС относительно дороги в большинстве POSIX-систем. Кроме того, переключение между native threads гораздо медленнее, чем между green threads.
Это всё означает, что в некоторых ситуациях green threads гораздо выгоднее, чем native threads. Система может поддерживать гораздо большее количество green threads, чем потоков OС. Например, гораздо практичнее запускать новый green thread для нового HTTP-соединения к веб-серверу, вместо создания нового native thread.
Однако есть и недостатки. Самый большой заключается в том, что вы не можете исполнять два потока одновременно. Поскольку существует только один native thread, только он и вызывается планировщиком ОС. Даже если у вас несколько процессоров и несколько green threads, только один процессор может вызывать green thread. И всё потому, что с точки зрения планировщика заданий ОС всё это выглядит одним потоком.
Начиная с версии 1.2 Java поддерживает native threads, и с тех пор они используются по умолчанию.
--------------------------------------------------------------------------------------------------------------------
Каким образом можно создать поток?

Создать потомка класса Thread и переопределить его метод run();

Создать объект класса Thread, передав ему в конструкторе экземпляр класса, реализующего интерфейс Runnable. Эти интерфейс содержит метод run(), который будет выполняться в новом потоке. Поток закончит выполнение, когда завершится его метод run().

Вызвать метод submit() у экземпляра класса реализующего интерфейс ExecutorService, передав ему в качестве параметра экземпляр класса реализующего интерфейс Runnable или Callable (содержит метод call(), в котором описывается логика выполнения).

--------------------------------------------------------------------------------------------------------------------
Чем различаются Thread и Runnable?

Thread - это класс, некоторая надстройка над физическим потоком.
Runnable - это интерфейс, представляющий абстракцию над выполняемой задачей.
Помимо того, что Runnable помогает разрешить проблему множественного наследования, несомненный плюс от его использования состоит в том, что он позволяет логически отделить логику выполнения задачи от непосредственного управления потоком.
--------------------------------------------------------------------------------------------------------------------
В чём заключается разница между методами start() и run()?

Несмотря на то, что start() вызывает метод run() внутри себя, это не то же самое, что просто вызов run(). Если run() вызывается как обычный метод, то он вызывается в том же потоке и никакой новый поток не запускается, как это происходит, в случае, когда вы вызываете метод start().

--------------------------------------------------------------------------------------------------------------------
Как принудительно запустить поток?

Никак. В Java не существует абсолютно никакого способа принудительного запуска потока. Это контролируется JVM и Java не предоставляет никакого API для управления этим процессом.

--------------------------------------------------------------------------------------------------------------------
Дайте определение понятию «синхронизация».

Синхронизация - это процесс, который позволяет выполнять потоки параллельно.
В Java все объекты имеют одну блокировку, благодаря которой только один поток одновременно может получить доступ к критическому коду в объекте. Такая синхронизация помогает предотвратить повреждение состояния объекта. Если поток получил блокировку, ни один другой поток не может войти в синхронизированный код, пока блокировка не будет снята. Когда поток, владеющий блокировкой, выходит из синхронизированного кода, блокировка снимается. Теперь другой поток может получить блокировку объекта и выполнить синхронизированный код. Если поток пытается получить блокировку объекта, когда другой поток владеет блокировкой, поток переходит в состояние Блокировки до тех пор, пока блокировка не снимется.
--------------------------------------------------------------------------------------------------------------------
Какие существуют способы синхронизации в Java?

Системная синхронизация с использованием wait()/notify(). Поток, который ждет выполнения каких-либо условий, вызывает у этого объекта метод wait(), предварительно захватив его монитор. На этом его работа приостанавливается. Другой поток может вызвать на этом же самом объекте метод notify() (опять же, предварительно захватив монитор объекта), в результате чего, ждущий на объекте поток «просыпается» и продолжает свое выполнение. В обоих случаях монитор надо захватывать в явном виде, через synchronized-блок, потому как методы wait()/notify() не синхронизированы!

Системная синхронизация с использованием join(). Метод join(), вызванный у экземпляра класса Thread, позволяет текущему потоку остановиться до того момента, как поток, связанный с этим экземпляром, закончит работу.

Использование классов из пакета java.util.concurrent, который предоставляет набор классов для организации межпоточного взаимодействия. Примеры таких классов - Lock, Semaphore и пр.. Концепция данного подхода заключается в использовании атомарных операций и переменных.

--------------------------------------------------------------------------------------------------------------------
В каких состояниях может находиться поток?

Потоки могут находиться в одном из следующих состояний:
Новый (New). После создания экземпляра потока, он находится в состоянии Новый до тех пор, пока не вызван метод start(). В этом состоянии поток не считается живым.

Работоспособный
(Runnable). Поток переходит в состояние Работоспособный, когда вызывается метод start(). Поток может перейти в это состояние также из состояния

Работающий или из состояния Блокирован. Когда поток находится в этом состоянии, он считается живым.
Работающий (Running). Поток переходит из состояния Работоспособный в состояние Работающий, когда Планировщик потоков выбирает его как работающий в данный момент.

Живой, но не работоспособный (Alive, but not runnable). Поток может быть живым, но не работоспособным по нескольким причинам:Ожидание (Waiting). Поток переходит в состояние Ожидания, вызывая метод wait(). Вызов notify() или notifyAll() может перевести поток из состояния Ожидания в состояние Работоспособный.Сон (Sleeping). Метод sleep() переводит поток в состояние Сна на заданный промежуток времени в миллисекундах.Блокировка (Blocked). Поток может перейти в это состояние, в ожидании ресурса, такого как ввод/вывод или из-за блокировки другого объекта. В этом случае поток переходит в состояние Работоспособный, когда ресурс становится доступен.Мёртвый (Dead). Поток считается мёртвым, когда его метод run() полностью выполнен. Мёртвый поток не может перейти ни в какое другое состояние, даже если для него вызван метод start().

--------------------------------------------------------------------------------------------------------------------
Можно ли создавать новые экземпляры класса, пока выполняется static synchronized метод?

Да, можно создавать новые экземпляры класса, так как статические поля не принадлежат к экземплярам класса.

--------------------------------------------------------------------------------------------------------------------
Зачем может быть нужен private мьютекс?

Объект для синхронизации делается private, чтобы сторонний код не мог на него синхронизироваться и случайно получить взаимную блокировку.

--------------------------------------------------------------------------------------------------------------------
Как работают методы wait() и notify()/notifyAll()?

Методы `wait()`, `notify()` и `notifyAll()` в Java являются частью механизма синхронизации, встроенного в каждый объект (через класс `Object`). Они используются для координации работы потоков в многопоточной среде, позволяя потокам ожидать определенных условий и уведомлять друг друга о выполнении этих условий. Эти методы тесно связаны с монитором объекта (monitor), который используется для обеспечения взаимоисключения (mutual exclusion) и синхронизации. Рассмотрим их работу углубленно, включая внутренние механизмы, поведение в JVM и примеры использования.

### 1. **Основы работы `wait()`, `notify()` и `notifyAll()`**
- **Монитор объекта**: Каждый объект в Java имеет связанный с ним монитор — внутренний механизм, обеспечивающий взаимоисключение. Только один поток может владеть монитором объекта в определенный момент времени. Монитор захватывается при входе в блок `synchronized` или при вызове синхронизированного метода.
- **Где определены**: Методы `wait()`, `notify()` и `notifyAll()` определены в классе `Object`, поэтому доступны для любого объекта в Java.
- **Требование синхронизации**: Эти методы должны вызываться только внутри блока `synchronized` или синхронизированного метода для объекта, монитор которого используется. В противном случае будет выброшено исключение `IllegalMonitorStateException`.

### 2. **Метод `wait()`**
- **Назначение**: Метод `wait()` заставляет текущий поток приостановить выполнение и освободить монитор объекта, переходя в состояние ожидания (waiting), пока другой поток не вызовет `notify()` или `notifyAll()` на том же объекте или пока не истечет таймаут (если используется `wait(long timeout)`).
- **Варианты метода**:
  - `wait()`: Ожидает бесконечно, пока не будет вызван `notify()` или `notifyAll()`.
  - `wait(long timeout)`: Ожидает указанное время (в миллисекундах).
  - `wait(long timeout, int nanos)`: Ожидает с точностью до наносекунд (используется редко).
- **Как работает**:
  1. Поток, вызывающий `wait()`, должен владеть монитором объекта (например, через `synchronized(obj)`).
  2. При вызове `wait()`:
    - Поток освобождает монитор объекта.
    - Поток переводится в состояние **WAITING** (или **TIMED_WAITING** для версии с таймаутом) и помещается в **wait set** (множество ожидающих потоков) объекта.
    - Поток приостанавливается и не потребляет процессорное время.
  3. Поток может возобновить выполнение в следующих случаях:
    - Другой поток вызывает `notify()` или `notifyAll()` на том же объекте.
    - Истекает таймаут (если указан).
    - Поток прерывается вызовом `Thread.interrupt()`, что приводит к выбросу `InterruptedException`.
  4. После пробуждения поток должен снова захватить монитор объекта, прежде чем продолжить выполнение. Это означает, что пробуждение не гарантирует немедленного продолжения работы — поток может ждать, пока монитор не станет свободным.

- **Важные детали**:
  - `wait()` не возвращает управление автоматически — поток должен быть явно пробужден.
  - После пробуждения поток продолжает выполнение с места, где был вызван `wait()`.
  - Рекомендуется вызывать `wait()` в цикле (паттерн "guarded block"), чтобы проверять условие, так как пробуждение может быть "ложным" (spurious wakeup — редкое явление, когда поток пробуждается без явного вызова `notify()` или `notifyAll()`).

### 3. **Методы `notify()` и `notifyAll()`**
- **Назначение**:
  - `notify()`: Пробуждает **один** поток, находящийся в состоянии ожидания (`wait()`) на мониторе объекта. Если в wait set несколько потоков, выбор потока не детерминирован (зависит от реализации JVM).
  - `notifyAll()`: Пробуждает **все** потоки, находящиеся в состоянии ожидания на мониторе объекта.
- **Как работают**:
  1. Поток, вызывающий `notify()` или `notifyAll()`, должен владеть монитором объекта (через `synchronized`).
  2. При вызове `notify()`:
    - Один поток из wait set объекта переводится в состояние **RUNNABLE**.
    - Этот поток не начинает выполнение немедленно — он должен дождаться, пока текущий поток освободит монитор (например, выйдет из блока `synchronized`).
  3. При вызове `notifyAll()`:
    - Все потоки из wait set переводятся в состояние **RUNNABLE**.
    - Все пробужденные потоки начинают конкурировать за захват монитора, но только один из них получит его и продолжит выполнение.
  4. Пробужденные потоки возвращаются к точке, где был вызван `wait()`, и продолжают выполнение.

- **Важные детали**:
  - `notify()` не гарантирует, какой именно поток будет пробужден, поэтому его использование может быть непредсказуемым в системах с несколькими ожидающими потоками.
  - `notifyAll()` предпочтительнее, если несколько потоков ожидают на одном объекте, и вы не уверены, какой именно поток должен быть пробужден.
  - Пробуждение не передает данные — оно лишь сигнализирует, что поток может проверить условие и продолжить выполнение.
  
### 4. **Внутренняя реализация в JVM**
- **Монитор объекта**:
  - Каждый объект в Java имеет связанный монитор, который реализован на уровне JVM (обычно через нативные структуры, такие как мьютексы или семафоры в операционной системе).
  - Монитор хранит два ключевых компонента:
    - **Lock**: Обеспечивает взаимоисключение (только один поток может владеть монитором).
    - **Wait Set**: Множество потоков, ожидающих на вызове `wait()` для этого объекта.
- **Механизм `wait()`**:
  - Когда поток вызывает `wait()`, JVM:
    1. Освобождает монитор объекта (разблокирует мьютекс).
    2. Переводит поток в состояние WAITING/TIMED_WAITING и добавляет его в wait set.
    3. Приостанавливает поток через системный вызов (например, `park()` в реализации HotSpot JVM).
  - При пробуждении (через `notify()`/`notifyAll()` или таймаут):
    1. Поток удаляется из wait set.
    2. JVM переводит поток в состояние RUNNABLE.
    3. Поток пытается снова захватить монитор (через системный вызов, например, `unpark()` в HotSpot).
- **Механизм `notify()` и `notifyAll()`**:
  - `notify()` выбирает один поток из wait set (реализация зависит от JVM, например, HotSpot может использовать FIFO или произвольный выбор).
  - `notifyAll()` переводит все потоки из wait set в состояние RUNNABLE.
  - Пробужденные потоки конкурируют за монитор, что реализуется через системные примитивы синхронизации (мьютексы).

- **Реализация в HotSpot JVM**:
  - В HotSpot JVM мониторы реализованы через структуру `ObjectMonitor`, которая содержит:
    - `_owner`: Указывает на поток, владеющий монитором.
    - `_WaitSet`: Список потоков, ожидающих на `wait()`.
    - `_EntryList`: Список потоков, ожидающих захвата монитора.
  - Операции `wait()` и `notify()` используют нативные вызовы (`park`/`unpark`) из библиотеки `java.util.concurrent.locks.LockSupport`.
  - В новых версиях Java (например, Java 21) мониторы оптимизированы для работы с виртуальными потоками (Project Loom), что снижает накладные расходы.
  

--------------------------------------------------------------------------------------------------------------------
В чем разница между notify() и notifyAll()?

Дело в том, что «висеть» на методе wait() одного монитора могут сразу несколько потоков. При вызове notify() только один из них выходит из wait() и пытается захватить монитор, а затем продолжает работу со следующего после wait() оператора. Какой из них выйдет - заранее неизвестно. А при вызове notifyAll(), все висящие на wait() потоки выходят из wait(), и все они пытаются захватить монитор. Понятно, что в любой момент времени монитор может быть захвачен только одним потоком, а остальные ждут своей очереди. Порядок очереди определяется планировщиком потоков Java.

--------------------------------------------------------------------------------------------------------------------
Почему методы wait() и notify() вызываются только в синхронизированном блоке?

Монитор надо захватывать в явном виде (через synchronized-блок), потому что методы wait() и notify() не синхронизированы.

--------------------------------------------------------------------------------------------------------------------
Чем отличается работа метода wait() с параметром и без параметра?

wait()
без параметров освобождает монитор и переводит вызывающий поток в состояние ожидания до тех пор, пока другой поток не вызовет метод notify()/notifyAll(),
с параметрами заставит поток ожидать заданное количество времени или вызова notify()/notifyAll().
--------------------------------------------------------------------------------------------------------------------
Чем отличаются методы Thread.sleep() и Thread.yield()?

Метод yield() служит причиной того, что поток переходит из состояния работающий (running) в состояние работоспособный (runnable), давая возможность другим потокам активизироваться. Но следующий выбранный для запуска поток может и не быть другим.
Метод sleep() вызывает засыпание текущего потока на заданное время, состояние изменяется с работающий (running) на ожидающий (waiting).
--------------------------------------------------------------------------------------------------------------------
Как работает метод Thread.join()?

Когда поток вызывает join() для другого потока, текущий работающий поток будет ждать, пока другой поток, к которому он присоединяется, не будет завершён:
void join()
void join(long millis)
void join(long millis, int nanos)
--------------------------------------------------------------------------------------------------------------------
Что такое deadlock?

Взаимная блокировка (deadlock) - явление, при котором все потоки находятся в режиме ожидания. Происходит, когда достигаются состояния:
взаимного исключения: по крайней мере один ресурс занят в режиме неделимости и, следовательно, только один поток может использовать ресурс в любой данный момент времени.
удержания и ожидания: поток удерживает как минимум один ресурс и запрашивает дополнительные ресурсов, которые удерживаются другими потоками.
отсутствия предочистки: операционная система не переназначивает ресурсы: если они уже заняты, они должны отдаваться удерживающим потокам сразу же.
цикличного ожидания: поток ждёт освобождения ресурса, другим потоком, который в свою очередь ждёт освобождения ресурса заблокированного первым потоком.
Простейший способ избежать взаимной блокировки - не допускать цикличного ожидания. Этого можно достичь, получая мониторы разделяемых ресурсов в определённом порядке и освобождая их в обратном порядке.
--------------------------------------------------------------------------------------------------------------------
Что такое livelock?

livelock - тип взаимной блокировки, при котором несколько потоков выполняют бесполезную работу, попадая в зацикленность при попытке получения каких-либо ресурсов. При этом их состояния постоянно изменяются в зависимости друг от друга. Фактической ошибки не возникает, но КПД системы падает до 0. Часто возникает в результате попыток предотвращения deadlock.
Реальный пример livelock, - когда два человека встречаются в узком коридоре и каждый, пытаясь быть вежливым, отходит в сторону, и так они бесконечно двигаются из стороны в сторону, абсолютно не продвигаясь в нужном им направлении.
--------------------------------------------------------------------------------------------------------------------
Как проверить, удерживает ли поток монитор определённого ресурса?

Метод Thread.holdsLock(lock) возвращает true, когда текущий поток удерживает монитор у определённого объекта.

--------------------------------------------------------------------------------------------------------------------
На каком объекте происходит синхронизация при вызове static synchronized метода?

У синхронизированного статического метода нет доступа к this, но есть доступ к объекту класса Class, он присутствует в единственном экземпляре и именно он выступает в качестве монитора для синхронизации статических методов. Таким образом, следующая конструкция:
public class SomeClass { public static synchronized void someMethod() { //code } }
эквивалентна такой:
public class SomeClass { public static void someMethod(){ synchronized(SomeClass.class){ //code } } }
--------------------------------------------------------------------------------------------------------------------
Для чего используется ключевое слово volatile, synchronized, transient, native?

volatile - этот модификатор вынуждает потоки отключить оптимизацию доступа и использовать единственный экземпляр переменной. Если переменная примитивного типа - этого будет достаточно для обеспечения потокобезопасности. Если же переменная является ссылкой на объект - синхронизировано будет исключительно значение этой ссылки. Все же данные, содержащиеся в объекте, синхронизированы не будут!
synchronized - это зарезервированное слово позволяет добиваться синхронизации в помеченных им методах или блоках кода.
Ключевые слова transient и native к многопоточности никакого отношения не имеют, первое используется для указания полей класса, которые не нужно сериализовать, а второе - сигнализирует о том, что метод реализован в платформо-зависимом коде.
--------------------------------------------------------------------------------------------------------------------
В чём различия между volatile и Atomic переменными?

volatile принуждает использовать единственный экземпляр переменной, но не гарантирует атомарность. Например, операция count++ не станет атомарной просто потому, что count объявлена volatile. C другой стороны class AtomicInteger предоставляет атомарный метод для выполнения таких комплексных операций атомарно, например getAndIncrement() - атомарная замена оператора инкремента, его можно использовать, чтобы атомарно увеличить текущее значение на один. Похожим образом сконструированы атомарные версии и для других типов данных.

--------------------------------------------------------------------------------------------------------------------
В чём заключаются различия между java.util.concurrent.Atomic*.compareAndSwap() и java.util.concurrent.Atomic*.weakCompareAndSwap()

weakCompareAndSwap() не создает memory barrier и не дает гарантии happens-before;
weakCompareAndSwap() сильно зависит от кэша/CPU, и может возвращать false без видимых причин;
weakCompareAndSwap(), более легкая, но поддерживаемая далеко не всеми архитектурами и не всегда эффективная операция.
--------------------------------------------------------------------------------------------------------------------
Что значит «приоритет потока»?

Приоритеты потоков используются планировщиком потоков для принятия решений о том, когда какому из потоков будет разрешено работать. Теоретически высокоприоритетные потоки получают больше времени процессора, чем низкоприоритетные. Практически объем времени процессора, который получает поток, часто зависит от нескольких факторов помимо его приоритета.
Чтобы установить приоритет потока, используется метод класса Thread: final void setPriority(int level). Значение level изменяется в пределах от Thread.MIN_PRIORITY = 1 до Thread.MAX_PRIORITY = 10. Приоритет по умолчанию - Thread.NORM_PRlORITY = 5.
Получить текущее значение приоритета потока можно вызвав метод: final int getPriority() у экземпляра класса Thread
--------------------------------------------------------------------------------------------------------------------
Что такое «потоки-демоны»?

Потоки-демоны работают в фоновом режиме вместе с программой, но не являются неотъемлемой частью программы. Если какой-либо процесс может выполняться на фоне работы основных потоков выполнения и его деятельность заключается в обслуживании основных потоков приложения, то такой процесс может быть запущен как поток-демон с помощью метода setDaemon(boolean value), вызванного у потока до его запуска. Метод boolean isDaemon() позволяет определить, является ли указанный поток демоном или нет. Базовое свойство потоков-демонов заключается в возможности основного потока приложения завершить выполнение потока-демона (в отличие от обычных потоков) с окончанием кода метода main(), не обращая внимания на то, что поток-демон еще работает.

--------------------------------------------------------------------------------------------------------------------
Можно ли сделать основной поток программы демоном?

Нет. Потоки-демоны позволяют описывать фоновые процессы, которые нужны только для обслуживания основных потоков выполнения и не могут существовать без них.

--------------------------------------------------------------------------------------------------------------------
Что значит «усыпить» поток?

Это значит приостановить его на определенный промежуток времени, вызвав в ходе его выполнения статический метод Thread.sleep() передав в качестве параметра необходимое количество времени в миллисекундах. До истечения этого времени поток может быть выведен из состояния ожидания вызовом interrupt() с выбрасыванием InterruptedException.

--------------------------------------------------------------------------------------------------------------------
Чем отличаются два интерфейса Runnable и Callable?

Интерфейс Runnable появился в Java 1.0, а интерфейс Callable был введен в Java 5.0 в составе библиотеки java.util.concurrent;
Классы, реализующие интерфейс Runnable для выполнения задачи должны реализовывать метод run(). Классы, реализующие интерфейс Callable - метод call();
Метод Runnable.run() не возвращает никакого значения, Callable.call() возвращает объект Future, который может содержать результат вычислений;
Метод run() не может выбрасывать проверяемые исключения, в то время как метод call() может.
--------------------------------------------------------------------------------------------------------------------
Что такое FutureTask?

FutureTask представляет собой отменяемое асинхронное вычисление в параллельном Java приложении. Этот класс предоставляет базовую реализацию Future, с методами для запуска и остановки вычисления, методами для запроса состояния вычисления и извлечения результатов. Результат может быть получен только когда вычисление завершено, метод получения будет заблокирован, если вычисление ещё не завершено. Объекты FutureTask могут быть использованы для обёртки объектов Callable и Runnable. Так как FutureTask реализует Runnable, его можно передать в Executor на выполнение.

--------------------------------------------------------------------------------------------------------------------
Как остановить поток?

На данный момент в Java принят уведомительный порядок остановки потока (хотя JDK 1.0 и имеет несколько управляющих выполнением потока методов, например stop(), suspend() и resume() - в следующих версиях JDK все они были помечены как deprecated из-за потенциальных угроз взаимной блокировки).
Для корректной остановки потока можно использовать метод класса Thread - interrupt(). Этот метод выставляет некоторый внутренний флаг-статус прерывания. В дальнейшем состояние этого флага можно проверить с помощью метода isInterrupted() или Thread.interrupted() (для текущего потока). Метод interrupt() также способен вывести поток из состояния ожидания или спячки. Т.е. если у потока были вызваны методы sleep() или wait() - текущее состояние прервется и будет выброшено исключение InterruptedException. Флаг в этом случае не выставляется.
Схема действия при этом получается следующей:
Реализовать поток.
В потоке периодически проводить проверку статуса прерывания через вызов isInterrupted().
Если состояние флага изменилось или было выброшено исключение во время ожидания/спячки, следовательно поток пытаются остановить извне.
Принять решение - продолжить работу (если по каким-то причинам остановиться невозможно) или освободить заблокированные потоком ресурсы и закончить выполнение.
Возможная проблема, которая присутствует в этом подходе - блокировки на потоковом вводе-выводе. Если поток заблокирован на чтении данных - вызов interrupt() из этого состояния его не выведет. Решения тут различаются в зависимости от типа источника данных. Если чтение идет из файла - долговременная блокировка крайне маловероятна и тогда можно просто дождаться выхода из метода read(). Если же чтение каким-то образом связано с сетью - стоит использовать неблокирующий ввод-вывод из Java NIO.
Второй вариант реализации метода остановки (а также и приостановки) - сделать собственный аналог interrupt(). Т.е. объявить в классе потока флаги - на остановку и/или приостановку и выставлять их путем вызова заранее определённых методов извне. Методика действия при этом остаётся прежней - проверять установку флагов и принимать решения при их изменении. Недостатки такого подхода. Во-первых, потоки в состоянии ожидания таким способом не «оживить». Во-вторых, выставление флага одним потоком совсем не означает, что второй поток тут же его увидит. Для увеличения производительности виртуальная машина использует кеш данных потока, в результате чего обновление переменной у второго потока может произойти через неопределенный промежуток времени (хотя допустимым решением будет объявить переменную-флаг как volatile).
--------------------------------------------------------------------------------------------------------------------
Почему не рекомендуется использовать метод Thread.stop()?

При принудительной остановке (приостановке) потока, stop() прерывает поток в недетерменированном месте выполнения, в результате становится совершенно непонятно, что делать с принадлежащими ему ресурсами. Поток может открыть сетевое соединение - что в таком случае делать с данными, которые еще не вычитаны? Где гарантия, что после дальнейшего запуска потока (в случае приостановки) он сможет их дочитать? Если поток блокировал разделяемый ресурс, то как снять эту блокировку и не переведёт ли принудительное снятие к нарушению консистентности системы? То же самое можно расширить и на случай соединения с базой данных: если поток остановят посередине транзакции, то кто ее будет закрывать? Кто и как будет разблокировать ресурсы?

--------------------------------------------------------------------------------------------------------------------
Что происходит, когда в потоке выбрасывается исключение?

Если исключение не поймано - поток «умирает» (переходит в состяние мёртв (dead)).
Если установлен обработчик непойманных исключений, то он возьмёт управление на себя. Thread.UncaughtExceptionHandler - интерфейс, определённый как вложенный интерфейс для других обработчиков, вызываемых, когда поток внезапно останавливается из-за непойманного исключения. В случае, если поток собирается остановиться из-за непойманного исключения, JVM проверяет его на наличие UncaughtExceptionHandler, используя Thread.getUncaughtExceptionHandler(), и если такой обработчик найдет, то вызовет у него метод uncaughtException(), передав этот поток и исключение в виде аргументов.
--------------------------------------------------------------------------------------------------------------------
В чем разница между interrupted() и isInterrupted()?

Механизм прерывания работы потока в Java реализован с использованием внутреннего флага, известного как статус прерывания. Прерывание потока вызовом Thread.interrupt() устанавливает этот флаг. Методы Thread.interrupted() и isInterrupted() позволяют проверить, является ли поток прерванным.
Когда прерванный поток проверяет статус прерывания, вызывая статический метод Thread.interrupted(), статус прерывания сбрасывается.
Нестатический метод isInterrupted() используется одним потоком для проверки статуса прерывания у другого потока, не изменяя флаг прерывания.
--------------------------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------------------------
В чем заключаются различия между cтеком (stack) и кучей (heap) с точки зрения многопоточности?

Cтек - участок памяти, тесно связанный с потоками. У каждого потока есть свой стек, которые хранит локальные переменные, параметры методов и стек вызовов. Переменная, хранящаяся в стеке одного потока, не видна для другого.
Куча - общий участок памяти, который делится между всеми потоками. Объекты, неважно локальные или любого другого уровня, создаются в куче. Для улучшения производительности, поток обычно кэширует значения из кучи в свой стек, в этом случае для того, чтобы указать потоку, что переменную следует читать из кучи используется ключевое слово volatile.
--------------------------------------------------------------------------------------------------------------------
Как поделиться данными между двумя потоками?

Данными между потоками возможно делиться, используя общий объект или параллельные структуры данных, например BlockingQueue.

--------------------------------------------------------------------------------------------------------------------
Какой параметр запуска JVM используется для контроля размера стека потока?

-Xss

--------------------------------------------------------------------------------------------------------------------
Как получить дамп потока?

Среды исполнения Java на основе HotSpot генерируют только дамп в формате HPROF. В распоряжении разработчика имеется несколько интерактивных методов генерации дампов и один метод генерации дампов на основе событий.
Интерактивные методы:

Использование Ctrl+Break: если для исполняющегося приложения установлена опция командной строки -XX:+HeapDumpOnCtrlBreak, то дамп формата HPROF генерируется вместе с дампом потока при наступлении события Ctrl+Break или SIGQUIT (обычно генерируется с помощью kill -3), которое инициируется посредством консоли. Эта опция может быть недоступна в некоторых версиях. В этом случае можно попытаться использовать следующую опцию: -Xrunhprof:format=b,file=heapdump.hprof

Использование инструмента jmap: утилита jmap, поставляемая в составе каталога /bin/ комплекта JDK, позволяет запрашивать дамп HPROF из исполняющегося процесса.

Использование операционной системы: Для создания файла ядра можно воспользоваться неразрушающей командой gcore или разрушающими командами kill -6 или kill -11. Затем извлечь дамп кучи из файла ядра с помощью утилиты jmap.

Использование инструмента JConsole. Операция dumpHeap предоставляется в JConsole как MBean-компонент HotSpotDiagnostic. Эта операция запрашивает генерацию дампа в формате HPROF.

Метод на основе событий:

Событие OutOfMemoryError: Если для исполняющегося приложения установлена опция командной строки -XX:+HeapDumpOnOutOfMemoryError, то при возникновении ошибки OutOfMemoryError генерируется дамп формата HPROF. Это идеальный метод для «production» систем, поскольку он практически обязателен для диагностирования проблем памяти и не сопровождается постоянными накладными расходами с точки зрения производительности. В старых выпусках сред исполнения Java на базе HotSpot для этого события не устанавливается предельное количество дампов кучи в пересчете на одну JVM; в более новых выпусках допускается не более одного дампа кучи для этого события на каждый запуск JVM.

--------------------------------------------------------------------------------------------------------------------
Что такое ThreadLocal-переменная?

ThreadLocal - класс, позволяющий имея одну переменную, иметь различное её значение для каждого из потоков.
У каждого потока - т.е. экземпляра класса Thread - есть ассоциированная с ним таблица ThreadLocal-переменных. Ключами таблицы являются cсылки на объекты класса ThreadLocal, а значениями - ссылки на объекты, «захваченные» ThreadLocal-переменными, т.е. ThreadLocal-переменные отличаются от обычных переменных тем, что у каждого потока свой собственный, индивидуально инициализируемый экземпляр переменной. Доступ к значению можно получить через методы get() или set().
Например, если мы объявим ThreadLocal-переменную: ThreadLocal<Object> locals = new ThreadLocal<Object>();. А затем, в потоке, сделаем locals.set(myObject), то ключом таблицы будет ссылка на объект locals, а значением - ссылка на объект myObject. При этом для другого потока существует возможность «положить» внутрь locals другое значение.
Следует обратить внимание, что ThreadLocal изолирует именно ссылки на объекты, а не сами объекты. Если изолированные внутри потоков ссылки ведут на один и тот же объект, то возможны коллизии.
Так же важно отметить, что т.к. ThreadLocal-переменные изолированы в потоках, то инициализация такой переменной должна происходить в том же потоке, в котором она будет использоваться. Ошибкой является инициализация такой переменной (вызов метода set()) в главном потоке приложения, потому как в данном случае значение, переданное в методе set(), будет «захвачено» для главного потока, и при вызове метода get() в целевом потоке будет возвращен null.
--------------------------------------------------------------------------------------------------------------------
Что такое «блокирующий метод»?

Блокирующий метод - метод, который блокируется, до тех пор, пока задание не выполнится, например метод accept() у ServerSocket блокируется в ожидании подключения клиента. Здесь блокирование означает, что контроль не вернётся к вызывающему методу до тех пор, пока не выполнится задание. Так же существуют асинхронные или неблокирующиеся методы, которые могут завершится до выполнения задачи.

--------------------------------------------------------------------------------------------------------------------
Что такое double checked locking Singleton?

double checked locking Singleton - это один из способов создания потокобезопасного класса реализующего шаблон Одиночка. Данный метод пытается оптимизировать производительность, блокируясь только случае, когда экземпляр одиночки создаётся впервые.

class DoubleCheckedLockingSingleton { private static volatile DoubleCheckedLockingSingleton instance; static DoubleCheckedLockingSingleton getInstance() { DoubleCheckedLockingSingleton current = instance; if (current == null) { synchronized (DoubleCheckedLockingSingleton.class) { current = instance; if (current == null) { instance = current = new DoubleCheckedLockingSingleton(); } } } return current; } }

Следует заметить, что требование volatile обязательно. Проблема Double Checked Lock заключается в модели памяти Java, точнее в порядке создания объектов, когда возможна ситуация, при которой другой поток может получить и начать использовать (на основании условия, что указатель не нулевой) не полностью сконструированный объект. Хотя эта проблема была частично решена в JDK 1.5, однако рекомендация использовать volatile для Double Cheсked Lock остаётся в силе.

--------------------------------------------------------------------------------------------------------------------
Как создать потокобезопасный Singleton?

Static field
public class Singleton { public static final Singleton INSTANCE = new Singleton(); }

Enum
public enum Singleton { INSTANCE; }

Synchronized Accessor
public class Singleton { private static Singleton instance; public static synchronized Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; } }

Double Checked Locking & volatile
public class Singleton { private static volatile

Singleton instance; public static Singleton getInstance() { Singleton localInstance = instance; if (localInstance == null) { synchronized (Singleton.class) { localInstance = instance; if (localInstance == null) { instance = localInstance = new Singleton(); } } } return localInstance; } }

On Demand Holder Idiom
public class Singleton { public static class SingletonHolder { public static final Singleton HOLDER_INSTANCE = new Singleton(); } public static Singleton getInstance() { return SingletonHolder.HOLDER_INSTANCE; } }
--------------------------------------------------------------------------------------------------------------------
Чем полезны неизменяемые объекты?

Неизменяемость (immutability) помогает облегчить написание многопоточного кода. Неизменяемый объект может быть использован без какой-либо синхронизации. К сожалению, в Java нет аннотации @Immutable, которая делает объект неизменяемым, для этого разработчикам нужно самим создавать класс с необходимыми характеристиками. Для этого необходимо следовать некоторым общим принципам: инициализация всех полей только в конструкторе, отсутствие методов setX() вносящих изменения в поля класса, отсутствие утечек ссылки, организация отдельного хранилища копий изменяемых объектов и т.д.

--------------------------------------------------------------------------------------------------------------------
Что такое busy spin?

busy spin - это техника, которую программисты используют, чтобы заставить поток ожидать при определённом условии. В отличие от традиционных методов wait(), sleep() или yield(), которые подразумевают уступку процессорного времени, этот метод вместо уступки выполняет пустой цикл. Это необходимо, для того, чтобы сохранить кэш процессора, т.к. в многоядерных системах, существует вероятность, что приостановленный поток продолжит своё выполнение уже на другом ядре, а это повлечет за собой перестройку состояния процессорного кэша, которая является достаточно затратной процедурой.

--------------------------------------------------------------------------------------------------------------------
Перечислите принципы, которым вы следуете в многопоточном программировании?

При написании многопоточных программ следует придерживаться определённых правил, которые помогают обеспечить достойную производительность приложения в сочетании с удобной отладкой и простотой дальнейшей поддержки кода.

Всегда давайте значимые имена своим потокам. Процесс отладки, нахождения ошибок или отслеживание исключения в многопоточном коде - довольно сложная задача. OrderProcessor, QuoteProcessor или TradeProcessor намного информативнее, чем Thread1, Thread2 и Thread3. Имя должно отражать задачу, выполняемую данным потоком.

Избегайте блокировок или старайтесь уменьшить масштабы синхронизации. Блокировка затратна, а переключение контекста ещё более ресурсоёмко. Пытайтесь избегать синхронизации и блокировки насколько это возможно, и организуйте критическую секцию в минимально необходимом объёме. Поэтому синхронизированный блок всегда предпочительней синхронизированного метода, дополнительно наделяя возможностью абсолютного контроля над масштабом блокировки.

Обрабатывайте прерывание потока с особой тщательностью. Нет ничего хуже оставшегося заблокированным ресурса или системы в неконстистентном, по причине неподтверждённой транзакции, состоянии.

Помните об обработке исключений. Выброшенные InterruptedException должны быть адекватно обработаны, а не просто подавлены. Так же не стоит пренебрегать Thread.UncaughtExceptionHandler. При использовании пула потоков необходимо помнить, что он зачастую просто «проглатывает» исключения. Так, если вы отправили на выполнение Runnable нужно обязательно поместить код выполнения задачи внутрь блока try-catch. Если в очередь пула помещается Callable, необходимо удостоверится, что результат выполнения всегда изымается помощью блокирующего get(), чтобы в случае возникновения существовала возможнотсь заново выбросить произошедшее исключение.

Между синхронизаторами и wait() и notify() следует выбирать синхронизаторы. Во-первых, синхронизаторы, типа CountDownLatch, Semaphore, CyclicBarrier или Exchanger упрощают написание кода. Очень сложно реализовывать комплексный управляющий поток, используя wait() и notify(). Во-вторых, эти классы написаны и поддерживаются настоящими мастерами своего дела и есть шанс, что в последующих версиях JDK они будут оптимизированы изнутри или заменены более производительной внешней реализацией.

Почти всегда использование Concurrent сollection выгоднее использования Synchronized сollection, т.к. первые более современны (используют все доступные на момент их написания новшества языка) и масштабируемы, чем их синхронизированые аналоги.

--------------------------------------------------------------------------------------------------------------------
Какое из следующих утверждений о потоках неверно?

1) Если метод start() вызывается дважды для одного и того же объекта Thread, во время выполнения генерируется исключение.

2) Порядок, в котором запускались потоки, может не совпадать с порядком их фактического выполнения.

3) Если метод run() вызывается напрямую для объекта Thread, во время выполнения генерируется исключение.

4) Если метод sleep() вызывается для потока, во время выполнения синхронизированного кода, блокировка не снимается.

Правильный ответ: 3. Если метод run() вызывается напрямую для объекта Thread, во время выполнения исключение не генерируется. Однако, код, написанный в методе run() будет выполняться текущим, а не новым потоком. Таким образом, правильный способ запустить поток - это вызов метода start(), который приводит к выполнению метода run() новым потоком.
Вызов метода start() дважды для одного и того же объекта Thread приведёт к генерированию исключения IllegalThreadStateException во время выполнения, следовательно, утверждение 1 верно. Утверждение 2 верно, так как порядок, в котором выполняются потоки, определяется Планировщиком потоков, независимо от того, какой поток запущен первым. Утверждение 4 верно, так как поток не освободит блокировки, которые он держит, когда он переходит в состояние Ожидания.
Что такое race condition?

Состояние гонки (race condition) - ошибка проектирования многопоточной системы или приложения, при которой эта работа напрямую зависит от того, в каком порядке выполняются потоки. Состояние гонки возникает, когда поток, который должен исполнится в начале, проиграл гонку и первым исполняется другой поток: поведение кода изменяется, из-за чего возникают недетерменированные ошибки.

--------------------------------------------------------------------------------------------------------------------
Существует ли способ решения проблемы race condition?

Существует ли способ решения проблемы race condition?

--------------------------------------------------------------------------------------------------------------------
С какими распространенными проблемами вы столкнулись в многопоточной среде?

Deadlock — два потока A и B, удерживайте lock_A и lock_B соответственно. Они оба хотят получить доступ к ресурсу R. Для безопасного доступа к R требуются и lock_A, и lock_B. Но поток A нуждается в lock_B, а поток B — в lock_A. Но оба они не готовы отказаться от замков, которые они держат. Следовательно, нет прогресса. Это тупик!

Условия гонки — Рассмотрим классический пример производителя-потребителя. Что если вы забудете заблокировать перед добавлением или удалением элемента из очереди? Представьте, что два потока A и B пытаются добавить элемент без блокировки. Поток A обращается к задней части очереди. Затем планировщик дает возможность запустить поток B, который успешно добавляет элемент и обновляет хвостовой указатель. Теперь указатель хвоста, прочитанный потоком A, устарел, но он думает, что это хвост, и добавляет элемент. Таким образом, пункт, добавленный B, потерян! Структура данных повреждена! Хуже того, это может также привести к утечке памяти во время очистки.

Гонка данных — представьте переменную флага, которую следует установить. Предположим, что вы установили замки, чтобы избежать условий гонки. Теперь разные потоки хотят устанавливать разные значения. Поскольку планировщик может планировать выполнение потока любым способом, вы не знаете, каково значение флага в конце.

Голодание — это проблема, вызванная
планировщиком потоков. Некоторые потоки не имеют возможности запустить и завершить или не могут получить требуемые блокировки, потому что другим потокам предоставляется более высокий приоритет. Они «жаждут» циклов ЦП или других ресурсов.
Инверсия приоритетов. Представьте себе два потока A и B. A имеет более высокий приоритет, чем B, и, следовательно, получает больше циклов ЦП, чем B. Но при доступе к общему ресурсу B удерживает блокировку, которая также требуется для A, и возвращает. Теперь A не может ничего сделать без блокировки, и много циклов ЦП тратится впустую, потому что B не получает достаточно циклов, но имеет блокировку.
--------------------------------------------------------------------------------------------------------------------
Разница между зеленым потоком и собственным потоком в Java?

Зеленые потоки относятся к модели, в которой сама виртуальная машина Java создает, управляет и переключает контекст всех потоков Java в рамках одного процесса операционной системы. Библиотека потоков операционной системы не используется.

Под собственными потоками понимается объект, в котором виртуальная машина Java создает потоки Java и управляет ими с помощью библиотеки потоков операционной системы — с именем libthread в UnixWare — и каждый поток Java отображается в один поток библиотеки потоков.

--------------------------------------------------------------------------------------------------------------------
Можно ли улучшить производительность приложения, используя многопоточность? Назовите несколько примеров.

Если у нас имеется более одного доступного ядра ЦП, производительность приложения можно повысить с помощью многопоточности, если возможно распараллелить вычисления на доступных ядрах ЦП. Примером может служить приложение, которое должно масштабировать все изображения, хранящиеся в структуре локального каталога. Вместо того, чтобы перебирать все изображения одно за другим, реализация производителя / потребителя может использовать один поток для сканирования структуры каталогов и группу рабочих потоков, которые выполняют фактическую операцию масштабирования. Другим примером может быть приложение, которое отображает некоторую веб-страницу. Вместо загрузки одной HTML-страницы за другой поток производителя может проанализировать первую HTML-страницу и выдать найденные ссылки в очередь. Рабочие потоки отслеживают очередь и загружают веб-страницы, найденные анализатором. Пока рабочие потоки ждут полной загрузки страницы, другие потоки могут использовать ЦП для анализа уже загруженных страниц и выдачи новых запросов.

--------------------------------------------------------------------------------------------------------------------
Приведите пример, почему улучшения производительности для однопоточных приложений могут привести к снижению производительности многопоточных приложений.

Ярким примером такой оптимизации является реализация List , в которой количество элементов хранится в виде отдельной переменной. Это повышает производительность для однопоточных приложений, поскольку операция size() не должна повторяться по всем элементам, но может возвращать текущее количество элементов напрямую. В многопоточном приложении дополнительный счетчик должен защищаться блокировкой, поскольку несколько параллельных потоков могут вставлять элементы в список. Эта дополнительная блокировка может стоить производительности, когда в списке больше обновлений, чем вызовов операции size() .

--------------------------------------------------------------------------------------------------------------------
Может ли конструктор быть синхронизирован?

Нет, конструктор не может быть синхронизирован. Причина, по которой это приводит к синтаксической ошибке, заключается в том, что только конструирующий поток должен иметь доступ к создаваемому объекту.

--------------------------------------------------------------------------------------------------------------------
Если два потока одновременно вызывают синхронизированный метод для разных экземпляров объекта, может ли один из этих потоков блокировать?

Оба метода блокируют один и тот же монитор. Следовательно, вы не можете одновременно выполнять их на одном и том же объекте из разных потоков (один из двух методов будет блокироваться, пока другой не будет завершен).

--------------------------------------------------------------------------------------------------------------------
Future vs CompletableFuture - концепция и отличия

Future - интерфейс, который представляет пока еще недовычисленный результат. Когда породившая его асинхронная операция заканчивается, он заполняется значением. Метод get блокирует выполнение до получения результата, isDone проверяет его наличие. К примеру результат выполнения задач в ExecutorService, ForkJoinTask, реализует интерфейс Future.

CompletableFuture появился в Java 8. Это класс-реализация старого интерфейса Future, а значит всё сказанное выше справедливо и для него. Вдобавок к этому, CompletableFuture реализует работу с отложенными результатами посредством коллбэков. Метод thenApply регистрирует код обработки значения, который будет автоматически вызван позже, когда это значение появится.
CompletableFutures были введены в Java 8 (2014). На самом деле они представляют собой эволюцию обычных Futures, вдохновленных Google Listenable Futures , частью библиотеки Guava . Это фьючерсы, которые также позволяют вам связывать задачи в цепочку. Вы можете использовать их, чтобы сказать некоторому рабочему потоку «иди и выполни задачу X, а когда закончишь, иди делай другую вещь, используя результат X». Используя CompletableFutures, вы можете что-то сделать с результатом операции, фактически не блокируя поток для ожидания результата.
--------------------------------------------------------------------------------------------------------------------
Какие Синхронизаторы есть в java?

| Название         | Описание                                                                 |
|------------------|--------------------------------------------------------------------------|
| **Semaphore**    | Объект синхронизации, ограничивающий количество потоков, которые могут «войти» в заданный участок кода. |
| **CountDownLatch** | Объект синхронизации, разрешающий вход в заданный участок кода при выполнении определенных условий. |
| **CyclicBarrier** | Объект синхронизации типа «барьер», блокирующий выполнение определенного кода для заданного количества потоков. |
| **Exchanger**    | Объект синхронизации, позволяющий провести обмен данными между двумя потоками. |
| **Phaser**       | Объект синхронизации типа «барьер», но в отличие от `CyclicBarrier`, предоставляет больше гибкости. |
-------------------------------------------------------------------------------------------------------------------
Объект синхронизации Semaphore?

**Semaphore** в Java — это синхронизационный механизм из пакета `java.util.concurrent`, используемый для управления доступом к ограниченному набору ресурсов в многопоточной среде. Он реализует классическую концепцию семафора, предложенную Эдсгером Дейкстрой, и позволяет контролировать количество потоков, которые одновременно могут получить доступ к ресурсу.

![Alt Text](img/Semaphore.gif)

`Semaphore` управляет доступом к ресурсам с помощью счётчика разрешений (permits). Основные характеристики:
- **Счётчик разрешений**: Указывает, сколько потоков могут одновременно получить доступ к ресурсу.
- **Приобретение (acquire)**: Поток запрашивает разрешение; если разрешений нет, поток блокируется до их появления.
- **Освобождение (release)**: Поток возвращает разрешение, позволяя другим потокам получить доступ.
- **Гибкость**: Поддерживает как справедливую (fair), так и несправедливую (non-fair) политику выдачи разрешений.

`Semaphore` часто используется для:
- Ограничения числа одновременно выполняющихся задач (например, ограничение числа соединений к базе данных).
- Реализации пула ресурсов.
- Координации потоков (например, в сценариях producer-consumer).

`Semaphore` в Java реализован в классе `java.util.concurrent.Semaphore` и основан на механизме **AbstractQueuedSynchronizer** (AQS) — фундаментальном классе для синхронизации в `java.util.concurrent`. AQS предоставляет очередь блокировки и управление состоянием, которые используются `Semaphore` для реализации счётчика разрешений.

#### **Ключевые компоненты**
1. **AbstractQueuedSynchronizer (AQS)**:
  - `Semaphore` использует внутренний класс `Sync`, который наследуется от `AQS`.
  - AQS хранит состояние (`state`) — это счётчик разрешений (`permits`).
  - AQS управляет очередью потоков, ожидающих разрешения, и обеспечивает блокировку/разблокировку.

2. **Два режима работы**:
  - **Fair (справедливый)**: Потоки получают разрешения в порядке их запроса (FIFO). Реализуется через `FairSync`.
  - **Non-fair (несправедливый)**: Потоки могут конкурировать за разрешения без строгого порядка (более эффективно, но может привести к "голоданию" некоторых потоков). Реализуется через `NonfairSync`.

3. **Счётчик разрешений**:
  - Состояние (`state`) в AQS интерпретируется как количество доступных разрешений.
  - При вызове `acquire()` счётчик уменьшается, при `release()` — увеличивается.

4. **Очередь ожидания**:
  - Если разрешений нет, поток помещается в очередь AQS (на основе `CLH lock queue` — очередь блокировки Крейга, Лэндиса и Хагерстена).
  - Потоки в очереди блокируются с помощью `LockSupport.park()` и разблокируются через `LockSupport.unpark()`.

#### **Ключевые методы**
- **`acquire(int permits)`**: Запрашивает указанное количество разрешений. Если их недостаточно, поток блокируется.
- **`release(int permits)`**: Освобождает указанное количество разрешений, позволяя другим потокам продолжить.
- **`tryAcquire(int permits, long timeout, TimeUnit unit)`**: Пытается получить разрешения с таймаутом.
- **`availablePermits()`**: Возвращает текущее число доступных разрешений.
- **`drainPermits()`**: Забирает все доступные разрешения, возвращая их количество.

#### **Механизм работы**
1. **Инициализация**:
  - Создаётся экземпляр `Sync` (`FairSync` или `NonfairSync`), унаследованный от `AQS`.
  - Состояние (`state`) устанавливается равным `permits`.

2. **Приобретение разрешений (`acquire`)**:
  - Поток вызывает `acquire(int permits)`, который передаётся в `Sync`.
  - `Sync` вызывает метод AQS `tryAcquireShared(int permits)`:
    - В **несправедливом режиме** (`NonfairSync`): Проверяется, можно ли уменьшить `state` на `permits` с помощью CAS (Compare-And-Set). Если успешно, `state` уменьшается, и поток продолжает выполнение.
    - В **справедливом режиме** (`FairSync`): Проверяется очередь ожидания. Если очередь пуста или поток находится в её начале, выполняется CAS. Иначе поток добавляется в очередь.
  - Если разрешений недостаточно, поток блокируется и помещается в очередь AQS.

3. **Освобождение разрешений (`release`)**:
  - Поток вызывает `release(int permits)`, который передаётся в `Sync`.
  - `Sync` вызывает метод AQS `tryReleaseShared(int permits)`:
    - Увеличивает `state` на `permits` с помощью CAS.
    - Если есть потоки в очереди, AQS разблокирует один или несколько потоков (через `LockSupport.unpark()`), чтобы они могли попытаться получить разрешения.

4. **Очередь ожидания**:
  - AQS использует CLH-очередь, где каждый узел (`Node`) представляет поток.
  - Узлы имеют состояние `SHARED` (для семафора), что позволяет обрабатывать несколько потоков одновременно, если хватает разрешений.
  - При освобождении разрешений AQS проверяет голову очереди и разблокирует потоки, если их запросы могут быть удовлетворены.

5. **Справедливость**:
  - В **справедливом режиме** (`FairSync`) потоки получают разрешения строго в порядке очереди.
  - В **несправедливом режиме** (`NonfairSync`) новый поток может "обойти" очередь, если разрешения доступны, что повышает производительность, но может привести к "голоданию" некоторых потоков.

--------------------------------------------------------------------------------------------------------------------
Объект синхронизации CountDownLatch

**CountDownLatch** в Java — это синхронизационный механизм из пакета `java.util.concurrent`, предназначенный для координации работы нескольких потоков. Он позволяет одному или нескольким потокам ожидать завершения определённого количества событий (или операций), прежде чем продолжить выполнение. `CountDownLatch` основан на концепции "защёлки" (latch), которая открывается, когда счётчик событий достигает нуля.


![Alt Text](img/CountDownLatch.gif)

### **Что такое CountDownLatch?**

`CountDownLatch` — это синхронизационный примитив, который:
- Инициализируется с заданным количеством событий (счётчиком).
- Позволяет потокам **ожидать** (`await`), пока счётчик не станет равным нулю.
- Уменьшает счётчик с помощью метода `countDown()`, вызываемого при завершении каждого события.
- "Открывает защёлку", когда счётчик достигает нуля, позволяя ожидающим потокам продолжить выполнение.

**Основные сценарии использования**:
- Ожидание завершения нескольких задач перед продолжением (например, инициализация системы).
- Координация старта нескольких потоков (например, запуск теста одновременно).
- Синхронизация в стиле "все или ничего" (все потоки должны завершить работу, прежде чем главный поток продолжит).


### 2. **Внутренняя реализация CountDownLatch**

`CountDownLatch` реализован в классе `java.util.concurrent.CountDownLatch` и основан на **AbstractQueuedSynchronizer** (AQS) — базовом классе для синхронизации в `java.util.concurrent`. AQS обеспечивает управление состоянием и очередью блокировки, которые `CountDownLatch` использует для отслеживания счётчика событий и координации потоков.

#### **Ключевые компоненты**
1. **AbstractQueuedSynchronizer (AQS)**:
  - `CountDownLatch` содержит внутренний класс `Sync`, унаследованный от `AQS`.
  - Состояние AQS (`state`) интерпретируется как текущее значение счётчика (`count`).
  - AQS управляет очередью потоков, ожидающих открытия защёлки (когда `state` становится равным 0).

2. **Счётчик**:
  - Счётчик (`state`) инициализируется заданным значением (`count`) при создании объекта.
  - Уменьшается атомарно с помощью метода `countDown()`.
  - Когда счётчик достигает нуля, защёлка "открывается", и все ожидающие потоки разблокируются.

3. **Очередь ожидания**:
  - Если поток вызывает `await()`, а счётчик не равен нулю, поток помещается в очередь AQS (CLH-очередь — очередь блокировки Крейга, Лэндиса и Хагерстена).
  - Потоки блокируются с помощью `LockSupport.park()` и разблокируются через `LockSupport.unpark()`.

4. **Одноразовость**:
  - `CountDownLatch` является одноразовым механизмом: после того как счётчик достигает нуля, защёлка остаётся открытой, и её нельзя переиспользовать.

#### **Ключевые методы**
- **`await()`**: Блокирует вызывающий поток, пока счётчик не станет равным нулю.
- **`await(long timeout, TimeUnit unit)`**: Ожидает с таймаутом; возвращает `true`, если счётчик достиг нуля, или `false`, если время ожидания истекло.
- **`countDown()`**: Уменьшает счётчик на 1. Если счётчик становится равным 0, все ожидающие потоки разблокируются.
- **`getCount()`**: Возвращает текущее значение счётчика.

### **Как работает CountDownLatch внутри?**

#### **Инициализация**
- При создании `CountDownLatch` с параметром `count` создаётся внутренний объект `Sync`, унаследованный от `AQS`.
- Состояние AQS (`state`) устанавливается равным `count`.

#### **Ожидание (`await`)**
- Поток вызывает `await()`, который передаётся в `Sync`.
- `Sync` вызывает метод AQS `acquireSharedInterruptibly(int arg)`:
  - Проверяется, равно ли состояние (`state`) нулю.
  - Если `state == 0`, защёлка открыта, и поток продолжает выполнение.
  - Если `state > 0`, поток добавляется в очередь AQS и блокируется с помощью `LockSupport.park()`.

#### **Уменьшение счётчика (`countDown`)**
- Поток вызывает `countDown()`, который передаётся в `Sync`.
- `Sync` вызывает метод AQS `tryReleaseShared(int releases)`:
  - Уменьшает `state` на 1 с помощью атомарной операции CAS (Compare-And-Set).
  - Если `state` становится равным 0, защёлка открывается, и AQS разблокирует все потоки в очереди с помощью `LockSupport.unpark()`.
  - Если `state > 0`, потоки в очереди продолжают ждать.

#### **Очередь ожидания**
- AQS использует CLH-очередь, где каждый узел (`Node`) представляет поток в режиме `SHARED`.
- Режим `SHARED` позволяет одновременно разблокировать все ожидающие потоки, когда счётчик достигает нуля.
- Очередь растёт, если много потоков вызывают `await()` до открытия защёлки.

#### **Атомарность**
- Все операции с счётчиком (`state`) выполняются атомарно через CAS, что обеспечивает потокобезопасность без необходимости явных блокировок.
- Например, метод `countDown()` использует `compareAndSetState` для уменьшения счётчика.

#### **Одноразовость**
- После того как счётчик достигает нуля, защёлка остаётся открытой навсегда.
- Последующие вызовы `countDown()` не изменяют состояние, а вызовы `await()` завершаются немедленно.

--------------------------------------------------------------------------------------------------------------------
Объект синхронизации CyclicBarrier

**CyclicBarrier** в Java — это синхронизационный механизм из пакета `java.util.concurrent`, предназначенный для координации работы нескольких потоков, которые должны дождаться друг друга в определённой точке (барьере), прежде чем продолжить выполнение. В отличие от `CountDownLatch`, который является одноразовым, `CyclicBarrier` многоразовый, что делает его подходящим для сценариев с повторяющимися этапами синхронизации.

![Alt Text](img/CyclicBarrier.gif)

`CyclicBarrier` позволяет заданному числу потоков (участников) синхронизироваться в точке барьера. Каждый поток, достигая барьера, вызывает метод `await()` и блокируется, пока все участники не достигнут барьера. После этого барьер "открывается", все потоки разблокируются, и может быть выполнен опциональный действие барьера (`barrierAction`). Поскольку барьер многоразовый, он сбрасывается и может быть использован снова для следующего цикла.

**Основные характеристики**:
- **Число участников**: Задаётся при создании барьера (`parties`) и определяет, сколько потоков должны достичь барьера для его открытия.
- **Многоразовость**: После открытия барьер сбрасывается и готов к следующему использованию.
- **Опциональное действие**: Можно указать `Runnable`, выполняемый при открытии барьера.
- **Обработка исключений**: Поддерживает механизмы для обработки сбоев (например, прерывания или таймаута).

**Сценарии использования**:
- Параллельные вычисления с несколькими фазами (например, итеративные алгоритмы).
- Тестирование, где несколько потоков должны стартовать одновременно.
- Моделирование процессов, где этапы выполнения требуют синхронизации всех участников.

### **Внутренняя реализация CyclicBarrier**

`CyclicBarrier` реализован в классе `java.util.concurrent.CyclicBarrier` и использует внутренний механизм на основе блокировки (`ReentrantLock`) и условия (`Condition`) из пакета `java.util.concurrent.locks`. В отличие от `CountDownLatch`, который опирается на `AbstractQueuedSynchronizer` (AQS), `CyclicBarrier` использует более простую модель синхронизации, основанную на явных блокировках.

#### **Ключевые компоненты**

1. **Поля класса**:
  - **`parties`**: Количество потоков, которые должны достичь барьера для его открытия.
  - **`count`**: Текущее количество потоков, ожидающих на барьере (уменьшается с каждым вызовом `await()`).
  - **`barrierAction`**: Опциональный объект `Runnable`, выполняемый при открытии барьера.
  - **`lock`**: Экземпляр `ReentrantLock`, используемый для синхронизации доступа к внутреннему состоянию.
  - **`trip`**: Объект `Condition`, связанный с `lock`, для управления ожиданием потоков.
  - **`generation`**: Внутренний объект `Generation`, отслеживающий текущий цикл барьера (для поддержки многоразовости).
  - **`broken`**: Флаг, указывающий, что барьер "сломан" (например, из-за прерывания или таймаута).

2. **Generation**:
  - Внутренний класс, представляющий текущий цикл барьера.
  - При каждом открытии барьера создаётся новый объект `Generation`, чтобы сбросить состояние.
  - Позволяет `CyclicBarrier` быть многоразовым.

3. **ReentrantLock и Condition**:
  - `ReentrantLock` обеспечивает потокобезопасный доступ к полям `count`, `broken` и другим.
  - `Condition trip` используется для блокировки потоков (`await()`) и их разблокировки (`signalAll()`), когда барьер открывается.

#### **Конструкторы**
```java
CyclicBarrier(int parties)
CyclicBarrier(int parties, Runnable barrierAction)
```
- `parties`: Количество потоков, которые должны достичь барьера.
- `barrierAction`: Опциональное действие, выполняемое при открытии барьера (в последнем потоке, достигшем барьера).

#### **Ключевые методы**
- **`await()`**: Блокирует поток, пока все `parties` потоков не вызовут `await()`. Возвращает индекс прибытия потока (от 0 до `parties-1`).
- **`await(long timeout, TimeUnit unit)`**: Ожидает с таймаутом; выбрасывает `TimeoutException`, если время ожидания истекло.
- **`reset()`**: Сбрасывает барьер в исходное состояние, ломая текущий цикл и создавая новый.
- **`isBroken()`**: Проверяет, сломан ли барьер (например, из-за прерывания или таймаута).
- **`getNumberWaiting()`**: Возвращает текущее число потоков, ожидающих на барьере.
- **`getParties()`**: Возвращает общее число участников барьера.


### **Как работает CyclicBarrier внутри?**

#### **Инициализация**
- При создании `CyclicBarrier` задаётся `parties` (число участников) и, опционально, `barrierAction`.
- Создаётся `ReentrantLock` и `Condition trip`.
- Поле `count` инициализируется значением `parties`.
- Создаётся объект `Generation` для отслеживания текущего цикла.

####  **Ожидание на барьере (`await`)**
1. Поток вызывает `await()`, который:
  - Захватывает `lock` для потокобезопасного доступа.
  - Проверяет, не сломан ли барьер (`broken == true`). Если сломан, выбрасывается `BrokenBarrierException`.
  - Уменьшает `count` на 1.
2. Если `count > 0`:
  - Поток вызывает `trip.await()` (или `trip.awaitNanos()` для версии с таймаутом), блокируясь через `LockSupport.park()`.
  - Поток добавляется в очередь условия (`Condition`).
3. Если `count == 0`:
  - Последний поток (достигший барьера) выполняет `barrierAction` (если задан).
  - Вызывается `trip.signalAll()`, разблокируя все потоки в очереди условия через `LockSupport.unpark()`.
  - Сбрасывается состояние: `count` возвращается к `parties`, создаётся новый объект `Generation`.
  - Освобождается `lock`.

#### **Сброс барьера (`reset`)**
- Захватывает `lock`.
- Устанавливает флаг `broken = true` для текущего цикла.
- Вызывает `trip.signalAll()`, чтобы разблокировать все ожидающие потоки (они получат `BrokenBarrierException`).
- Создаёт новый объект `Generation` и сбрасывает `count` на `parties`.

#### **Обработка сбоев**
- Если поток прерывается во время `await()`, барьер становится "сломанным" (`broken = true`), и все ожидающие потоки получают `BrokenBarrierException`.
- Если таймаут истекает в `await(long timeout, TimeUnit unit)`, поток также вызывает "ломку" барьера.
- Сломанный барьер можно сбросить с помощью `reset()`.

#### **Потокобезопасность**
- Все операции (`await`, `reset`, `getNumberWaiting`) защищены `ReentrantLock`, что обеспечивает атомарность и отсутствие гонок данных.
- `Condition trip` позволяет эффективно управлять ожиданием и уведомлением потоков.

--------------------------------------------------------------------------------------------------------------------
Объект синхронизации Exchanger

**Exchanger** в Java — это синхронизационный механизм из пакета `java.util.concurrent`, предназначенный для обмена данными между двумя потоками в определённой точке синхронизации. Он позволяет двум потокам встретиться и обменяться объектами, блокируя каждый поток, пока другой не достигнет точки обмена. `Exchanger` особенно полезен в сценариях, где два потока выполняют парное взаимодействие, например, в паттернах producer-consumer или при реализации алгоритмов, требующих обмена данными между парами потоков. 

![Alt Text](img/Exchanger.gif)

### **Что такое Exchanger?**

`Exchanger` предоставляет точку синхронизации, где два потока могут обменяться объектами. Каждый поток вызывает метод `exchange()` и передаёт свой объект, затем блокируется, пока второй поток не вызовет `exchange()` и не предоставит свой объект. После этого потоки обмениваются данными и продолжают выполнение.

**Основные характеристики**:
- **Парный обмен**: Работает только с двумя потоками одновременно.
- **Блокировка**: Поток, вызвавший `exchange()`, ждёт, пока второй поток не достигнет точки обмена.
- **Многоразовость**: `Exchanger` можно использовать многократно для повторных обменов.
- **Обработка исключений**: Поддерживает прерывания и таймауты.

**Сценарии использования**:
- Обмен данными между двумя потоками (например, буферами в паттерне producer-consumer).
- Алгоритмы, такие как генетические алгоритмы или сортировка, где потоки обмениваются промежуточными результатами.
- Тестирование, где два потока должны синхронизировать свои действия.

### **Внутренняя реализация Exchanger**

`Exchanger` реализован в классе `java.util.concurrent.Exchanger`. В отличие от других механизмов синхронизации, таких как `CountDownLatch` или `CyclicBarrier`, которые используют `AbstractQueuedSynchronizer` (AQS) или `ReentrantLock`, `Exchanger` имеет собственную специализированную реализацию, оптимизированную для парного обмена. Он использует атомарные операции (CAS) и сложную структуру на основе арены для управления обменом.

#### **Ключевые компоненты**

1. **Node**:
  - Внутренний класс, представляющий узел, связанный с потоком, который ожидает обмена.
  - Содержит:
    - `item`: Объект, который поток предлагает для обмена.
    - `match`: Ссылка на объект, полученный от другого потока.
    - `parked`: Ссылка на поток, который заблокирован в ожидании (`Thread`).
    - `hole`: Атомарная ссылка (`AtomicReference`) для управления состоянием узла.

2. **Arena**:
  - Массив (`arena`) из атомарных ссылок (`AtomicReference`), используемый для предотвращения конфликтов при конкурентном доступе.
  - Введён в Java 9 для повышения производительности на многоядерных системах, где конкуренция за одну точку обмена может вызывать узкие места.
  - Каждый элемент массива представляет "слот" для обмена, и потоки распределяются по слотам для минимизации конфликтов.

3. **AtomicReference и CAS**:
  - `Exchanger` использует `AtomicReference` для атомарного обновления состояния (например, для установки узлов или обмена данными).
  - CAS-операции (`compareAndSet`) обеспечивают потокобезопасность без явных блокировок.

4. **spinCount и bound**:
  - `spinCount`: Количество итераций спин-блокировки (активного ожидания) перед использованием блокировки (`LockSupport.park()`).
  - `bound`: Параметр для управления размером `arena`, связанный с количеством процессоров (`Runtime.getRuntime().availableProcessors()`).

5. **arenaBuffer**:
  - Специальный объект-заглушка, используемый для инициализации и очистки слотов в `arena`.

#### **Ключевые методы**
- **`exchange(V x)`**: Вызывается потоком для обмена объектом `x`. Блокирует поток, пока второй поток не вызовет `exchange()`. Возвращает объект, полученный от второго потока.
- **`exchange(V x, long timeout, TimeUnit unit)`**: То же, что и `exchange(V x)`, но с таймаутом. Выбрасывает `TimeoutException`, если второй поток не достиг точки обмена в указанное время.
- **Исключения**:
  - `InterruptedException`: Если поток прерывается во время ожидания.
  - `TimeoutException`: Если истекает таймаут в версии с ограничением времени.

### **Как работает Exchanger внутри?**

#### **Инициализация**
- При создании `Exchanger` инициализируются:
  - Поле `arena` (изначально `null`, создаётся при первом вызове `exchange()`).
  - `spinCount` и `bound`, зависящие от числа процессоров.
- Поле `participant` (типа `ThreadLocal<Node>`) используется для хранения узла, связанного с текущим потоком.

#### **Процесс обмена (`exchange`)**
1. **Первый поток**:
  - Поток вызывает `exchange(V x)` и создаёт узел `Node` с объектом `x` (данные для обмена).
  - Проверяет, инициализирован ли массив `arena`:
    - Если `arena == null`, поток пытается занять слот через поле `slot` (устаревший механизм до Java 9).
    - Если `arena` существует, поток выбирает слот на основе хэша потока (`System.identityHashCode(Thread.currentThread())`).
  - Устанавливает свой узел в слот через CAS (`AtomicReference.compareAndSet`).
  - Если слот пуст, поток:
    - Выполняет спин-блокировку (активное ожидание) до `spinCount` итераций.
    - Если второй поток не появляется, блокируется через `LockSupport.park()`.

2. **Второй поток**:
  - Второй поток вызывает `exchange(V x)` и находит слот с узлом первого потока.
  - Устанавливает свой объект `match` в узел первого потока через CAS.
  - Разблокирует первый поток через `LockSupport.unpark()`.
  - Получает объект первого потока и возвращает его.

3. **Обмен завершён**:
  - Каждый поток получает объект другого потока.
  - Слот очищается (устанавливается в `arenaBuffer` или `null`).
  - Потоки продолжают выполнение.

4. **Arena-механизм**:
  - Массив `arena` позволяет распределять потоки по разным слотам, снижая конкуренцию на многоядерных системах.
  - Каждый поток вычисляет индекс слота с помощью хэша и проверяет слоты циклически, чтобы найти партнёра для обмена.
  - Если слот занят, поток пробует другой слот или блокируется.

#### **Обработка таймаута (`exchange(V x, long timeout, TimeUnit unit)`)**
- Поток ожидает с ограничением времени (`LockSupport.parkNanos()`).
- Если таймаут истекает, поток удаляет свой узел из слота и выбрасывает `TimeoutException`.
- Если второй поток появляется до истечения таймаута, обмен происходит как обычно.

#### **Обработка прерываний**
- Если поток прерывается во время ожидания (`LockSupport.park()`), выбрасывается `InterruptedException`.
- Поток очищает свой узел из слота, чтобы избежать утечек.

#### **Потокобезопасность**
- Все операции с узлами и слотами выполняются через CAS, что обеспечивает атомарность и отсутствие явных блокировок.
- `arena` минимизирует конкуренцию, распределяя потоки по разным слотам.

--------------------------------------------------------------------------------------------------------------------
Объект синхронизации Phaser

**Phaser** в Java — это мощный и гибкий синхронизационный механизм из пакета `java.util.concurrent`, предназначенный для координации работы нескольких потоков в многофазных задачах. Он является более продвинутой альтернативой `CyclicBarrier` и `CountDownLatch`, поддерживая динамическое изменение числа участников, многофазную синхронизацию и возможность завершения. `Phaser` особенно полезен в сценариях, где требуется синхронизация потоков на нескольких этапах, с возможностью добавления или удаления участников во время выполнения. В этой статье я подробно разберу, как устроен `Phaser` внутри, его ключевые компоненты, принцип работы и особенности реализации.

![Alt Text](img/Phaser.gif)

### **Что такое Phaser?**

`Phaser` позволяет синхронизировать потоки, работающие в фазах, где каждая фаза завершается, когда все зарегистрированные участники достигают точки синхронизации (барьера). После завершения фазы потоки могут продолжить выполнение следующей фазы, а `Phaser` может выполнять опциональное действие. В отличие от `CyclicBarrier`, `Phaser` поддерживает динамическое изменение числа участников и может быть завершён явно.

**Основные характеристики**:
- **Фазы**: Задачи делятся на этапы (фазы), и потоки синхронизируются в конце каждой фазы.
- **Динамическое число участников**: Потоки могут регистрироваться и сниматься с регистрации во время выполнения.
- **Многоразовость**: Поддерживает многократное использование для последовательных фаз.
- **Завершение**: `Phaser` может быть завершён, после чего дальнейшая синхронизация невозможна.
- **Гибкость**: Поддерживает иерархическую структуру (родительские и дочерние фазеры) для сложных сценариев.

**Сценарии использования**:
- Многофазные параллельные алгоритмы (например, итеративные вычисления, симуляции).
- Координация задач с переменным числом участников.
- Тестирование, где потоки должны синхронизироваться на каждом этапе.
- Управление сложными рабочими процессами с иерархической структурой.


###  **Внутренняя реализация Phaser**

`Phaser` реализован в классе `java.util.concurrent.Phaser` и основан на **AbstractQueuedSynchronizer** (AQS), который используется для управления состоянием и очередью ожидания. В отличие от `CyclicBarrier`, использующего `ReentrantLock`, `Phaser` применяет AQS для более эффективной синхронизации и поддержки сложных функций, таких как динамическое изменение участников.

#### **Ключевые компоненты**

1. **Состояние (state)**:
  - `Phaser` использует 64-битное поле `state` (тип `long`), которое хранит три значения:
    - **Число зарегистрированных участников** (`parties`): 16 бит, максимум 65 535 участников.
    - **Число необработанных участников** (`unarrived`): 16 бит, отслеживает, сколько участников ещё не достигли барьера.
    - **Номер фазы** (`phase`): 31 бит, максимум 2^31-1 фаз, после чего счётчик сбрасывается в 0.
  - Состояние обновляется атомарно через CAS (`compareAndSetLong`).

2. **Очереди AQS**:
  - `Phaser` использует две очереди AQS:
    - **EvenQ**: Для чётных фаз.
    - **OddQ**: Для нечётных фаз.
  - Это позволяет избежать конфликтов при переходе между фазами, так как потоки в одной фазе используют одну очередь, а в следующей — другую.
  - Очереди содержат узлы (`QNode`), представляющие потоки, ожидающие на барьере.

3. **Иерархия фазеров**:
  - `Phaser` поддерживает родительские и дочерние фазеры.
  - Каждый фазер имеет ссылку на родительский (`parent`) и корневой (`root`) фазер.
  - Дочерние фазеры синхронизируются с родительскими, что позволяет координировать сложные структуры.

4. **Завершение**:
  - Флаг завершения (`state` с отрицательным `phase`) указывает, что фазер завершён.
  - После завершения новые участники не могут регистрироваться, а вызовы `await` возвращаются немедленно.

#### **Конструкторы**
```java
Phaser() // Пустой фазер без участников
Phaser(int parties) // Фазер с заданным числом участников
Phaser(Phaser parent) // Дочерний фазер с родителем
Phaser(Phaser parent, int parties) // Дочерний фазер с числом участников
```

#### **Ключевые методы**
- **`register()`**: Регистрирует нового участника, увеличивая `parties` и `unarrived`.
- **`bulkRegister(int parties)`**: Регистрирует несколько участников сразу.
- **`arrive()`**: Отмечает прибытие участника без ожидания других. Уменьшает `unarrived`.
- **`arriveAndDeregister()`**: Отмечает прибытие и снимает участника с регистрации.
- **`arriveAndAwaitAdvance()`**: Отмечает прибытие и ждёт завершения фазы (аналог `CyclicBarrier.await()`).
- **`awaitAdvance(int phase)`**: Ждёт завершения указанной фазы, если она ещё не завершена.
- **`forceTermination()`**: Завершает фазер, делая его неактивным.
- **`getPhase()`**: Возвращает текущий номер фазы.
- **`isTerminated()`**: Проверяет, завершён ли фазер.

### **Как работает Phaser внутри?**

#### **Инициализация**
- При создании `Phaser` инициализируется:
  - Поле `state` с заданным числом участников (`parties`) и необработанных участников (`unarrived`).
  - Поле `phase = 0` (первая фаза).
  - Две очереди AQS (`evenQ` и `oddQ`) для чётных и нечётных фаз.
  - Если указан родительский фазер, он регистрируется как участник родителя.

#### **Регистрация участников**
- Вызов `register()` или `bulkRegister(int parties)`:
  - Атомарно увеличивает `parties` и `unarrived` в `state` через CAS.
  - Если фазер дочерний, обновляет состояние родительского фазера.

#### **Прибытие на барьер (`arrive`, `arriveAndAwaitAdvance`)**
1. **arrive()**:
  - Уменьшает `unarrived` в `state` через CAS.
  - Если `unarrived` становится 0, фазер переходит к следующей фазе:
    - Вызывается метод `onAdvance(int phase, int registeredParties)` (по умолчанию возвращает `true`, если `parties == 0`).
    - Если `onAdvance` возвращает `true`, фазер завершается.
    - Иначе сбрасывается `unarrived` на `parties`, и `phase` увеличивается.
  - Поток не блокируется.

2. **arriveAndAwaitAdvance()**:
  - Вызывает `arrive()` для уменьшения `unarrived`.
  - Проверяет текущую фазу и, если она не завершена, вызывает AQS `acquireSharedInterruptibly`:
    - Если `unarrived > 0`, поток добавляется в очередь (`evenQ` или `oddQ`) и блокируется через `LockSupport.park()`.
    - Если `unarrived == 0`, поток продолжает выполнение.
  - Когда фаза завершается, все потоки в очереди разблокируются через `LockSupport.unpark()`.

3. **arriveAndDeregister()**:
  - Уменьшает `unarrived` и `parties` через CAS.
  - Если `unarrived` становится 0, фазер переходит к следующей фазе или завершается.

#### **Переход между фазами**
- Когда `unarrived` достигает 0:
  - Вызывается `onAdvance(int phase, int registeredParties)` для проверки, завершать ли фазер.
  - Если фазер не завершён, `phase` увеличивается, `unarrived` сбрасывается на `parties`, и создаётся новый объект `Generation`.
  - Все потоки в очереди AQS (`evenQ` или `oddQ`) разблокируются.
- Если фазер дочерний, он уведомляет родительский фазер о завершении фазы.

#### **Завершение**
- Фазер завершается, если:
  - `onAdvance` возвращает `true` (по умолчанию, когда `parties == 0`).
  - Вызывается `forceTermination()`.
- После завершения `phase` становится отрицательным, и все вызовы `await` возвращаются немедленно.

#### **Потокобезопасность**
- Все операции с `state` (`parties`, `unarrived`, `phase`) выполняются атомарно через CAS.
- AQS управляет очередями ожидающих потоков, обеспечивая эффективную блокировку и разблокировку.

--------------------------------------------------------------------------------------------------------------------
Расскажи на чем основаны обьекты синхранизации?

**AbstractQueuedSynchronizer** (AQS) в Java — это фундаментальный класс из пакета `java.util.concurrent`, который служит основой для реализации многих синхронизационных механизмов, таких как `ReentrantLock`, `Semaphore`, `CountDownLatch`, `Phaser`, и других. AQS предоставляет общий каркас для управления блокировкой и синхронизацией потоков, основанный на атомарных операциях и очереди ожидания. Он позволяет разработчикам создавать собственные синхронизаторы, реализуя лишь несколько абстрактных методов. 

### 1. **Что такое AbstractQueuedSynchronizer?**

AQS — это абстрактный класс, обеспечивающий инфраструктуру для реализации блокировок и синхронизаторов, которые управляют доступом потоков к ресурсам. Он использует очередь ожидания (на основе CLH — Craig, Landin, and Hagersten lock queue) и атомарные операции (CAS) для координации потоков. AQS поддерживает два режима синхронизации:
- **Эксклюзивный (exclusive)**: Только один поток может получить доступ (например, `ReentrantLock`).
- **Общий (shared)**: Несколько потоков могут получить доступ одновременно (например, `Semaphore`, `CountDownLatch`).

**Основные характеристики**:
- **Состояние (state)**: Целочисленное значение (`int` или `long` в некоторых случаях), которое интерпретируется синхронизатором (например, счётчик разрешений в `Semaphore` или счётчик в `CountDownLatch`).
- **Очередь ожидания**: Потоки, не получившие доступ, помещаются в очередь и блокируются.
- **Атомарность**: Использует CAS для управления состоянием и очередью.
- **Гибкость**: Позволяет создавать кастомные синхронизаторы, реализуя методы для управления состоянием.

**Сценарии использования**:
- Реализация блокировок (`ReentrantLock`, `ReentrantReadWriteLock`).
- Синхронизация событий (`CountDownLatch`, `CyclicBarrier`, `Phaser`).
- Управление доступом к ресурсам (`Semaphore`).
- Создание пользовательских синхронизаторов для специфических задач.

### 2. **Внутренняя реализация AbstractQueuedSynchronizer**

AQS реализован в классе `java.util.concurrent.locks.AbstractQueuedSynchronizer` и использует очередь CLH для управления потоками, ожидающими доступа, и атомарные операции для обновления состояния.

#### 2.1. **Ключевые компоненты**

1. **Состояние (`state`)**:
  - Поле `state` (тип `int`, атомарно обновляемое через `Unsafe` или `AtomicIntegerFieldUpdater`).
  - Интерпретация зависит от конкретного синхронизатора:
    - В `ReentrantLock`: количество блокировок (0 — свободно, >0 — занято).
    - В `Semaphore`: число доступных разрешений.
    - В `CountDownLatch`: число оставшихся событий.
  - Обновляется через методы `getState()`, `setState(int)`, и `compareAndSetState(int, int)`.

2. **Очередь ожидания (CLH)**:
  - AQS использует модифицированную очередь CLH — двусвязный список узлов (`Node`).
  - Каждый узел представляет поток, ожидающий доступа, и содержит:
    - `prev`: Ссылка на предыдущий узел.
    - `next`: Ссылка на следующий узел.
    - `thread`: Ссылка на поток.
    - `waitStatus`: Состояние узла (например, `CANCELLED`, `SIGNAL`, `CONDITION`, `PROPAGATE`).
    - `nextWaiter`: Используется для условий (`Condition`).
  - Очередь имеет голову (`head`) и хвост (`tail`), обновляемые через CAS.

3. **Режимы синхронизации**:
  - **Эксклюзивный**: Только один поток может получить доступ (методы `acquire`, `release`).
  - **Общий**: Несколько потоков могут получить доступ одновременно (методы `acquireShared`, `releaseShared`).

4. **Condition**:
  - AQS поддерживает условия (`ConditionObject`), которые позволяют потокам ждать определённых событий.
  - Реализуется через очередь условий, связанную с основным синхронизатором.

5. **LockSupport**:
  - Используется для блокировки (`LockSupport.park()`) и разблокировки (`LockSupport.unpark()`) потоков в очереди.
  - Обеспечивает эффективное управление ожиданием без явных блокировок.

#### 2.2. **Ключевые методы для переопределения**
AQS — абстрактный класс, и разработчики должны переопределить следующие методы для реализации конкретного синхронизатора:
- **`tryAcquire(int arg)`**: Пытается получить эксклюзивный доступ. Возвращает `true`, если успешно.
- **`tryRelease(int arg)`**: Пытается освободить эксклюзивный доступ. Возвращает `true`, если освобождение завершено.
- **`tryAcquireShared(int arg)`**: Пытается получить общий доступ. Возвращает неотрицательное значение, если успешно.
- **`tryReleaseShared(int arg)`**: Пытается освободить общий доступ. Возвращает `true`, если другие потоки могут быть разблокированы.
- **`isHeldExclusively()`**: Проверяет, удерживается ли синхронизатор в эксклюзивном режиме.

Эти методы определяют логику управления состоянием, а AQS обеспечивает инфраструктуру для очередей и блокировки.

#### 2.3. **Основные публичные методы**
- **Эксклюзивный режим**:
  - `acquire(int arg)`: Блокирует поток, пока не удастся получить доступ через `tryAcquire`.
  - `release(int arg)`: Освобождает доступ через `tryRelease` и разблокирует следующий поток.
  - `acquireInterruptibly(int arg)`: То же, что `acquire`, но чувствителен к прерываниям.
- **Общий режим**:
  - `acquireShared(int arg)`: Блокирует поток, пока не удастся получить общий доступ через `tryAcquireShared`.
  - `releaseShared(int arg)`: Освобождает общий доступ через `tryReleaseShared`.
- **Условия**:
  - `newCondition()`: Создаёт объект `Condition` для ожидания событий.
  - `await()` / `signal()`: Методы `Condition` для блокировки и уведомления потоков.


### 3. **Как работает AbstractQueuedSynchronizer внутри?**

#### 3.1. **Инициализация**
- При создании AQS инициализируются:
  - Поле `state` (по умолчанию 0).
  - Голова (`head`) и хвост (`tail`) очереди (изначально `null`).
- Конкретные синхронизаторы (например, `ReentrantLock`) задают начальное значение `state` и логику его интерпретации.

#### 3.2. **Эксклюзивный доступ (`acquire`)**:
1. Поток вызывает `acquire(int arg)`:
  - Вызывается `tryAcquire(arg)` для попытки захвата ресурса.
  - Если `tryAcquire` возвращает `true`, поток продолжает выполнение.
  - Если `false`, поток добавляется в очередь CLH.
2. Добавление в очередь:
  - Создаётся узел `Node` с `thread = Thread.currentThread()` и режимом `EXCLUSIVE`.
  - Узел добавляется в конец очереди через CAS (`compareAndSetTail`).
  - Если очередь пуста, создаётся фиктивный узел (`head`).
3. Блокировка:
  - Поток проверяет, может ли предыдущий узел (`pred`) сигнализировать о разблокировке (`waitStatus = SIGNAL`).
  - Если да, поток блокируется через `LockSupport.park()`.
4. Разблокировка:
  - Когда ресурс освобождается (`release`), AQS вызывает `unparkSuccessor`, разблокируя следующий узел в очереди через `LockSupport.unpark()`.

#### 3.3. **Общий доступ (`acquireShared`)**:
1. Поток вызывает `acquireShared(int arg)`:
  - Вызывается `tryAcquireShared(arg)`:
    - Возвращает отрицательное значение, если доступ невозможен.
    - Возвращает 0, если доступ возможен, но дальнейшие потоки не могут получить доступ.
    - Возвращает положительное значение, если другие потоки тоже могут получить доступ.
  - Если результат отрицательный, поток добавляется в очередь в режиме `SHARED`.
2. Разблокировка:
  - При вызове `releaseShared` AQS вызывает `doReleaseShared`, который разблокирует все потоки в режиме `SHARED`, если `tryReleaseShared` возвращает `true`.

#### 3.4. **Очередь CLH**
- Очередь состоит из узлов, представляющих потоки.
- Состояния узлов (`waitStatus`):
  - `CANCELLED` (1): Поток отменён (например, из-за прерывания или таймаута).
  - `SIGNAL` (-1): Следующий узел ожидает уведомления.
  - `CONDITION` (-2): Узел находится в очереди условия.
  - `PROPAGATE` (-3): Используется в общем режиме для передачи уведомлений.
  - 0: Начальное состояние.
- Узлы добавляются в конец очереди через CAS (`compareAndSetTail`), а удаляются при разблокировке.

#### 3.5. **Условия (Condition)**
- AQS поддерживает условия через `ConditionObject`.
- Потоки, вызывающие `condition.await()`, помещаются в отдельную очередь условия.
- Вызов `condition.signal()` переносит узел из очереди условия обратно в основную очередь AQS.
- Условия используются, например, в `ReentrantLock` для реализации `lock.newCondition()`.

#### 3.6. **Потокобезопасность**
- Все операции с `state` и очередью выполняются через CAS (`compareAndSetState`, `compareAndSetHead`, `compareAndSetTail`).
- `LockSupport` используется для эффективной блокировки и разблокировки потоков.
- AQS поддерживает справедливую (fair) и несправедливую (non-fair) политику, в зависимости от реализации `tryAcquire`.

--------------------------------------------------------------------------------------------------------------------
Что такое Lock?

`Lock` это интерфейс из пакета `java.util.concurrent.locks`, введённый в Java 5 предоставляет явный механизм блокировки, где поток должен явно захватить блокировку (`lock()`) перед доступом к критической секции и освободить её (`unlock()`) после завершения. Это контрастирует с `synchronized`, где блокировка и освобождение происходят автоматически при входе и выходе из блока или метода.

Основные характеристики:
- **Явное управление**: Поток сам решает, когда захватить и освободить блокировку.
- **Гибкость**: Поддерживает различные стратегии захвата (блокирующий, неблокирующий, с таймаутом, прерываемый).
- **Условия (`Condition`)**: Позволяет создавать объекты `Condition` для координации потоков (аналог `wait()`/`notify()`).
- **Потокобезопасность**: Гарантирует, что только один поток может владеть блокировкой в данный момент.

Ключевой интерфейс `Lock`:
```java
public interface Lock {
    void lock(); // Блокирующий захват
    void lockInterruptibly() throws InterruptedException; // Прерываемый захват
    boolean tryLock(); // Неблокирующая попытка захвата
    boolean tryLock(long time, TimeUnit unit) throws InterruptedException; // Попытка с таймаутом
    void unlock(); // Освобождение блокировки
    Condition newCondition(); // Создание объекта Condition
}
```
--------------------------------------------------------------------------------------------------------------------
Что такое ReentrantLock?

`ReentrantLock` — это класс в Java из пакета `java.util.concurrent.locks`, реализующий интерфейс `Lock`. Он предоставляет потокобезопасный механизм синхронизации, позволяющий управлять доступом к общим ресурсам в многопоточной среде. `ReentrantLock` является более гибкой альтернативой встроенному механизму `synchronized`, обеспечивая такие возможности, как прерываемость, таймауты, неблокирующие попытки захвата и поддержка условий (`Condition`). Название "reentrant" отражает его способность поддерживать **повторный вход** (reentrancy), то есть поток, уже владеющий блокировкой, может захватить её снова без блокировки самого себя.


### **1. Основной принцип работы**
`ReentrantLock` позволяет потоку явно захватывать блокировку (`lock()`) для выполнения критической секции кода и освобождать её (`unlock()`) после завершения. Основные характеристики:
- **Явное управление**: В отличие от `synchronized`, где блокировка и освобождение происходят автоматически, `ReentrantLock` требует ручного вызова `lock()` и `unlock()`.
- **Повторный вход**: Поток, уже владеющий блокировкой, может захватить её снова, увеличивая счётчик входов.
- **Гибкость**: Поддерживает неблокирующие попытки (`tryLock`), прерываемые блокировки (`lockInterruptibly`), таймауты и справедливый режим (fair mode).
- **Условия (`Condition`)**: Позволяет создавать объекты `Condition` для координации потоков, аналогично `wait()`/`notify()`.

### **2. Внутренняя структура**
`ReentrantLock` основан на **AbstractQueuedSynchronizer (AQS)** — низкоуровневом фреймворке синхронизации, который является основой для большинства классов в `java.util.concurrent`. AQS управляет состоянием блокировки и очередью ожидающих потоков.

Упрощённая структура (на основе исходного кода JDK):
```java
public class ReentrantLock implements Lock, Serializable {
    private final Sync sync;

    // Абстрактный базовый класс для синхронизации
    abstract static class Sync extends AbstractQueuedSynchronizer {
        // Реализация логики блокировки
    }

    // Несправедливая (nonfair) реализация
    static final class NonfairSync extends Sync { ... }

    // Справедливая (fair) реализация
    static final class FairSync extends Sync { ... }

    public ReentrantLock() {
        sync = new NonfairSync(); // По умолчанию несправедливая блокировка
    }

    public ReentrantLock(boolean fair) {
        sync = fair ? new FairSync() : new NonfairSync();
    }
}
```

- **AQS**: Использует поле `state` (типа `int`) для отслеживания состояния блокировки:
  - `state == 0`: Блокировка свободна.
  - `state > 0`: Блокировка занята, значение указывает на количество повторных входов текущего потока.
- **Очередь ожидания**: AQS поддерживает CLH-очередь (Craig, Landin, Hagersten) для потоков, ожидающих захвата блокировки.
- **CAS**: Атомарные операции (Compare-And-Swap) используются для изменения `state` и управления очередью

### **3. Основные операции**
Рассмотрим, как работают ключевые методы `ReentrantLock`.

#### **Захват блокировки (`lock`)**
- **Процесс**:
  1. Поток пытается атомарно установить `state` с 0 на 1 через CAS (`compareAndSetState(0, 1)`).
  2. Если CAS успешен, поток становится владельцем (`setExclusiveOwnerThread`).
  3. Если поток уже владеет блокировкой, `state` увеличивается на 1 (повторный вход).
  4. Если CAS не удался (другой поток владеет), поток добавляется в очередь ожидания и паркуется (`LockSupport.park()`).
- **Fair vs Nonfair**:
  - **Nonfair** (по умолчанию): Новый поток может попытаться захватить блокировку сразу (barging), даже если другие ждут в очереди, что повышает производительность, но может привести к голоданию.
  - **Fair**: Потоки получают блокировку строго в порядке очереди, минимизируя голодание, но увеличивая накладные расходы.

#### **Освобождение блокировки (`unlock`)**
- **Процесс**:
  1. Поток уменьшает `state` на 1.
  2. Если `state` становится 0, блокировка освобождается, и следующий поток из очереди разблокируется (`LockSupport.unpark()`).
  3. Если `state > 0`, блокировка остаётся у текущего потока (для повторных входов)

#### **Неблокирующая попытка (`tryLock`)**
- **tryLock()**: Проверяет, свободна ли блокировка, и пытается захватить её через CAS. Возвращает `true`, если успешно, иначе `false`.
- **tryLock(long time, TimeUnit unit)**: Ждёт указанное время, периодически проверяя доступность блокировки, и поддерживает прерывание.

#### **Прерываемая блокировка (`lockInterruptibly`)**
- Позволяет прервать поток, ожидающий блокировку, через `Thread.interrupt()`. Если поток прерывается, выбрасывается `InterruptedException`.

#### **Условия (`Condition`)**
- Метод `newCondition()` создаёт объект `Condition`, связанный с `ReentrantLock`.
- `Condition` используется для координации потоков:
  - `await()`: Освобождает блокировку и переводит поток в ожидание.
  - `signal()`/`signalAll()`: Разбуживает один или все ожидающие потоки.
- Используется, например, в `ArrayBlockingQueue` для ожидания непустой (`notEmpty`) или незаполненной (`notFull`) очереди.

--------------------------------------------------------------------------------------------------------------------
Как использовать ReadWriteLock?

`ReadWriteLock` — это интерфейс в Java из пакета `java.util.concurrent.locks`, введённый в Java 5, который предоставляет механизм синхронизации, разделяющий доступ к ресурсу на два типа блокировок: **чтение** (`readLock`) и **запись** (`writeLock`). Он предназначен для сценариев, где операции чтения значительно преобладают над операциями записи, позволяя множеству потоков одновременно читать данные, но только одному потоку выполнять запись. Это обеспечивает более высокую конкурентность по сравнению с обычной блокировкой, такой как `ReentrantLock`, которая эксклюзивно блокирует доступ для всех операций. Основная реализация `ReadWriteLock` — это класс `ReentrantReadWriteLock`.


### **1. Основной принцип работы**
`ReadWriteLock` разделяет доступ к ресурсу на:
- **Read Lock** (`readLock`): Позволяет множеству потоков одновременно читать данные, если нет активной записи. Это повышает производительность в сценариях с частым чтением.
- **Write Lock** (`writeLock`): Эксклюзивная блокировка, позволяющая только одному потоку выполнять запись, блокируя все операции чтения и другие записи.

Ключевые характеристики:
- **Многопоточное чтение**: Несколько потоков могут удерживать `readLock` одновременно, если нет активного `writeLock`.
- **Эксклюзивная запись**: Только один поток может удерживать `writeLock`, и он блокирует все операции чтения и записи.
- **Потокобезопасность**: Гарантирует отсутствие состояний гонки при конкурентном доступе.
- **Гибкость**: Поддерживает повторный вход (reentrancy), справедливый режим (fairness) и условия (`Condition`) для `writeLock`.

Интерфейс `ReadWriteLock`:
```java
public interface ReadWriteLock {
    Lock readLock(); // Возвращает блокировку для чтения
    Lock writeLock(); // Возвращает блокировку для записи
}
```

### **2. Основная реализация: `ReentrantReadWriteLock`**
`ReentrantReadWriteLock` — это основная реализация `ReadWriteLock`, которая:
- Поддерживает повторный вход: поток, удерживающий `readLock` или `writeLock`, может снова захватить ту же блокировку.
- Использует **AbstractQueuedSynchronizer (AQS)** для управления состоянием и очередью ожидающих потоков.
- Поддерживает два режима:
  - **Nonfair** (по умолчанию): Новый поток может захватить блокировку, даже если другие ждут, что повышает производительность, но может привести к голоданию.
  - **Fair**: Потоки получают блокировку в порядке очереди, минимизируя голодание, но снижая производительность.
  

### **3. Внутренняя структура**
`ReentrantReadWriteLock` состоит из двух объектов `Lock`:
- `ReadLock`: Реализация для операций чтения.
- `WriteLock`: Реализация для операций записи.

Оба используют общий синхронизатор (`Sync`), основанный на AQS. Упрощённая структура (на основе исходного кода JDK):
```java
public class ReentrantReadWriteLock implements ReadWriteLock, Serializable {
    private final ReentrantReadWriteLock.ReadLock readerLock;
    private final ReentrantReadWriteLock.WriteLock writerLock;
    final Sync sync;

    // Абстрактный синхронизатор
    abstract static class Sync extends AbstractQueuedSynchronizer { ... }

    // Несправедливая или справедливая реализация
    static final class NonfairSync extends Sync { ... }
    static final class FairSync extends Sync { ... }

    public ReentrantReadWriteLock() {
        sync = new NonfairSync();
        readerLock = new ReadLock(this);
        writerLock = new WriteLock(this);
    }

    public ReentrantReadWriteLock(boolean fair) {
        sync = fair ? new FairSync() : new NonfairSync();
        readerLock = new ReadLock(this);
        writerLock = new WriteLock(this);
    }

    public Lock readLock() { return readerLock; }
    public Lock writeLock() { return writerLock; }
}
```

### **4. Операции и их реализация**

#### **Захват `readLock`**
- **Процесс**:
  1. Поток проверяет, свободен ли `writeLock` (`state` в младших битах == 0).
  2. Если `writeLock` не занят, поток увеличивает счётчик чтений (старшие биты `state`) через CAS.
  3. Если `writeLock` занят, но текущий поток — владелец `writeLock`, чтение разрешается (reentrancy).
  4. Если `writeLock` занят другим потоком, текущий поток добавляется в очередь ожидания и паркуется (`LockSupport.park()`).
- **Особенности**:
  - Множественные потоки могут удерживать `readLock`, если нет `writeLock`.
  - Сложность O(1) для захвата, если нет конфликтов.
  - В fair-режиме проверяется очередь, чтобы избежать пропуска ожидающих потоков.

#### **Захват `writeLock`**
- **Процесс**:
  1. Поток проверяет, свободны ли `readLock` и `writeLock` (`state == 0`).
  2. Если свободно, поток атомарно устанавливает `state` через CAS и становится владельцем (`setExclusiveOwnerThread`).
  3. Если текущий поток уже владеет `writeLock`, увеличивается счётчик повторных входов.
  4. Если `readLock` или `writeLock` заняты другим потоком, текущий поток добавляется в очередь и паркуется.
- **Особенности**:
  - Эксклюзивный доступ: только один поток может удерживать `writeLock`.
  - Блокирует все `readLock` и другие `writeLock`.
  

#### **Освобождение блокировок**
- **readLock.unlock()**:
  - Уменьшает счётчик чтений в `state` через CAS.
  - Если счётчик чтений становится 0 и нет `writeLock`, разбуживается следующий поток из очереди (`LockSupport.unpark()`).
- **writeLock.unlock()**:
  - Уменьшает счётчик повторных входов.
  - Если счётчик становится 0, блокировка освобождается, и разбуживаются ожидающие потоки.

#### **Условия (`Condition`)**
- `writeLock` поддерживает создание объектов `Condition` через `writeLock().newCondition()`.
- `readLock` не поддерживает `Condition`, так как это редко нужно для операций чтения.
- `Condition` используется для ожидания определённых условий, как в `ReentrantLock`.
--------------------------------------------------------------------------------------------------------------------
Когда используется StampedLock?

`StampedLock` — это класс в Java, введённый в Java 8 в пакете `java.util.concurrent.locks`, который предоставляет более гибкий и производительный механизм синхронизации по сравнению с `ReentrantLock` и `ReentrantReadWriteLock`. Он предназначен для сценариев, где требуется высокая конкурентность, особенно при большом количестве операций чтения и редких операциях записи. В отличие от других блокировок, `StampedLock` поддерживает **оптимистическое чтение** (optimistic read), что позволяет минимизировать блокировки в сценариях с низкой вероятностью конфликтов. Однако он не реализует интерфейс `Lock`, что делает его использование менее стандартным, но более эффективным в определённых случаях.

### **1. Основной принцип работы**
`StampedLock` предоставляет три типа доступа к ресурсу:
- **Write Lock**: Эксклюзивная блокировка для записи, аналогичная `writeLock` в `ReentrantReadWriteLock`. Только один поток может удерживать её, блокируя все другие операции.
- **Read Lock**: Блокировка для чтения, позволяющая множеству потоков читать одновременно, если нет активной записи. Аналогична `readLock` в `ReentrantReadWriteLock`.
- **Optimistic Read**: Неблокирующий режим чтения, который проверяет, не было ли изменений данных во время чтения, без захвата блокировки.

Ключевые характеристики:
- **Штампы (stamps)**: Каждая операция блокировки возвращает `long` (штамп), который используется для проверки или освобождения блокировки.
- **Оптимистичное чтение**: Позволяет читать данные без блокировки, проверяя их консистентность позже, что повышает производительность в сценариях с редкими конфликтами.
- **Не reentrant**: В отличие от `ReentrantLock` и `ReentrantReadWriteLock`, `StampedLock` не поддерживает повторный вход (reentrancy), что делает его менее интуитивным, но более лёгким.
- **Высокая производительность**: Оптимизирован для сценариев с преобладанием чтения, минимизируя накладные расходы на синхронизацию.

### **2. Внутренняя структура**
`StampedLock` основан на внутренней реализации, использующей очередь ожидания и атомарные операции, но не на `AbstractQueuedSynchronizer` (AQS), как `ReentrantLock` или `ReentrantReadWriteLock`. Вместо этого он использует собственную реализацию с состоянием (`state`) типа `long`.

Упрощённая структура (на основе исходного кода JDK):
```java
public class StampedLock implements Serializable {
    // Состояние блокировки
    private volatile long state;
    // Очередь ожидания
    private transient volatile WNode whead;
    private transient volatile WNode wtail;

    // Константы для режимов
    private static final int WRITE = 1; // Бит для записи
    private static final int READ = 128; // Биты для чтения
}
```

- **Состояние (`state`)**: Хранит информацию о текущем состоянии блокировки:
  - Младшие биты: Количество активных операций чтения или индикатор записи.
  - Старшие биты: Счётчик штампов, увеличивающийся для каждой операции блокировки.
- **Штамп**: Уникальный `long`, возвращаемый при захвате блокировки или оптимистическом чтении, используемый для проверки или освобождения.
- **Очередь ожидания**: Хранит потоки, ожидающие блокировки (аналогично CLH-очереди в AQS).
- **CAS**: Атомарные операции (через `Unsafe` или `VarHandle`) используются для изменения `state`.


### **3. Основные операции**
`StampedLock` предоставляет методы для трёх режимов доступа. Рассмотрим их подробно.

#### **Write Lock**
- **Метод**: `long writeLock()`
- **Процесс**:
  1. Поток пытается установить бит записи в `state` через CAS.
  2. Если нет активных операций чтения или записи, блокировка захватывается, и возвращается штамп (`long`).
  3. Если блокировка занята, поток добавляется в очередь ожидания и паркуется (`LockSupport.park()`).
  4. После захвата блокировки другие потоки не могут читать или писать.
- **Освобождение**: `unlockWrite(long stamp)` проверяет штамп и сбрасывает бит записи через CAS.

#### **Read Lock**
- **Метод**: `long readLock()`
- **Процесс**:
  1. Поток увеличивает счётчик чтений в `state` через CAS, если нет активной записи.
  2. Если запись активна, поток добавляется в очередь ожидания.
  3. Множественные потоки могут удерживать `readLock` одновременно.
  4. Возвращается штамп, уникальный для этой операции.
- **Освобождение**: `unlockRead(long stamp)` уменьшает счётчик чтений.

#### **Optimistic Read**
- **Метод**: `long tryOptimisticRead()`
- **Процесс**:
  1. Возвращает текущий штамп (`state`), не захватывая блокировку.
  2. Поток читает данные без синхронизации.
  3. После чтения проверяется, не изменился ли штамп через `validate(long stamp)`.
  4. Если `validate` возвращает `false` (была запись), данные могли измениться, и поток должен повторить чтение с `readLock`.
- **Особенности**:
  - Не блокирует другие операции, что делает его очень быстрым.
  - Требует проверки консистентности через `validate`.
  

#### **Конверсия блокировок**
- **Методы**: `tryConvertToWriteLock`, `tryConvertToReadLock`, `tryConvertToOptimisticRead`
- Позволяют переключаться между типами блокировок, сохраняя штамп, если это возможно, или возвращая новый штамп.
- Пример: Поток с `readLock` может попытаться перейти на `writeLock`, если нет других читателей.


### **4. Внутренняя реализация**
`StampedLock` использует собственную реализацию синхронизации, не основанную на AQS:
- **Состояние (`state`)**: `long` хранит счётчик чтений, индикатор записи и штампы. Старшие биты увеличиваются для уникальности штампов.
- **Очередь ожидания**: Хранит потоки, ожидающие `readLock` или `writeLock`, с разделением на читателей и писателей.
- **CAS**: Атомарные операции (`Unsafe.compareAndSwapLong`) обновляют `state`.
- **Cowait**: Специальный механизм для управления ожидающими читателями, чтобы минимизировать конкуренцию.
- **Отсутствие reentrancy**: `StampedLock` не отслеживает владельца блокировки, что делает его легче, но требует осторожности (нельзя захватить блокировку дважды).

--------------------------------------------------------------------------------------------------------------------
Зачем выбирать ReentrantLock вместо synchronized?

| Характеристика            | `ReentrantLock`                          | `synchronized`                          |
|---------------------------|------------------------------------------|----------------------------------------|
| **Тип блокировки**        | Явная, ручное управление                 | Неявная, автоматическое управление     |
| **Повторный вход**        | Поддерживается                           | Поддерживается                         |
| **Прерываемость**         | Да (`lockInterruptibly`)                 | Нет                                    |
| **Неблокирующая попытка** | Да (`tryLock`)                           | Нет                                    |
| **Таймаут**               | Да (`tryLock(time, unit)`)               | Нет                                    |
| **Условия**               | Множественные `Condition`                | Ограничено `wait()`/`notify()`         |
| **Справедливость**        | Настраиваемая (`fair`)                   | Нет (несправедливая)                   |
| **Производительность**    | Гибкая, но сложнее                       | Простая, оптимизирована JVM            |

---------------------------------------------------------------------------------------------------------------------
Что такое Executor?

`Executor` — это интерфейс, определённый в пакете `java.util.concurrent`. Его основная задача — отделить выполнение задач от их непосредственного запуска в потоках. Вместо того чтобы вручную создавать и управлять потоками (`Thread`), вы передаёте задачу (в виде объекта `Runnable` или `Callable`) в `Executor`, а он решает, как и когда её выполнить.

Интерфейс `Executor` очень прост и содержит всего один метод:
```java
void execute(Runnable command);
```

- **`command`** — это задача, представленная в виде объекта, реализующего интерфейс `Runnable`. Задача не возвращает результата (void).
- `Executor` сам решает, в каком потоке или контексте будет выполнена задача.

Пример простого использования:
```java
Executor executor = Executors.newSingleThreadExecutor();
executor.execute(() -> System.out.println("Задача выполняется в отдельном потоке"));
```

--------------------------------------------------------------------------------------------------------------------
Что такое ExecutorService?

**ExecutorService** — это интерфейс в Java из пакета `java.util.concurrent`, расширяющий базовый интерфейс `Executor`. Он предоставляет более продвинутые возможности для управления выполнением задач и жизненным циклом пулов потоков по сравнению с простым `Executor`. `ExecutorService` является ключевой частью **Executor Framework**, предназначенного для упрощения работы с многопоточностью.
  В отличие от `Runnable`, задачи `Callable` могут возвращать результат и выбрасывать проверяемые исключения.

**Расширение Executor**:
  - Наследует метод `execute(Runnable)` от `Executor`.
  - Добавляет методы для более сложных операций, таких как выполнение задач с возвратом результата, управление жизненным циклом пула и массовое выполнение задач.

**Ключевые методы**:
  - **`submit(Runnable/Callable)`**: Запускает задачу и возвращает объект `Future`, через который можно получить результат выполнения (для `Callable`) или проверить статус задачи.
  - **`invokeAll(Collection<Callable>)`**: Выполняет список задач и возвращает список `Future` с результатами.
  - **`invokeAny(Collection<Callable>)`**: Выполняет список задач и возвращает результат первой успешно завершённой.
  - **`shutdown()`**: Инициирует плавное завершение пула, позволяя выполнить все задачи в очереди, но не принимая новые.
  - **`shutdownNow()`**: Пытается немедленно остановить пул, прерывая выполняющиеся задачи.
  - **`isShutdown()` / `isTerminated()`**: Проверяют состояние пула.
  - **`awaitTermination()`**: Ожидает завершения всех задач в течение заданного времени.

### Основные реализации
`ExecutorService` обычно создаётся через утилитный класс `Executors`:
- **`Executors.newFixedThreadPool(int n)`**: Пул с фиксированным числом потоков.
- **`Executors.newCachedThreadPool()`**: Пул, создающий потоки по мере необходимости, с переиспользованием неактивных.
- **`Executors.newSingleThreadExecutor()`**: Один поток для последовательного выполнения задач.
- **`Executors.newScheduledThreadPool(int n)`**: Пул для задач с планированием (расширяет `ScheduledExecutorService`).

Также можно создать кастомный пул с помощью класса `ThreadPoolExecutor`, позволяющего настроить параметры (число потоков, очередь задач, политику отклонения).

--------------------------------------------------------------------------------------------------------------------
Что такое ThreadPoolExecutor и зачем он нужен?

**ThreadPoolExecutor** — это класс в Java из пакета `java.util.concurrent`, реализующий интерфейс `ExecutorService`. Он предоставляет гибкий и настраиваемый пул потоков для выполнения задач, позволяя разработчикам контролировать такие аспекты, как количество потоков, очередь задач, обработка переполнения и поведение при завершении. Это основа большинства реализаций пулов потоков, создаваемых через утилитный класс `Executors`, но `ThreadPoolExecutor` даёт больше возможностей для тонкой настройки.

`ThreadPoolExecutor` — это реализация пула потоков, которая:
- Управляет набором рабочих потоков (worker threads), выполняющих задачи (`Runnable` или `Callable`).
- Хранит задачи в очереди, если все потоки заняты.
- Позволяет настраивать параметры пула, такие как минимальное и максимальное число потоков, время жизни неактивных потоков и политику обработки переполнения.

Основное преимущество `ThreadPoolExecutor` — возможность оптимизировать выполнение задач под конкретные потребности приложения, избегая накладных расходов на создание новых потоков и управляя ресурсами.

Основной конструктор `ThreadPoolExecutor` выглядит так:
```java
ThreadPoolExecutor(int corePoolSize,
                   int maximumPoolSize,
                   long keepAliveTime,
                   TimeUnit unit,
                   BlockingQueue<Runnable> workQueue,
                   ThreadFactory threadFactory,
                   RejectedExecutionHandler handler)
```
- **`corePoolSize`**: Минимальное количество потоков, которые всегда активны в пуле, даже если нет задач.
- **`maximumPoolSize`**: Максимальное количество потоков, которое может быть создано при переполнении очереди.
- **`keepAliveTime`**: Время (в единицах `unit`), в течение которого неактивные потоки сверх `corePoolSize` будут жить перед удалением.
- **`unit`**: Единица измерения времени для `keepAliveTime` (например, `TimeUnit.SECONDS`).
- **`workQueue`**: Очередь для хранения задач, ожидающих выполнения.
- **`threadFactory`**: Фабрика для создания новых потоков (обычно `Executors.defaultThreadFactory()`).
- **`handler`**: Политика обработки задач, которые не могут быть приняты (например, при переполнении очереди и достижении `maximumPoolSize`).

#### **Основные компоненты**
1. **Пул потоков**:
  - Состоит из рабочих потоков (`Worker`), которые выполняют задачи.
  - Каждый `Worker` — это внутренний класс, представляющий поток, который берёт задачи из очереди и выполняет их.
  - Пул поддерживает от `corePoolSize` до `maximumPoolSize` потоков.

2. **Очередь задач (`workQueue`)**:
  - Используется для хранения задач, если все потоки заняты.
  - Типы очередей:
    - **`LinkedBlockingQueue`**: Неограниченная очередь (по умолчанию в `FixedThreadPool`).
    - **`ArrayBlockingQueue`**: Ограниченная очередь с фиксированным размером.
    - **`SynchronousQueue`**: Очередь без буфера, передающая задачи напрямую потокам (используется в `CachedThreadPool`).
    - **`PriorityBlockingQueue`**: Очередь с приоритетами для задач.

3. **Политика выполнения задач**:
  - Когда задача подаётся через `execute(Runnable)`:
    1. Если число активных потоков меньше `corePoolSize`, создаётся новый поток.
    2. Если число потоков равно `corePoolSize`, задача помещается в очередь.
    3. Если очередь заполнена и число потоков меньше `maximumPoolSize`, создаётся дополнительный поток.
    4. Если очередь заполнена и достигнут `maximumPoolSize`, применяется `RejectedExecutionHandler`.

4. **RejectedExecutionHandler**:
  - Определяет, что делать с задачей, если она не может быть принята. Стандартные политики:
    - **`AbortPolicy`**: Выбрасывает `RejectedExecutionException` (по умолчанию).
    - **`CallerRunsPolicy`**: Выполняет задачу в потоке вызывающего кода.
    - **`DiscardPolicy`**: Тихо отбрасывает задачу.
    - **`DiscardOldestPolicy`**: Удаляет самую старую задачу из очереди и добавляет новую.
    
  **ThreadFactory**:
  - Отвечает за создание новых потоков.
  - Позволяет настраивать параметры потоков (например, имена, приоритет, демонические потоки).

#### **Жизненный цикл пула**
`ThreadPoolExecutor` имеет несколько состояний:
- **RUNNING**: Принимает новые задачи и выполняет существующие.
- **SHUTDOWN**: Не принимает новые задачи, но завершает существующие.
- **STOP**: Не принимает новые задачи и пытается прервать выполняющиеся.
- **TIDYING**: Все задачи завершены, потоки освобождены.
- **TERMINATED**: Пул полностью завершён.

Методы управления:
- `shutdown()`: Переводит в состояние `SHUTDOWN`.
- `shutdownNow()`: Переводит в состояние `STOP`.
- `awaitTermination()`: Ожидает перехода в `TERMINATED`.

####  **Внутренний механизм Worker**
- Каждый рабочий поток (`Worker`) — это объект, реализующий `Runnable` и содержащий `Thread`.
- `Worker` циклически берёт задачи из `workQueue` с помощью метода `getTask()` и выполняет их.
- Если задача не найдена (например, очередь пуста и истекло `keepAliveTime`), поток может быть удалён, если число потоков превышает `corePoolSize`.

### **Ключевые внутренние механизмы**

1. **Управление потоками**:
  - Потоки создаются только при необходимости (до `corePoolSize` или `maximumPoolSize`).
  - Неактивные потоки сверх `corePoolSize` удаляются после `keepAliveTime`.

2. **Очередь задач**:
  - `workQueue` блокирует потоки, если задач нет (используется `BlockingQueue.take()`).
  - Если очередь заполнена, создаются дополнительные потоки (до `maximumPoolSize`).

3. **Обработка исключений**:
  - Исключения в задачах не влияют на пул, но могут быть пойманы через `Future.get()` или переопределение метода `afterExecute`.

4. **Метрики и мониторинг**:
  - Методы, такие как `getActiveCount()`, `getPoolSize()`, `getQueue().size()`, позволяют отслеживать состояние пула.

5. **Кастомизация**:
  - Переопределение методов `beforeExecute`, `afterExecute`, `terminated` позволяет добавлять пользовательскую логику (например, логирование или обработку ошибок).


### **Отличия от других реализаций ExecutorService**

- **`FixedThreadPool`**: Эквивалент `ThreadPoolExecutor` с `corePoolSize = maximumPoolSize` и неограниченной очередью.
- **`CachedThreadPool`**: Использует `SynchronousQueue` и `maximumPoolSize = Integer.MAX_VALUE`.
- **`SingleThreadExecutor`**: `ThreadPoolExecutor` с `corePoolSize = maximumPoolSize = 1`.

`ThreadPoolExecutor` предоставляет более детальный контроль, чем эти реализации, но требует ручной настройки.

--------------------------------------------------------------------------------------------------------------------
Расскажи про FixedThreadPool?

**Executors.newFixedThreadPool(int n)** — это статический метод утилитного класса `Executors` из пакета `java.util.concurrent`, который создаёт пул потоков с фиксированным количеством потоков (`n`). Этот пул является реализацией интерфейса `ExecutorService` и основан на классе `ThreadPoolExecutor`. Он предназначен для выполнения задач в многопоточной среде с ограниченным числом потоков, что делает его подходящим для приложений с предсказуемой нагрузкой.


### **Что делает Executors.newFixedThreadPool(int n)?**

Метод `Executors.newFixedThreadPool(int n)` создаёт объект `ExecutorService`, который:
- Поддерживает ровно `n` рабочих потоков для выполнения задач.
- Хранит задачи, превышающие количество доступных потоков, в неограниченной очереди (`LinkedBlockingQueue`).
- Переиспользует существующие потоки для выполнения новых задач, минимизируя накладные расходы на создание потоков.
- Не создаёт дополнительные потоки сверх `n`, даже при высокой нагрузке.

Возвращаемый объект является экземпляром `ThreadPoolExecutor` с фиксированной конфигурацией:
- `corePoolSize` = `maximumPoolSize` = `n`.
- `keepAliveTime` = 0 (потоки не завершаются, пока пул не будет явно закрыт).
- `workQueue` = `LinkedBlockingQueue` (неограниченная очередь).
- `threadFactory` = `Executors.defaultThreadFactory()` (стандартная фабрика для создания потоков).
- `handler` = `AbortPolicy` (выбрасывает исключение при переполнении, но в данном случае переполнение невозможно из-за неограниченной очереди).

### **Внутренняя реализация**

`Executors.newFixedThreadPool(int n)` эквивалентен следующей ручной настройке `ThreadPoolExecutor`:
```java
new ThreadPoolExecutor(n, n, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue<Runnable>());
```

**Ключевые аспекты**:
- **Фиксированное число потоков**: Пул всегда содержит ровно `n` потоков. Если все потоки заняты, новые задачи помещаются в очередь.
- **Неограниченная очередь**: Используется `LinkedBlockingQueue`, которая может расти без ограничений (теоретически до исчерпания памяти).
- **Отсутствие завершения потоков**: Поскольку `corePoolSize` равно `maximumPoolSize` и `keepAliveTime` равно 0, потоки не завершаются, пока пул активен.
- **Обработка задач**: Задачи, поданные через `execute(Runnable)` или `submit(Callable)`, выполняются в одном из `n` потоков или ожидают в очереди.

### **Как работает FixedThreadPool?**

1. **Инициализация**:
  - Создаётся пул с `n` потоками. Изначально потоки неактивны, пока не поступят задачи.
  - Каждый поток является объектом `Worker` (внутренний класс `ThreadPoolExecutor`), который циклически берёт задачи из `LinkedBlockingQueue`.

2. **Подача задач**:
  - Когда вызывается `execute(Runnable)` или `submit(Callable)`:
    - Если есть свободный поток (число активных потоков меньше `n`), задача выполняется немедленно.
    - Если все `n` потоков заняты, задача добавляется в очередь `LinkedBlockingQueue`.
  - Как только поток завершает задачу, он берёт следующую из очереди.

3. **Завершение**:
  - Пул продолжает работать, пока не вызван `shutdown()` (плавное завершение, выполняет все задачи в очереди) или `shutdownNow()` (немедленное прерывание).
  - Метод `awaitTermination()` позволяет ждать завершения всех задач.

--------------------------------------------------------------------------------------------------------------------
Расскажи про Executors.newCachedThreadPool()?

**Executors.newCachedThreadPool()** — это статический метод утилитного класса `Executors` из пакета `java.util.concurrent`, который создаёт пул потоков с динамическим количеством потоков. Этот пул является реализацией интерфейса `ExecutorService` и основан на классе `ThreadPoolExecutor`. Он предназначен для выполнения множества короткоживущих задач, автоматически создавая и переиспользуя потоки по мере необходимости. Давайте разберёмся углублённо в его назначение, внутреннюю реализацию, особенности и сценарии использования.

### **Что делает Executors.newCachedThreadPool()?**

Метод `Executors.newCachedThreadPool()` создаёт объект `ExecutorService`, который:
- **Динамически создаёт потоки**: Если все существующие потоки заняты, создаётся новый поток для выполнения задачи.
- **Переиспользует неактивные потоки**: Потоки, которые не используются в течение определённого времени (по умолчанию 60 секунд), завершаются и удаляются из пула.
- **Использует очередь без буфера**: Задачи передаются напрямую потокам без хранения в очереди, что минимизирует задержки.
- **Подходит для лёгких задач**: Идеален для приложений с большим количеством коротких асинхронных задач, где создание нового потока не создаёт значительных накладных расходов.

Возвращаемый объект — это `ThreadPoolExecutor` с следующей конфигурацией:
- `corePoolSize` = 0 (нет минимального числа потоков).
- `maximumPoolSize` = `Integer.MAX_VALUE` (практически неограниченное число потоков).
- `keepAliveTime` = 60 секунд (неактивные потоки завершаются через 60 секунд).
- `workQueue` = `SynchronousQueue` (очередь без буфера, передающая задачи напрямую потокам).
- `threadFactory` = `Executors.defaultThreadFactory()` (стандартная фабрика для создания потоков).
- `handler` = `AbortPolicy` (выбрасывает `RejectedExecutionException`, если создание нового потока невозможно).

### **Внутренняя реализация**

`Executors.newCachedThreadPool()` эквивалентен следующей ручной настройке `ThreadPoolExecutor`:
```java
new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue<Runnable>());
```

**Ключевые аспекты**:
- **Динамическое масштабирование**: Пул начинает с нуля потоков и создаёт новый поток для каждой задачи, если нет свободных.
- **SynchronousQueue**: Это не очередь в традиционном смысле, а механизм передачи задач напрямую от вызывающего потока к рабочему потоку. Если нет свободного потока, создаётся новый.
- **Время жизни потоков**: Неиспользуемые потоки завершаются через 60 секунд, что позволяет освобождать ресурсы при снижении нагрузки.
- **Неограниченное число потоков**: Теоретически пул может создать до `Integer.MAX_VALUE` потоков, что может привести к проблемам при очень высокой нагрузке.

### **Как работает CachedThreadPool?**

1. **Инициализация**:
  - Пул создаётся без активных потоков (`corePoolSize = 0`).
  - При поступлении задачи создаётся новый поток, если нет доступных.

2. **Подача задач**:
  - Когда вызывается `execute(Runnable)` или `submit(Callable)`:
    - Если есть свободный поток (неиспользуемый из пула), он берёт задачу.
    - Если свободных потоков нет, задача передаётся через `SynchronousQueue`, и создаётся новый поток.
    - Если создание потока невозможно (например, из-за системных ограничений), применяется `AbortPolicy` (выбрасывается `RejectedExecutionException`).
  - После выполнения задачи поток остаётся в пуле и ждёт новую задачу в течение 60 секунд. Если задача не поступает, поток завершается.

3. **Завершение**:
  - Пул продолжает работать, пока не вызван `shutdown()` (выполняет все задачи) или `shutdownNow()` (пытается прервать текущие задачи).
  - Метод `awaitTermination()` позволяет дождаться завершения всех задач.

--------------------------------------------------------------------------------------------------------------------
Расскажи про SingleThreadExecutor?

**Executors.newSingleThreadExecutor()** — это статический метод утилитного класса `Executors` из пакета `java.util.concurrent`, который создаёт пул потоков, содержащий ровно один рабочий поток. Этот пул является реализацией интерфейса `ExecutorService` и основан на классе `ThreadPoolExecutor`. Он предназначен для последовательного выполнения задач в одном потоке, обеспечивая их строгую очерёдность (FIFO — first-in, first-out). Давайте разберёмся углублённо в его назначение, внутреннюю реализацию, особенности и сценарии использования.

### **Что делает Executors.newSingleThreadExecutor()?**

Метод `Executors.newSingleThreadExecutor()` создаёт объект `ExecutorService`, который:
- Использует **один поток** для выполнения всех задач.
- Гарантирует **последовательное выполнение**: задачи выполняются в том порядке, в котором они были поданы.
- Хранит задачи, ожидающие выполнения, в **неограниченной очереди** (`LinkedBlockingQueue`).
- Переиспользует один и тот же поток для всех задач, минимизируя накладные расходы на создание потоков.
- Подходит для задач, которые должны выполняться строго по очереди или в контексте, где многопоточность нежелательна.

Возвращаемый объект — это `ThreadPoolExecutor` с фиксированной конфигурацией:
- `corePoolSize` = `maximumPoolSize` = 1 (всегда один поток).
- `keepAliveTime` = 0 (поток не завершается, пока пул активен).
- `workQueue` = `LinkedBlockingQueue` (неограниченная очередь для хранения задач).
- `threadFactory` = `Executors.defaultThreadFactory()` (стандартная фабрика для создания потока).
- `handler` = `AbortPolicy` (выбрасывает исключение при переполнении, но в данном случае переполнение невозможно из-за неограниченной очереди).

### **Внутренняя реализация**

`Executors.newSingleThreadExecutor()` эквивалентен следующей ручной настройке `ThreadPoolExecutor`:
```java
new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue<Runnable>());
```

**Ключевые аспекты**:
- **Один поток**: Пул содержит ровно один рабочий поток (`Worker`), который выполняет задачи по очереди.
- **Неограниченная очередь**: Если поток занят, новые задачи помещаются в `LinkedBlockingQueue`, которая может расти без ограничений (теоретически до исчерпания памяти).
- **Сохранение потока**: Поскольку `corePoolSize` = 1 и `keepAliveTime` = 0, поток не завершается, пока пул активен.
- **Последовательность**: Задачи выполняются строго в порядке подачи, что эквивалентно выполнению в одном потоке без параллелизма.

### **Как работает SingleThreadExecutor?**

1. **Инициализация**:
  - Пул создаётся с одним потоком. Поток активируется при поступлении первой задачи.
  - Поток представлен объектом `Worker` (внутренний класс `ThreadPoolExecutor`), который циклически берёт задачи из `LinkedBlockingQueue`.

2. **Подача задач**:
  - Когда вызывается `execute(Runnable)` или `submit(Callable)`:
    - Если поток свободен, задача выполняется немедленно.
    - Если поток занят, задача добавляется в очередь `LinkedBlockingQueue`.
  - После завершения задачи поток берёт следующую задачу из очереди. Если очередь пуста, поток блокируется, ожидая новую задачу.

3. **Завершение**:
  - Пул продолжает работать, пока не вызван `shutdown()` (выполняет все задачи в очереди) или `shutdownNow()` (пытается прервать текущую задачу и игнорирует очередь).
  - Метод `awaitTermination()` позволяет дождаться завершения всех задач.

--------------------------------------------------------------------------------------------------------------------
Зачем нужен ScheduledExecutorService?

**Executors.newScheduledThreadPool(int n)** — это статический метод утилитного класса `Executors` из пакета `java.util.concurrent`, который создаёт пул потоков с фиксированным количеством потоков (`n`), предназначенный для выполнения задач по расписанию. Этот пул является реализацией интерфейса `ScheduledExecutorService`, который расширяет `ExecutorService`, добавляя функциональность для планирования задач с задержкой или периодическим выполнением. Он основан на классе `ScheduledThreadPoolExecutor`, который, в свою очередь, является специализированной версией `ThreadPoolExecutor`. Давайте разберёмся углублённо в его назначение, внутреннюю реализацию, особенности и сценарии использования.


### **Что делает Executors.newScheduledThreadPool(int n)?**

Метод `Executors.newScheduledThreadPool(int n)` создаёт объект `ScheduledExecutorService`, который:
- Поддерживает **фиксированное количество потоков** (`n`) для выполнения задач.
- Позволяет **планировать задачи** для выполнения:
  - Через определённую задержку (`schedule`).
  - Периодически с фиксированной частотой (`scheduleAtFixedRate`).
  - Периодически с фиксированной задержкой между задачами (`scheduleWithFixedDelay`).
- Хранит задачи в **приоритетной очереди**, основанной на времени выполнения.
- Переиспользует потоки для минимизации накладных расходов на их создание.
- Подходит для задач, которые требуют выполнения по расписанию, таких как периодические обновления, таймеры или задачи с отложенным запуском.

Возвращаемый объект — это `ScheduledThreadPoolExecutor` с конфигурацией:
- `corePoolSize` = `n` (фиксированное число потоков).
- `maximumPoolSize` = `n` (не масштабируется сверх заданного числа).
- `keepAliveTime` = 0 (потоки не завершаются, пока пул активен).
- `workQueue` = `DelayedWorkQueue` (внутренняя очередь с приоритетами, основанная на времени выполнения задач).
- `threadFactory` = `Executors.defaultThreadFactory()` (стандартная фабрика для создания потоков).
- `handler` = `AbortPolicy` (выбрасывает исключение при переполнении, но переполнение маловероятно из-за структуры очереди).

### 2. **Внутренняя реализация**

`Executors.newScheduledThreadPool(int n)` эквивалентен созданию:
```java
new ScheduledThreadPoolExecutor(n);
```

**Ключевые аспекты**:
- **ScheduledThreadPoolExecutor**: Это подкласс `ThreadPoolExecutor`, специализированный для задач с планированием. Он использует `DelayedWorkQueue` — внутреннюю реализацию очереди, основанную на приоритетной куче (`PriorityQueue`), которая упорядочивает задачи по времени их выполнения.
- **Фиксированное число потоков**: Пул поддерживает ровно `n` потоков. Если все потоки заняты, задачи ждут в очереди до освобождения потока.
- **DelayedWorkQueue**: Очередь хранит задачи в порядке их запланированного времени выполнения. Задачи извлекаются, только когда наступает время их запуска.
- **Периодические задачи**: Для `scheduleAtFixedRate` и `scheduleWithFixedDelay` задачи автоматически повторно добавляются в очередь после выполнения, с учётом заданного интервала или задержки.


### 3. **Как работает ScheduledThreadPool?**

1. **Инициализация**:
  - Пул создаётся с `n` потоками. Потоки активируются по мере поступления задач.
  - Каждый поток представлен объектом `Worker`, который берёт задачи из `DelayedWorkQueue`.

2. **Подача задач**:
  - Поддерживаются три типа планирования:
    - **`schedule(Runnable/Callable, long delay, TimeUnit unit)`**: Выполняет задачу один раз после указанной задержки.
    - **`scheduleAtFixedRate(Runnable, long initialDelay, long period, TimeUnit unit)`**: Выполняет задачу периодически с фиксированной частотой (период между началами выполнения).
    - **`scheduleWithFixedDelay(Runnable, long initialDelay, long delay, TimeUnit unit)`**: Выполняет задачу периодически с фиксированной задержкой между концом одной задачи и началом следующей.
  - Задачи помещаются в `DelayedWorkQueue`, которая упорядочивает их по времени выполнения.
  - Если все `n` потоков заняты, задачи ждут в очереди, пока не наступит их время и не освободится поток.

3. **Завершение**:
  - Пул продолжает работать, пока не вызван `shutdown()` (выполняет все запланированные задачи) или `shutdownNow()` (пытается прервать текущие задачи и игнорирует очередь).
  - Периодические задачи продолжают выполняться, пока пул не завершён или задача не отменена через `Future.cancel()`.

--------------------------------------------------------------------------------------------------------------------
Что делает метод shutdown() и shutdownNow() у ExecutorService?

shutdown()
метода инициирует остановку ExecutorService. Все задачи, которые уже были отправлены на обработку, будут завершены, новые задачи приниматься не будут.

List<Runnable> shutdownNow()
Вызов метода инициирует остановку ExecutorService. Все задачи, которые уже были отправлены на обработку, получат команду Thread.interrupt. Задачи, находящиеся в очереди, возвращаются в виде списка как результат вызова метода.
Метод не ожидает завершения всех задач, которые находятся "в работе" на момент вызова метода.
--------------------------------------------------------------------------------------------------------------------
Какого размера должен быть пул потоков?

Настраивая размер пула потоков, важно избежать двух ошибок: слишком мало потоков (очередь на выполнение будет расти, потребляя много памяти) или слишком много потоков (замедление работы всей систему из-за частых переключений контекста).
Оптимальный размер пула потоков зависит от количества доступных процессоров и природы задач в рабочей очереди. На N-процессорной системе для рабочей очереди, которая будет выполнять исключительно задачи с ограничением по скорости вычислений, можно достигнуть максимального использования CPU с пулом потоков, в котором содержится N или N+1 поток. Для задач, которые могут ждать осуществления I/O (ввода - вывода) - например, задачи, считывающей HTTP-запрос из сокета - может понадобиться увеличение размера пула свыше количества доступных процессоров, потому, что не все потоки будут работать все время. Используя профилирование, можно оценить отношение времени ожидания (WT) ко времени обработки (ST) для типичного запроса. Если назвать это соотношение WT/ST, то для N-процессорной системе понадобится примерно N*(1 + WT/ST) потоков для полной загруженности процессоров.
Использование процессора - не единственный фактор, важный при настройке размера пула потоков. По мере возрастания пула потоков, можно столкнуться с ограничениями планировщика, доступной памяти, или других системных ресурсов, таких, как количество сокетов, дескрипторы открытого файла, или каналы связи базы данных.
--------------------------------------------------------------------------------------------------------------------
Что будет, если очередь пула потоков уже заполнена, но подаётся новая задача?

Если очередь пула потоков заполнилась, то поданная задача будет «отклонена». Например - метод submit() у ThreadPoolExecutor выкидывает RejectedExecutionException, после которого вызывается RejectedExecutionHandler.

--------------------------------------------------------------------------------------------------------------------
В чём заключается различие между методами submit() и execute() у пула потоков?

Оба метода являются способами подачи задачи в пул потоков, но между ними есть небольшая разница.
execute(Runnable command) определён в интерфейсе Executor и выполняет поданную задачу и ничего не возвращает.
submit() - перегруженный метод, определённый в интерфейсе ExecutorService. Способен принимать задачи типов Runnable и Callable и возвращать объект Future, который можно использовать для контроля и управления процессом выполнения, получения его результата.

--------------------------------------------------------------------------------------------------------------------
Какими коллекциями пользоваться в многопоточной среде?

Первый вариант - превратить в синхронизированную обычную коллекцию, вызвав соответствующий ее типу метод Collections.synchronized*(). Самый общий и самый примитивный способ, создает обертку с синхронизацией всех операций с помощью synchronized.

Если работа с коллекцией состоит в основном из чтения, лучшая в плане производительности альтернатива - CopyOnWriteArrayList, и содержащий его в реализации CopyOnWriteArraySet. 
Потокобезопасность достигается копированием внутреннего массива при любой модификации, оригинальный массив остается immutable. 
Program order достигается модификатором volatile на внутреннем массиве.

Третий вариант - использование Concurrent-коллекций:
• Неблокирующие хэш-таблицы ConcurrentSkipListMap, ConcurrentHashMap и ConcurrentSkipListSet (хэш-таблица в основе реализации)
• Неблокирующие очереди ConcurrentLinkedQueue и ConcurrentLinkedDeque
• Большой набор различных блокирующих очередей ArrayBlockingQueue, LinkedBlockingQueue
--------------------------------------------------------------------------------------------------------------------
Как внутри работает CopyOnWriteArrayList?

### **Основной принцип работы**
`CopyOnWriteArrayList` основан на концепции "копирование при записи" (copy-on-write). Это означает, что:
- Внутренние данные хранятся в массиве (`Object[]`).
- При любой модификации (добавление, удаление, обновление) создаётся **новая копия массива**, в которую вносятся изменения, а исходный массив остаётся неизменным.
- Операции чтения (например, `get`, итерация) выполняются на текущем массиве без блокировок, так как он не изменяется во время чтения.

Этот подход обеспечивает:
- **Потокобезопасность**: Все операции чтения и записи безопасны без необходимости явной синхронизации со стороны пользователя.
- **Консистентность данных**: Итераторы работают со "снимком" данных на момент их создания, не видя последующих изменений.
- **Высокую производительность чтения**: Чтение не требует блокировок, что делает его быстрым в многопоточной среде.

Однако за это приходится платить:
- Высокая стоимость операций записи из-за копирования массива.
- Большое потребление памяти при частых модификациях, особенно для больших списков.


### **Внутренняя структура**
`CopyOnWriteArrayList` использует следующие ключевые элементы:

- **Массив `Object[] array`**: Основное хранилище данных. Все элементы списка хранятся в этом массиве.
- **ReentrantLock `lock`**: Используется для синхронизации операций записи, чтобы предотвратить одновременное изменение массива несколькими потоками.
- **Volatile поле для массива**: Ссылка на массив помечена как `volatile`, чтобы гарантировать видимость изменений для всех потоков после завершения записи.

Пример упрощённой внутренней структуры (на основе исходного кода JDK):

```java
public class CopyOnWriteArrayList<E> implements List<E>, RandomAccess, Cloneable, Serializable {
    // Блокировка для операций записи
    final transient ReentrantLock lock = new ReentrantLock();
    // Массив для хранения элементов, помечен как volatile
    private transient volatile Object[] array;
    
    // Конструктор
    public CopyOnWriteArrayList() {
        setArray(new Object[0]);
    }
    
    // Установка нового массива
    final void setArray(Object[] a) {
        array = a;
    }
}
```

- **Volatile**: Гарантирует, что все потоки видят актуальную ссылку на массив после завершения модификации.
- **ReentrantLock**: Используется только для операций записи, чтобы обеспечить эксклюзивный доступ к процессу копирования массива.

---

### **Операции и их реализация**
Рассмотрим, как реализованы основные операции в `CopyOnWriteArrayList`, и как они обеспечивают потокобезопасность.

#### **Операции чтения**
Операции чтения, такие как `get(int index)`, `size()`, или итерация, выполняются **без блокировок**:
- **get(int index)**:
    - Получает текущий массив через `getArray()` (чтение volatile переменной).
    - Возвращает элемент по индексу: `return (E) array[index];`.
    - Поскольку массив неизменяем до следующей операции записи, чтение безопасно для всех потоков.

    - **Сложность**: Очень быстрые (O(1) для `get`), так как не требуют синхронизации.
  
- **Итерация**:
    - Итератор создаётся на основе "снимка" текущего массива (копия ссылки на массив на момент создания итератора).
    - Итератор работает с этим снимком и не видит последующих изменений в списке.
    - Это называется **snapshot-итерация** (не "fail-fast", как в `ArrayList`, а "fail-safe").
    - Итератор не поддерживает операции модификации (например, `remove()` вызовет `UnsupportedOperationException`).


#### **Операции записи**
Операции записи, такие как `add(E element)`, `remove(int index)`, `set(int index, E element)`, используют **блокировку** через `ReentrantLock`:
- **add(E element)**:
    1. Захватывается блокировка (`lock.lock()`).
    2. Получается текущий массив (`Object[] oldArray = getArray()`).
    3. Создаётся новый массив размером `oldArray.length + 1`.
    4. Копируются все элементы из старого массива в новый.
    5. Новый элемент добавляется в конец нового массива.
    6. Ссылка на массив обновляется (`setArray(newArray)`).
    7. Блокировка снимается (`lock.unlock()`).

- **remove(int index)**:
    - Аналогично: захватывается блокировка, создаётся новый массив без удаляемого элемента, обновляется ссылка на массив.
- **set(int index, E element)**:
    - Создаётся копия массива, заменяется элемент по индексу, обновляется ссылка.
    
- **Сложность**: Медленные (O(n) для большинства операций из-за копирования массива).

#### **Ключевые моменты операций записи**:
- **Копирование массива**: Каждая операция записи создаёт новый массив, что делает её дорогостоящей по времени и памяти.
- **Атомарность**: Блокировка (`ReentrantLock`) гарантирует, что только один поток может выполнять модификацию в момент времени.
- **Видимость**: Использование `volatile` для массива обеспечивает, что все потоки видят обновлённый массив после завершения записи.

--------------------------------------------------------------------------------------------------------------------
Как внутри работает CopyOnWriteArraySet?

### **Основной принцип работы**
`CopyOnWriteArraySet` — это обёртка над `CopyOnWriteArrayList`, которая обеспечивает функциональность множества (Set), то есть гарантирует уникальность элементов. Основные характеристики:
- Внутренне хранит элементы в `CopyOnWriteArrayList`.
- Потокобезопасность достигается за счёт создания новой копии внутреннего массива при каждой операции модификации (добавление, удаление).
- Операции чтения выполняются без блокировок, так как работают с неизменяемым "снимком" данных.
- Подходит для сценариев с редкими модификациями и частым чтением.


### **2. Внутренняя структура**
`CopyOnWriteArraySet` не хранит данные напрямую, а делегирует это `CopyOnWriteArrayList`. Ключевые компоненты:
- **Поле `CopyOnWriteArrayList<E> al`**: Единственное поле класса, которое хранит все элементы множества.
- **ReentrantLock** (унаследован от `CopyOnWriteArrayList`): Используется для синхронизации операций записи.
- **Volatile массив** (унаследован от `CopyOnWriteArrayList`): Внутренний массив `Object[]` в `CopyOnWriteArrayList`, помеченный как `volatile` для гарантии видимости изменений.

Упрощённая структура класса (на основе исходного кода JDK):
```java
public class CopyOnWriteArraySet<E> extends AbstractSet<E> implements Serializable {
    private final CopyOnWriteArrayList<E> al;

    public CopyOnWriteArraySet() {
        al = new CopyOnWriteArrayList<E>();
    }
}
```

### **Как работает `CopyOnWriteArraySet`**
Поскольку `CopyOnWriteArraySet` полностью основан на `CopyOnWriteArrayList`, его поведение во многом повторяет поведение списка, но с дополнительной логикой для обеспечения уникальности элементов.

#### **Операции чтения**
- Операции чтения (например, `contains`, `size`, итерация) делегируются напрямую `CopyOnWriteArrayList`:
    - **contains(Object o)**: Проверяет наличие элемента в списке через `al.contains(o)`, что выполняется без блокировок, так как массив неизменяем.
    - **size()**: Возвращает размер списка через `al.size()`.
    - **Итерация**: Итератор создаётся через `al.iterator()`, который возвращает `COWIterator` — итератор, работающий со "снимком" массива на момент создания. Это обеспечивает **fail-safe** итерацию, не видящую последующих изменений.
- Чтение сложность (O(n) для `contains` из-за линейного поиска), так как не требует синхронизации.

#### **Операции записи**
- Операции записи (например, `add`, `remove`) также делегируются `CopyOnWriteArrayList`, но с проверкой уникальности элементов:
    - **add(E e)**:
        1. Захватывается `ReentrantLock` (внутри `CopyOnWriteArrayList`).
        2. Проверяется, содержится ли элемент в списке (`al.contains(e)`).
        3. Если элемент уже есть, операция завершается без изменений (`return false`).
        4. Если элемента нет, вызывается `al.add(e)`, что:
            - Создаёт копию внутреннего массива.
            - Добавляет новый элемент в конец нового массива.
            - Обновляет ссылку на массив (`setArray(newArray)`).
        5. Блокировка снимается.
        - **Запись сложность**: Медленная (O(n) из-за копирования массива и проверки уникальности). Операции добавления и удаления особенно дороги для больших множеств.
    
    - **remove(Object o)**:
        1. Захватывается блокировка.
        2. Создаётся новый массив без указанного элемента (через `al.remove(o)`).
        3. Обновляется ссылка на массив.
        4. Блокировка снимается.

- **Атомарность**: Все операции записи атомарны благодаря `ReentrantLock` в `CopyOnWriteArrayList`.
- **Копирование массива**: Как и в `CopyOnWriteArrayList`, каждая модификация создаёт новый массив, что делает запись дорогостоящей (O(n)).

#### **Уникальность элементов**
- `CopyOnWriteArraySet` гарантирует, что каждый элемент уникален, используя метод `addIfAbsent` из `CopyOnWriteArrayList`.
- Проверка уникальности выполняется линейным поиском (`contains`), что имеет сложность O(n), так как `CopyOnWriteArrayList` не использует хеш-таблицу.

--------------------------------------------------------------------------------------------------------------------
Как ConcurrentHashMap работал до java 8?

До Java 8 `ConcurrentHashMap` использовал совершенно другую архитектуру, основанную на сегментировании (segment-based), которая обеспечивала потокобезопасность с помощью тонкой блокировки.


1. **Сегментированная структура**:
    - Хэш-таблица делилась на фиксированное количество сегментов (по умолчанию 16)
    - Каждый сегмент был независимой хэш-таблицей (похожей на `HashMap`)
    - Сегменты создавались при инициализации и не изменялись

2. **Механизм блокировок**:
    - Каждый сегмент защищался собственной `ReentrantLock`
    - Операции блокировали только нужный сегмент (lock striping)
    - Чтение без блокировок (volatile reads)

3. **Детали реализации**:
   ```java
   final Segment<K,V>[] segments; // Массив сегментов

   static final class Segment<K,V> extends ReentrantLock {
       volatile HashEntry<K,V>[] table; // Хэш-бакеты сегмента
       transient int count; // Количество элементов
   }

   static final class HashEntry<K,V> {
       final K key;
       volatile V value;
       final int hash;
       final HashEntry<K,V> next;
   }
   ```

4. **Характеристики производительности**:
    - Параллелизм = количеству сегментов (по умолчанию 16 потоков)
    - Блокировка на уровне сегмента (меньше contention, чем у `Hashtable`)
    - Нулевая блокировка для операций чтения
    - При достижении размера threshold в сегменте - ресайзинг только этого сегмента

5. **Недостатки**:
    - Фиксированный уровень параллелизма (не масштабировался динамически)
    - Блокировки даже для некоторых read-операций (например, size())
    - Менее эффективное использование памяти из-за фиксированной сегментации

Эта реализация была заменена в Java 8 на более современную, использующую синхронизацию на уровне отдельных бакетов с помощью `synchronized` и CAS-операций, что обеспечило лучшую масштабируемость.

--------------------------------------------------------------------------------------------------------------------
Как внутри работает ConcurrentHashMap?

`ConcurrentHashMap` оптимизирован для конкурентного доступа, обеспечивая:
- **Высокую производительность чтения**: Операции чтения (например, `get`) обычно выполняются без блокировок, благодаря использованию `volatile` полей и атомарных операций.
- **Конкурентные записи**: Операции записи (например, `put`, `remove`) используют блокировки, но только на уровне отдельных сегментов (или бакетов), а не всей структуры.
- **Отсутствие полной блокировки**: В отличие от `Hashtable` или `Collections.synchronizedMap`, которые блокируют всю карту, `ConcurrentHashMap` применяет сегментированную блокировку (lock striping) или неблокирующие алгоритмы (в Java 8+).
- **Потокобезопасность без `null`**: Не допускает `null` в ключах или значениях, чтобы избежать неоднозначностей при конкурентном доступе.

Ключевой принцип: **разделение данных на сегменты (бакеты)** и использование минимально необходимых блокировок для обеспечения конкурентности.

### **Внутренняя структура**
`ConcurrentHashMap` хранит данные в массиве бакетов (таблице), где каждый бакет может содержать связный список или красно-чёрное дерево (в случае высокой коллизии). Основные компоненты:

- **Массив `Node[] table`**: Основное хранилище, где каждый элемент (бакет) — это либо `Node` (для связного списка), либо `TreeBin` (для красно-чёрного дерева).
- **Volatile поля**: Поля, такие как `table` и `next` в узлах, помечены как `volatile` для обеспечения видимости изменений между потоками.
- **CAS-операции** (Compare-And-Swap): Используются для атомарных обновлений, например, при инициализации таблицы или изменении размера.
- **CounterCells**: Специальная структура для подсчёта количества элементов (`size`) в многопоточной среде.

Упрощённая структура (на основе исходного кода JDK):
```java
public class ConcurrentHashMap<K,V> extends AbstractMap<K,V> implements ConcurrentMap<K,V>, Serializable {
    // Основной массив бакетов
    private transient volatile Node<K,V>[] table;
    // Временный массив для ресайзинга
    private transient volatile Node<K,V>[] nextTable;
    // Счётчик элементов (для size())
    private transient volatile long baseCount;
    // Массив для конкурентного подсчёта
    private transient volatile CounterCell[] counterCells;
    // Состояние ресайзинга и инициализации
    private transient volatile int sizeCtl;
}

static class Node<K,V> implements Map.Entry<K,V> {
    final int hash;
    final K key;
    volatile V val; // Значение помечено как volatile
    volatile Node<K,V> next; // Ссылка на следующий узел
}
```

### **Операции и их реализация**

#### **Инициализация таблицы**
- Таблица (`table`) изначально не создаётся (null), чтобы минимизировать память при создании объекта.
- При первой операции `put` или аналогичной таблица инициализируется (обычно с размером 16 бакетов).
- Инициализация выполняется атомарно с использованием CAS (через `sizeCtl`), чтобы только один поток выполнил инициализацию.

#### **Операции чтения (`get`)**
- **get(K key)**:
    1. Вычисляется хэш ключа (`hash = spread(key.hashCode())`).
    2. Определяется индекс бакета (`index = (table.length - 1) & hash`).
    3. Если бакет пуст, возвращается `null`.
    4. Если бакет содержит `Node` (связный список), выполняется линейный поиск по ключу.
    5. Если бакет содержит `TreeBin` (красно-чёрное дерево), поиск выполняется по дереву (O(log n)).
- **Особенности**:
    - Не использует блокировки, так как поля `val` и `next` в `Node` помечены как `volatile`, что гарантирует видимость изменений.
    - Высокая производительность (O(1) в среднем, O(log n) для деревьев).
    - Неблокирующее чтение позволяет множеству потоков одновременно читать данные.

#### **Операции записи (`put`, `remove`)**
- **put(K key, V value)**:
    1. Вычисляется хэш ключа.
    2. Если таблица не инициализирована, выполняется инициализация.
    3. Определяется индекс бакета.
    4. Если бакет пуст, новый узел добавляется атомарно через CAS (без блокировки).
    5. Если бакет занят, используется `synchronized` на первом узле бакета:
        - Для связного списка: проверяется наличие ключа, обновляется значение или добавляется новый узел.
        - Для красно-чёрного дерева: добавление выполняется с балансировкой.
    6. Если бакет становится слишком длинным (по умолчанию 8 узлов), связный список преобразуется в красно-чёрное дерево.
    7. Обновляется счётчик элементов (`addCount`).
- **remove(K key)**:
    - Аналогично `put`, но удаляет узел из бакета (либо из списка, либо из дерева).
- **Особенности**:
    - Блокировка применяется только к конкретному бакету, а не ко всей таблице.
    - CAS используется для оптимизации вставки в пустые бакеты.
    - Если происходит ресайзинг, поток записи помогает завершить его (см. ниже).
    - **Сложноть**: O(1) в среднем для `put`/`remove`, но может быть O(log n) для деревьев. Блокировки ограничены бакетом.

#### **Ресайзинг (увеличение таблицы)**
- Когда таблица заполняется (по умолчанию load factor = 0.75), выполняется расширение:
    1. Создаётся новый массив `nextTable` удвоенного размера.
    2. Потоки, выполняющие операции записи, участвуют в переносе данных (cooperative resizing).
    3. Перенос выполняется по сегментам: каждый поток обрабатывает подмножество бакетов.
    4. Бакеты переносятся с сохранением порядка (для связных списков) или ребалансировкой (для деревьев).
    5. После завершения переноса ссылка `table` обновляется на `nextTable`.
- **Особенности**:
    - Ресайзинг не блокирует чтение: операции `get` работают с текущей таблицей.
    - Потоки записи помогают в ресайзинге, что распределяет нагрузку.

#### **Подсчёт элементов (`size`)**
- Используется структура `CounterCells` для конкурентного подсчёта.
- Каждый поток обновляет свой счётчик в `CounterCells` через CAS, чтобы избежать блокировок.
- Итоговый размер вычисляется суммированием `baseCount` и значений в `CounterCells`.

--------------------------------------------------------------------------------------------------------------------
Как внутри работает ConcurrentSkipListMap?

### **1. Основной принцип работы**
`ConcurrentSkipListMap` использует **skip list** — вероятностную структуру данных, которая обеспечивает эффективный поиск, вставку и удаление (в среднем O(log n)) за счёт многоуровневой организации узлов. Основные характеристики:
- **Потокобезопасность**: Операции чтения и записи выполняются без полной блокировки, используя атомарные операции (Compare-And-Swap, CAS) и `volatile` поля.
- **Упорядоченность**: Ключи хранятся в отсортированном порядке (по естественному порядку или с использованием компаратора).
- **Конкурентность**: Поддерживает высокую степень параллелизма благодаря отсутствию глобальных блокировок и использованию неблокирующих алгоритмов.
- **Отсутствие `null`**: Не допускает `null` в ключах или значениях для устранения неоднозначностей при конкурентном доступе.

Ключевой принцип: **skip list** сочетает простоту связного списка с эффективностью поиска, близкой к бинарному дереву, а потокобезопасность достигается через атомарные обновления и логические удаления.

### **2. Внутренняя структура**
`ConcurrentSkipListMap` основана на структуре skip list, которая представляет собой многоуровневый связный список, где каждый уровень ускоряет поиск за счёт "пропуска" части узлов. Основные компоненты:

- **Узлы (`Node`)**: Хранят пары ключ-значение и ссылки на следующий узел на том же уровне.
- **Индексные узлы (`Index`)**: Формируют дополнительные уровни skip list, указывая на узлы нижних уровней и ускоряя поиск.
- **Голова (`HeadIndex`)**: Указатель на верхний уровень skip list, с которого начинается обход.
- **Volatile поля**: Используются для обеспечения видимости изменений между потоками.
- **CAS-операции**: Применяются для атомарного обновления ссылок и значений.

Упрощённая структура (на основе исходного кода JDK):
```java
public class ConcurrentSkipListMap<K,V> extends AbstractMap<K,V>
    implements ConcurrentNavigableMap<K,V>, Cloneable, Serializable {
    // Голова skip list (указатель на верхний уровень)
    private transient volatile HeadIndex<K,V> head;
    
    // Компаратор для сортировки ключей
    final Comparator<? super K> comparator;

    // Базовый узел, хранящий ключ и значение
    static final class Node<K,V> {
        final K key;
        volatile Object value; // Значение или маркер удаления
        volatile Node<K,V> next; // Ссылка на следующий узел
    }

    // Индексный узел для уровней skip list
    static final class Index<K,V> {
        final Node<K,V> node; // Связь с базовым узлом
        final Index<K,V> down; // Ссылка на нижний уровень
        volatile Index<K,V> right; // Ссылка на следующий индекс на том же уровне
    }

    // Голова skip list
    static final class HeadIndex<K,V> extends Index<K,V> {
        final int level; // Уровень в skip list
    }
}
```

- **Skip List**: Каждый узел может быть связан с несколькими уровнями. Верхние уровни содержат меньше узлов, что ускоряет поиск.
- **Вероятностная структура**: Новые узлы получают случайный уровень (обычно с геометрическим распределением, где вероятность добавления на следующий уровень = 1/2).
- **Маркер удаления**: Вместо физического удаления узлов используется логическое удаление (значение узла помечается как `null` или специальный маркер).

### **Как работает Skip List**
Skip list — это многоуровневый связный список, где:
- **Нижний уровень (уровень 0)**: Содержит все узлы в порядке сортировки, как обычный связный список.
- **Высшие уровни**: Содержат подмножество узлов, что позволяет "перепрыгивать" через узлы при поиске, приближая сложность к O(log n).
- **Вероятностное распределение**: Каждый узел случайным образом получает высоту (количество уровней), что обеспечивает балансировку без сложных операций, как в деревьях.

Пример структуры skip list:
```
Level 3:  Head ----> [10] ----------------> [50]
Level 2:  Head ----> [10] ----> [30] ----> [50]
Level 1:  Head ----> [10] -> [20] -> [30] -> [50]
Level 0:  Head -> [5] -> [10] -> [15] -> [20] -> [30] -> [40] -> [50]
```

- Поиск начинается с верхнего уровня, переходя на нижний, если следующий узел на текущем уровне слишком далеко.


### **Операции и их реализация**

#### **Инициализация**
- При создании `ConcurrentSkipListMap` инициализируется пустой skip list с головой (`HeadIndex`), указывающей на минимальный уровень (0).
- Если задан компаратор, он используется для сортировки ключей; иначе используется естественный порядок (`Comparable`).

#### **Операции чтения (`get`, `containsKey`)**
- **get(K key)**:
  1. Начинается с верхнего уровня (`head`).
  2. Выполняется поиск, двигаясь вправо и вниз, пока не найдётся узел с искомым ключом или его ближайший предшественник.
  3. Если узел найден и не помечен как удалённый (значение не является маркером), возвращается значение.
  4. Если узел не найден или помечен как удалённый, возвращается `null`.
- **Особенности**:
  - Полностью неблокирующая операция, так как использует `volatile` поля (`next`, `right`, `value`) для видимости.
  - Сложность в среднем O(log n), так как skip list позволяет пропускать узлы.
  - Не требует синхронизации, что обеспечивает высокую производительность при чтении.

#### **Операции записи (`put`, `remove`)**
- **put(K key, V value)**:
  1. Выполняется поиск позиции для вставки (аналогично `get`), определяя предшественника и уровень нового узла (случайный, с вероятностью 1/2 для каждого уровня).
  2. Создаётся новый узел (`Node`) с ключом и значением.
  3. Используется CAS для атомарного обновления ссылки `next` у предшественника, чтобы вставить новый узел.
  4. Если узел уже существует, значение обновляется через CAS.
  5. Для каждого уровня создаются индексные узлы (`Index`), которые также вставляются с помощью CAS.
  6. Если CAS не удаётся (другой поток изменил структуру), операция повторяется.
- **remove(K key)**:
  1. Выполняется поиск узла с заданным ключом.
  2. Узел логически помечается как удалённый (значение устанавливается в специальный маркер через CAS).
  3. Ссылки на узел постепенно удаляются с помощью CAS на каждом уровне.
  4. Физическое удаление узлов не выполняется сразу — сборщик мусора очищает их позже.
- **Особенности**:
  - Используются неблокирующие CAS-операции (через `Unsafe` или `VarHandle` в JDK) для обновления ссылок.
  - Логическое удаление минимизирует влияние на другие потоки.
  - Сложность в среднем O(log n) для вставки и удаления.
  - Конфликты CAS (если другой поток изменил структуру) приводят к повторным попыткам, что делает алгоритм lock-free.
--------------------------------------------------------------------------------------------------------------------
Как внутри работает ConcurrentLinkedDeque?

`ConcurrentLinkedDeque` представляет собой двусвязный список, где элементы можно добавлять или удалять с обоих концов (head и tail). Основные характеристики:
- **Потокобезопасность**: Все операции (добавление, удаление, чтение) выполняются без блокировок, используя CAS для атомарного обновления ссылок.
- **Двусторонняя очередь**: Поддерживает операции с начала (`head`) и конца (`tail`) очереди, такие как `addFirst`, `addLast`, `pollFirst`, `pollLast`.
- **Неограниченный размер**: Очередь не имеет фиксированного размера, растёт по мере добавления элементов.
- **Отсутствие `null`**: Не допускает `null` элементы для устранения неоднозначностей при конкурентном доступе.
- **Lock-free алгоритм**: Использует CAS для координации изменений, что минимизирует конкуренцию между потоками.

Ключевой принцип: **неблокирующий двусвязный список**, где атомарные операции обеспечивают корректность изменений даже при одновременном доступе множества потоков.

### **Внутренняя структура**
`ConcurrentLinkedDeque` основана на двусвязном списке, где каждый узел содержит элемент и ссылки на предыдущий и следующий узлы. Основные компоненты:

- **Узлы (`Node`)**: Хранят элемент и ссылки на соседние узлы (`prev` и `next`).
- **Head и Tail**: Указатели на первый и последний узлы списка, обновляемые атомарно.
- **Volatile поля**: Ссылки в узлах (`item`, `prev`, `next`) помечены как `volatile` для обеспечения видимости изменений.
- **CAS-операции**: Используются для атомарного обновления ссылок и элементов.

Упрощённая структура (на основе исходного кода JDK):
```java
public class ConcurrentLinkedDeque<E> extends AbstractCollection<E> implements Deque<E>, Serializable {
    // Указатели на начало и конец списка
    private transient volatile Node<E> head;
    private transient volatile Node<E> tail;

    // Узел двусвязного списка
    private static final class Node<E> {
        volatile E item; // Элемент (или null для удалённых узлов)
        volatile Node<E> prev; // Ссылка на предыдущий узел
        volatile Node<E> next; // Ссылка на следующий узел
    }
}
```

- **Head и Tail**: Указывают на первый и последний активные узлы, но могут временно быть несогласованными из-за конкурентных операций.
- **Node**: Каждый узел хранит элемент и ссылки, причём `item` может быть `null` для обозначения логически удалённого узла.
- **CAS**: Используется через `Unsafe` или `VarHandle` для атомарного обновления полей `prev`, `next` и `item`.


### **Операции и их реализация**
Рассмотрим ключевые операции и как они обеспечивают потокобезопасность.

#### **Инициализация**
- При создании `ConcurrentLinkedDeque` создаётся пустой список, где `head` и `tail` указывают на фиктивный узел (sentinel node) или `null`.
- Первый добавленный элемент инициализирует структуру, создавая первый реальный узел.

#### **Операции добавления (`addFirst`, `addLast`, `offerFirst`, `offerLast`)**
- **addLast(E e)**:
  1. Создаётся новый узел с элементом `e` (`new Node<>(e)`).
  2. Находится текущий `tail` узел.
  3. Проверяется, можно ли добавить новый узел как следующий за `tail`:
    - CAS используется для атомарного обновления `tail.next` на новый узел.
    - Если CAS успешен, обновляется `tail.prev` предыдущего узла и `tail` указатель.
  4. Если CAS не удаётся (другой поток изменил `tail` или `next`), операция повторяется.
- **addFirst(E e)**:
  - Аналогично, но добавление происходит в начало списка, обновляя `head` и `prev`/`next` ссылки.
- **Особенности**:
  - CAS обеспечивает атомарность вставки.
  - Повторные попытки при конфликтах делают операцию lock-free.
  - Сложность в среднем O(1), так как добавление происходит в начало или конец, но конфликты CAS могут увеличить время.

#### **Операции удаления (`pollFirst`, `pollLast`, `removeFirst`, `removeLast`)**
- **pollFirst()**:
  1. Находится текущий `head` узел.
  2. Если `head.item` не `null`, элемент извлекается, а узел логически удаляется:
    - CAS устанавливает `head.item` в `null`.
    - CAS обновляет `head` на следующий узел (`head.next`) и корректирует `prev`/`next` ссылки.
  3. Если `head.item` уже `null` или список пуст, возвращается `null`.
  4. Если CAS не удаётся, операция повторяется.
- **pollLast()**:
  - Аналогично, но работает с `tail`, удаляя последний элемент.
- **Особенности**:
  - Логическое удаление (установка `item` в `null`) минимизирует изменения структуры.
  - Сложность O(1) в среднем, но конфликты CAS могут вызывать повторные попытки.

#### **Операции чтения (`peekFirst`, `peekLast`)**
- **peekFirst()**:
  1. Находится текущий `head` узел.
  2. Возвращается `head.item`, если он не `null`, иначе ищется следующий непустой узел.
- **Особенности**:
  - Полностью неблокирующая операция, так как использует `volatile` поля.
  - Сложность O(1) в среднем, но может быть O(n) в худшем случае, если много удалённых узлов.

#### **Итерация**
- Итераторы (`iterator`, `descendingIterator`) являются **weakly consistent**:
  - Работают со снимком списка на момент создания, обходя узлы через `next` или `prev`.
  - Пропускают узлы с `item == null` (логически удалённые).
  - Не вызывают `ConcurrentModificationException`, но могут не отражать все изменения.
- Итерация неблокирующая, так как использует `volatile` ссылки.

--------------------------------------------------------------------------------------------------------------------
Как внутри работает ArrayBlockingQueue?

### **Основной принцип работы**
`ArrayBlockingQueue` — это ограниченная очередь (bounded queue), которая:
- Хранит элементы в массиве фиксированного размера, заданного при создании.
- Поддерживает FIFO (First-In-First-Out) порядок.
- Использует **одну блокировку** (`ReentrantLock`) для синхронизации всех операций (чтения и записи).
- Применяет **условия** (`Condition`) для блокировки потоков, когда очередь полна (для `put`) или пуста (для `poll`).
- Обеспечивает потокобезопасность, но с меньшей конкурентностью по сравнению с lock-free структурами, такими как `ConcurrentLinkedDeque`.

Ключевой принцип: **блокирующая очередь с фиксированным размером**, где операции добавления и извлечения синхронизируются через одну блокировку, а потоки могут ожидать выполнения условий (например, появления свободного места или элементов).

### **Внутренняя структура**
`ArrayBlockingQueue` использует циклический массив (circular buffer) для хранения элементов, что позволяет эффективно переиспользовать пространство. Основные компоненты:

- **Массив `Object[] items`**: Фиксированного размера, хранит элементы очереди.
- **Индексы**:
  - `takeIndex`: Индекс, указывающий на следующий элемент для извлечения (голова очереди).
  - `putIndex`: Индекс, указывающий на место для добавления следующего элемента (хвост очереди).
- **Счётчик `count`**: Количество элементов в очереди.
- **ReentrantLock `lock`**: Единая блокировка для всех операций.
- **Condition `notEmpty`, `notFull`**: Условия для координации потоков (сигнализируют, когда очередь становится непустой или незаполненной).
- **Volatile поля**: Поля, такие как `count`, могут быть помечены как `volatile` для видимости изменений, хотя основная синхронизация идёт через `lock`.

Упрощённая структура (на основе исходного кода JDK):
```java
public class ArrayBlockingQueue<E> extends AbstractQueue<E> implements BlockingQueue<E>, Serializable {
    // Массив для хранения элементов
    final Object[] items;
    // Индекс для извлечения (голова)
    int takeIndex;
    // Индекс для добавления (хвост)
    int putIndex;
    // Количество элементов
    int count;
    // Единая блокировка
    final ReentrantLock lock;
    // Условие для ожидания непустой очереди
    private final Condition notEmpty;
    // Условие для ожидания свободного места
    private final Condition notFull;
}
```

### **Как работает циклический массив**
`ArrayBlockingQueue` использует циклический массив, где:
- Элементы добавляются в `putIndex`, который увеличивается и оборачивается (modulo размер массива), если достигает конца.
- Элементы извлекаются из `takeIndex`, который также оборачивается.
- Это позволяет эффективно использовать фиксированный массив без необходимости сдвига элементов.

Пример:
```
items: [A, B, C, null, null]
takeIndex: 0 (указывает на A)
putIndex: 3 (указывает на следующее свободное место)
count: 3
capacity: 5
```

После добавления `D`:
```
items: [A, B, C, D, null]
takeIndex: 0
putIndex: 4
count: 4
```

После извлечения `A` и добавления `E`:
```
items: [E, B, C, D, null]
takeIndex: 1
putIndex: 0 (обернулся)
count: 4
```


### **Операции и их реализация**
Рассмотрим ключевые операции и их потокобезопасность.

#### **Инициализация**
- При создании задаётся фиксированная ёмкость (`capacity`), и создаётся массив `items` этого размера.
- Инициализируются `lock`, `notEmpty` и `notFull` для синхронизации.
- `takeIndex` и `putIndex` начинаются с 0, `count` равен 0.

#### **Операции добавления (`put`, `offer`, `add`)**
- **put(E e)** (блокирующая):
  1. Захватывается `lock`.
  2. Если очередь полна (`count == items.length`), поток блокируется через `notFull.await()`, ожидая освобождения места.
  3. Элемент добавляется в `items[putIndex]`, `putIndex` увеличивается (с обёртыванием: `putIndex = (putIndex + 1) % capacity`).
  4. Увеличивается `count`.
  5. Сигнализируется `notEmpty.signal()`, чтобы разбудить потоки, ожидающие извлечения.
  6. Блокировка снимается.
  
- **offer(E e)**: Неблокирующая версия, возвращает `false`, если очередь полна.

#### **Операции извлечения (`take`, `poll`)**
- **take()** (блокирующая):
  1. Захватывается `lock`.
  2. Если очередь пуста (`count == 0`), поток блокируется через `notEmpty.await()`, ожидая появления элементов.
  3. Извлекается элемент из `items[takeIndex]`, `takeIndex` увеличивается (с обёртыванием).
  4. Уменьшается `count`, элемент в массиве обнуляется (`items[takeIndex] = null`).
  5. Сигнализируется `notFull.signal()`, чтобы разбудить потоки, ожидающие добавления.
  6. Блокировка снимается.
- **poll()**: Неблокирующая версия, возвращает `null`, если очередь пуста.

#### **Операции чтения (`peek`)**
- **peek()**:
  1. Захватывается `lock`.
  2. Возвращается `items[takeIndex]`, если очередь не пуста, иначе `null`.
  3. Блокировка снимается.
- Сложность O(1), но требует блокировки.

#### **Итерация**
- Итератор создаётся через снимок массива (`Itrs` внутренний класс).
- Итераторы **weakly consistent**, могут не отражать изменения, сделанные после их создания.
- Итерация требует блокировки для доступа к `items`, что снижает конкурентность.

--------------------------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------------------------
Даны 3 потока Т1, Т2 и Т3? Как реализовать выполнение в последовательности Т1, Т2, Т3?

Такой последовательности выполнения можно достичь многими способами, например просто воспользоваться методом join(), чтобы запустить поток в момент, когда другой уже закончит своё выполнение. Для реализации заданной последовательности, нужно запустить последний поток первым, и затем вызывать метод join() в обратном порядке, то есть Т3 вызывает Т2.join, а Т2 вызывает Т1.join, таким образом Т1 закончит выполнение первым, а Т3 последним.

--------------------------------------------------------------------------------------------------------------------
Напишите минимальный неблокирующий стек (всего два метода — push() и pop()).

class NonBlockingStack<T> {
private final AtomicReference<Element> head = new AtomicReference<>(null);
Stack<T> push(final T value) {
final Element current = new Element();
current.value = value;
Element recent;
do {
recent = head.get();
current.previous = recent;
} while (!head.compareAndSet(recent, current));
return this;
}
T pop() {
Element result;
Element previous;
do {
result = head.get();
if (result == null) {
return null;
}
previous = result.previous;
} while (!head.compareAndSet(result, previous));
return result.value;
}
private class Element {
private T value;
private Element previous;
}
}
--------------------------------------------------------------------------------------------------------------------
Напишите минимальный неблокирующий стек (всего два метода — push() и pop()) с использованием Semaphore.

class SemaphoreStack<T> {
private final Semaphore semaphore = new Semaphore(1);
private Node<T> head = null;
SemaphoreStack<T> push(T value) {
semaphore.acquireUninterruptibly();
try {
head = new Node<>(value, head);
} finally {
semaphore.release();
}
return this;
}
T pop() {
semaphore.acquireUninterruptibly();
try {
Node<T> current = head;
if (current != null) {
head = head.next;
return current.value;
}
return null;
} finally {
semaphore.release();
}
}
private static class Node<E> {
private final E value;
private final Node<E> next;
private Node(E value, Node<E> next) {
this.value = value;
this.next = next;
}
}
}
--------------------------------------------------------------------------------------------------------------------
Напишите минимальный неблокирующий ArrayList (всего четыре метода — add(), get(), remove(), size()).

class NonBlockingArrayList<T> {
private volatile Object[] content = new Object[0];
NonBlockingArrayList<T> add(T item) {
return add(content.length, item);
}
NonBlockingArrayList<T> add(int index, T item) {
if (index < 0) {
throw new IllegalArgumentException();
}
boolean needsModification = index > content.length - 1;
if (!needsModification) {
if (item == null) {
needsModification = content[index] != null;
} else {
needsModification = item.equals(content[index]);
}
}
if (needsModification) {
final Object[] renewed = Arrays.copyOf(content, Math.max(content.length, index + 1));
renewed[index] = item;
content = renewed;
}
return this;
}
NonBlockingArrayList<T> remove(int index) {
if (index < 0 || index >= content.length) {
throw new IllegalArgumentException();
}
int size = content.length - 1;
final Object[] renewed = new Object[size];
System.arraycopy(content, 0, renewed, 0, index);
if (index + 1 < size) {
System.arraycopy(content, index + 1, renewed, index, size - index);
}
content = renewed;
return this;
}
T get(int index) {
return (T) content[index];
}
int size() {
return content.length;
}
}
--------------------------------------------------------------------------------------------------------------------
Напишите потокобезопасную реализацию класса с неблокирующим методом BigInteger next(), который возвращает элементы последовательности: [1, 2, 4, 8, 16, ...].

class PowerOfTwo {
private AtomicReference<BigInteger> current = new AtomicReference<>(null);

BigInteger next() {
BigInteger recent, next;
do {
recent = current.get();
next = (recent == null) ? BigInteger.valueOf(1) : recent.shiftLeft(1);
} while (!current.compareAndSet(recent, next));
return next;
}
}
--------------------------------------------------------------------------------------------------------------------
Напишите простейший многопоточный ограниченный буфер с использованием synchronized.

class QueueSynchronized<T> {
private volatile int size = 0;
private final Object[] content;
private final int capacity;
private int out;
private int in;
private final Object isEmpty = new Object();
private final Object isFull = new Object();
QueueSynchronized(final int capacity) {
this.capacity = capacity;
content = new Object[this.capacity];
out = 0;
in = 0;
size = 0;
}
private int cycleInc(int index) {
return (++index == capacity)
? 0
: index;
}
@SuppressWarnings("unchecked")
T get() throws InterruptedException {
if (size == 0) {
synchronized (isEmpty) {
while (size < 1) {
isEmpty.wait();
}
}
}
try {
synchronized (this) {
final Object value = content[out];
content[out] = null;
if (size > 1) {
out = cycleInc(out);
}
size--;
return (T) value;
}
} finally {
synchronized (isFull) {
isFull.notify();
}
}
}
QueueSynchronized<T> put(T value) throws InterruptedException {
if (size == capacity) {
synchronized (isFull) {
while (size == capacity) {
isFull.wait();
}
}
}
synchronized (this) {
if (size == 0) {
content[in] = value;
} else {
in = cycleInc(in);
content[in] = value;
}
size++;
}
synchronized (isEmpty) {
isEmpty.notify();
}
return this;
}
}
--------------------------------------------------------------------------------------------------------------------
Напишите простейший многопоточный ограниченный буфер с использованием ReentrantLock.

class QueueReentrantLock<T> {
private volatile int size = 0;
private final Object[] content;
private final int capacity;
private int out;
private int in;
private final ReentrantLock lock = new ReentrantLock();
private final Condition isEmpty = lock.newCondition();
private final Condition isFull = lock.newCondition();
QueueReentrantLock(int capacity) {
try {
lock.lock();
this.capacity = capacity;
content = new Object[capacity];
out = 0;
in = 0;
} finally {
lock.unlock();
}
}
private int cycleInc(int index) {
return (++index == capacity)
? 0
: index;
}
@SuppressWarnings("unchecked")
T get() throws InterruptedException {
try {
lock.lockInterruptibly();
if (size == 0) {
while (size < 1) {
isEmpty.await();
}
}
final Object value = content[out];
content[out] = null;
if (size > 1) {
out = cycleInc(out);
}
size--;
isFull.signal();
return (T) value;
} finally {
lock.unlock();
}
}
QueueReentrantLock<T> put(T value) throws InterruptedException {
try {
lock.lockInterruptibly();
if (size == capacity) {
while (size == capacity) {
isFull.await();
}
}
if (size == 0) {
content[in] = value;
} else {
in = cycleInc(in);
content[in] = value;
}
size++;
isEmpty.signal();
} finally {
lock.unlock();
}
return this;
}
}
--------------------------------------------------------------------------------------------------------------------
